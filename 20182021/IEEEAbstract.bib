@INPROCEEDINGS{8786031,
author={Amin-Naji, Mostafa and Mahdavinataj, Hami and Aghagolzadeh, Ali},
booktitle={2019 4th International Conference on Pattern Recognition and Image Analysis (IPRIA)}, title={Alzheimer's disease diagnosis from structural MRI using Siamese convolutional neural network},
year={2019},
volume={},
number={},
pages={75-79},
abstract={Deep learning (DL) methods have been recently utilized in medical imaging diagnosis and prognosis, which have significantly improved the performance of algorithms. As Alzheimer's Disease (AD) is one of the most financial costly diseases, many researchers have concentrated on introducing a high accuracy automated algorithm for classifying the AD and the Normal Control (NC) cases. In this paper we proposed a new deep learning based automated method for Alzheimer's disease diagnosis. Among the DL networks, the Siamese Convolutional Neural Network (SCNN) is implemented with three branches of ResNet-34 to discriminate between the AD and NC from the Structural Magnetic Resonance Imaging (sMRI). We selected 235 subjects from OASIS dataset. The proposed method achieved the accuracy of 98.72%. The proposed method has the best performance compared with the previous state of the art methods.},
keywords={Alzheimer's disease;Convolutional neural networks;Training;Magnetic resonance imaging;Medical diagnosis;Alzheimer's Disease;Deep Learning;Siamese Convolutional Neural Network;Structural MRI},
doi={10.1109/PRIA.2019.8786031},
ISSN={2049-3630},
month={March},}
@INPROCEEDINGS{8529808,
author={Ullah, H. M. Tarek and Onik, ZishanAhmed and Islam, Riashat and Nandi, Dip},
booktitle={2018 3rd International Conference for Convergence in Technology (I2CT)}, title={Alzheimer's Disease and Dementia Detection from 3D Brain MRI Data Using Deep Convolutional Neural Networks},
year={2018},
volume={},
number={},
pages={1-3},
abstract={As reported by the the Alzheimer's Association, there are more than 5 million Americans living with Alzheimer's today, with an anticipated 16 million by 2050. The neurodegenerative disease is currently the 6th leading source of death in the US. In 2017 this disease would cost the nation $1.1 trillion. 1 in 3 seniors die in Alzheimer's disease or another dementia. It kills more than breast cancer and prostate cancer combined. [14] As of the this papers writing, detecting Alzheimer's is a difficult and time consuming task, but requires brain imaging report and human expertise. Needless to say, this conventional approach to detect Alzheimer's is costly and often error prone. In this paper an alternative approach has been discussed, that is fast, costs less and more reliable. Deep Learning represents the true bleeding edge of Machine Intelligence. Convolutional Neural Networks are biologically inspired Multilayer perceptron specially capable of image processing. In this paper we present a state of the art Deep Convolutional Neural Network to detect Alzheimer's Disease and Dementia from 3D MRI image.},
keywords={Alzheimer's disease;Magnetic resonance imaging;Three-dimensional displays;Biological neural networks;Neural Networks;Deep Learning;3D Brain MRI;Alzheimer's Disease And Dementia;Machine Learning;Big Data;High Dimensional Input},
doi={10.1109/I2CT.2018.8529808},
ISSN={},
month={April},}
@INPROCEEDINGS{8824320,
author={Martínez-Murcia, F. J. and Górriz, J. M. and Ramírez, J. and Castillo-Barnes, D. and Segovia, F. and Salas-González, D. and Ortiz, A.},
booktitle={2018 IEEE Nuclear Science Symposium and Medical Imaging Conference Proceedings (NSS/MIC)}, title={A Deep Decomposition of MRI to Explore Neurodegeneration in Alzheimer’s Disease},
year={2018},
volume={},
number={},
pages={1-3},
abstract={Deep learning has revolutionized data analysis and particularly medical imaging, providing unprecedented insight to non-linear features. Image decomposition techniques such as Principal Component Analysis have been used for a long time, evolving towards complex non-linear decomposition algorithms. Convolutional networks, and particularly convolutional autoen-coders are known for providing high-level abstract features that describe the internal distribution of data in high-dimensional manifolds. In this work, we aim at gaining a deeper understanding the progression of the disease by predicting neuropsycho-logical test outcomes based solely on MRI data. In order to do so, we perform a self-supervised decomposition of the MRI data using a deep convolutional autoencoder. The distribution of features in the z-layer is then used within a neural network based regression, in order to test whether these imaging-derived biomarkers are related to several neuropsychological tests. The prediction of neuropsychological test outcomes achieved R2 rates up to more than 0.3, with correlations higher than 0.5 in the case of variables heavily linked to neurogedeneration and cognitive state such as the MMSE or the ADAS11 scores.},
keywords={Alzheimer's disease;Biomedical imaging;Magnetic resonance imaging;Convolutional neural networks;Convolutional codes;Correlation;Magnetic Resonance Imaging;Alzheimer’s Disease;Subspace Analysis;Convolutional Neural Networks;Deep Neural Networks;Regression Analysis},
doi={10.1109/NSSMIC.2018.8824320},
ISSN={2577-0829},
month={Nov},}
@INPROCEEDINGS{8759397,
author={Li, Hongming and Fan, Yong},
booktitle={2019 IEEE 16th International Symposium on Biomedical Imaging (ISBI 2019)}, title={Early Prediction Of Alzheimer’s Disease Dementia Based On Baseline Hippocampal MRI and 1-Year Follow-Up Cognitive Measures Using Deep Recurrent Neural Networks},
year={2019},
volume={},
number={},
pages={368-371},
abstract={Multi-modal biological, imaging, and neuropsychological markers have demonstrated promising performance for distinguishing Alzheimer's disease (AD) patients from cognitively normal elders. However, it remains difficult to early predict when and which mild cognitive impairment (MCI) individuals will convert to AD dementia. Informed by pattern classification studies which have demonstrated that pattern classifiers built on longitudinal data could achieve better classification performance than those built on cross-sectional data, we develop a deep learning model based on recurrent neural networks (RNNs) to learn informative representation and temporal dynamics of longitudinal cognitive measures of individual subjects and combine them with baseline hippocampal MRI for building a prognostic model of AD dementia progression. Experimental results on a large cohort of MCI subjects have demonstrated that the deep learning model could learn informative measures from longitudinal data for characterizing the progression of MCI subjects to AD dementia, and the prognostic model could early predict AD progression with high accuracy.},
keywords={Predictive models;Data models;Magnetic resonance imaging;Alzheimer's disease;Prognosis;recurrent neural networks;longitudinal data;Alzheimer’s disease},
doi={10.1109/ISBI.2019.8759397},
ISSN={1945-8452},
month={April},}
@INPROCEEDINGS{8884939,
author={Jabason, Emimal and Ahmad, M. Omair and Swamy, M.N.S.},
booktitle={2019 IEEE 62nd International Midwest Symposium on Circuits and Systems (MWSCAS)}, title={Classification of Alzheimer’s Disease from MRI Data Using an Ensemble of Hybrid Deep Convolutional Neural Networks},
year={2019},
volume={},
number={},
pages={481-484},
abstract={Although there is no cure for Alzheimer's disease (AD), an accurate early diagnosis is extremely important for both the patient and social care, and it will become even more significant once disease-modifying agents are available to prevent, cure, or even slow down the progression of the disease. In recent years, classification of AD through deep learning techniques has been one of the most active research areas in the medical field. However, most of the existing techniques cannot leverage the entire spatial information; hence, they lose the inter-slice correlation. In this paper, we propose a novel classification algorithm to discriminate patients having AD, mild cognitive impairment (MCI), and cognitively normal (CN) using an ensemble of hybrid deep learning architectures to leverage a more complete spatial information from the MRI data. The experimental results obtained by applying the proposed algorithm on the OASIS dataset show that the performance of the proposed classification framework to be superior to that of the some conventional methods.},
keywords={Magnetic resonance imaging;Feature extraction;Training;Alzheimer's disease;Deep learning;Alzheimer’s Disease;MRI Data;Deep Convolutional Neural Networks;Classification},
doi={10.1109/MWSCAS.2019.8884939},
ISSN={1558-3899},
month={Aug},}
@ARTICLE{8585141,
author={Lian, Chunfeng and Liu, Mingxia and Zhang, Jun and Shen, Dinggang},
journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, title={Hierarchical Fully Convolutional Network for Joint Atrophy Localization and Alzheimer's Disease Diagnosis Using Structural MRI},
year={2020},
volume={42},
number={4},
pages={880-893},
abstract={Structural magnetic resonance imaging (sMRI) has been widely used for computer-aided diagnosis of neurodegenerative disorders, e.g., Alzheimer's disease (AD), due to its sensitivity to morphological changes caused by brain atrophy. Recently, a few deep learning methods (e.g., convolutional neural networks, CNNs) have been proposed to learn task-oriented features from sMRI for AD diagnosis, and achieved superior performance than the conventional learning-based methods using hand-crafted features. However, these existing CNN-based methods still require the pre-determination of informative locations in sMRI. That is, the stage of discriminative atrophy localization is isolated to the latter stages of feature extraction and classifier construction. In this paper, we propose a hierarchical fully convolutional network (H-FCN) to automatically identify discriminative local patches and regions in the whole brain sMRI, upon which multi-scale feature representations are then jointly learned and fused to construct hierarchical classification models for AD diagnosis. Our proposed H-FCN method was evaluated on a large cohort of subjects from two independent datasets (i.e., ADNI-1 and ADNI-2), demonstrating good performance on joint discriminative atrophy localization and brain disease diagnosis.},
keywords={Feature extraction;Solid modeling;Atrophy;Brain modeling;Alzheimer's disease;Medical diagnosis;Support vector machines;Computer-aided alzheimer's disease diagnosis;fully convolutional networks;discriminative atrophy localization;weakly-supervised learning;structural MRI},
doi={10.1109/TPAMI.2018.2889096},
ISSN={1939-3539},
month={April},}
@INPROCEEDINGS{8845325,
author={Manzak, Dilek and Çetinel, Gökçen and Manzak, Ali},
booktitle={2019 14th International Conference on Computer Science Education (ICCSE)}, title={Automated Classification of Alzheimer’s Disease using Deep Neural Network (DNN) by Random Forest Feature Elimination},
year={2019},
volume={},
number={},
pages={1050-1053},
abstract={Determining Alzheimer's Disease (AD) in its early stages is very important to prepare proper care for the patient. In this study, we aimed to create fast and accurate automated classification system to determine AD with the minimum data collected from the patient. Magnetic Resonance Imaging (MRI) is widely used to diagnose AD. When the cost of the technique and risks of the procedures are considered, there is a need for different solutions. With the availability of neural network chips, it is even possible to build portable devices for Alzheimer's detection. We propose fast and successful method to detect Alzheimer using Deep Neural Network (DNN). To reduce the complexity of the algorithm, Random Forest method was used to eliminate some of the features. Success of Random Forest to eliminate the features and success of DNN to detect AD are discussed.},
keywords={Biological neural networks;Alzheimer's disease;Magnetic resonance imaging;Feature extraction;Alzheimer’s Disease;Deep Neural Network;Feature Selection;Random Forest},
doi={10.1109/ICCSE.2019.8845325},
ISSN={2473-9464},
month={Aug},}
@INPROCEEDINGS{8585550,
author={Jabason, Emimal and Ahmad, M. Omair and Swamy, M. N. S},
booktitle={2018 16th IEEE International New Circuits and Systems Conference (NEWCAS)}, title={Shearlet based Stacked Convolutional Network for Multiclass Diagnosis of Alzheimer’s Disease using the Florbetapir PET Amyloid Imaging Data},
year={2018},
volume={},
number={},
pages={344-347},
abstract={Although there is no cure for Alzheimer's disease (AD), an accurate early diagnosis is essential for health and social care, and will be of great significance when the course of the disease could be reversed through treatment options. Florbetapir positron emission tomography (18F-AV-45 PET) is proven to be the most powerful imaging technique to investigate the deposition of amyloid plaques, one of the potential hallmarks of AD, signifying the onset of AD before it changes the brains structure. In this paper, we propose a novel classification algorithm to discriminate the patients having AD, early mild cognitive impairment (MCI), late MCI, and normal control in 18F-AV-45 PET using shearlet based deep convolutional neural network (CNN). It is known that the conventional CNNs involve convolution and pooling layers, which in fact produce the smoothed representation of data, and this results in losing detailed information. In view of this fact, the conventional CNN is integrated with shearlet transform incorporating the multiresolution details of the data. Once the model is pretrained to transform the input data into a better stacked representation, the resulting final layer is passed to softmax classifier, which returns the probabilities of each class. Through experimental results, it is shown that the performance of the proposed classification framework is superior to that of the traditional CNN in Alzheimer's disease neuroimaging initiative (ADNI) database in terms of classification accuracy. As a result, it has the potential to distinguish the different stages of AD progression with less clinical prior information.},
keywords={Positron emission tomography;Feature extraction;Alzheimer's disease;Transforms;Databases;Alzheimer’s disease (AD);Florbetapir positron emission tomography (¹⁸F-AV-45 PET) amyloid imaging;Shearlet transform (ST);Convolutional neural network (CNN);Softmax;Deep learning},
doi={10.1109/NEWCAS.2018.8585550},
ISSN={},
month={June},}
@ARTICLE{9354805,
author={Basher, Abol and Kim, Byeong C. and Lee, Kun Ho and Jung, Ho Yub},
journal={IEEE Access}, title={Volumetric Feature-Based Alzheimer’s Disease Diagnosis From sMRI Data Using a Convolutional Neural Network and a Deep Neural Network},
year={2021},
volume={9},
number={},
pages={29870-29882},
abstract={Alzheimer's disease (AD) is a progressive neurodegenerative disorder that is mostly prevalent in people older than 65 years. The hippocampus is a widely studied region of interest (ROI) for a number of reasons, such as memory function analysis, stress development observation and neurological disorder investigation. Moreover, hippocampal volume atrophy is known to be linked with Alzheimer's disease. On the other hand, several biomarkers, such as amyloid beta (aß42) protein, tau, phosphorylated tau and hippocampal volume atrophy, are being used to diagnose AD. In this research work, we have proposed a method to diagnose AD based on slice-wise volumetric features extracted from the left and right hippocampi of structural magnetic resonance imaging (sMRI) data. The proposed method is an aggregation of a convolutional neural network (CNN) model with a deep neural network (DNN) model. The left and right hippocampi have been localized automatically using a two-stage ensemble Hough-CNN. The localized hippocampal positions are used to extract (80 × 80x80 voxels) 3-D patches. The 2-D slices are then separated from the 3-D patches along axial, sagittal, and coronal views. The pre-processed 2-D patches are used to extract volumetric features from each slice by using a discrete volume estimation convolutional neural network (DVE-CNN) model. The extracted volumetric features have been used to train and test the classification network. The proposed approach has achieved average weighted classification accuracies of 94.82% and 94.02% based on the extracted volumetric features attributed to the left and right hippocampi, respectively. In addition, it has achieved area under the curve (AUC) values of 92.54% and 90.62% for the left and right hippocampi, respectively. Our method has outperformed the other methods by a certain margin in the same dataset.},
keywords={Feature extraction;Diseases;Alzheimer's disease;Biomarkers;Hippocampus;Brain modeling;Atrophy;Hippocampus;volumetric features;2-D/3-D patches;hough-CNN;CNN;DNN;MRI;Alzheimer’s disease;classification;knowledge transfer},
doi={10.1109/ACCESS.2021.3059658},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{8609974,
author={Khagi, Bijen and Lee, Chung Ghiu and Kwon, Goo-Rak},
booktitle={2018 11th Biomedical Engineering International Conference (BMEiCON)}, title={Alzheimer’s disease Classification from Brain MRI based on transfer learning from CNN},
year={2018},
volume={},
number={},
pages={1-4},
abstract={Various Convolutional Neural Network (CNN) architecture has been proposed for image classification and Object recognition. For the image based classification, it is a complex task for CNN to deal with hundreds of MRI Image slices, each of almost identical nature in a single patient. So, classifying a number of patients as an AD, MCI or NC based on 3D MRI becomes vague technique using 2D CNN architecture. Hence, to address this issue, we have simplified the idea of classifying patients on basis of 3D MRI but acknowledging the 2D features generated from the CNN framework. We present our idea regarding how to obtain 2D features from MRI and transform it to be applicable to classify using machine learning algorithm. Our experiment shows the result of classifying 3 class subjects patients. We employed scratched trained CNN or pretrained Alexnet CNN as generic feature extractor of 2D image which dimensions were reduced using PCA+TSNE, and finally classifying using simple Machine learning algorithm like KNN, Navies Bayes Classifier. Although the result is not so impressive but it definitely shows that this can be better than scratch trained CNN softmax classification based on probability score. The generated feature can be well manipulated and refined for better accuracy, sensitivity, and specificity.},
keywords={Magnetic resonance imaging;Feature extraction;Alzheimer's disease;Training;Convolutional neural networks;Biomedical imaging;CNN;MRI;generic feature;PCA;TSNE;Classifier},
doi={10.1109/BMEiCON.2018.8609974},
ISSN={2334-3052},
month={Nov},}
@INPROCEEDINGS{8512372,
author={Wang, Yan and Yang, Yanwu and Guo, Xin and Ye, Chenfei and Gao, Na and Fang, Yuan and Ma, Heather T.},
booktitle={2018 40th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)}, title={A Novel Multimodal MRI Analysis for Alzheimer's Disease Based on Convolutional Neural Network},
year={2018},
volume={},
number={},
pages={754-757},
abstract={Recent years, Alzheimer's disease (AD) has become a significant threat to human health while the accurate screening and diagnosis of AD remain a tough problem. Multimodal Magnetic resonance imaging (MRI) can help to identify the variation of brain function and structure in a non-invasive way. Deep learning, especially the convolutional neural networks (CNN), can be utilized to automatically detect appropriate features for classification, which is well adapted for computer-aided AD screening and identification. This paper proposed a multimodal MRI analytical method based on CNN, which is also suitable for single type MRI data analysis. First, the human brain network connectivity matrix were extracted from multimodal MRI data, used as the input data for CNN. Then a novel CNN framework was proposed to process the network matrix and classify AD, amnestic mild cognitive impairment (aMCI) patients and normal controls (NC). The advantage of this method lies in that we combined multimodal MRI information through CNN convolution kernel, and achieved a higher classification accuracy. In our experiments, the comprehensive classification accuracy of AD, aMCI patients and NC was as high as 92.06% when using multimodal MRI data as input, which is effective enough to provide a reference for multimodal MRI data analysis.},
keywords={Functional magnetic resonance imaging;Diffusion tensor imaging;Convolution;Dementia},
doi={10.1109/EMBC.2018.8512372},
ISSN={1558-4615},
month={July},}
@ARTICLE{8883215,
author={Sarraf, Saman and Desouza, Danielle D. and Anderson, John A. E. and Saverino, Cristina},
journal={IEEE Access}, title={MCADNNet: Recognizing Stages of Cognitive Impairment Through Efficient Convolutional fMRI and MRI Neural Network Topology Models},
year={2019},
volume={7},
number={},
pages={155584-155600},
abstract={Mild cognitive impairment (MCI) represents the intermediate stage between normal cerebral aging and dementia associated with Alzheimer's disease (AD). Early diagnosis of MCI and AD through artificial intelligence has captured considerable scholarly interest; researchers hope to develop therapies capable of slowing or halting these processes. We developed a state-of-the-art deep learning algorithm based on an optimized convolutional neural network (CNN) topology called MCADNNet that simultaneously recognizes MCI, AD, and normally aging brains in adults over the age of 75 years, using structural and functional magnetic resonance imaging (fMRI) data. Following highly detailed preprocessing, four-dimensional (4D) fMRI and 3D MRI were decomposed to create 2D images using a lossless transformation, which enables maximum preservation of data details. The samples were shuffled and subject-level training and testing datasets were completely independent. The optimized MCADNNet was trained and extracted invariant and hierarchical features through convolutional layers followed by multi-classification in the last layer using a softmax layer. A decision-making algorithm was also designed to stabilize the outcome of the trained models. To measure the performance of classification, the accuracy rates for various pipelines were calculated before and after applying the decision-making algorithm. Accuracy rates of 99.77% ± 0.36% and 97.5% ± 1.16% were achieved for MRI and fMRI pipelines, respectively, after applying the decision-making algorithm. In conclusion, a cutting-edge and optimized topology called MCADNNet was designed and preceded a preprocessing pipeline; this was followed by a decision-making step that yielded the highest performance achieved for simultaneous classification of the three cohorts examined.},
keywords={Magnetic resonance imaging;Feature extraction;Alzheimer's disease;Computer architecture;Deep learning;Deep learning;classification;structural and functional magnetic resonance imaging;brain;Alzheimer’s disease;MCI},
doi={10.1109/ACCESS.2019.2949577},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{8784845,
author={Ebrahimi-Ghahnavieh, Amir and Luo, Suhuai and Chiong, Raymond},
booktitle={2019 IEEE International Conference on Industry 4.0, Artificial Intelligence, and Communications Technology (IAICT)}, title={Transfer Learning for Alzheimer's Disease Detection on MRI Images},
year={2019},
volume={},
number={},
pages={133-138},
abstract={In this paper, we focus on Alzheimer's disease detection on Magnetic Resonance Imaging (MRI) scans using deep learning techniques. The lack of sufficient data for training a deep model is a major challenge along this line of research. From our literature review, we realised that one of the current trends is using transfer learning for 2D convolutional neural networks to classify subjects with Alzheimer's disease. In this way, each 3D MRI volume is divided into 2D image slices and a pre-trained 2D convolutional neural network can be re-trained to classify image slices independently. One issue here, however, is that the 2D convolutional neural network would not be able to consider the relationship between 2D image slices in an MRI volume and make decisions on them independently. To address this issue, we propose to use a recurrent neural network after a convolutional neural network to understand the relationship between sequences of images for each subject and make a decision based on all input slices instead of each of the slices. Our results show that training the recurrent neural network on features extracted from a convolutional neural network can improve the accuracy of the whole system.},
keywords={Magnetic resonance imaging;Two dimensional displays;Deep learning;Diseases;Training;Neuroimaging;Convolutional neural networks;deep learning;transfer learning;Alzheimer’s disease;convolutional neural networks;recurrent neural networks},
doi={10.1109/ICIAICT.2019.8784845},
ISSN={},
month={July},}
@INPROCEEDINGS{9352897,
author={Kavitha, D and Murugan, A and Sathiyanarayanan, Mithileysh},
booktitle={2021 International Conference on COMmunication Systems NETworkS (COMSNETS)}, title={Deep Analysis of Dementia Disorder Using Artificial Intelligence to Improve Healthcare Services},
year={2021},
volume={},
number={},
pages={378-380},
abstract={Dementia is a worldwide concern and early discovery of dementia is substantial for the administration of mental illness and healthy living. The data acquired from Magnetic resonance imaging (MRI), Positron Emission Tomography (PET) and Computed Tomography (CT) are used in identifying dementia. Albeit numerous non-AI and AI techniques have been implemented to understand the reasons behind dementia there is very little success to predict at an early stage. Considering the self-determination medicine, a new healthcare model that could be delivered by 5G, there is a pressing need to diagnose dementia patients in early stages using deep learning techniques and that can constantly improve assessment and diagnostic tools for distinguishing people with normal brain aging from those who will develop mild cognitive impairment. We will conduct state-of-the-art research to identify various deep learning algorithms and approaches that can be used for the diagnosis of dementia and aid in predicting at an early stage. We will develop and evaluate an intelligent algorithm that will predict and distinguish people with normal brain aging from those with mild cognitive impairment on a constant basis, which will be a good fit to the future healthcare model that will be delivered by 5G.},
keywords={Deep learning;Magnetic resonance imaging;Computed tomography;Medical services;Prediction algorithms;Positron emission tomography;Dementia;Dementia;Alzheimer’s disease (AD);Magnetic resonance Imaging (MRI);Positron emission tomography (PET);deep learning;machine learning;artificial intelligence},
doi={10.1109/COMSNETS51098.2021.9352897},
ISSN={2155-2509},
month={Jan},}
@INPROCEEDINGS{9166286,
author={Tufail, Ahsan Bin and Ma, Yongkui and Zhang, Qiu-Na},
booktitle={2020 8th International Conference on Information and Communication Technology (ICoICT)}, title={Classification of subjects of Mild Cognitive Impairment and Alzheimer’s Disease through Neuroimaging modalities and Convolutional Neural Networks},
year={2020},
volume={},
number={},
pages={1-6},
abstract={Alzheimer's Disease (AD) is an irreversible neurodegenerative disorder that is affecting the elderly population worldwide. The staggering costs associated with this disease merits further research in the diagnosis and prognosis of this disease. Magnetic Resonance Imaging (MRI) and Positron Emission Tomography (PET) are widely used modalities to capture the structural changes in the brain caused by AD in its early stages. Early diagnosis of AD is important from clinical perspective to improve the life of an individual who is at the risk of developing memory deficits. Deep learning architectures such as 2D and 3D Convolutional Neural Networks (CNNs) have shown promising performances in extracting features and building useful representations of data for computer vision tasks. This study is geared towards understanding the performance differences between these architectures. We used transfer and non-transfer learning approaches to study the underlying disease phenomenon. In our experiments on binary classification of early stages of AD, we found the performance of 3D architectures to be better in comparison to their 2D counterparts. For instance, the 3D-CNN architecture which is trained on PET modality data achieved an accuracy of 71.728%, specificity of 73.196%, and sensitivity of 70.213% on the AD class while its 2D-CNN counterpart achieved an accuracy of 56.901%, specificity of 59.764%, and sensitivity of 53.947% on the same class. Further, we found the performance of 3D architecture trained on PET neuroimaging modality data to be the best in terms of performance metrics which shows superior diagnostic power of this type of architecture.},
keywords={Three-dimensional displays;Magnetic resonance imaging;Training;Convolution;Neurons;Feature extraction;Neuroimaging;Convolutional Neural Networks;Binary Classification;Mild Cognitive Impairment;Alzheimer’s Disease;Magnetic Resonance Imaging;Positron Emission Tomography},
doi={10.1109/ICoICT49345.2020.9166286},
ISSN={},
month={June},}
@INPROCEEDINGS{8759256,
author={Zhao, Xin and Zhou, Feng and Ou-Yang, Le and Wang, Tianfu and Lei, Baiying},
booktitle={2019 IEEE 16th International Symposium on Biomedical Imaging (ISBI 2019)}, title={Graph Convolutional Network Analysis for Mild Cognitive Impairment Prediction},
year={2019},
volume={},
number={},
pages={1598-1601},
abstract={Mild cognitive impairment (MCI) is an early stage of Alzheimer's disease (AD), which is a neurodegenerative disease. Functional connectivity networks (FCN) provide an effective method for analyzing brain functional regions connectivity. However, most methods only considered the neuroimaging information and focused on group relationship without the subjects' individual features, and ignored the demographic relationship. To handle it, in this paper, we introduce a novel method based on graph convolutional networks (GCN), which combines image and other information for MCI prediction tasks. The proposed model is capable of representing the individual features and data associations among subjects from potentially populations simultaneously. Specifically, we use different collection devices and gender information to build a graph called MCI-graph and modify convolutional neural networks (CNN) to construct GCN for MCI prediction. The experimental results demonstrate that our proposed method has achieved remarkable prediction performance.},
keywords={Convolution;Feature extraction;Diseases;Imaging;Kernel;Deep learning;Chebyshev approximation;Mild cognitive impairment;Functional connectivity network;Graph convolutional network;MCI-graph},
doi={10.1109/ISBI.2019.8759256},
ISSN={1945-8452},
month={April},}
@INPROCEEDINGS{9339504,
author={Suresha, Halebeedu Subbaraya and Parthasarathy, Srirangapatna Sampathkumaran},
booktitle={2020 Third International Conference on Advances in Electronics, Computers and Communications (ICAECC)}, title={Alzheimer Disease Detection Based on Deep Neural Network with Rectified Adam Optimization Technique using MRI Analysis},
year={2020},
volume={},
number={},
pages={1-6},
abstract={Alzheimer is a memory depletion disease, which is widely recognized as dementia. The research on early detection of dementia has received huge interest among the researchers to help in reducing mortality rates of Alzheimer's patients. In recent years in the medical field, the deep learning techniques play an important role in computer aided diagnosis. In this research, the automatic recognition of Alzheimer Disease (AD) based on the Magnetic Resonance Imaging (MRI) is accomplished by implementing an unsupervised classification technique named Deep Neural Network (DNN) with the rectified Adam optimizer. At first, Histogram of Oriented Gradients (HOG) is utilized to extract the feature values from the brain images, which were acquired from National Institute of Mental Health and Neurosciences (NIMHANS) and Alzheimer disease Neuroimaging Initiative (ADNI) datasets. Next, the extracted features were given as the input to DNN with the rectified Adam optimizer to distinguish the healthy, AD and Mild Cognitive Impairment (MCI) patients. The experimental results have revealed that the HOG-DNN with the rectified Adam optimizer has achieved better performance in AD recognition and showed 16% enhancement in classification accuracy compared to other existing work; Landmark based features with support vector machine classifier.},
keywords={Support vector machines;Brain;Magnetic resonance imaging;Feature extraction;Alzheimer's disease;Biological neural networks;Optimization;Alzheimer Disease;Deep Neural Network with Rectified Adam Optimizer;Histogram of Oriented Gradients;Image Normalization},
doi={10.1109/ICAECC50550.2020.9339504},
ISSN={2642-6595},
month={Dec},}
@INPROCEEDINGS{8824317,
author={Sahumbaiev, I. and Popov, A. and Ramírez, J. and Górriz, J. M. and Ortiz, A.},
booktitle={2018 IEEE Nuclear Science Symposium and Medical Imaging Conference Proceedings (NSS/MIC)}, title={3D-CNN HadNet classification of MRI for Alzheimer’s Disease diagnosis},
year={2018},
volume={},
number={},
pages={1-4},
abstract={The human brain consists of billions of neurons and their loss caused by neurodegenerative disorder dramatically affects cognitive brain functions. Such a state is known as Alzheimer's disease (AD). At this moment, AD remains without a decent cure, and its diagnosis mostly depends on the experience of clinicians; therefore, early diagnostics is critical because AD is progressive and at the beginning, its' development can be slowed down. In this paper, we use a deep learning advances to developed a classification system based on a 3D convolutional neural network for analyzing Magnetic Resonance Imaging (MRI) data collected for healthy individuals, patients with mild cognitive impairment (MCI) and with AD. The dataset of MR images was collected from Alzheimer's Disease Neuroimaging Initiative (ADNI); spatially normalized with statistical parametric mapping (SPM) toolbox and the skull-stripped for better 3D-CNN (HadNet) training. The backbone of the HadNet architecture is to use stacked convolutions (inception approach) which allows accessing more internal features of the MR image related to the AD. The hyperparameters of the HadNet were fine-tuned through the Bayesian optimization process. The developed classifier does not use segmented brain regions and can automatically process the whole MR image and based on learned features, during training, detect to which class input belongs. In our work, we select three classes: Healthy, MCI and AD; the final 3D-CNN architecture consists of three inception blocks. The HadNet was end-to-end trained using MR brain scans of 530 subjects including 185 AD patients, 185 MCI patients and 160 healthy individuals (HC). Evaluation results show that the trained classifier can distinguish between AD, MCI and HC with accuracy of 88.31% what is a promising classification results.},
keywords={Diseases;Feature extraction;Three-dimensional displays;Training;Optimization;Magnetic resonance imaging;Bayes methods},
doi={10.1109/NSSMIC.2018.8824317},
ISSN={2577-0829},
month={Nov},}
@INPROCEEDINGS{9183323,
author={Yagis, Ekin and Citi, Luca and Diciotti, Stefano and Marzi, Chiara and Workalemahu Atnafu, Selamawet and G. Seco De Herrera, Alba},
booktitle={2020 IEEE 33rd International Symposium on Computer-Based Medical Systems (CBMS)}, title={3D Convolutional Neural Networks for Diagnosis of Alzheimer's Disease via Structural MRI},
year={2020},
volume={},
number={},
pages={65-70},
abstract={Alzheimer's Disease (AD) is a widespread neurodegenerative disease caused by structural changes in the brain and leads to deterioration of cognitive functions. Patients usually experience diagnostic symptoms at later stages after irreversible neural damage occurs. Therefore, early detection of AD is crucial to start treatments to decelerate the progress of the disease and to maximize patients' quality of life. With the rapid advances in machine learning and scanning, early detection of AD may be possible via computer-assisted systems using neuroimaging data. Among all, deep learning utilizing magnetic resonance imaging (MRI) has become a prominent tool due to its capability to extract high-level features through local connectivity, weight sharing, and spatial invariance. This paper describes our investigation of the classification accuracy based on two publicly available data sets, namely, ADNI and OASIS, by building a 3D VGG variant convolutional network (CNN). We used 3D models to avoid information loss, which occurs during the process of slicing 3D MRI into 2D images and analyzing them by 2D convolutional filters. We also conducted a pre-processing of the data to enhance the effectiveness and classification performance of the model. The proposed model achieved 73.4% classification accuracy on ADNI and 69.9% on OASIS dataset with 5-fold cross-validation (CV), outperforming 2D network models.},
keywords={Magnetic resonance imaging;Three-dimensional displays;Dementia;Two dimensional displays;Feature extraction;Data models;Alzheimer's Disease, Machine Learning, Deep Learning, Image Classification, 3D CNN, MRI, Neuroimaging},
doi={10.1109/CBMS49503.2020.00020},
ISSN={2372-9198},
month={July},}
@INPROCEEDINGS{9398800,
author={Ullanat, Varun and Balamurali, Vinay and Rao, Ananya},
booktitle={2020 IEEE-EMBS Conference on Biomedical Engineering and Sciences (IECBES)}, title={A Novel Residual 3-D Convolutional Network for Alzheimer's disease diagnosis based on raw MRI scans},
year={2021},
volume={},
number={},
pages={82-87},
abstract={One of the most widely used deep learning architectures for image classification, Convolutional Neural Networks (CNNs) are used in a diverse range of research areas. Over the past five years, CNNs have been extended for use in disease classification and diagnosis based on body imaging data. In this paper, we propose one such CNN model to diagnose Alzheimer's Disease using raw, volumetric Magnetic Resonance Imaging (MRI) scans. The MRI dataset used contains 857 scans (302 AD and 555 Normal Control) in total and was procured from the ADNI study. The performance of the proposed residual CNN was compared with 3-D ResNet-18 with and without an attention mechanism. Finally, 3-D Gradient-weighted Class Activation Mapping was used to evaluate how effective the models were in recognizing brain regions pertaining to AD. The best performing model obtained an accuracy of 91%.},
keywords={Solid modeling;Magnetic resonance imaging;Brain modeling;Convolutional neural networks;Alzheimer's disease;Standards;Diseases;Convolutional Neural Networks;Alzheimer's disease;Attention mechanism;Gradient-weighted Class Activation Mapping},
doi={10.1109/IECBES48179.2021.9398800},
ISSN={},
month={March},}
@INPROCEEDINGS{8965827,
author={Yu, Xinying and Peng, Bo and Shi, Jun and Zhu, Jianbin and Dai, Yakang},
booktitle={2019 12th International Congress on Image and Signal Processing, BioMedical Engineering and Informatics (CISP-BMEI)}, title={3D Convolutional Networks Based Automatic Diagnosis of Alzheimer's Disease Using Structural MRI},
year={2019},
volume={},
number={},
pages={1-6},
abstract={Early diagnosis of Alzheimer's disease (AD) can help take timely treatment before patients suffer from irreversible brain damage. However, current studies using manually feature extraction and 2D CNN methods cannot make the classification performance optimized. We proposed an approach using 3D convolutional neural network (CNN) to diagnose AD and mild cognitive impairment (MCI), which is the prodromal stage of AD, from structural magnetic resonance images. Subjects of 150 AD, 129 MCI, and 112 normal controls (NC) from the Alzheimer's Disease Neuroimaging Initiative dataset were used in this study. Specifically, weights of a 3-class network were trained to initialize the 2-class network and fine-tuned, which saves time and avoids overfitting. The experimental results show that our 3D-sVoxCNN model significantly improves the classification performance with the accuracy of 95.05% (AD vs MCI vs NC), 99.47% (AD vs. NC), 98.32% (MCI vs. NC), and 98.32% (AD vs. MCI).},
keywords={Three-dimensional displays;Convolution;Solid modeling;Diseases;Feature extraction;Magnetic resonance imaging;Biomedical imaging;Alzheimer's disease;Mild cognitive decline;Magnetic resonance imaging;Deep learning;3D convolutional neural networks},
doi={10.1109/CISP-BMEI48845.2019.8965827},
ISSN={},
month={Oct},}
@INPROCEEDINGS{8530910,
author={Mathew, Nimmy Ann and Vivek, R.S. and Anurenjan, P.R.},
booktitle={2018 International CET Conference on Control, Communication, and Computing (IC4)}, title={Early Diagnosis of Alzheimer's Disease from MRI Images Using PNN},
year={2018},
volume={},
number={},
pages={161-164},
abstract={Here we propose a new method for the diagnosis of Alzheimer's disease from MRI images. The most prevalent, reliable and result-oriented methods for diagnosis of Alzheimer's disease are: Firstly, measuring the rate of atrophy of the hippocampus and total brain volume; Secondly, extracting information from the gray matter, white matter and cerebro spinal fluid (CSF) of the brain. In this work, different statistical features such as contrast, homogeneity, correlation, energy and also shape features are extracted from the MRI images. For every image a number of features are extracted and these are fed to the classifier. The images are classified into any of the three classes: Alzheimer's Disease (AD), Mild Cognitive Impairment (MCI) or Normal Control (NC). The proposed approach compares the performances of Probabilistic Neural Network (PNN), Support Vector Machines(SVM) and K-Nearest Neighbour (KNN) in terms of their accuracy, specificity and sensitivity. The MRI images are obtained from the ADNI database. ADNI is a clinically validated database of MRI, PET and FMRI images of subjects.},
keywords={Feature extraction;Alzheimer's disease;Magnetic resonance imaging;Support vector machines;Probabilistic logic;Training;Gray Level Co-occurrence Matrix(GLCM);Support Vector Machines(SVM);Probabilistic Neural Net-works(PNN);K-Nearest Neighbour(KNN);Principal Component Analysis(PCA)},
doi={10.1109/CETIC4.2018.8530910},
ISSN={},
month={July},}
@INPROCEEDINGS{8477516,
author={Sahumbaiev, Ivan and Popov, Anton and Ivanushkina, Nataliia and Ramírez, Javier and Górriz, Juan Manuel},
booktitle={2018 IEEE 38th International Conference on Electronics and Nanotechnology (ELNANO)}, title={Florbetapir Image Analysis for Alzheimer's Disease Diagnosis},
year={2018},
volume={},
number={},
pages={277-280},
abstract={Over decades Alzheimer's disease (AD) remains without decent cure, and only disease-modifying methods are available. This paper is devoted to the analysis of amyloid-PET images with florbetapir (18F-AV-45) tracer to detect the presence of AD or Mild Cognitive Impairment (MCI). The first part of the article dedicated to image processing pipeline, specifically, spacial normalisation and feature extraction. The second part is devoted to the development of the multiclass classifier with deep learning methods. In particular, deep neural network was developed to distinguish three stages: health control (HC), MCI and AD. After tuning and training a neural network, the final specificity of 78% and sensitivity of 90% has been achieved.},
keywords={Dementia;Artificial neural networks;Feature extraction;Positron emission tomography;Magnetic resonance imaging;Machine learning;Alzheimer's disease;Amyloid Imaging;Florbetapir;Deep learning;PET imaging},
doi={10.1109/ELNANO.2018.8477516},
ISSN={},
month={April},}
@INPROCEEDINGS{8711088,
author={Angkoso, Cucun Very and Purnama, I Ketut Eddy and Purnomo, Mauridhi Hery},
booktitle={2018 International Conference on Computer Engineering, Network and Intelligent Multimedia (CENIM)}, title={Analysis of Brain Tissue and Cerebrospinal Fluid Feature for Alzheimer’s Disease Detection},
year={2018},
volume={},
number={},
pages={285-288},
abstract={Alzheimer's disease (AD) is a progressive neurodegenerative disorder which connected to the progression of declining in memory and thinking skills. A more accurate diagnosis and appropriate management are needed to determine correct treatments. Human brain imagery using Magnetic Resonance Imaging (MRI) has different kinds of brain tissue: Grey-Matter (GM) and White Matter (WM), and image of colorless body fluid which called Cerebrospinal Fluid (CSF). This article discusses the use of GM, WM and CSF imagery and the proportion values of the volume of each image in determining Alzheimer's identification. Our study is using 3different anatomical plane image acquisition of MRI and using feature extraction based on Kolmogorov-Smirnov distance. Supervised Neural Network Backpropagation was used for classifier machine. The results of testing on every combination of the different anatomical plane of MRI images we finally proposed that individual WM or GM analyses are a better compared to the scenario of combining between GM, WM, and CSF.},
keywords={Magnetic resonance imaging;Feature extraction;Alzheimer's disease;Image segmentation;Brain;Backpropagation;Alzheimer’s;grey matter;white matter;cerebrospinal fluid;Kolmogorov–Smirnov distance;neural network backpropagation},
doi={10.1109/CENIM.2018.8711088},
ISSN={},
month={Nov},}
@INPROCEEDINGS{9215402,
author={Salehi, Ahmad Waleed and Baglat, Preety and Sharma, Brij Bhushan and Gupta, Gaurav and Upadhya, Ankita},
booktitle={2020 International Conference on Smart Electronics and Communication (ICOSEC)}, title={A CNN Model: Earlier Diagnosis and Classification of Alzheimer Disease using MRI},
year={2020},
volume={},
number={},
pages={156-161},
abstract={Alzheimer 's Disease (AD) is the most common form of dementia that can lead to a neurological brain disorder that causes progressive memory loss as a result of damaging the brain cells and the ability to perform daily activities. Using MRI (Magnetic Resonance Imaging) scan brain images, we can get the help of Artificial intelligence (AI) technology for detection and prediction of this disease and classify the AD patients whether they have or may not have this deadly disease in future. The main purpose of doing all this is to make the best prediction and detection tools for the help of radiologists, doctors, caregivers to save time, cost, and help the patient suffering from this disease. In recent years, the Deep Learning (DL) algorithms are very useful for the diagnosis of AD as DL algorithms work well with large datasets. In this paper, we have implemented Convolutional Neural Network (CNN) for the earlier diagnosis and classification of AD using MRI images, the ADNI 3 class of images with the total number of 1512 mild, 2633 normal and 2480 AD were used. A significant accuracy of 99% achieved in which the model performed well as we compared with many other related works. Furthermore, we also compared the result with our previous work on which ma-chine learning algorithms were applied using OASIS dataset and it showed that when dealing with large amount of data like medical data the deep learning approaches can be a better option over the traditional machine learning techniques.},
keywords={Magnetic resonance imaging;Training;Machine learning;Alzheimer's disease;Classification algorithms;Alzheimer’s Disease;Deep Learning;Convolutional Neural Network;Magnetic Resonance Imaging;ADNI},
doi={10.1109/ICOSEC49089.2020.9215402},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{8575412,
author={Islam, Jyoti and Zhang, Yanqing},
booktitle={2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)}, title={Early Diagnosis of Alzheimer's Disease: A Neuroimaging Study with Deep Learning Architectures},
year={2018},
volume={},
number={},
pages={1962-19622},
abstract={Alzheimer's Disease is an incurable, progressive neurological brain disorder. Early diagnosis of Alzheimer's Disease can help with proper treatment and prevent brain tissue damage. Several statistical and machine learning models have been exploited by researchers for Alzheimer's Disease diagnosis. Detection of Alzheimer's Disease is exacting due to the similarity in Alzheimer's Disease Magnetic Resonance Imaging (MRI) data and standard healthy MRI data of older people. Recently, advanced deep learning techniques have successfully demonstrated human-level performance in numerous fields including medical image analysis. We propose a deep convolutional neural network for Alzheimer's Disease diagnosis using brain MRI data analysis. We have conducted ample experiments to demonstrate that our proposed model outperforms comparative baselines on the Open Access Series of Imaging Studies (OASIS) dataset.},
keywords={Alzheimer's disease;Magnetic resonance imaging;Brain modeling;Training;Medical diagnosis},
doi={10.1109/CVPRW.2018.00247},
ISSN={2160-7516},
month={June},}
@INPROCEEDINGS{8947800,
author={Kang, Hyeon and Kang, Do-Young and Park, Jang-Sik and Ha, Sung Wook},
booktitle={2018 International Conference on Computational Science and Computational Intelligence (CSCI)}, title={VGG19-Based Classification of Amyloid PET Image in Patients with MCI and AD},
year={2018},
volume={},
number={},
pages={1442-1443},
abstract={Amyloid brain positron emission tomography (PET) images are visually and subjectively analyzed by the physician with a lot of time and effort to determine the β-Amyloid (Aβ) deposition. We designed a convolutional neural network (CNN) model that predicts the Aβ-positive and Aβ-negative status. We performed 18F-florbetaben (FBB) brain PET on controls and patients (n =176) with mild cognitive impairment and Alzheimer's disease (AD). We classified brain PET images visually as per the on the brain amyloid plaque load score. We designed the visual geometry group (VGG16) model for the visual assessment of slice-based samples. To evaluate only the gray matter and not the white matter, gray matter masking (GMM) was applied to the slice-based standard samples. All the performance metrics were higher with GMM than without GMM (accuracy 92.39 vs. 89.60, sensitivity 87.93 vs. 85.76, and specificity 98.94 vs. 95.32). For the patient-based standard, all the performance metrics were almost the same (accuracy 89.78 vs. 89.21), lower (sensitivity 93.97 vs. 99.14), and higher (specificity 81.67 vs. 70.00). The area under the curve with the VGG16 model that observed the gray matter region only was slightly higher than the model that observed the whole brain for both slice-based and patient-based decision processes. Amyloid brain PET images can be appropriately analyzed using the CNN model for predicting the Aβ-positive and Aβ-negative status.},
keywords={Brain modeling;Grey matter;Standards;Positron emission tomography;Probability;Visualization;Sensitivity;Alzheimer's Disease;β-Amyloid;Convolutional Neural Network;18F-florbetaben PET;Gray Matter},
doi={10.1109/CSCI46756.2018.00281},
ISSN={},
month={Dec},}
@INPROCEEDINGS{9207167,
author={Ieracitano, Cosimo and Mammone, Nadia and Hussain, Amir and Morabito, Francesco Carlo},
booktitle={2020 International Joint Conference on Neural Networks (IJCNN)}, title={A Convolutional Neural Network based self-learning approach for classifying neurodegenerative states from EEG signals in dementia},
year={2020},
volume={},
number={},
pages={1-8},
abstract={In this paper, a novel deep learning based approach is proposed for the automatic classification of Electroencephalographic (EEG) signals of subjects diagnosed with the dementia of Alzheimer's disease (AD), Mild Cognitive Impairment (MCI) and Healthy Control (HC). Specifically, a custom Convolutional Neural Network (CNN) is designed to receive as input AD/MCI/HC EEG segments (epochs) of the same temporal width, and perform 2-way classification tasks: AD vs. HC, AD vs. MCI, MCI vs. HC. Our proposed architecture, termed EEG-CNN, is shown to exhibit remarkable abilities to self-learn relevant features directly from the EEG traces, avoiding the need for hand-crafted feature extraction engineering. Comparative experimental results demonstrate the promising performance of EEG-CNN, which is based on an analysis of the EEG time series only, reporting accuracies of 85.78 ± 2.18%, 69.03 ± 1.33%, 85.34 ± 1.86% in AD vs. HC, AD vs. MCI and MCI vs. HC classifications, respectively.},
keywords={Electroencephalography;Dementia;Feature extraction;Convolutional neural networks;Convolution;Medical diagnostic imaging;Deep Learning;Convolutional Neural Network;Self-learning;EEG signal;Alzheimer's disease;Mild Cognitive Impairment},
doi={10.1109/IJCNN48605.2020.9207167},
ISSN={2161-4407},
month={July},}
@INPROCEEDINGS{8964911,
author={Siar, Masoumeh and Teshnehlab, Mohammad},
booktitle={2019 9th International Conference on Computer and Knowledge Engineering (ICCKE)}, title={Age Detection from Brain MRI Images Using the Deep Learning},
year={2019},
volume={},
number={},
pages={369-374},
abstract={Estimating the age of the brains of individuals from brain images can be very useful in many applications. The brain's age has greatly contributed to predicting and preventing early deaths in the medical community. It can also be very useful for diagnosing diseases, such as Alzheimer's. According to the authors knowledge, this paper is one of the first researches that have been done in age detection by brain images using Deep Learning (DL). In this paper, the convolution neural network (CNN), used for age detection from brain magnetic resonance images (MRI). The images used in this paper are from the imaging centers and collected by the author of the paper. In this paper 1290 images have been collected, 941 images for train data and 349 images for test images. Images collected at the centers were labeled age. In this paper, the Alexnet model is used in CNN architecture. The used architecture of the architecture has 5 Convolutional layers and 3 Sub-sampling layers that the last layer has been used to categorize the image. The CNN that the last layer has been used to categorize the images into five age classes.The accuracy of the CNN is obtained by the Softmax classifier 79%, Support Vector Machine (SVM) classifier 75% and the Decision Tree (DT) classifier, 49%. In addition to the accuracy criterion, we use the benchmarks of Recall, Precision and F1-Score to evaluate network performance.},
keywords={Age detection;deep neural network;convolutional neural network;magnetic resonance imaging;feature extraction},
doi={10.1109/ICCKE48569.2019.8964911},
ISSN={2643-279X},
month={Oct},}
@ARTICLE{8765628,
author={Kam, Tae-Eui and Zhang, Han and Jiao, Zhicheng and Shen, Dinggang},
journal={IEEE Transactions on Medical Imaging}, title={Deep Learning of Static and Dynamic Brain Functional Networks for Early MCI Detection},
year={2020},
volume={39},
number={2},
pages={478-487},
abstract={While convolutional neural network (CNN) has been demonstrating powerful ability to learn hierarchical spatial features from medical images, it is still difficult to apply it directly to resting-state functional MRI (rs-fMRI) and the derived brain functional networks (BFNs). We propose a novel CNN framework to simultaneously learn embedded features from BFNs for brain disease diagnosis. Since BFNs can be built by considering both static and dynamic functional connectivity (FC), we first decompose rs-fMRI into multiple static BFNs with modified independent component analysis. Then, the voxel-wise variability in dynamic FC is used to quantify BFN dynamics. A set of paired 3D images representing static/dynamic BFNs can be fed into 3D CNNs, from which we can hierarchically and simultaneously learn static/dynamic BFN features. As a result, the dynamic BFN features can complement static BFN features and, at the meantime, different BFNs can help each other toward a joint and better classification. We validate our method with a publicly accessible, large cohort of rs-fMRI dataset in early-stage mild cognitive impairment (eMCI) diagnosis, which is one of the most challenging problems to the clinicians. By comparing with a conventional method, our method shows significant diagnostic performance improvement by almost 10%. This result demonstrates the effectiveness of deep learning in preclinical Alzheimer's disease diagnosis, based on the complex and high-dimensional voxel-wise spatiotemporal patterns of the resting-state brain functional connectomics. The framework provides a new but intuitive way to fully exploit deeply embedded diagnostic features from rs-fMRI for a better-individualized diagnosis of various neurological diseases.},
keywords={Convolutional neural networks;Neurophysiology;Brain;Deep learning;Feature extraction;Functional magnetic resonance imaging;Image classification;Diagnosis;convolutional neural networks;brain network;independent component analysis;mild cognitive impairment;deep learning;resting state;functional MRI},
doi={10.1109/TMI.2019.2928790},
ISSN={1558-254X},
month={Feb},}
@INPROCEEDINGS{8706339,
author={Khagi, Bijen and Lee, Bumshik and Pyun, Jae-Young and Kwon, Goo-Rak},
booktitle={2019 International Conference on Electronics, Information, and Communication (ICEIC)}, title={CNN Models Performance Analysis on MRI images of OASIS dataset for distinction between Healthy and Alzheimer's patient},
year={2019},
volume={},
number={},
pages={1-4},
abstract={Here in this paper we present the performance result of pretrained model trained on natural Image and its result in medical image classification. Besides, scratch trained model is also trained from available medical MRI images, in order to have a comparative analysis. We have performed shallow tuning and fine tuning of pretrained model (Alexnet, Googlenet, and Resnet50) in a bunch of layers in order to find the impact of each section of layers in classification result. We have used 28 Normal controls (NC) and 28 Alzheimer's disease (AD) patients for classification, selecting 30 important slices from each patient. Once all the slices are collected, each model was trained, validated and tested in ratio of 6:2:2 on random selection basis. The resulting testing results are reported and analyzed. So, that the final CNN model was built with minimal number of layers for optimal performance.},
keywords={Tuning;Training;Magnetic resonance imaging;Biomedical imaging;Convolution;Alzheimer's disease;Solid modeling;Medical MRI images;CNN;Alexnet;Googlenet;Resnet50;CAD},
doi={10.23919/ELINFOCOM.2019.8706339},
ISSN={},
month={Jan},}
@INPROCEEDINGS{9306649,
author={Abed, Mahjabeen Tamanna and Fatema, Umme and Nabil, Shanewas Ahmed and Alam, Md. Ashraful and Reza, Md Tanzim},
booktitle={2020 Joint 9th International Conference on Informatics, Electronics Vision (ICIEV) and 2020 4th International Conference on Imaging, Vision Pattern Recognition (icIVPR)}, title={Alzheimer's Disease Prediction Using Convolutional Neural Network Models Leveraging Pre-existing Architecture and Transfer Learning},
year={2020},
volume={},
number={},
pages={1-6},
abstract={Early Alzheimer's Disease (AD) or Mild Cognitive Impairment (MCI) can be diagnosed through proper examination of several brain biomarkers. In recent times, several high-dimensional classification techniques have been suggested to discriminate between AD and MCI on the basis of T1-weighted MRI of patients. These techniques have been implemented mostly from scratch, making it really difficult to achieve any meaningful result within a short span of time. Therefore, the classification of AD is usually a very daunting and time-consuming task. In our study, we trained high dimensional Deep Neural Network (DNN) models with transfer learning in order to achieve meaningful results very quickly in terms of detecting AD from fMRI image. The fMRI image dataset has been collected from Alzheimer's Disease Neuroimaging Initiative (ADNI). We have used three different DNN models for our study: VGG19, Inception v3, and ResNet50 to classify AD, MCI, and Cognitively Normal (CN) patients. Firstly, we implemented some pre-processing steps on the images and divided them into training, testing, and validation sets. Secondly, we initialized these DNN models with the weights from pre-existing models trained on the ImageNet dataset. Finally, we trained and evaluated all the DNN models. After a relatively short amount of training (15 epochs), we achieved an approximate of 90% accuracy with VGG19, 85% accuracy with Inception v3, and 70% with ResNet50. Thus, we achieved excellent classification accuracy in a very short time with our research. Contribution - Classification between early-stage and late-stage AD at improved accuracy with transfer learning.},
keywords={Diseases;Alzheimer's disease;Training;Neuroimaging;Functional magnetic resonance imaging;Computer architecture;Biomarkers;VGG19;Inception;Residual Network (ResNet);Convolutional Neural Network (CNN);Transfer Learning;Magnetic Resonance Imaging (MRI)},
doi={10.1109/ICIEVicIVPR48672.2020.9306649},
ISSN={},
month={Aug},}
@INPROCEEDINGS{9141553,
author={Tufail, Ahsan Bin and Ma, Yongkui and Zhang, Qiu-Na},
booktitle={2020 IEEE 5th Information Technology and Mechatronics Engineering Conference (ITOEC)}, title={Multiclass classification of initial stages of Alzheimer's Disease through Neuroimaging modalities and Convolutional Neural Networks},
year={2020},
volume={},
number={},
pages={51-56},
abstract={Alzheimer's Disease (AD) is the most common form of dementia that causes memory related brain changes which impair the thinking patterns of its subjects. Magnetic Resonance Imaging (MRI) and Positron Emission Tomography (PET) are widely used modalities to capture the structural changes in the brain caused by AD in its early stages. Early diagnosis of AD is important from clinical perspective to improve the life of an individual who is at the risk of developing memory deficits. Deep learning architectures such as 2D and 3D Convolutional Neural Networks (CNNs) have shown promising performances in extracting features and building useful representations of data for computer vision tasks. This study is geared towards understanding the performance differences between these architectures. We used transfer and non-transfer learning approaches to study the underlying disease phenomenon. In our experiments on three class classification of early stages of AD, we found the performance of 3D architectures to be better in comparison to their 2D counterparts. We found the performance of 3D architecture trained on PET neuroimaging modality data to be the best in terms of performance metrics which shows superior diagnostic power of this type of architecture.},
keywords={Magnetic resonance imaging;Three-dimensional displays;Training;Convolution;Neurons;Dementia;Positron emission tomography;Convolutional Neural Networks;Multiclass Classification;Mild Cognitive Impairment;Alzheimer's Disease;Magnetic Resonance Imaging;Positron Emission Tomography},
doi={10.1109/ITOEC49072.2020.9141553},
ISSN={},
month={June},}
@INPROCEEDINGS{8986170,
author={Simon, Blessy C and Baskar, D and Jayanthi, V S},
booktitle={2019 9th International Conference on Advances in Computing and Communication (ICACC)}, title={Alzheimer’s Disease Classification Using Deep Convolutional Neural Network},
year={2019},
volume={},
number={},
pages={204-208},
abstract={Alzheimer's Disease is the most common form of dementia which initially destroys the memory and finally progresses to death. This irreversible disease is mostly found among older people. The latest innovations on the multimodal neuroimaging data made it possible to detect the disease in life which was a major breakthrough in neuroscience. However, the larger degree of similarity between the brain images was the major challenge in the diagnosis. The Deep Learning technique has gained excellent results on image classification among the present researches. Hence it is utilized for the classification of brain images among Cognitively Normal (CN), Early Mild Cognitive Impairment (EMCL), Mild Cognitive Impairment (MCL), Late Mild Cognitive Impairment (LMCI), Alzheimer's Disease (AD) which are the five classes of AD thus ensuring very precise and accurate diagnosis. The transfer learning approach has been taken up for the classification process by which three pre-trained networks, namely AlexNet, ResNet-18 and, GoogLe Net are modified and trained for 3000 images. All the three networks are trained for the same set of images which were acquired from the ADNI database.},
keywords={Alzheimer’s disease;Deep learning;Classification;Convolutional Neural Network;Transfer learning;Pre-trained Networks},
doi={10.1109/ICACC48162.2019.8986170},
ISSN={},
month={Nov},}
@INPROCEEDINGS{9318172,
author={Nawaz, Ali and Anwar, Syed Muhammad and Liaqat, Rehan and Iqbal, Javid and Bagci, Ulas and Majid, Muhammad},
booktitle={2020 IEEE 23rd International Multitopic Conference (INMIC)}, title={Deep Convolutional Neural Network based Classification of Alzheimer's Disease using MRI Data},
year={2020},
volume={},
number={},
pages={1-6},
abstract={Alzheimer's disease (AD) is a progressive and incurable neurodegenerative disease which destroys brain cells and causes loss to patient's memory. Early detection can prevent the patient from further damage to the brain cells and hence avoid permanent memory loss. In the past few years, various automatic tools and techniques have been proposed for the diagnosis of AD. Several methods focus on fast, accurate, and early detection of the disease to minimize the loss to a patient's mental health. Although machine learning and deep learning techniques have significantly improved medical imaging systems for AD by providing diagnostic performance close to the human level. But the main problem faced during multi-class classification is the presence of highly correlated features in the brain structure. In this paper, we have proposed a smart and accurate way of diagnosing AD based on a two-dimensional deep convolutional neural network (2D-DCNN) using an imbalanced three-dimensional MRI dataset. Experimental results on Alzheimer's Disease Neuroimaging Initiative magnetic resonance imaging (MRI) dataset confirms that the proposed 2D-DCNN model is superior in terms of accuracy, efficiency, and robustness. The model classifies MRI into three categories: AD, mild cognitive impairment, and normal control; and has achieved 99.89% classification accuracy with imbalanced classes. The proposed model exhibits noticeable improvement in accuracy as compared to state-of-the-art methods.},
keywords={Magnetic resonance imaging;Feature extraction;Data models;Three-dimensional displays;Deep learning;Computational modeling;Brain modeling;Alzheimer's disease;Deep learning;deep Convolutional neural network;Brain MRI;Multi-class},
doi={10.1109/INMIC50486.2020.9318172},
ISSN={2049-3630},
month={Nov},}
@ARTICLE{8703035,
author={Feng, Chiyu and Elazab, Ahmed and Yang, Peng and Wang, Tianfu and Zhou, Feng and Hu, Huoyou and Xiao, Xiaohua and Lei, Baiying},
journal={IEEE Access}, title={Deep Learning Framework for Alzheimer’s Disease Diagnosis via 3D-CNN and FSBi-LSTM},
year={2019},
volume={7},
number={},
pages={63605-63618},
abstract={Alzheimer's disease (AD) is an irreversible progressive neurodegenerative disorder. Mild cognitive impairment (MCI) is the prodromal state of AD, which is further classified into a progressive state (i.e., pMCI) and a stable state (i.e., sMCI). With the development of deep learning, the convolutional neural networks (CNNs) have made great progress in image recognition using magnetic resonance imaging (MRI) and positron emission tomography (PET) for AD diagnosis. However, due to the limited availability of these imaging data, it is still challenging to effectively use CNNs for AD diagnosis. Toward this end, we design a novel deep learning framework. Specifically, the virtues of 3D-CNN and fully stacked bidirectional long short-term memory (FSBi-LSTM) are exploited in our framework. First, we design a 3D-CNN architecture to derive deep feature representation from both MRI and PET. Then, we apply FSBi-LSTM on the hidden spatial information from deep feature maps to further improve its performance. Finally, we validate our method on the AD neuroimaging initiative (ADNI) dataset. Our method achieves average accuracies of 94.82%, 86.36%, and 65.35% for differentiating AD from normal control (NC), pMCI from NC, and sMCI from NC, respectively, and outperforms the related algorithms in the literature.},
keywords={Magnetic resonance imaging;Three-dimensional displays;Feature extraction;Kernel;Deep learning;Diseases;Two dimensional displays;Alzheimer’s disease;3D-CNN;FSBi-LSTM;multi-modal fusion},
doi={10.1109/ACCESS.2019.2913847},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{9116921,
author={Amini, Morteza and Sajedi, Hedieh and Mahmoodi, Tayeb and Mirzaei, Sayeh},
booktitle={2020 International Conference on Machine Vision and Image Processing (MVIP)}, title={Fast Prediction of Cortical Dementia Based on Original Brain MRI images Using Convolutional Neural Network},
year={2020},
volume={},
number={},
pages={1-4},
abstract={Fast and automatic identification of different types of Cortical Dementia, specially Alzheimer's disease, based on Brain MRI images, is a crucial technology which can help physicians in early and effective treatment. Although preprocessing of MRI images could improve the accuracy of machine learning techniques for classification of the normal and abnormal cases, this could slow down the process of automatic identification and tarnish the applicability of these methods in clinics and laboratories. In this paper we examine classification of a small sample of the original brain MRI images, using a 2D Convolutional Neural Network (CNN). The data consists of 172 healthy individuals as the control group (HC) and only 89 patients with different grades of Dementia (DP) which was collected in National Brain Mapping Center of Iran. The model could achieve an accuracy of 97.47% on the test set and 93.88% based on a 5-fold cross-validation.},
keywords={Index Terms—Convolutional Neural Network;National Brain Mapping Center;Magnetic Resonance Imaging;Classification},
doi={10.1109/MVIP49855.2020.9116921},
ISSN={2166-6784},
month={Feb},}
@INPROCEEDINGS{8512468,
author={Spasov, Simeon E. and Passamonti, Luca and Duggento, Andrea and Liò, Pietro and Toschi, Nicola},
booktitle={2018 40th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)}, title={A Multi-modal Convolutional Neural Network Framework for the Prediction of Alzheimer’s Disease},
year={2018},
volume={},
number={},
pages={1271-1274},
abstract={This paper presents a multi-modal Alzheimer's disease (AD) classification framework based on a convolutional neural network (CNN) architecture. The devised model takes structural MRI, and clinical assessment and genetic (APOe4) measures as inputs. Our CNN structure is designed to be efficient in its use of parameters which reduces overfitting, computational complexity, memory requirements and speed of prototyping. This is achieved by factorising the convolutional layers in parallel streams which also enables the simultaneous extraction of high and low level feature representations. Our method consistently achieves high classification results in discriminating between AD and control subjects with an average of 99% accuracy, 98% sensitivity, 100% specificity and an AUC of 1 across all test folds. Our study confirms that careful tuning of CNN characteristics can result in a framework which delivers extremely accurate predictions in a clinical problem despite data paucity, opening new avenues for application to prediction tasks which regard patient stratification, prediction of clinical evolution and eventually personalised medicine applications.},
keywords={Feature extraction;Dementia;Magnetic resonance imaging;Training;Biomedical imaging;Computer architecture},
doi={10.1109/EMBC.2018.8512468},
ISSN={1558-4615},
month={July},}
@INPROCEEDINGS{8512398,
author={Shen, Ting and Jiang, Jiehui and Li, Yupeng and Wu, Ping and Zuo, Chuantao and Yan, Zhuangzhi},
booktitle={2018 40th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)}, title={Decision Supporting Model for One-year Conversion Probability from MCI to AD using CNN and SVM},
year={2018},
volume={},
number={},
pages={738-741},
abstract={Prediction of Alzheimer's disease (AD) from Mild Cognitive Impairment (MCI) has become popular in recent years. Especially, deep learning technique has been used to extract high-quality features and for classification in this topic. Whether the patient would converse from MCI into AD is a particular evaluation criteria in clinics. However, there is no such a conversion prediction model in literature. Therefore, the purpose of this study is to propose a decision supporting model based on deep learning and machine learning to predict the conversion probability from MCI into AD within one year. We analyzed 165 samples with MRI scans from Alzheimer's Disease Neuroimaging Initiative (ADNI) database, in which all MCI patients were converted into AD in different time span for conversion. In this model, we first extracted image features based on convolutional neural network (CNN) method, and then we used support vector machine (SVM) classifier to classify these features. The results showed that the classification accuracy using linear, polynomial and RBF kernel could achieve 91.0%, 90.0% and 92.3%. As a result, this study indicated that the decision supporting model is potential to be applied into predicting the conversion probability from MCI into AD within one year.},
keywords={Feature extraction;Support vector machines;Magnetic resonance imaging;Kernel;Training;Dementia;Alzheimer’s disease;Mild Cognitive Impairment;convolutional neural network (CNN);prediction;support vector machine (SVM)},
doi={10.1109/EMBC.2018.8512398},
ISSN={1558-4615},
month={July},}
@INPROCEEDINGS{8663765,
author={Wang, Xinying and Wang, Wanqiu},
booktitle={2018 IEEE 9th International Conference on Software Engineering and Service Science (ICSESS)}, title={MRI Brain Image Classification Based on Improved Topographic Sparse Coding},
year={2018},
volume={},
number={},
pages={1116-1119},
abstract={As the field of neuroimaging grows, imaging technology plays an increasingly important role in the auxiliary diagnosis of brain lesions. An Alzheimer's disease recognition method for magnetic resonance imaging (MRI)based on improved topological sparse coding (ITSC)is proposed. The data source is taken from the ADNI database, after correction, registration, segmentation, smoothing and other operations, the gray matter image of the brain are obtained, and then the improved topological sparse coding model of unsupervised feature learning is used to construct the deep neural network. And the optimization algorithm is used to replace the network model. The valence function is optimized iteratively, the weight matrix is studied and the new feature expression is obtained. Finally, the Softmax classifier and the auxiliary fine-tuning method are used to identify the disease. Compared with principal component analysis and a self-learning neural network, the experimental results show that the proposed method has better recognition performance.},
keywords={Magnetic resonance imaging;Alzheimer's disease;Grey matter;Image coding;Sparse matrices;Principal component analysis;topographic sparse coding;Structural MRI;greedy algorithm;Alzheimer's disease},
doi={10.1109/ICSESS.2018.8663765},
ISSN={2327-0594},
month={Nov},}
@ARTICLE{9130719,
author={Yamanakkanavar, Nagaraj and Lee, Bumshik},
journal={IEEE Access}, title={Using a Patch-Wise M-Net Convolutional Neural Network for Tissue Segmentation in Brain MRI Images},
year={2020},
volume={8},
number={},
pages={120946-120958},
abstract={Accurate segmentation of brain tissues, such as gray matter (GM), white matter (WM), and cerebrospinal fluid (CSF), in magnetic resonance imaging (MRI) images, is helpful for the diagnosis of neurological disorders, such as schizophrenia, Alzheimer's disease, and dementia. Studies on MRI-based brain segmentation have received significant attention in recent years based on the non-invasive imaging and good soft-tissue contrast provided by MRI. A number of studies have used conventional machine learning strategies, as well as convolutional neural network approaches. In this paper, we propose a patch-wise M-net architecture for the automatic segmentation of brain MRI images. In the proposed brain segmentation method, slices from a brain MRI scan are divided into non-overlapping patches, which are then fed into an M-net model with corresponding ground-truth patches to train the network, which is composed of two encoder-decoder processes. Dilated convolutional kernels with different sizes are used in the encoder and decoder modules to derive abundant semantic features from brain MRI scans. The proposed patch-wise M-net overcomes the drawbacks of conventional methods and provides greater retention of fine details. The proposed M-net model was trained and tested on the open-access series of imaging studies dataset. The performance was measured quantitatively using the Dice similarity coefficient. Experimental results demonstrate that the proposed method achieves average segmentation accuracies of 94.81% for CSF, 95.44% for GM, and 96.33% for WM, meaning it outperforms state-of-the-art methods.},
keywords={Image segmentation;Magnetic resonance imaging;Brain modeling;Feature extraction;Three-dimensional displays;Deep learning;Brain MRI;convolutional neural network;M-net;tissue segmentation},
doi={10.1109/ACCESS.2020.3006317},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{9321061,
author={Puspaningrum, Eva Y and Wahid, Radical Rakhman and Amaliyah, Rahayu Prabawati and Nisa’, Chilyatun},
booktitle={2020 6th Information Technology International Seminar (ITIS)}, title={Alzheimer’s Disease Stage Classification using Deep Convolutional Neural Networks on Oversampled Imbalance Data},
year={2020},
volume={},
number={},
pages={57-62},
abstract={One problem that is often faced in health data sets is a high level of imbalance. Imbalanced data can mean that the data used in machine learning has an unbalanced data distribution between different classes. One of the data is Alzheimer's disease data. The data used are Dataset containing 6400 images of brain magnetic resonance imaging that is indicated as having Alzheimer's disease or not. This study used Deep Learning Architecture to classify brains affected by Alzheimer's disease and healthy brains. We produced a trained and predictive model using Deep Convolutional Neural Networks (CNN), where the data had previously gone through the oversampling stage due to an imbalance in the data distribution. From the evaluation metric table provided in this study, the highest accuracy for detecting Alzheimer's disease was obtained by ResNetl8 with an accuracy of 60.67%. Still, the shortest training time was obtained by ShuffleNet V2 with 624.4 seconds using non-oversampled. While the results obtained by using oversampled, ShuffleNet V2 provide 60.75% accuracy with the fastest training time of 1478.6 seconds. The special CNN model that the author proposes gets an accuracy of 50% using non-oversampled and 55.27% accuracy using oversampled.},
keywords={Training;Seminars;Measurement;Magnetic resonance imaging;Predictive models;Convolutional neural networks;Diseases;Alzheimer’s;image classification;oversampled;MRI image data;convolutional neural network},
doi={10.1109/ITIS50118.2020.9321061},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9068680,
author={Fong, Jia Xian and Shapiai, Mohd Ibrahim and Tiew, Yuan You and Batool, Uzma and Fauzi, Hilman},
booktitle={2020 16th IEEE International Colloquium on Signal Processing Its Applications (CSPA)}, title={Bypassing MRI Pre-processing in Alzheimer's Disease Diagnosis using Deep Learning Detection Network},
year={2020},
volume={},
number={},
pages={219-224},
abstract={Although promising results have been achieved in the area of Alzheimer's Disease diagnosis via hippocampal atrophy analysis, most of these solutions are heavily dependent on various MRI pre-processing techniques to obtain a good result. Besides, most recent works using deep learning methods such as Convolutional Neural Network (CNN) solve Alzheimer's Disease diagnosis based on a classification problem, leaving a research gap to use deep learning object detection method on Alzheimer's Disease diagnosis. In this study, we make two contributions to solve this problem. Firstly, we are the first group to propose an Alzheimer's Disease diagnosis solution without requiring any MRI pre-processing technique. Secondly, we introduce recent deep learning object detection architectures such as Faster R-CNN, SSD and YOLOv3 into the area of Alzheimer's Disease diagnosis. As a side product of our research, we provide a new Deep Learning Alzheimer's Disease/Normal Control (AD/NC) object detection benchmark dataset which includes 500 raw, unprocessed screening instances per class from Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset for future object detection research. This dataset consists of a collection of T1 weighted sagittal MRI dicom slices in MP-Rage series in DICOM 16-bit and PNG 16-bit image format, annotated with their respective class label and bounding box in Pascal VOC format. We call this benchmark dataset UTM-ADNI-RAW*. In this study, without using any MRI preprocessing technique, we managed to obtain a detection accuracy of 0.998 for YOLOv3, 0.982 for SSD and 0.988 for Faster R-CNN in AD/NC territory while surpassing 0.75 IoU threshold across all three deep learning architectures.},
keywords={Magnetic resonance imaging;Machine learning;Dementia;Object detection;Medical diagnosis;Detectors;Alzheimer' ‘s Disease;MRI;Deep Learning;CNN;Object Detection;UTM-ADNI-RAW},
doi={10.1109/CSPA48992.2020.9068680},
ISSN={},
month={Feb},}
@INPROCEEDINGS{9096819,
author={Vinutha, N and Pattar, Santosh and Kumar, Chiranjeev and Agarwal, Akash and Shenoy, P Deepa and Venugopal, KR},
booktitle={2018 Fourteenth International Conference on Information Processing (ICINPRO)}, title={A Convolution Neural Network based Classifier for Diagnosis of Alzheimer’s Disease},
year={2018},
volume={},
number={},
pages={1-6},
abstract={Data in today's modern digital world is characterized by various varieties, multiple modalities, huge volume and is getting generated and accumulated at a rapid speed. Deep learning techniques have emerged as a breakthrough tools in analyzing this data. In this paper, we employ a Convolution Neural Network (CNN) on three dimensional structural MRI (sMRI) images of human brain for diagnosis of Alzheimers Disease (AD). The longitudinal images of various subjects are obtained at different time points from the ADNI dataset and subjected to our proposed classification framework. We construct six different datasets based on the number of image slices of GM images with combinations of different time points of scans or only the baseline visit. The classification results obtained from our proposed CNN model shows better performance for Gray Matter (GM) images that are obtained at different time points. Also, the model achieves best classification performance when the number of training features are low and the training sample size is high.},
keywords={Feature extraction;Machine learning;Diseases;Magnetic resonance imaging;Computational modeling;Solid modeling;Biological neural networks;Alzheimer’s Disease;Computer Aided Diagnosis;Convolution Neural Network;Deep Learning Techniques;Longitudinal Images;Magnetic Resonance Imaging},
doi={10.1109/ICINPRO43533.2018.9096819},
ISSN={},
month={Dec},}
@INPROCEEDINGS{8983391,
author={Velazquez, Matthew and Anantharaman, Rajaram and Velazquez, Salma and Lee, Yugyung and null},
booktitle={2019 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)}, title={RNN-Based Alzheimer's Disease Prediction from Prodromal Stage using Diffusion Tensor Imaging},
year={2019},
volume={},
number={},
pages={1665-1672},
abstract={Alzheimer's Disease is an irreversible, progressive brain disorder that slowly destroys cognitive abilities. In recent years, the relationship between the prodromal Mild Cognitive Impairment (MCI) stage and the Alzheimer's Disease (AD) stage has been extensively researched in hopes of finding a path towards early diagnosis. Early detection at the MCI stage can help determine appropriate treatment plans as well as assist in clinical trial enrollment as 32% of individuals with MCI will develop AD within 5 years. Computer vision studies leveraging Magnetic Resonance Imaging (sMRI, fMRI), Diffusion Tensor Imaging (DTI), and Positron Emission Tomography (PET) have led to encouraging results in classifying the different stages of AD. Studies around DTI specifically have shown that structural differences in white matter are prevalent between these stages. Rather than classification between stages, we propose a recurrent neural network model (RNN) based on the DTI modality for identifying the subset (32%) of individuals with Early Mild Cognitive Impairment (EMCI) that will develop AD. Our results are state-of-the-art and demonstrate high accuracy in determining which individuals will develop AD within the next 5-7 years. Additionally, we propose our augmentation methods for DTI data as well as our classification accuracy across the traditional AD stage categories.},
keywords={Recurrent Neural Networks;Deep Learning;Alzheimer's Disease;Mild Cognitive Impairment;Diffusion Tensor Imaging},
doi={10.1109/BIBM47256.2019.8983391},
ISSN={},
month={Nov},}
@INPROCEEDINGS{9248213,
author={Hussain, Emtiaz and Hasan, Mahmudul and Hassan, Syed Zafrul and Hassan Azmi, Tanzina and Rahman, Md Anisur and Zavid Parvez, Mohammad},
booktitle={2020 15th IEEE Conference on Industrial Electronics and Applications (ICIEA)}, title={Deep Learning Based Binary Classification for Alzheimer’s Disease Detection using Brain MRI Images},
year={2020},
volume={},
number={},
pages={1115-1120},
abstract={Alzheimer's disease is an irremediable, continuous brain disorder that gradually destroys memory and thinking skills and, eventually, the ability to carry out the simplest tasks. It has become one of the critical diseases throughout the world. Moreover, there is no remedy for Alzheimer's disease. Machine learning techniques, especially deep learning-based Convolutional Neural Network (CNN), are used to improve the process for the detection of Alzheimer's disease. In recent days, CNN has achieved major success in MRI image analysis and biomedical research. A lot of research has been carried out for the detection of Alzheimer's disease based on brain MRI images using CNN. However, one of the fundamental limitations is that proper comparison between a proposed CNN model and pre-trained CNN models (InceptionV3, Xception, MobilenetV2, VGG) was not established. Therefore, in this paper, we present a model based on 12-layer CNN for binary classification and detection of Alzheimer's disease using brain MRI data. The performance of the proposed model is compared with some existing CNN models in terms of accuracy, precision, recall, F1 score, and ROC curve on the Open Access Series of Imaging Studies (OASIS) dataset. The main contribution of the paper is a 12-layer CNN model with an accuracy of 97.75%, which is higher than any other existing CNN models published on this dataset. The paper also shows side by side comparison between our proposed model and pre-trained CNN models (InceptioV3, Xception, MobilenetV2, VGG). The experimental results show the superiority of the proposed model over the existing models.},
keywords={Deep learning;Open Access;Magnetic resonance imaging;Biological system modeling;Brain modeling;Task analysis;Diseases;Alzheimer;Machine Learning;Deep Learning;CNN;MRI;OASIS-1;Confusion Matrix;Accuracy;ROC Curve},
doi={10.1109/ICIEA48937.2020.9248213},
ISSN={2158-2297},
month={Nov},}
@INPROCEEDINGS{9206837,
author={Nigri, Eduardo and Ziviani, Nivio and Cappabianco, Fabio and Antunes, Augusto and Veloso, Adriano},
booktitle={2020 International Joint Conference on Neural Networks (IJCNN)}, title={Explainable Deep CNNs for MRI-Based Diagnosis of Alzheimer’s Disease},
year={2020},
volume={},
number={},
pages={1-8},
abstract={Deep Convolutional Neural Networks (CNNs) are becoming prominent models for semi-automated diagnosis of Alzheimer's Disease (AD) using brain Magnetic Resonance Imaging (MRI). Although being highly accurate, deep CNN models lack transparency and interpretability, precluding adequate clinical reasoning and not complying with most current regulatory demands. One popular choice for explaining deep image models is occluding regions of the image to isolate their influence on the prediction. However, existing methods for occluding patches of brain scans generate images outside the distribution to which the model was trained for, thus leading to unreliable explanations. In this paper, we propose an alternative explanation method that is specifically designed for the brain scan task. Our method, which we refer to as Swap Test, produces heatmaps that depict the areas of the brain that are most indicative of AD, providing interpretability for the model's decisions in a format understandable to clinicians. Experimental results using an axiomatic evaluation show that the proposed method is more suitable for explaining the diagnosis of AD using MRI while the opposite trend was observed when using a typical occlusion test. Therefore, we believe our method may address the inherent black-box nature of deep neural networks that are capable of diagnosing AD.},
keywords={Brain modeling;Magnetic resonance imaging;Three-dimensional displays;Solid modeling;Dementia;Explainable Deep Learning;Computer-aided detection and diagnosis (CAD);Magnetic resonance imaging (MRI);Brain},
doi={10.1109/IJCNN48605.2020.9206837},
ISSN={2161-4407},
month={July},}
@INPROCEEDINGS{8852138,
author={Silva, Iago R. R. and Silva, Gabriela S. L. and de Souza, Rodrigo G. and dos Santos, Wellington P. and de A. Fagundes, Roberta A.},
booktitle={2019 International Joint Conference on Neural Networks (IJCNN)}, title={Model Based on Deep Feature Extraction for Diagnosis of Alzheimer’s Disease},
year={2019},
volume={},
number={},
pages={1-7},
abstract={Alzheimer's disease (AD) is a neurodegenerative disease that results in loss of cognitive ability of the patient. Computational intelligence, more specifically Deep Learning, has been a powerful method for AD diagnosis. In this work we propose a model for AD diagnosis based on deep feature extraction for the classification using magnetic resonance imaging. This model aims to classify AD vs. HC (Healthy Controls). The database used in this project is the Minimal Interval Resonance Imaging in Alzheimer's Disease (MIRIAD), for validation of the proposed method. We select thirty slices from the upper region of the brain, above the eyes, for the apprenticeship in this work. The Convolutional Neural Network (CNN) architecture is designed in three convolutional layers to extract the best features of the selected region. After that, we put the selected attributes in a vector for learning and detection of patterns by another technique of computational intelligence. Finally, the data are partitioned with the 10-folds cross-validation method and trained with the Random Forest, Support Vector Machine (SVM), and K-Nearest Neighbor (K-NN) algorithms with different parameters for evaluation. The results of accuracy are 0.8832, 0.9607 and 0.8745, for the algorithms mentioned above, respectively. According to a comparative analysis performed with other works of the literature, we can prove the efficiency and reliability of the model for the diagnosis of Alzheimer's disease.},
keywords={Feature extraction;Magnetic resonance imaging;Alzheimer's disease;Deep learning;Sensitivity;Neurons;Alzheimer’s Disease;Diagnosis;Deep Learning;CNN;SVM},
doi={10.1109/IJCNN.2019.8852138},
ISSN={2161-4407},
month={July},}
@ARTICLE{9269972,
author={Khagi, Bijen and Kwon, Goo-Rak},
journal={IEEE Access}, title={3D CNN Design for the Classification of Alzheimer’s Disease Using Brain MRI and PET},
year={2020},
volume={8},
number={},
pages={217830-217847},
abstract={Attempt to diagnose Alzheimer's disease (AD) using imaging modalities is one of the scopes of deep learning. While considering the theoretical background from past studies, we are trying to identify convolutional neural network (CNN) behaviors moving from 2D to 3D architecture. This study aims to explore the output from a variety of CNN models implemented in the MRI or/and PET classification tasks for AD prediction while trying to summarize its characteristics with a variety of parameters that are tuned and changed. There are many architectures available; however, we are testing a basic architecture with a change in the reception area based on the convolutional layer's kernel size and its strides. The architecture has been categorized as converging, diverging, or equivalent if the filter kernel size is unchanged. This investigation studies a simple encoder based CNN with a sequential flow of features from low-level to high-level feature extraction. The idea is to present a diverging reception area by increasing the filter size and stride from a lower to a higher level. As a result, the feature redundancy is reduced and the trivial features keep on diminishing. The proposed architecture is referred to as `divNet', and several experiments were performed to determine how effective the architecture is in terms of the consumed memory, the number of parameters, running time, classification error, and the generalization error. This study surveys several related experiments by changing the hyper-parameters setting, the architecture selection based on the depth and area of the reception feature, and the data size.},
keywords={Magnetic resonance imaging;Three-dimensional displays;Feature extraction;Computer architecture;Neurons;Two dimensional displays;Brain;3D CNN;CNN architecture;Alzheimer’s disease;reception area;feature redundancy;data size;MRI classification},
doi={10.1109/ACCESS.2020.3040486},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{8983046,
author={Cui, Zhenyu and Gao, Zhiao and Leng, Jiaxu and Zhang, Tianlin and Quan, Pei and Zhao, Wei},
booktitle={2019 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)}, title={Alzheimer's Disease Diagnosis Using Enhanced Inception Network Based on Brain Magnetic Resonance Image},
year={2019},
volume={},
number={},
pages={2324-2330},
abstract={An estimated 24 million people worldwide have dementia, the majority of whom are thought to have Alzheimer's disease(AD). Nowadays, Alzheimer's disease represents a significant public health concern and has been identified as a research priority. Most unfortunately, there is little chance of a cure for Alzheimer's disease, and the disease is difficult to detect before the dominant characteristics such as memory loss are manifested. Therefore, the diagnosis of Alzheimer's disease has become an urgent problem today. Studies have shown that mild cognitive impairment(MCI) is a state between Alzheimer's disease and normal, and the chance of it turning into Alzheimer's disease is high. Therefore, if machines can automatically learn the characteristics of three kinds of human brain magnetic resonance(MR) images through deep learning, and help doctors to diagnose patients with mild cognitive impairment or Alzheimer's disease accurately, it will be beneficial for the early diagnosis of Alzheimer's disease. In this paper, we improve the Inception(V3) neural network and further test the effectiveness of the enhanced network based on the international Alzheimer's disease data set, which consists of brain magnetic resonance images. The results show that the average accuracy of our approach can reach 85.7%.},
keywords={Alzheimer's disease diagnosis;magnetic resonance image;neural network},
doi={10.1109/BIBM47256.2019.8983046},
ISSN={},
month={Nov},}
@ARTICLE{8674823,
author={Liu, Mingxia and Zhang, Jun and Lian, Chunfeng and Shen, Dinggang},
journal={IEEE Transactions on Cybernetics}, title={Weakly Supervised Deep Learning for Brain Disease Prognosis Using MRI and Incomplete Clinical Scores},
year={2020},
volume={50},
number={7},
pages={3381-3392},
abstract={As a hot topic in brain disease prognosis, predicting clinical measures of subjects based on brain magnetic resonance imaging (MRI) data helps to assess the stage of pathology and predict future development of the disease. Due to incomplete clinical labels/scores, previous learning-based studies often simply discard subjects without ground-truth scores. This would result in limited training data for learning reliable and robust models. Also, existing methods focus only on using hand-crafted features (e.g., image intensity or tissue volume) of MRI data, and these features may not be well coordinated with prediction models. In this paper, we propose a weakly supervised densely connected neural network (wiseDNN) for brain disease prognosis using baseline MRI data and incomplete clinical scores. Specifically, we first extract multiscale image patches (located by anatomical landmarks) from MRI to capture local-to-global structural information of images, and then develop a weakly supervised densely connected network for task-oriented extraction of imaging features and joint prediction of multiple clinical measures. A weighted loss function is further employed to make full use of all available subjects (even those without ground-truth scores at certain time-points) for network training. The experimental results on 1469 subjects from both ADNI-1 and ADNI-2 datasets demonstrate that our proposed method can efficiently predict future clinical measures of subjects.},
keywords={Magnetic resonance imaging;Diseases;Brain modeling;Feature extraction;Training;Deep learning;Prognostics and health management;Alzheimer’s disease (AD);clinical score;disease prognosis;neural network;weakly supervised learning},
doi={10.1109/TCYB.2019.2904186},
ISSN={2168-2275},
month={July},}
@ARTICLE{8726324,
author={Basher, Abol and Choi, Kyu Yeong and Lee, Jang Jae and Lee, Bumshik and Kim, Byeong C. and Lee, Kun Ho and Jung, Ho Yub},
journal={IEEE Access}, title={Hippocampus Localization Using a Two-Stage Ensemble Hough Convolutional Neural Network},
year={2019},
volume={7},
number={},
pages={73436-73447},
abstract={In this paper, we present a two-stage ensemble-based approach to localize the anatomical structure of interest from magnetic resonance imaging (MRI) scans. We combine a Hough voting method with a convolutional neural network to automatically localize brain anatomical structures such as the hippocampus. The hippocampus is one of the regions that can be affected by the Alzheimer's disease, and this region is known to be related to memory loss. The structural changes of the hippocampus are important biomarkers for dementia. To analyze the structural changes, accurate localization plays a vital role. Furthermore, for segmentation and registration of anatomical structures, exact localization is desired. Our proposed models use a deep convolutional neural network (CNN) to calculate displacement vectors by exploiting the Hough voting strategy from multiple 3-viewpoint patch samples. The displacement vectors are added to the sample position to estimate the target position. To efficiently learn from samples, we employed a local and global strategy. The multiple global models were trained using randomly selected 3-viewpoint patches from the whole MRI scan. The results from global models are aggregated to obtain global predictions. Similarly, we trained multiple local models, extracting patches from the vicinity of the hippocampus location and assembling them to obtain a local prediction. The proposed models exploit the Alzheimer's disease neuroimaging initiative (ADNI) MRI dataset and the Gwangju Alzheimer's and related dementia (GARD) cohort MRI dataset for training, validating and testing. The average prediction error using the proposed two-stage ensemble Hough convolutional neural network (Hough-CNN) models are 2.32 and 2.25 mm for the left and right hippocampi, respectively, for 65 test MRIs from the GARD cohort dataset. Similarly, for the ADNI MRI dataset, the average prediction error for the left and right hippocampi are 2.31 and 2.04 mm, respectively, for 56 MRI scans.},
keywords={Hippocampus;Magnetic resonance imaging;Convolutional neural networks;Predictive models;Shape;Anatomical structure;Alzheimer's disease;Ensemble Hough-CNN;hippocampus;displacement vector;MRI;Hough voting},
doi={10.1109/ACCESS.2019.2920005},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{8759455,
author={Jin, Dan and Xu, Jian and Zhao, Kun and Hu, Fangzhou and Yang, Zhengyi and Liu, Bing and Jiang, Tianzi and Liu, Yong},
booktitle={2019 IEEE 16th International Symposium on Biomedical Imaging (ISBI 2019)}, title={Attention-based 3D Convolutional Network for Alzheimer’s Disease Diagnosis and Biomarkers Exploration},
year={2019},
volume={},
number={},
pages={1047-1051},
abstract={Modern advancements in deep learning provide a powerful framework for disease classification based on neuroimaging data. However, interpreting the classification decision of convolutional neural network remains a challenging task. It is crucial to track the attention of neural network and provide valuable information about which brain areas are particularly related to the diagnosis of disease. In this paper, we propose a novel attention-based 3D ResNet architecture to diagnose Alzheimer's disease (AD) and explore potential biological markers. Experiments are conducted on 532 subjects (0227 of patients with AD and 305 of normal controls). By introducing the attention mechanism, the proposed approach further improves the classification performance and identifies important brain regions for AD classification simultaneously. The experiments also show that significant brain regions for AD diagnosis captured by our attention-based network are accompanied by significant changes in gray matter.},
keywords={Three-dimensional displays;Diseases;Grey matter;Biomarkers;Brain modeling;Deep learning;Magnetic resonance imaging;Attention mechanism;convolutional neural network;Alzheimer’s disease;computer-aided diagnosis},
doi={10.1109/ISBI.2019.8759455},
ISSN={1945-8452},
month={April},}
@INPROCEEDINGS{8989287,
author={Satapathy, Pranati and Pradhan, Sateesh Kumar and Hota, Sarbeswara},
booktitle={2019 International Conference on Applied Machine Learning (ICAML)}, title={An Empirical Performance Analysis of Brain Image Classification Models Using Variants of Neural Networks},
year={2019},
volume={},
number={},
pages={87-91},
abstract={This paper presents the empirical comparison of different neural network models for the classification of brain Magnetic Resonance Images (MRIs). This work comprises of four stages i.e. dataset collection, feature extraction, feature reduction and classification. The two brain MRI datasets i.e. the Glioma and Alzheimer datasets are considered for this work. Discrete wavelet transformation (DWT) technique is used for the extraction of features from brain MRIs. Principal Component Analysis (PCA) technique is used to for feature reduction to get relevant features. For the classification task, two variants of neural networks i.e. Backpropagation Neural Network (BPNN) and Extreme Learning Machine (ELM) are used and the classification performances are compared using different performance measures. The simulation study exhibits that DWT+PCA+ELM model outperformed the other models for the classification of normal and diseased brain for the two datasets.},
keywords={Machine Learning, Pathological, Magnetic Resonance Imaging, Backpropagation, Discrete Wavelet Transformation},
doi={10.1109/ICAML48257.2019.00025},
ISSN={},
month={May},}
@INPROCEEDINGS{9315695,
author={Raju, Manu and Sudila, T. V. and Gopi, Varun P. and Anitha, V. S.},
booktitle={2020 International Conference on Recent Trends on Electronics, Information, Communication Technology (RTEICT)}, title={Classification of Mild Cognitive Impairment and Alzheimer’s Disease from Magnetic Resonance Images using Deep Learning},
year={2020},
volume={},
number={},
pages={52-57},
abstract={Mild cognitive impairment (MCI) is an early stage of Alzheimer's disease (AD). Since AD is unlikely to modify its related and intrinsic decay, early diagnosis is crucial, which gives patients a chance to rearrange their lives. Identifying the MCI level is essential, as it assists with further treatment and preliminary steps to control the forward progression towards AD. Brain tissue segmentation is an important aspect of clinical diagnostic tools, yielding excellent results compared to conventional segmentation methods or individual modalities. In this work, the Meta-Heuristic Markov Random Field Segmentation method is used to separate brain tissue, followed by the extraction of intensity, texture, and shape-based features of the segmented Cerebral Spinal Fluid (CSF) and Grey Matter (GM). With the proposed technique, the pre-processing of the input image improves quality and reduces noise. The segmentation is based on multilevel thresholding using Particle Swarm Optimization (PSO) and further improving using Markov Random Field model. Segmented brain tissue (GM and CSF) are used to extract features on shape, intensity, and texture. The four-layer deep neural network is used to classify features. The proposed method is tested with the standard dataset from Alzheimer's disease-neuro imaging (ADNI). The proposed method achieved a high accuracy rate of 97.5%. A comparison with the previous work yielded results that demonstrate this method's superiority in terms of the classification of AD and MCI.},
keywords={Feature extraction;Magnetic resonance imaging;Image segmentation;Deep learning;Alzheimer's disease;Image edge detection;Markov random fields;Mild Cognitive Impairment;Alzheimer’s Disease;Deep Learning;Meta-Heuristic Markov Random Field Segmentation;Particle Swarm Optimization},
doi={10.1109/RTEICT49044.2020.9315695},
ISSN={},
month={Nov},}
@INPROCEEDINGS{8663065,
author={Puranik, Mukul and Shah, Himanshu and Shah, Keval and Bagul, Sudhir},
booktitle={2018 Second International Conference on Intelligent Computing and Control Systems (ICICCS)}, title={Intelligent Alzheimer's Detector Using Deep Learning},
year={2018},
volume={},
number={},
pages={318-323},
abstract={Researchers of the era are constantly striving to achieve accurate, precise algorithms incorporated in highly affordable models, trying to assist the medical practitioners in solving complex medical problems(Alzheimer's). Deep Learning is state-of-the-art learning algorithm in classification and exceptionally efficacious in extracting high level features from multi-dimensional data. In this system we use Convolutional Neural Network particularly for classification of fMRI clinical data on stages of Alzheimer's disease brain from Diseased(AD), Early Mild Cognitive Impairment(EMCI) to those who are normal, having healthy brains. Usage of MRI data has already been done[1] for binary classification. We aim to generalize the classifier into categorizing the images into three different distinct classes. The deep learning pipeline involved critical steps of correctly preprocessing 4D fMRI images i.e. 3D images varying with time. The preprocessing steps involved, proved to be critical in having distinct 2D image slices of Normal, EMCI and AD for better accuracy in understanding the most discriminative features of the fMRI brain scans. Transfer Learning is the concept involved wherein we utilize pretrained complex deep models for classification of images. Advantage of this learning over constructing a new convolutional network is that the knowledge gained during training of ImageNet Dataset fastens the learning process in addition to increased accuracy. We have adopted Inception Resnet V2 model and hope to achieve a competitive accuracy. The aim of the project is to create an Alzheimer's Detector ousting the accuracy of modern radiologists so as to reduce the effort and money of consulting a Radiologist.},
keywords={Feature extraction;Neurons;Diseases;Functional magnetic resonance imaging;Deep learning;Computational modeling;Convolutional Neural Network;Deep Learning;fMRI;Alzheimer's Disease},
doi={10.1109/ICCONS.2018.8663065},
ISSN={},
month={June},}
@INPROCEEDINGS{9098621,
author={Xia, Zaimin and Yue, Guanghui and Xu, Yanwu and Feng, Chiyu and Yang, Mengya and Wang, Tianfu and Lei, Baiying},
booktitle={2020 IEEE 17th International Symposium on Biomedical Imaging (ISBI)}, title={A Novel End-to-End Hybrid Network for Alzheimer's Disease Detection Using 3D CNN and 3D CLSTM},
year={2020},
volume={},
number={},
pages={1-4},
abstract={Structural magnetic resonance imaging (sMRI) plays an important role in Alzheimer's disease (AD) detection as it shows morphological changes caused by brain atrophy. Convolutional neural network (CNN) has been successfully used to achieve good performance in accurate diagnosis of AD. However, most existing methods utilized shallow CNN structures due to the small amount of sMRI data, which limits the ability of CNN to learn high-level features. Thus, in this paper, we propose a novel unified CNN framework for AD identification, where both 3D CNN and 3D convolutional long short-term memory (3D CLSTM) are employed. Specifically, we firstly exploit a 6-layer 3D CNN to learn informative features, then 3D CLSTM is leveraged to further extract the channel-wise higher-level information. Extensive experimental results on ADNI dataset show that our model has achieved an accuracy of 94.19% for AD detection, which outperforms the state-of-the-art methods and indicates the high effectiveness of our proposed method.},
keywords={Three-dimensional displays;Feature extraction;Magnetic resonance imaging;Two dimensional displays;Convolution;Diseases;Solid modeling;Alzheimer 's disease detection;Structural magnetic resonance imaging;3D convolutional neural network;3D convolutional long short-term memory},
doi={10.1109/ISBI45749.2020.9098621},
ISSN={1945-8452},
month={April},}
@INPROCEEDINGS{8787315,
author={Kompanek, Matej and Tamajka, Martin and Benesova, Wanda},
booktitle={2019 International Conference on Systems, Signals and Image Processing (IWSSIP)}, title={Volumetrie Data Augmentation as an Effective Tool in MRI Classification Using 3D Convolutional Neural Network},
year={2019},
volume={},
number={},
pages={115-119},
abstract={Deep learning has become a default choice for many researchers in the areas of prediction and automatic diagnostics of different diseases. One of the prerequisites for achieving good results in the domain of an automatic diagnostics is the size and quality of the training set. One of the most serious challenges in the domain of a medical image analysis is the lack of manually annotated data. In this work, we use a relatively simple convolutional neural network to classify MRI images as either cognitively normal or those suffering from Alzheimer's disease. Based on a quantitative analysis of multiple techniques, we propose to use a specific set of data augmentation techniques to improve the generalization of the deep neural network model. The proposed approach was compared with three different approaches using the same neural network - one approach with no data augmentation, one with regularization not specific to visual data (dropout and weight decay) and one with extensive data augmentation specific for images. We conclude that by using the proposed set of augmentation techniques, including novel perturbed normalization, we postponed overfitting, which resulted in a better generalized model.},
keywords={Magnetic resonance imaging;Diseases;Training;Task analysis;Three-dimensional displays;Biological neural networks;Brain modeling;3D CNN;Alzheimer’s disease;MRI;volumetric data augmentation},
doi={10.1109/IWSSIP.2019.8787315},
ISSN={2157-8702},
month={June},}
@ARTICLE{9093026,
author={Basher, Abol and Kim, Byeong C. and Lee, Kun Ho and Jung, Ho Yub},
journal={IEEE Access}, title={Automatic Localization and Discrete Volume Measurements of Hippocampi From MRI Data Using a Convolutional Neural Network},
year={2020},
volume={8},
number={},
pages={91725-91739},
abstract={Automatic hippocampal volume measurement from brain magnetic resonance imaging (MRI) is a crucial task and an important research area, especially in the study of neurodegenerative diseases; hippocampal volume atrophy is known to be connected with Alzheimer's disease. In this research work, we propose a deep learning-based method to automatically measure the discrete hippocampal volume without prior segmentation of the volumetric MRI scans. We constructed a 2-D convolutional neural network (CNN) model that uses 3-channel 2-D patches to predict the number of voxels attributed to the hippocampus; the number of estimated hippocampal voxels is multiplied by the voxel volume to measure the discrete volume of the hippocampus. In addition, we demonstrate a preprocessing scheme to prepare the data using a relatively small number of MRI scans. The average errors in the measured volumes of the proposed approach and the compared atlas-based system were 4.3173 ± 3.5436 (avg. error% ± STD) and 4.1562 ±3.5262 (avg. error % ± STD) for the left and right hippocampi, respectively. The correlation coefficients of the proposed approach with atlas-based volume measurement were statistically significant (p-value <; 0.01, R2 = 0.834 (left hippocampus), and R2 = 0.848 (right hippocampus) based on 0.05 significance level), which suggests that the proposed approach can be used as a proxy method for the atlas-based system. Furthermore, the proposed approach is computationally efficient and requires less than 2 seconds to calculate the number of voxels for an MRI scan. Moreover, our method outperforms the state-of-the-art deep learning approach, such as 2-D U-Net and SegNet in the context of voxel/volume estimation errors% for the left and right hippocampi.},
keywords={Magnetic resonance imaging;Volume measurement;Hippocampus;Dementia;Image segmentation;Machine learning;MRI;hippocampus;patch;Hough-CNN;localization;CNN;discrete volume},
doi={10.1109/ACCESS.2020.2994388},
ISSN={2169-3536},
month={},}
@ARTICLE{8726332,
author={Ahmed, Samsuddin and Choi, Kyu Yeong and Lee, Jang Jae and Kim, Byeong C. and Kwon, Goo-Rak and Lee, Kun Ho and Jung, Ho Yub},
journal={IEEE Access}, title={Ensembles of Patch-Based Classifiers for Diagnosis of Alzheimer Diseases},
year={2019},
volume={7},
number={},
pages={73373-73383},
abstract={There is ongoing research for the automatic diagnosis of Alzheimer's disease (AD) based on traditional machine learning techniques, and deep learning-based approaches are becoming a popular choice for AD diagnosis. The state-of-the-art techniques that consider multimodal diagnosis have been shown to have accuracy better than a manual diagnosis. However, collecting data from different modalities is time-consuming and expensive, and some modalities may have radioactive side effects. Our study is confined to structural magnetic resonance imaging (sMRI). The objectives of our attempt are as follows: 1) to increase the accuracy level that is comparable to the state-of-the-art methods; 2) to overcome the overfitting problem, and; 3) to analyze proven landmarks of the brain that provide discernible features for AD diagnosis. Here, we focused specifically on both the left and right hippocampus areas. To achieve the objectives, at first, we incorporate ensembles of simple convolutional neural networks (CNNs) as feature extractors and softmax cross-entropy as the classifier. Then, considering the scarcity of data, we deployed a patch-based approach. We have performed our experiment on the Gwangju Alzheimer's and Related Dementia (GARD) cohort dataset prepared by the National Research Center for Dementia (GARD), Gwangju, South Korea. We manually localized the left and right hippocampus and fed three view patches (TVPs) to the CNN after the preprocessing steps. We achieve 90.05% accuracy. We have compared our model with the state-of-the-art methods on the same dataset they have used and found our result comparable.},
keywords={Magnetic resonance imaging;Alzheimer's disease;Biomedical imaging;Deep learning;Hippocampus;Alzheimer disease classification;ALZHEIMER disease detection;Alzheimer disease diagnosis;convolutional neural network;deep learning;machine learning;medical imaging},
doi={10.1109/ACCESS.2019.2920011},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{9313561,
author={Maryam Tavakoli, H and Xie, Tianyi and Shi, Jingyi and Hadzikadic, Mirsad and Ge, Yaorong},
booktitle={2020 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)}, title={Predicting Neural Deterioration in Patients with Alzheimer’s Disease Using a Convolutional Neural Network},
year={2020},
volume={},
number={},
pages={1951-1958},
abstract={Alzheimer's disease causes neural damage, including brain atrophy in the patient. Consequently, ventricles that contain cerebral fluid a re e xpanded to filling th oseregions, which increases the proportional volume of ventricles in the brain. Therefore, abnormal growth of ventricle volume is an important indicator for estimating neural damage and, in turn, for the progression of Alzheimer's diseases. The rate of this volumegrowth, i.e., neural damage, can be predicted by predictive and machine learning models using the patient's current status. These predictions help assess the effectiveness of a particular treatment for a patient, in addition to providing some expectation of the disease timeline. In this work, we propose a convolutional neural network (CNN) model using region-level features for predicting ventricle volume biomarkers. The region-level representation with domaindriven features benefits from the CNN spatial pattern recognition capability. It also prevents learning irrelevant features and overfitting tot he t raining d ata a s a r esult 0 fd ata scarcity. Our model is applied to the ADNI dataset in the TADPOLE competition and outperforms the best leaderboard results.},
keywords={Diseases;Biomarkers;Biological system modeling;Magnetic resonance imaging;Predictive models;Alzheimer's disease;Volume measurement;deep learning;Alzheimer’s disease;disease progression model;convolutional neural network;small data},
doi={10.1109/BIBM49941.2020.9313561},
ISSN={},
month={Dec},}
@INPROCEEDINGS{8749023,
author={Shah, Pir Masoom and Zeb, Adnan and Shafi, Uferah and Zaidi, Syed Farhan Alam and Shah, Munam Ali},
booktitle={2018 24th International Conference on Automation and Computing (ICAC)}, title={Detection of Parkinson Disease in Brain MRI using Convolutional Neural Network},
year={2018},
volume={},
number={},
pages={1-6},
abstract={Parkinson Disease (PD) is one of the most critical progressive neurological diseases which mainly affects the motor system. The accurate diagnosis of PD has been a challenge to date, mainly due to the close relevance of PD to other neurological diseases. These close characteristics are the reasons that cause 25% inaccurate manual diagnosis of PD. In this paper, we present a Convolutional Neural Network (CNN) based automatic diagnosis system which accurately classifies PD and healthy control (HC). Parkinson's Progression Markers Initiative (PPMI) provides publically available benchmark T2-weighted Magnetic Resonance Imaging (MRI) for both PD and HC. The mid-brain slices of 500, T2-weighted MRI are selected and aligned using image registration technique. The performance of the proposed technique is evaluated using accuracy, sensitivity, specificity and AUC (Area Under Curve). The detailed comparison in the result section shows that the CNN archived a better performance from 3%-9% in terms of accuracy, sensitivity, specificity, and AUC when compared to the some existing techniques.},
keywords={Magnetic resonance imaging;Feature extraction;Support vector machines;Alzheimer's disease;Training;Parkinson Disease;MRI;Deep Learning;Convolutional Neural Network;CNN},
doi={10.23919/IConAC.2018.8749023},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{8877477,
author={Bakkouri, Ibtissam and Afdel, Karim and Benois-Pineau, Jenny and Catheline, Gwenaelle},
booktitle={2019 International Conference on Content-Based Multimedia Indexing (CBMI)}, title={Recognition of Alzheimer's Disease on sMRI based on 3D Multi-Scale CNN Features and a Gated Recurrent Fusion Unit},
year={2019},
volume={},
number={},
pages={1-6},
abstract={Accurate diagnosis of Alzheimer's Disease (AD) is still a public health challenge, and has been studied for several years now to make it efficient and more automatic. In this paper, we propose a novel Computer-Aided Diagnosis (CAD) system based on 3D Multi-scale Feature (3DMF) blocks and Gated Recurrent Fusion Unit (GRFU). Hippocampal Volumes Of Interest (VOI) are used as input. The method is applied on sMRI imaging modality standard for patients screening. First, multiscale features are extracted via 3D Convolutional Neural Network (CNN). They are then taken as input to Gated Recurrent Units (GRU) for performance improvement. Extensive experiments are performed on the public Alzheimers Disease Neuroimaging Initiative (ADNI) dataset. The experimental results demonstrate that our 3DMF model combined with GRFU obtains the state-of-the-art performance compared with the existing conventional methods. Furthermore, proposed approach yields a significant enhancement in terms of avoiding high similarity between classes and overfitting issue. Hence, our proposed CAD has the potential to significantly improve the conventional recognition and classification strategies for use in clinical applications.},
keywords={Three-dimensional displays;Alzheimer's disease;Feature extraction;Logic gates;Magnetic resonance imaging;Convolutional neural networks;Alzheimer's disease;Multi-scale features;3D convolutional neural network;Gated recurrent unit},
doi={10.1109/CBMI.2019.8877477},
ISSN={1949-3991},
month={Sep.},}
@INPROCEEDINGS{8965182,
author={He, Guangyu and Ping, An and Wang, Xi and Zhu, Yufei},
booktitle={2019 10th International Conference on Information Technology in Medicine and Education (ITME)}, title={Alzheimer's Disease Diagnosis Model Based on Three-Dimensional Full Convolutional DenseNet},
year={2019},
volume={},
number={},
pages={13-17},
abstract={Dementia has become one of the major diseases causing death and disability in the elderly. Alzheimer's disease is the primary cause of dementia, and its clinical diagnosis, especially early diagnosis, is very urgent. The research on the diagnosis of Alzheimer's disease based on deep convolutional neural network has made good progress. However, it is still difficult to meet the requirements of clinical application. In clinic, most of them are structural MRI images, with limited sample size and few scanning layers. But deep learning needs enough annotated data. Aiming at the practical needs of clinical diagnosis of Alzheimer's disease, this paper proposes a increment method of dataset by weighted combination of positive and negative samples and a learning method for small number of samples, and establishes a 3D full convolutional DenseNet classification model, which can not only obtain better image feature information, but also improve the generalization ability of the model.},
keywords={Alzheimer's disease;Training;Magnetic resonance imaging;Convolutional neural networks;Solid modeling;Data models;Alzheimer's disease;artificial intelligence;medical diagnosis;deep learning;medical image analysis},
doi={10.1109/ITME.2019.00014},
ISSN={2474-3828},
month={Aug},}
@ARTICLE{8950078,
author={Choi, Jae Young and Lee, Bumshik},
journal={IEEE Signal Processing Letters}, title={Combining of Multiple Deep Networks via Ensemble Generalization Loss, Based on MRI Images, for Alzheimer's Disease Classification},
year={2020},
volume={27},
number={},
pages={206-210},
abstract={This letter proposes a novel way of using an ensemble of multiple deep convolutional neural networks (DCNNs) for Alzheimer's disease classification, based on magnetic resonance imaging (MRI) images. To create this ensemble of DCNNs, we propose to combine the use of multiple MRI projections (as input) with that of different DCNN architectures to increase the deep ensemble diversity. In particular, to find the optimal fusion weights of the DCNN members, we designed a novel deep ensemble generalization loss, which accounts for interaction and cooperation during the optimal weight search. The optimization framework, equipped with our ensemble generalization loss, was formulated and solved using the sequential quadratic programming. Through this method, we achieved optimal DCNN fusion weights (i.e., a high generalization performance). The experimental results showed that our proposed DCNN ensemble outperforms current deep learning-based methods: it is able to produce state-of-the-art results on the Alzheimer's disease neuroimaging initiative (ADNI) dataset.},
keywords={Magnetic resonance imaging;Optimization;Alzheimer's disease;Deep learning;Training;Three-dimensional displays;Alzheimer's disease classification;ensemble deep learning;generalization loss},
doi={10.1109/LSP.2020.2964161},
ISSN={1558-2361},
month={},}
@ARTICLE{8926342,
author={Wang, Mingliang and Lian, Chunfeng and Yao, Dongren and Zhang, Daoqiang and Liu, Mingxia and Shen, Dinggang},
journal={IEEE Transactions on Biomedical Engineering}, title={Spatial-Temporal Dependency Modeling and Network Hub Detection for Functional MRI Analysis via Convolutional-Recurrent Network},
year={2020},
volume={67},
number={8},
pages={2241-2252},
abstract={Early identification of dementia at the stage of mild cognitive impairment (MCI) is crucial for timely diagnosis and intervention of Alzheimer's disease (AD). Although several pioneering studies have been devoted to automated AD diagnosis based on resting-state functional magnetic resonance imaging (rs-fMRI), their performance is somewhat limited due to non-effective mining of spatial-temporal dependency. Besides, few of these existing approaches consider the explicit detection and modeling of discriminative brain regions (i.e., network hubs) that are sensitive to AD progression. In this paper, we propose a unique Spatial-Temporal convolutional-recurrent neural Network (STNet) for automated prediction of AD progression and network hub detection from rs-fMRI time series. Our STNet incorporates the spatial-temporal information mining and AD-related hub detection into an end-to-end deep learning model. Specifically, we first partition rs-fMRI time series into a sequence of overlapping sliding windows. A sequence of convolutional components are then designed to capture the local-to-global spatially-dependent patterns within each sliding window, based on which we are able to identify discriminative hubs and characterize their unique contributions to disease diagnosis. A recurrent component with long short-term memory (LSTM) units is further employed to model the whole-brain temporal dependency from the spatially-dependent pattern sequences, thus capturing the temporal dynamics along time. We evaluate the proposed method on 174 subjects with 563 rs-fMRI scans from the Alzheimer's Disease Neuroimaging Initiative (ADNI) database, with results suggesting the effectiveness of our method in both tasks of disease progression prediction and AD-related hub detection.},
keywords={Time series analysis;Convolution;Dementia;Functional magnetic resonance imaging;Brain modeling;Feature extraction;Spatial-temporal dependency;neural network;Alzheimer's disease;hub detection;resting-state functional MRI},
doi={10.1109/TBME.2019.2957921},
ISSN={1558-2531},
month={Aug},}
@INPROCEEDINGS{9011301,
author={Jabason, Emimal and Ahmad, M. Omair and Swamy, M.N.S.},
booktitle={2019 22th International Conference on Information Fusion (FUSION)}, title={Hybrid Feature Fusion Using RNN and Pre-trained CNN for Classification of Alzheimer's Disease (Poster)},
year={2019},
volume={},
number={},
pages={1-4},
abstract={The accurate classification of AD is very essential for both patient and social care, and it will be more significant once the treatment options are available to reverse the progress of the disease. The recent success of deep learning techniques has rapidly advanced the automatic classification of AD using neuroimaging biomarkers such as MRI. However, there exist two major challenges. First, training a deep convolutional neural network (CNN) from scratch relies on a large number of labeled training data to obtain high accuracy without overfitting. Second, due to high computational cost, most of the existing techniques employ 2D CNN that cannot leverage the complete spatial information; hence, it loses the inter-slice correlation. To address these limitations, we combine a recurrent neural network (RNN), specifically long short-term memory (LSTM) on top of the bottleneck layer of pre-trained DenseNet architecture, a deep CNN has already been trained on a large-scale dataset called ImageNet. In addition to the intra-slice features extracted from the deep CNN, the proposed technique exploits the inter-slice features through LSTM in order to discriminate the patients having AD and cognitively normal (CN) clinical status from the brain MRI data. Through experimental results, we show that our proposed model has better performance than state-of-the-art deep learning methods on the Open Access Series of Imaging Studies (OASIS) dataset using 5-fold cross validation.},
keywords={Feature extraction;Magnetic resonance imaging;Training;Three-dimensional displays;Dementia;Machine learning;Alzheimer's disease (AD);Magnetic resonance imaging (MRI);Transfer learning;DenseNet;Long short-term memory (LSTM);Hybrid feature fusion},
doi={},
ISSN={},
month={July},}
@INPROCEEDINGS{8803731,
author={Ge, Chenjie and Qu, Qixun and Gu, Irene Yu-Hua and Store Jakola, Asgeir},
booktitle={2019 IEEE International Conference on Image Processing (ICIP)}, title={Multiscale Deep Convolutional Networks for Characterization and Detection of Alzheimer’s Disease Using MR images},
year={2019},
volume={},
number={},
pages={789-793},
abstract={This paper addresses the issues of Alzheimer's disease (AD) characterization and detection from Magnetic Resonance Images (MRIs). Many existing AD detection methods use single-scale feature learning from brain scans. In this paper, we propose a multiscale deep learning architecture for learning AD features. The main contributions of the paper include: (a) propose a novel 3D multiscale CNN architecture for the dedicated task of AD detection; (b) propose a feature fusion and enhancement strategy for multiscale features; (c) empirical study on the impact of several settings, including two dataset partitioning approaches, and the use of multiscale and feature enhancement. Experiments were conducted on an open ADNI dataset (1198 brain scans from 337 subjects), test results have shown the effectiveness of the proposed method with test accuracy of 93.53%, 87.24% (best, average) on subject-separated dataset, and 99.44%, 98.80% (best, average) on random brain scan-partitioned dataset. Comparison with eight existing methods has provided further support to the proposed method.},
keywords={Feature extraction;Three-dimensional displays;Training;Alzheimer's disease;Magnetic resonance imaging;Testing;Alzheimer’s disease detection;MR images;multiscale features;multiscale CNN;feature fusion and enhancement},
doi={10.1109/ICIP.2019.8803731},
ISSN={2381-8549},
month={Sep.},}
@ARTICLE{9369104,
author={Lian, Chunfeng and Liu, Mingxia and Wang, Li and Shen, Dinggang},
journal={IEEE Transactions on Neural Networks and Learning Systems}, title={Multi-Task Weakly-Supervised Attention Network for Dementia Status Estimation With Structural MRI},
year={2021},
volume={},
number={},
pages={1-13},
abstract={Accurate prediction of clinical scores (of neuropsychological tests) based on noninvasive structural magnetic resonance imaging (MRI) helps understand the pathological stage of dementia (e.g., Alzheimer's disease (AD)) and forecast its progression. Existing machine/deep learning approaches typically preselect dementia-sensitive brain locations for MRI feature extraction and model construction, potentially leading to undesired heterogeneity between different stages and degraded prediction performance. Besides, these methods usually rely on prior anatomical knowledge (e.g., brain atlas) and time-consuming nonlinear registration for the preselection of brain locations, thereby ignoring individual-specific structural changes during dementia progression because all subjects share the same preselected brain regions. In this article, we propose a multi-task weakly-supervised attention network (MWAN) for the joint regression of multiple clinical scores from baseline MRI scans. Three sequential components are included in MWAN: 1) a backbone fully convolutional network for extracting MRI features; 2) a weakly supervised dementia attention block for automatically identifying subject-specific discriminative brain locations; and 3) an attention-aware multitask regression block for jointly predicting multiple clinical scores. The proposed MWAN is an end-to-end and fully trainable deep learning model in which dementia-aware holistic feature learning and multitask regression model construction are integrated into a unified framework. Our MWAN method was evaluated on two public AD data sets for estimating clinical scores of mini-mental state examination (MMSE), clinical dementia rating sum of boxes (CDRSB), and AD assessment scale cognitive subscale (ADAS-Cog). Quantitative experimental results demonstrate that our method produces superior regression performance compared with state-of-the-art methods. Importantly, qualitative results indicate that the dementia-sensitive brain locations automatically identified by our MWAN method well retain individual specificities and are biologically meaningful.},
keywords={Dementia;Magnetic resonance imaging;Feature extraction;Solid modeling;Brain modeling;Predictive models;Task analysis;Clinical score prediction;convolutional neural networks (CNNs);dementia;structural magnetic resonance imaging (MRI);weakly supervised localization.},
doi={10.1109/TNNLS.2021.3055772},
ISSN={2162-2388},
month={},}
@ARTICLE{9051688,
author={Guo, Huiming and Zeng, Weiming and Shi, Yuhu and Deng, Jin and Zhao, Le},
journal={IEEE Transactions on Neural Systems and Rehabilitation Engineering}, title={Kernel Granger Causality Based on Back Propagation Neural Network Fuzzy Inference System on fMRI Data},
year={2020},
volume={28},
number={5},
pages={1049-1058},
abstract={Granger causality (GC) is one of the most popular measures to investigate causality influence among brain regions and has been achieved significant results for exploring brain networks based on functional magnetic resonance imaging (fMRI). However, the predictors and order selection of conventional GC are based on linear models which result in such restrictions as poorly detection of nonlinearity and so on, in the application. This paper proposes a novel GC model called back propagation (BP) based kernel function Granger causality (BP_KFGC), in which symplectic geometry is used for embedding dimension and fuzzy inference system for predicting time series. The proposed method doesn't depend on the prediction of the vector auto-regression model, so that time series don't need to be wide-sense stationary as linear GC and kernel GC. In addition, it is a multivariate approach which is applicable to both linear and nonlinear systems and eliminates the effects of latent variables. The performance of the new method is evaluated and compared with linear GC, partial GC, neural network GC and kernel GC by simulated data with multiple adjustments to the nonlinearity. The results show that BP_KFGC outperforms the other four methods in detecting both linear and nonlinear causalities. Furthermore, we applied BP_KFGC to construct directed weight network (DWN) of Alzheimer's disease (AD) patients and health controls (HCs), and then nine graph-based features of DWN were used for classification by the classifier of support vector machine with radial basis kernel function. The accuracy of 95.89%, sensitivity of 93.31%, and specificity of 94.97% were achieved which may provide an auxiliary mean for the clinical diagnosis of AD.},
keywords={Time series analysis;Functional magnetic resonance imaging;Reactive power;Kernel;Predictive models;Backpropagation;Fuzzy logic;fMRI;Granger causality measurement;back propagation neural network;fuzzy inference system;kernel function;support vector machine},
doi={10.1109/TNSRE.2020.2984519},
ISSN={1558-0210},
month={May},}
@ARTICLE{9119997,
author={Guo, Haibing and Zhang, Yongjin},
journal={IEEE Access}, title={Resting State fMRI and Improved Deep Learning Algorithm for Earlier Detection of Alzheimer’s Disease},
year={2020},
volume={8},
number={},
pages={115383-115392},
abstract={The development of computerized healthcare has been powered by diagnostic imaging and machine learning techniques. In particular, recent advances in deep learning have opened a new era in support of multimedia healthcare distribution. For earlier detection of Alzheimer's disease, the study suggested the Improved Deep Learning Algorithm (IDLA) and statistically significant text information. The specific information in clinical text includes the age, sex and genes of the person and apolipoprotein E; the brain function is established using resting-state functional data (MRI) for the measurement of connectivity in the brain regions. A specialized network of autoencoders is used in earlier diagnosis to distinguish between natural aging and disorder progression. The suggested approach incorporates effectively biased neural network functionality and allows a reliable Alzheimer's disease recognition. In comparison with conventional classifiers depends on time series R-fMRI results, the proposed deep learning algorithm has improved significantly and, in the best cases, the standard deviation reduced by 45%, indicating the forecast model is more reliable and efficient in relation to conventional methodologies. The work examines the benefits of improved deep learning algorithms from recognizing high-dimensional information in healthcare and can lead to the early diagnosis and prevention of Alzheimer's disease.},
keywords={Functional magnetic resonance imaging;Alzheimer's disease;Deep learning;Data models;Brain modeling;Alzheimer’s disease;autoencoder network;improved deep learning algorithm (IDLA);R-fMRI data},
doi={10.1109/ACCESS.2020.3003424},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{8363672,
author={Gupta, Vikash and Thomopoulos, Sophia I. and Corbin, Conor K. and Rashid, Faisal and Thompson, Paul M.},
booktitle={2018 IEEE 15th International Symposium on Biomedical Imaging (ISBI 2018)}, title={FIBERNET 2.0: An automatic neural network based tool for clustering white matter fibers in the brain},
year={2018},
volume={},
number={},
pages={708-711},
abstract={The brain's white matter fiber tracts are impaired in a range of common and devastating conditions, from Alzheimer's disease to brain trauma, and in developmental disorders such as autism and neurogenetic syndromes. Many studies now examine the connectivity and microstructure of the brain's neural pathways, spurring the development of algorithms to extract and measure tracts and fiber bundles. Clustering white matter (WM) fibers, from whole-brain tractography, into anatomically meaningful bundles is still a challenging problem. Existing tract segmentation methods use atlases or regions of interest (ROI) or unsupervised spectral clustering. Even so, atlas-based segmentation does not always partition the brain into a set of recognizable fiber bundles. Deep learning techniques can be applied to automatically segment and cluster white matter fibers. Here we propose a robust approach using convolutional neural networks (CNNs) to learn shape features of the fiber bundles, which we then exploit to cluster WM fibers into bundles. In a range of tests across diverse fiber bundles, we illustrate the accuracy of our method, and its ability to suppress false positive fibers.},
keywords={Optical fiber networks;White matter;Image resolution;Imaging;Neural networks;Tools;Diseases;Fiber clustering;deep learning;CNN},
doi={10.1109/ISBI.2018.8363672},
ISSN={1945-8452},
month={April},}
@INPROCEEDINGS{8759531,
author={Song, Tzu-An and Chowdhury, Samadrita Roy and Yang, Fan and Jacobs, Heidi and Fakhri, Georges El and Li, Quanzheng and Johnson, Keith and Dutta, Joyita},
booktitle={2019 IEEE 16th International Symposium on Biomedical Imaging (ISBI 2019)}, title={Graph Convolutional Neural Networks For Alzheimer’s Disease Classification},
year={2019},
volume={},
number={},
pages={414-417},
abstract={Graph convolutional neural networks (GCNNs) aim to extend the data representation and classification capabilities of convolutional neural networks, which are highly effective for signals defined on regular Euclidean domains, e.g. image and audio signals, to irregular, graph-structured data defined on non-Euclidean domains. Graph-theoretic tools that enable us to study the brain as a complex system are of great significance in brain connectivity studies. Particularly, in the context of Alzheimer's disease (AD), a neurodegenerative disorder associated with network dysfunction, graph-based tools are vital for disease classification and staging. Here, we implement and test a multi-class GCNN classifier for network-based classification of subjects on the AD spectrum into four categories: cognitively normal, early mild cognitive impairment, late mild cognitive impairment, and AD. We train and validate the network using structural connectivity graphs obtained from diffusion tensor imaging data. Using receiver operating characteristic curves, we show that the GCNN classifier outperforms a support vector machine classifier by margins that are reliant on disease category. Our findings indicate that the performance gap between the two methods increases with disease progression from CN to AD. We thus demonstrate that GCNN is a competitive tool for staging and classification of subjects on the AD spectrum.},
keywords={Alzheimer's disease;Support vector machines;Convolution;Diffusion tensor imaging;Convolutional neural networks;Training;Graph CNN;convolutional neural network;Alzheimer’s disease;classification},
doi={10.1109/ISBI.2019.8759531},
ISSN={1945-8452},
month={April},}
@INPROCEEDINGS{9098638,
author={Zhang, Lu and Wang, Li and Zhu, Dajiang},
booktitle={2020 IEEE 17th International Symposium on Biomedical Imaging (ISBI)}, title={Jointly Analyzing Alzheimer's Disease Related Structure-Function Using Deep Cross-Model Attention Network},
year={2020},
volume={},
number={},
pages={563-567},
abstract={Reversing the pathology of Alzheimer's disease (AD) has so far not been possible, a more tractable way may be having the intervention in its earlier stage, such as mild cognitive impairment (MCI) which is considered as the precursor of AD. Recent advances in deep learning have triggered a new era in AD/MCI classification and a variety of deep models and algorithms have been developed to classify multiple clinical groups (e.g. aged normal control - CN vs. MCI) and AD conversion. Unfortunately, it is still largely unknown what is the relationship between the altered functional connectivity and structural connectome at individual level. In this work, we introduced a deep cross-model attention network (DCMAT) to jointly model brain structure and function. Specifically, DCMAT is composed of one RNN (Recurrent Neural Network) layer and multiple graph attention (GAT) blocks, which can effectively represent disease-specific functional dynamics on individual structural network. The designed attention layer (in GAT block) aims to learn deep relations among different brain regions when differentiating MCI from CN. The proposed DCMAT shows promising classification performance compared to recent studies. More importantly, our results suggest that the MCI related functional interactions might go beyond the directly connected brain regions.},
keywords={Brain modeling;Dementia;Correlation;Recurrent neural networks;Functional magnetic resonance imaging;Attention;Alzheimer's disease;GAT},
doi={10.1109/ISBI45749.2020.9098638},
ISSN={1945-8452},
month={April},}
@ARTICLE{8412492,
author={Pan, Xiaoxi and Adel, Mouloud and Fossati, Caroline and Gaidon, Thierry and Guedj, Eric},
journal={IEEE Journal of Biomedical and Health Informatics}, title={Multilevel Feature Representation of FDG-PET Brain Images for Diagnosing Alzheimer's Disease},
year={2019},
volume={23},
number={4},
pages={1499-1506},
abstract={Using a single imaging modality to diagnose Alzheimer's disease (AD) or mild cognitive impairment (MCI) is a challenging task. FluoroDeoxyGlucose Positron Emission Tomography (FDG-PET) is an important and effective modality used for that purpose. In this paper, we develop a novel method by using single modality (FDG-PET) but multilevel feature, which considers both region properties and connectivities between regions to classify AD or MCI from normal control. First, three levels of features are extracted: statistical, connectivity, and graph-based features. Then, the connectivity features are decomposed into three different sets of features according to a proposed similarity-driven ranking method, which can not only reduce the feature dimension but also increase the classifier's diversity. Last, after feeding the three levels of features to different classifiers, a new classifier selection strategy, maximum Mean squared Error (mMsE), is developed to select a pair of classifiers with high diversity. In order to do the majority voting, a decision-making scheme, a nested cross validation technique is applied to choose another classifier according to the accuracy. Experiments on Alzheimer's Disease Neuroimaging Initiative database show that the proposed method outperforms most FDG-PET-based classification algorithms, especially for classifying progressive MCI (pMCI) from stable MCI (sMCI).},
keywords={Feature extraction;Dementia;Magnetic resonance imaging;Neuroimaging;Informatics;Alzheimer's disease (AD);ensemble classification;FDG-PET;multilevel feature representation},
doi={10.1109/JBHI.2018.2857217},
ISSN={2168-2208},
month={July},}
@ARTICLE{8463559,
author={Liu, Mingxia and Zhang, Jun and Adeli, Ehsan and Shen, Dinggang},
journal={IEEE Transactions on Biomedical Engineering}, title={Joint Classification and Regression via Deep Multi-Task Multi-Channel Learning for Alzheimer's Disease Diagnosis},
year={2019},
volume={66},
number={5},
pages={1195-1206},
abstract={In the field of computer-aided Alzheimer's disease (AD) diagnosis, jointly identifying brain diseases and predicting clinical scores using magnetic resonance imaging (MRI) have attracted increasing attention since these two tasks are highly correlated. Most of existing joint learning approaches require hand-crafted feature representations for MR images. Since hand-crafted features of MRI and classification/regression models may not coordinate well with each other, conventional methods may lead to sub-optimal learning performance. Also, demographic information (e.g., age, gender, and education) of subjects may also be related to brain status, and thus can help improve the diagnostic performance. However, conventional joint learning methods seldom incorporate such demographic information into the learning models. To this end, we propose a deep multi-task multi-channel learning (DM2L) framework for simultaneous brain disease classification and clinical score regression, using MRI data and demographic information of subjects. Specifically, we first identify the discriminative anatomical landmarks from MR images in a data-driven manner, and then extract multiple image patches around these detected landmarks. We then propose a deep multi-task multi-channel convolutional neural network for joint classification and regression. Our DM2L framework can not only automatically learn discriminative features for MR images, but also explicitly incorporate the demographic information of subjects into the learning process. We evaluate the proposed method on four large multi-center cohorts with 1984 subjects, and the experimental results demonstrate that DM2 L is superior to several state-of-the-art joint learning methods in both the tasks of disease classification and clinical score regression.},
keywords={Task analysis;Feature extraction;Magnetic resonance imaging;Dementia;Convolutional neural networks;Education;Anatomical landmark;brain disease diagnosis;classification;convolutional neural network (CNN);regression},
doi={10.1109/TBME.2018.2869989},
ISSN={1558-2531},
month={May},}
@INPROCEEDINGS{9074422,
author={Manokar, Vigneshwar and Balaji, R. and Nandhini, V.M. and Shankar, S. and Patnaik, L.M.},
booktitle={2020 6th International Conference on Advanced Computing and Communication Systems (ICACCS)}, title={Wavelet Decomposition and Classification of Diseased fMRI Brain Images Using Self Organized Maps},
year={2020},
volume={},
number={},
pages={1342-1348},
abstract={There are many solutions for detection and classification and classification of dementia into its corresponding patterns using PET, SPECT, MRI, fMRI addressing to the classification based on the patterns. They are classified based on the corresponding diseased and Non-diseased Syndrome types. Here in this scope, solution anticipated to the inter- related disease with Picks Syndrome (PD) and Alzheimers Disease Syndrome (AD). The image data sets implied her are the functional Magnetic Resonance Images. The images become very contrasting based on many parameters - capturing intensity, noise content, geographical locations, Image acquisition based on the different corporate machines, capability of the Radiologist, the moment during the motion capturing, patient nature, etc., and hence many more features that comes into the account. Ultimately this effects the intensity and the noise level imposed during the motion capturing. A Daubechies Wavelet Transform is implied here. Its properties are: 1) Smoothening filters 2) extraction of frequency (feature) components 3) Median filter - removing the random noises better. A fourth level of extraction of features using the Wavelet Decomposition by Daubechies type was implied for formation of the feature vectors. From the sub-band regions of H-H level order with fourth level of decomposition level which will have high resolution was chosen for this act. Other have low-high combinatory, and fourth band has low - low combination which are very difficult to pick up the resolution points. This obtained features were implied for feature vector formation. The extraction of the features was obtained from the approximated co-efficients got from the Approximated sub-band levels thus chosen to form the input images and extracted co-efficients were fed to design, train and test the network for convergence, network framing and efficiency estimation respectively. A Self Organizing Map technique was chosen for designing up of the network using the Competitive Neural Network. This was used to classify the normal and Dementia based image types into its corresponding types. This enables a good proviso for designing up of the network and also provides efficiency in convergence of the network, classification of the two types of diseases and also in classification of the disease types into its individual inter dependent types such as Demential and Non-Demential types.},
keywords={Dementia;Feature extraction;Proteins;Functional magnetic resonance imaging;Mood;Alzheimers' Diseaase - AD;Pick's disease -PD;Self - Organized Maps - SOM;Artificial Neural Network - ANN;Self-Organized Feature Maps - SOFM;Discrete Wavelet Transform - DWT;Daubechies Wavelet - DW;functional Magnetic Resonance Image-fMRI},
doi={10.1109/ICACCS48705.2020.9074422},
ISSN={2575-7288},
month={March},}
@ARTICLE{7827160,
author={Shi, Jun and Zheng, Xiao and Li, Yan and Zhang, Qi and Ying, Shihui},
journal={IEEE Journal of Biomedical and Health Informatics}, title={Multimodal Neuroimaging Feature Learning With Multimodal Stacked Deep Polynomial Networks for Diagnosis of Alzheimer's Disease},
year={2018},
volume={22},
number={1},
pages={173-183},
abstract={The accurate diagnosis of Alzheimer's disease (AD) and its early stage, i.e., mild cognitive impairment, is essential for timely treatment and possible delay of AD. Fusion of multimodal neuroimaging data, such as magnetic resonance imaging (MRI) and positron emission tomography (PET), has shown its effectiveness for AD diagnosis. The deep polynomial networks (DPN) is a recently proposed deep learning algorithm, which performs well on both large-scale and small-size datasets. In this study, a multimodal stacked DPN (MM-SDPN) algorithm, which MM-SDPN consists of two-stage SDPNs, is proposed to fuse and learn feature representation from multimodal neuroimaging data for AD diagnosis. Specifically speaking, two SDPNs are first used to learn high-level features of MRI and PET, respectively, which are then fed to another SDPN to fuse multimodal neuroimaging information. The proposed MM-SDPN algorithm is applied to the ADNI dataset to conduct both binary classification and multiclass classification tasks. Experimental results indicate that MM-SDPN is superior over the state-of-the-art multimodal feature-learning-based algorithms for AD diagnosis.},
keywords={Neuroimaging;Feature extraction;Classification algorithms;Magnetic resonance imaging;Prediction algorithms;Diseases;Positron emission tomography;Alzheimer's disease;deep learning;deep polynomial networks;multimodal stacked deep polynomial networks;multimodal neuroimaging},
doi={10.1109/JBHI.2017.2655720},
ISSN={2168-2208},
month={Jan},}
@INPROCEEDINGS{8512231,
author={Kim, Donghyeon and Kim, Kiseon},
booktitle={2018 40th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)}, title={Detection of Early Stage Alzheimer’s Disease using EEG Relative Power with Deep Neural Network},
year={2018},
volume={},
number={},
pages={352-355},
abstract={Electroencephalogram (EEG) signal based early diagnosis of Alzheimer's Disease (AD), especially a discrimination between healthy control (HC) and mild cognitive impairment (MCI) has received remarkable attentions to complement conventional diagnosing methods in clinical fields. A relative power (RP) metric which quantifies the abnormal EEG pattern 'slowing' has widely been used as a major feature to distinguish HC and MCI, however, the optimal spectral ranges of the RP are influenced by the given dataset. In this study, we proposed the deep neural network based classifier using the RP to fully exploit and recombine the features through its own learning structure. The DNN enhanced the diagnosis results compared to shallow neural network, and enabled to interpret the results as we used the wellknown RP features as the domain knowledge. We investigated and explored the potentials of DNN based detection of the earlystage AD.},
keywords={Electroencephalography;Feature extraction;Dementia;Biological neural networks},
doi={10.1109/EMBC.2018.8512231},
ISSN={1558-4615},
month={July},}
@INPROCEEDINGS{8687207,
author={Yue, Lulu and Gong, Xiaoliang and Chen, Kaibo and Mao, Mingze and Li, Jie and Nandi, Asoke K. and Li, Maozhen},
booktitle={2018 14th International Conference on Natural Computation, Fuzzy Systems and Knowledge Discovery (ICNC-FSKD)}, title={Auto-Detection of Alzheimer's Disease Using Deep Convolutional Neural Networks},
year={2018},
volume={},
number={},
pages={228-234},
abstract={Alzheimer's disease(AD) is a kind of progressive neurodegenerative disease. One who is diagnosed as an Alzheimer's disease patient may has many symptoms, such as deterioration of memory and language. Once those symptoms was noticed, they usually can survive 4 to 20 years. So far, Alzheimer's disease has become the sixth leading cause of death, and it has become a worldwide health and social challenge. Traditional methods of diagnosing AD and mild cognitive impairment(MCI), mostly depend on capturing features from variable modalities of brain image data. It is a big challenge to pick out the MCI from normal controller (NC) and AD, especially for those who are lacking experience. In this article, we employ deep convolutional neural network (DCNN) to extract the most useful features of the structural magnetic resonance imaging (MRI). Firstly, the structural MRls are pre-processed in a strict pipeline. Then, instead of parcellating regions of interest, we re-slice each volume, and put the resliced images into a DCNN directly. Finally, four stages of Alzheimer's are identified, and the average accuracy is 94.5% for NC versus LMCI, 96.9% for NC versus AD, 97.2% for LMCI and AD, 97.81 % for EMCI versus AD, 94.8% for LMCI versus EMCI. The results show that the DCNN outperforms existing methods.},
keywords={Deep Learning;Alzheimer's Disease;MRI;Early Diagnose},
doi={10.1109/FSKD.2018.8687207},
ISSN={},
month={July},}
@INPROCEEDINGS{8363833,
author={Cui, Ruoxuan and Liu, Manhua and Li, Gang},
booktitle={2018 IEEE 15th International Symposium on Biomedical Imaging (ISBI 2018)}, title={Longitudinal analysis for Alzheimer's disease diagnosis using RNN},
year={2018},
volume={},
number={},
pages={1398-1401},
abstract={Alzheimer's disease (AD) is a kind of neurodegenerative disorder with progressive impairment of memory and cognitive functions. Structural magnetic resonance images (MRI) is widely used as an important imaging modality for AD diagnosis. Most of existing methods for MRI classification are based on image data of single time point. However, the longitudinal analysis of sequential MR images is also important to model and measure the progression of the disease along the time axis. In this paper, we present a classification framework based on combination of Multi-Layer Perceptron (MLP) neural network and Recurrent Neural Networks (RNN) for longitudinal analysis of MR images for AD diagnosis. First, MLP is constructed to learn the spatial features of MR images with the task of AD classification. After that, RNN with cascaded two bidirectional gated recurrent units (BGRU) layers is trained on the MLP outputs for extracting the longitudinal features from the imaging data of multiple time points, providing a final classification predicting score. The proposed method can automatically learn the spatial and longitudinal features from the imaging data of multiple time points with variable length for classification. Our method is evaluated using T1-weighted structural MR images on 428 subjects including 198 AD patients and 229 normal controls (NC) from Alzheimer's Disease Neuroimaging Initiative (ADNI) database. Experimental results show the proposed method achieves an accuracy of 89.7% for AD classification, demonstrating the promising classification performance.},
keywords={Feature extraction;Time series analysis;Training;Logic gates;Data models;Diseases;Computational modeling;Alzheimer's disease;longitudinal study;Convolutional neural network;Recurrent neural network;Deep learning},
doi={10.1109/ISBI.2018.8363833},
ISSN={1945-8452},
month={April},}
@ARTICLE{8737996,
author={Martinez-Murcia, Francisco J. and Ortiz, Andres and Gorriz, Juan-Manuel and Ramirez, Javier and Castillo-Barnes, Diego},
journal={IEEE Journal of Biomedical and Health Informatics}, title={Studying the Manifold Structure of Alzheimer's Disease: A Deep Learning Approach Using Convolutional Autoencoders},
year={2020},
volume={24},
number={1},
pages={17-26},
abstract={Many classical machine learning techniques have been used to explore Alzheimer's disease (AD), evolving from image decomposition techniques such as principal component analysis toward higher complexity, non-linear decomposition algorithms. With the arrival of the deep learning paradigm, it has become possible to extract high-level abstract features directly from MRI images that internally describe the distribution of data in low-dimensional manifolds. In this work, we try a new exploratory data analysis of AD based on deep convolutional autoencoders. We aim at finding links between cognitive symptoms and the underlying neurodegeneration process by fusing the information of neuropsychological test outcomes, diagnoses, and other clinical data with the imaging features extracted solely via a data-driven decomposition of MRI. The distribution of the extracted features in different combinations is then analyzed and visualized using regression and classification analysis, and the influence of each coordinate of the autoencoder manifold over the brain is estimated. The imaging-derived markers could then predict clinical variables with correlations above 0.6 in the case of neuropsychological evaluation variables such as the MMSE or the ADAS11 scores, achieving a classification accuracy over 80% for the diagnosis of AD.},
keywords={Feature extraction;Magnetic resonance imaging;Manifolds;Alzheimer's disease;Computer architecture;Deep learning;Alzheimer's disease;deep learning;convolutional autoencoder;manifold learning;data fusion},
doi={10.1109/JBHI.2019.2914970},
ISSN={2168-2208},
month={Jan},}
@INPROCEEDINGS{8614243,
author={Forouzannezhad, Parisa and Abbaspour, Alireza and Li, Chunfei and Cabrerizo, Mercedes and Adjouadi, Malek},
booktitle={2018 17th IEEE International Conference on Machine Learning and Applications (ICMLA)}, title={A Deep Neural Network Approach for Early Diagnosis of Mild Cognitive Impairment Using Multiple Features},
year={2018},
volume={},
number={},
pages={1341-1346},
abstract={Alzheimer's disease (AD) is the most prevalent neurodegenerative disease that is progressive and can be characterized mostly by neuronal atrophy, amyloid deposition, accompanied by cognition, behavioral and psychological deficits. In the recent decade, a variety of machine learning algorithms have been explored and used for AD diagnosis, focusing on its subtle prodromal stage of mild cognitive impairment (MCI) to assess essential features that characterize its early manifestation and to plan for early treatment. However, diagnosis of early MCI (EMCI) remains most challenging as it is extremely difficult to delineate from cognitively normal controls (CN), and as a consequence, most of the classification algorithms for these two groups are mixed with low classification accuracy results. In this study, a machine learning approach based on deep neural network (DNN) has been proposed in order to detect AD in its early stage using multimodal imaging, combining magnetic resonance imaging (MRI), positron emission tomography (PET) and standard neuropsychological test scores. The proposed approach makes use of the optimization method of Adam to update the learning weights in order to improve its accuracy. The algorithm is able to classify cognitively normal control group from EMCI with an unprecedented accuracy of 84.0%. Although the focus here is distinguishing the two groups of CN and EMCI for early diagnosis and treatment planning, this study also shows how the proposed deep learning algorithm can be extended for multiclass classification involving CN and all the stages of EMCI, late MCI (LMCI) and AD.},
keywords={Conferences;Machine learning;Artificial Intelligence;Deep Neural Network;MRI;PET;EMCI;Alzheimer's Disease},
doi={10.1109/ICMLA.2018.00218},
ISSN={},
month={Dec},}
@ARTICLE{9104657,
author={Ramzan, Farheen and Khan, Muhammad Usman Ghani and Iqbal, Sajid and Saba, Tanzila and Rehman, Amjad},
journal={IEEE Access}, title={Volumetric Segmentation of Brain Regions From MRI Scans Using 3D Convolutional Neural Networks},
year={2020},
volume={8},
number={},
pages={103697-103709},
abstract={Automated brain segmentation is an active research domain due to the association of various neurological disorders with different regions of the brain, to help medical professionals in prognostics and diagnostics. Traditional techniques like atlas-based and pattern recognition-based methods led to the development of various tools for automated brain segmentation. Recently, deep learning techniques are outperforming classical state-of-the-art methods and gradually becoming more mature. Consequently, deep learning has been extensively employed as a tool for precise segmentation of brain regions because of its capability to learn the intricate features of the high-dimensional data. In this work, a network for the segmentation of multiple brain regions has been proposed that is based on 3D convolutional neural networks and utilizes residual learning and dilated convolution operations to efficiently learn the end-to-end mapping from MRI volumes to the voxel-level brain segments. This research is focused on the segmentation of up to nine brain regions including cerebrospinal fluid, white matter and gray matter as well as their sub-regions. Mean dice scores of 0.879 and 0.914 have been achieved for three and nine brain regions, respectively by using the data from three different sources. Comparative analysis shows that our network gives better dice scores for most of the brain regions than state-of-the-artwork. Moreover, the mean dice score of 0.903, obtained for eight brain regions segmentation with MRBrains18 dataset, is better than 0.876 which was achieved in the previous work.},
keywords={Image segmentation;Three-dimensional displays;Deep learning;Magnetic resonance imaging;Task analysis;Two dimensional displays;Biomedical imaging;Brain segmentation;convolutional neural networks;magnetic resonance imaging;volumetric segmentation},
doi={10.1109/ACCESS.2020.2998901},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{9364155,
author={Zaabi, Marwa and Smaoui, Nadia and Derbel, Houda and Hariri, Walid},
booktitle={2020 17th International Multi-Conference on Systems, Signals Devices (SSD)}, title={Alzheimer's disease detection using convolutional neural networks and transfer learning based methods},
year={2020},
volume={},
number={},
pages={939-943},
abstract={Alzheimer's disease (AD) remains a major public health problem. This neurodegenerative pathology affects generally old people. Its symptoms are loss of memory followed over the years by more hard ability of expression and various handicaps. Therefore, early detection of AD is become an active research area in recent years. In this paper, we propose a deep based method for the detection of AD (i.e. classify brain images into normal brain or brain with AD). The proposed method contains two main steps. The first step is region of interest extraction; it is based on the partition of the image into separate blocks to extract only the part that contains the hippocampus of the brain. The second step is the classification of images using two deep based techniques namely convolutional neural network (CNN) and Transfer Learning. In one hand, CNN allows extracting the characteristics from brain images, then classifies them into normal brain or AD brain. Transfer Learning, in the other hand, consists of using features acquired from the Alexnet architecture to classify the images. We have assessed the proposed method on Oasis dataset (Open Access Series of Imaging Studies). The obtained results show that the classification of images using Transfer Learning with 92.86 % outperformed the CNN's classification rate.},
keywords={Brain;Quantization (signal);Transfer learning;Convolutional neural networks;Alzheimer's disease;Public healthcare;Hippocampus;Alzheimer's disease;Region of interest;Classification;Convolutional neural network;Transfer Learning;Alexnet},
doi={10.1109/SSD49366.2020.9364155},
ISSN={2474-0446},
month={July},}
@ARTICLE{8318637,
author={Garali, Imène and Adel, Mouloud and Bourennane, Salah and Guedj, Eric},
journal={IEEE Journal of Translational Engineering in Health and Medicine}, title={Histogram-Based Features Selection and Volume of Interest Ranking for Brain PET Image Classification},
year={2018},
volume={6},
number={},
pages={1-12},
abstract={Positron emission tomography (PET) is a molecular medical imaging modality which is commonly used for neurodegenerative diseases diagnosis. Computer-aided diagnosis, based on medical image analysis, could help quantitative evaluation of brain diseases such as Alzheimer's disease (AD). A novel method of ranking the effectiveness of brain volume of interest (VOI) to separate healthy control from AD brains PET images is presented in this paper. Brain images are first mapped into anatomical VOIs using an atlas. Histogram-based features are then extracted and used to select and rank VOIs according to the area under curve (AUC) parameter, which produces a hierarchy of the ability of VOIs to separate between groups of subjects. The top-ranked VOIs are then input into a support vector machine classifier. The developed method is evaluated on a local database image and compared to the known selection feature methods. Results show that using AUC outperforms classification results in the case of a two group separation.},
keywords={Feature extraction;Positron emission tomography;Support vector machines;Dementia;Brain;Machine learning;computer-aided diagnosis;first order statistics;feature selection;positron emission tomography;classification;Alzheimer’s disease},
doi={10.1109/JTEHM.2018.2796600},
ISSN={2168-2372},
month={},}
@INPROCEEDINGS{9290616,
author={Ebrahimi, Amir and Luo, Suhuai and Chiong, Raymond},
booktitle={2020 35th International Conference on Image and Vision Computing New Zealand (IVCNZ)}, title={Introducing Transfer Learning to 3D ResNet-18 for Alzheimer’s Disease Detection on MRI Images},
year={2020},
volume={},
number={},
pages={1-6},
abstract={This paper focuses on detecting Alzheimer's Disease (AD) using the ResNet-18 model on Magnetic Resonance Imaging (MRI). Previous studies have applied different 2D Convolutional Neural Networks (CNNs) to detect AD. The main idea being to split 3D MRI scans into 2D image slices, so that classification can be performed on the image slices independently. This idea allows researchers to benefit from the concept of transfer learning. However, 2D CNNs are incapable of understanding the relationship among 2D image slices in a 3D MRI scan. One solution is to employ 3D CNNs instead of 2D ones. In this paper, we propose a method to utilise transfer learning in 3D CNNs, which allows the transfer of knowledge from 2D image datasets to a 3D image dataset. Both 2D and 3D CNNs are compared in this study, and our results show that introducing transfer learning to a 3D CNN improves the accuracy of an AD detection system. After using an optimisation method in the training process, our approach achieved 96.88% accuracy, 100% sensitivity, and 93.75% specificity.},
keywords={Training;Solid modeling;Three-dimensional displays;Magnetic resonance imaging;Computational modeling;Two dimensional displays;Diseases;Alzheimer’s Disease;Convolutional Neural Networks;ResNet;MRI;Transfer learning;Taguchi},
doi={10.1109/IVCNZ51579.2020.9290616},
ISSN={2151-2205},
month={Nov},}
@ARTICLE{8540939,
author={Cui, Ruoxuan and Liu, Manhua},
journal={IEEE Journal of Biomedical and Health Informatics}, title={Hippocampus Analysis by Combination of 3-D DenseNet and Shapes for Alzheimer's Disease Diagnosis},
year={2019},
volume={23},
number={5},
pages={2099-2107},
abstract={Hippocampus is one of the first involved regions in Alzheimer's disease (AD) and mild cognitive impairment (MCI), a prodromal stage of AD. Hippocampal atrophy is a validated, easily accessible, and widely used biomarker for AD diagnosis. Most of existing methods compute the shape and volume features for hippocampus analysis using structural magnetic resonance images (MRI). However, the regions adjacent to hippocampus may be relevant to AD, and the visual features of the hippocampal region are important for disease diagnosis. In this paper, we have proposed a new hippocampus analysis method to combine the global and local features of hippocampus by three-dimensional densely connected convolutional networks and shape analysis for AD diagnosis. The proposed method can make use of the local visual and global shape features to enhance the classification. Tissue segmentation and nonlinear registration are not required in the proposed method. Our method is evaluated with the T1-weighted structural MRIs from 811 subjects including 192 AD, 396 MCI (231 stable MCI and 165 progressive MCI), and 223 normal control in Alzheimer's disease neuroimaging initiative database. Experimental results show the proposed method achieves a classification accuracy of 92.29% and area under the ROC curve of 96.95% for AD diagnosis. Results comparison demonstrates the proposed method performs better than other methods.},
keywords={Hippocampus;Three-dimensional displays;Shape;Magnetic resonance imaging;Diseases;Feature extraction;Alzheimer's disease;hippocampus;3D densenet;deep learning;structural magnetic resonance image},
doi={10.1109/JBHI.2018.2882392},
ISSN={2168-2208},
month={Sep.},}
@INPROCEEDINGS{9058417,
author={Ismail, Mohamed and Hofmann, Klaus and El Ghany, Mohamed A. Abd},
booktitle={2019 IEEE Global Conference on Internet of Things (GCIoT)}, title={Early Diagnoses of Alzheimer using EEG data and Deep Neural Networks classification},
year={2019},
volume={},
number={},
pages={1-5},
abstract={Alzheimer's disease has always been a challenge to be detected at early stages as it has always been mistaken as normal aging. It can be recognized when the patient starts to have Mild Cognitive Impairment (MCI) and by that stage, only little can be done as no treatment can reverse its effect but only to delay its progression. In this work, we present a method for early diagnoses of AD by creating a low-cost EEG device along with using a deep neural network that can classify the suspected patients into three classes: MCI patients, AD patients, and healthy patients. This is done using collecting brain wave signals using Electroencephalography (EEG) device during a 3 level N-Back working memory test. This is called event-related potential (ERP), later the data will be cut into small frames, FFT transformed to extract brainwave subbands (theta, alpha, and beta) and then projected to 2D images where it will be used in training convolution neural network for classification. Early detection of Alzheimer will reduce the progression of AD at early stages. We implement and evaluate our hardware and classification with an accuracy of 90.36% for MCI and 92.52% for Alzheimer's disease detection.},
keywords={Electroencephalography;Electrodes;Alzheimer's disease;Instruments;Hardware;Active filters;Alzheimer;Mild Cognitive impairment;early detection;Electroneuronography;Hardware;N-Back Test;Convolutional Neural Network;classification},
doi={10.1109/GCIoT47977.2019.9058417},
ISSN={},
month={Dec},}
@INPROCEEDINGS{8363543,
author={Bäckström, Karl and Nazari, Mahmood and Gu, Irene Yu-Hua and Jakola, Asgeir Store},
booktitle={2018 IEEE 15th International Symposium on Biomedical Imaging (ISBI 2018)}, title={An efficient 3D deep convolutional network for Alzheimer's disease diagnosis using MR images},
year={2018},
volume={},
number={},
pages={149-153},
abstract={Automatic extraction of features from MRI brain scans and diagnosis of Alzheimer's Disease (AD) remain a challenging task. In this paper, we propose an efficient and simple three-dimensional convolutional network (3D ConvNet) architecture that is able to achieve high performance for detection of AD on a relatively large dataset. The proposed 3D ConvNet consists of five convolutional layers for feature extraction, followed by three fully-connected layers for AD/NC classification. The main contributions of the paper include: (a) propose a novel and effective 3D ConvNet architecture; (b) study the impact of hyper-parameter selection on the performance of AD classification; (c) study the impact of pre-processing; (d) study the impact of data partitioning; (e) study the impact of dataset size. Experiments conducted on an ADNI dataset containing 340 subjects and 1198 MRI brain scans have resulted good performance (with the test accuracy of 98.74%, 100% AD detection rate and 2,4% false alarm). Comparisons with 7 existing state-of-the-art methods have provided strong support to the robustness of the proposed method.},
keywords={Three-dimensional displays;Magnetic resonance imaging;Feature extraction;Training;Machine learning;Robustness;Dementia;Alzheimer's disease detection;3D deep convolutional networks;automatic feature learning;deep learning;computer-aided diagnosis;MR imaging},
doi={10.1109/ISBI.2018.8363543},
ISSN={1945-8452},
month={April},}
@ARTICLE{9335007,
author={Song, Xiaofan and Mao, Mingyi and Qian, Xiaohua},
journal={IEEE Journal of Biomedical and Health Informatics}, title={Auto-Metric Graph Neural Network Based on a Meta-learning Strategy for the Diagnosis of Alzheimer's disease},
year={2021},
volume={},
number={},
pages={1-1},
abstract={Alzheimer's disease (AD) is the most common cognitive disorder. In recent years, many computer-aided diagnosis techniques have been proposed for AD diagnosis and progression predictions. Among them, graph neural networks (GNNs) have received extensive attention owing to their ability to effectively fuse multimodal features and model the correlation between samples. However, many GNNs for node classification use an entire dataset to construct a large fixed-graph structure, which cannot be used for independent testing. To overcome this limitation while maintaining the advantages of the GNN, we propose an auto-metric GNN (AMGNN) model for AD diagnosis. First, a metric-based meta-learning strategy is introduced to realize inductive learning for independent testing through multiple node classification tasks. In the meta-tasks, the small graphs help make the model insensitive to the sample size, thus improving the performance under small sample size conditions. Furthermore, an AMGNN layer with a probability constraint is designed to realize node similarity metric learning and effectively fuse multimodal data. We verified the model on two tasks based on the TADPOLE dataset: early AD diagnosis and mild cognitive impairment (MCI) conversion prediction. Our model provides excellent performance on both tasks with accuracies of 94.44% and 87.50% and median accuracies of 94.19% and 86.25%, respectively. These results show that our model improves flexibility while ensuring a good classification performance, thus promoting the development of graph-based deep learning algorithms for disease diagnosis.},
keywords={Task analysis;Diseases;Magnetic resonance imaging;Graph neural networks;Testing;Training;Predictive models;Alzheimer's disease;Early diagnosis;Conversion prediction;Graph neural network;Meta-learning},
doi={10.1109/JBHI.2021.3053568},
ISSN={2168-2208},
month={},}
@INPROCEEDINGS{9182970,
author={Liu, Haohui and Nai, Ying-Hwey and Chen, Christopher and Reilhac, Anthonin},
booktitle={2020 IEEE 33rd International Symposium on Computer-Based Medical Systems (CBMS)}, title={Deep Learning-Based Estimation of Non-Specific Uptake in Amyloid-PET Images from Structural MRI for Improved Quantification of Amyloid Load in Alzheimer's Disease},
year={2020},
volume={},
number={},
pages={573-578},
abstract={Methods like PET imaging which use radiotracers that bind to amyloid-β (Aβ) - plaques that accumulate and lead to Alzheimer's disease (AD) - are crucial to detect AD early. However, current semi-quantitative methods that quantify Aβ using the Standardized Uptake Values Ratio (SUVr) cannot distinguish between the specific binding of radiotracers to Aβ and non-specific binding to other targets. In this paper, we propose a novel method to predict non-specific binding from MR images using deep learning by developing a novel conditional Generative Adversarial Network (cGAN) to improve Aβ quantification. PET images with low amyloid load were selected to represent non-specific uptake of the Aβ [11C]PiB radiotracer. Paired MR and PET images with low amyloid load were used for training, with the MRI image as the network input and the PET image as the training label. The cGAN was trained to learn the mapping between the MR image and the non-specific PET image. The generated non-specific PET images were compared to the real PET scans, achieving a mean SUVr difference of 1.90% in the gray matter. The small SUVr difference indicated that we have successfully developed cGAN for predicting the non-specific uptake of PET and that deep learning can be used to estimate the non-specific binding of Aβ PET radiotracer from MR images.},
keywords={Training;Generators;Positron emission tomography;White matter;Diseases;Grey matter;Alzheimer's Disease;Amyloid PET;Quantification;Deep Learning;Non-Specific Uptake},
doi={10.1109/CBMS49503.2020.00114},
ISSN={2372-9198},
month={July},}
@INPROCEEDINGS{9071592,
author={Wen, Dong and Wei, Zhenhao and Zhou, Yanhong and Bian, Zhijie and Yin, Shimin},
booktitle={2019 IEEE International Conference on Computational Intelligence and Virtual Environments for Measurement Systems and Applications (CIVEMSA)}, title={Classification of ERP Signals from Mild Cognitive Impairment Patients with Diabetes using Dual Input Encoder Convolutional Neural Network},
year={2019},
volume={},
number={},
pages={1-4},
abstract={Mild Cognitive Impairment (MCI) is the early stage of Alzheimers Disease (AD), which is an irreversible neurological disease. Type II diabetes is also closely related to brain recognition, so it is extremely necessary to diagnose the patient's cognition as early as possible. Among them, the event-related potential (ERP) based on electroencephalogram (EEG) is an important research method. In order to diagnose the disease more accurately, machine learning has been widely used. However, deep learning still has a broad application space. Convolutional neural networks (CNN) is high-performance model for deep learning. In this study, we constructed a Daul input encoder convolutional neural network (DIE-CNN) for event related potential (ERP) data with type 2 diabetes. In experiments with multiple models, DIE-CNN performed optimally. The results show that DIE-CNN is an effective method to diagnose the condition of the subject, and the method also retains the expansion space to build a more complex comprehensive evaluation system.},
keywords={Brain modeling;Machine learning;Dementia;Electroencephalography;Diabetes;Data models;Mild Cognitive Impairment;ERP signals;Dual input encoder convolutional neural network},
doi={10.1109/CIVEMSA45640.2019.9071592},
ISSN={2377-9322},
month={June},}
@INPROCEEDINGS{8614108,
author={Wang, Shuqiang and Wang, Hongfei and Shen, Yanyan and Wang, Xiangyu},
booktitle={2018 17th IEEE International Conference on Machine Learning and Applications (ICMLA)}, title={Automatic Recognition of Mild Cognitive Impairment and Alzheimers Disease Using Ensemble based 3D Densely Connected Convolutional Networks},
year={2018},
volume={},
number={},
pages={517-523},
abstract={Automatic diagnosis of Alzheimers disease (AD) and mild cognition impairment (MCI) from 3D brain magnetic resonance (MR) images plays an important role in early treatment of dementia disease. Deep learning architectures can extract potential features of dementia disease and capture brain anatomical changes from MRI scans. This paper proposes an ensemble of 3D densely connected convolutional networks (3D-DenseNets) for AD and MCI diagnosis. First, dense connections were introduced to maximize the information flow, where each layer connects with all subsequent layers directly. Then weighted-based fusion method was employed to combine 3D-DenseNets with different architectures. Extensive experiments were conducted to analyze the performance of 3D-DenseNet with different hyper-parameters and architectures. Superior performance of the proposed model was demonstrated on ADNI dataset including 833 subjects.},
keywords={Three-dimensional displays;Magnetic resonance imaging;Feature extraction;Alzheimer's disease;Training;3D-dense-connection;ensemble-learning;convolutional-neural-network;Alzheimers-disease},
doi={10.1109/ICMLA.2018.00083},
ISSN={},
month={Dec},}
@INPROCEEDINGS{9317428,
author={Yifan, Peng and Bowen, Ding},
booktitle={2020 17th International Computer Conference on Wavelet Active Media Technology and Information Processing (ICCWAMTIP)}, title={An Efficient Deep Learning Model for Predicting Alzheimer's Disease Diagnosis by Using Pet},
year={2020},
volume={},
number={},
pages={366-372},
abstract={Aiming at the difficulty of artificially classifying diseased images in the field of brain positron emission tomography disease classification, we improved the network bottleneck of ResNet on this specific task in this work. And with the ensemble of improved ResNet and efficient network, our network was proposed. Also, a variety of image preprocessing methods were used to augment the characteristics of the lesion. Through experiments, the effectiveness of our proposed network structure and training strategies were proved.},
keywords={Training;Brain modeling;Positron emission tomography;Convolution;Predictive models;Data models;Smoothing methods;PET image;Image preprocessing;Deep convolution network for medical;Ensemble model},
doi={10.1109/ICCWAMTIP51612.2020.9317428},
ISSN={2576-8964},
month={Dec},}
@ARTICLE{9311146,
author={Santamaría-Vázquez, Eduardo and Martínez-Cagigal, Víctor and Vaquerizo-Villar, Fernando and Hornero, Roberto},
journal={IEEE Transactions on Neural Systems and Rehabilitation Engineering}, title={EEG-Inception: A Novel Deep Convolutional Neural Network for Assistive ERP-Based Brain-Computer Interfaces},
year={2020},
volume={28},
number={12},
pages={2773-2782},
abstract={In recent years, deep-learning models gained attention for electroencephalography (EEG) classification tasks due to their excellent performance and ability to extract complex features from raw data. In particular, convolutional neural networks (CNN) showed adequate results in brain-computer interfaces (BCI) based on different control signals, including event-related potentials (ERP). In this study, we propose a novel CNN, called EEG-Inception, that improves the accuracy and calibration time of assistive ERP-based BCIs. To the best of our knowledge, EEG-Inception is the first model to integrate Inception modules for ERP detection, which combined efficiently with other structures in a light architecture, improved the performance of our approach. The model was validated in a population of 73 subjects, of which 31 present motor disabilities. Results show that EEG-Inception outperforms 5 previous approaches, yielding significant improvements for command decoding accuracy up to 16.0%, 10.7%, 7.2%, 5.7% and 5.1% in comparison to rLDA, xDAWN + Riemannian geometry, CNN-BLSTM, DeepConvNet and EEGNet, respectively. Moreover, EEG-Inception requires very few calibration trials to achieve state-of-the-art performances taking advantage of a novel training strategy that combines cross-subject transfer learning and fine-tuning to increase the feasibility of this approach for practical use in assistive applications.},
keywords={Electroencephalography;Brain modeling;Computer architecture;Visualization;Training;Convolutional neural networks;Convolution;Brain-computer interfaces;event-related potentials;P300;deep learning;convolutional neural networks;inception;transfer learning},
doi={10.1109/TNSRE.2020.3048106},
ISSN={1558-0210},
month={Dec},}
@INPROCEEDINGS{8893225,
author={Neffati, Syrine and Taouali, Okba and Bouzrara, Kais},
booktitle={2019 16th International Multi-Conference on Systems, Signals Devices (SSD)}, title={New kernel method for MRI classification},
year={2019},
volume={},
number={},
pages={1-6},
abstract={The classification of brain Magnetic Resonance Images (MRI) into healthy or pathological subjects can be considered as the key for the preclinical state of a patient. If we consider classifying MRIs manually, this procedure can be time-consuming. In this work, we aim to present an automatic Computer Aided Design (CAD) system for brain MRI classification based on the new Downsized Kernel Principal Component Analysis (DKPCA) and Artificial Neural Network (ANN) entitled ANN-DKPCA. The proposed study contains three main steps; Data acquisition and preprocessing stage, feature extraction and feature reduction stage and finally the classification stage. The Alzheimer's Disease Neuroimaging Initiative (ADNI) database was used to validate the proposed ANN-DKPCA method. The results show that the proposed algorithm is effective and robust compared with other recent works.},
keywords={Kernel;Principal component analysis;Magnetic resonance imaging;Feature extraction;Alzheimer's disease;Artificial neural networks;DKPCA;Downsized Kernel Principal Component Analysis;kernel methods;Alzheimer's Disease;AD;ANN;pre-diagnoses;machine learning;pattern recognition},
doi={10.1109/SSD.2019.8893225},
ISSN={2474-0446},
month={March},}
@INPROCEEDINGS{8404447,
author={Yiğit, Altuğ and Işik, Zerrin},
booktitle={2018 26th Signal Processing and Communications Applications Conference (SIU)}, title={Application of artificial neural networks in dementia and alzheimer's diagnosis},
year={2018},
volume={},
number={},
pages={1-4},
abstract={Diagnosis in the early phases of many diseases makes it possible to treat the disease and affects the treatment process positively. This is especially important for diseases like Alzheimer in the field of neurology. The use of a computerized support system, which can autonomously perform the diagnostic process by the expert in this process, saves time and helps to reduce the most human errors. In this study, machine learning models with the ability to diagnose dementia and Alzheimer's disease were developed by predicting the Clinical Dementia Rating (CDR) value. Artificial Neural Networks (ANN), Logistic Regression (LR), k-nearest neighbors (KNN), and Decision Tree (DT) classifiers were applied to compare the classification performances. The Open Access Series of Imaging Studies (OASIS) longitudinal and cross-sectional datasets have been used to train models. As a result of the tests, best performance of the detection and identification of Alzheimer's disease has been shown by LR and YSA models.},
keywords={Alzheimer's disease;Brain modeling;Magnetic resonance imaging;Electroencephalography;Artificial neural networks;Artificial Neural Networks;Alzheimer Disease;Dementia;Machine Learning;Medical Diagnosis},
doi={10.1109/SIU.2018.8404447},
ISSN={},
month={May},}
@INPROCEEDINGS{9033832,
author={N., Vinutha and S., Sandeep and Kulkarni, Aditya N. and Deepa Shenoy, P. and K.R., Venugopal},
booktitle={2019 IEEE 5th International Conference for Convergence in Technology (I2CT)}, title={A Texture based Image Retrieval for Different Stages of Alzheimer’s Disease},
year={2019},
volume={},
number={},
pages={1-5},
abstract={In the last few years, using digital images have become significant across most of the sectors including healthcare and medical labs. To analyze and interpret the large collection of images having a complex disease pattern requires the knowledge of medical experts. So, the image retrieval technique plays an important role to assist the doctors to carefully examine an image of a new patient by comparing with most similar images existing in the database and also to take a correct decision during diagnosis. So, we carried out our studies by collecting the images of Magnetic Resonance Imaging (MRI) from the Open Access Series of Imaging Studies (OASIS) database. Later, we have categorized the collected MRI images into three different groups based on the size of a ventricular region of the brain and then employed second and higher order statistical methods to extract the textural features from each image. Thus, we obtain multiple textural features using Gray Level Co-occurrence Matrix (GLCM) and Law Texture Energy Measure. After obtaining the textural features, the top matched images are retrieved based on the similarity measure computed between the feature vector of a query image and the images present in the database. Finally, the retrieval performance is compared for the extracted texture features from GLCM, Laws Texture Energy Measure and a combination of these two methods. The combination of features from the above methods shows the better precision of 80% and 60 % in the retrieval of Group1 and Group3 images.},
keywords={Feature extraction;Magnetic resonance imaging;Image retrieval;Medical diagnostic imaging;Statistical analysis;Alzheimer’s Disease;Content-based Image Retrieval;Magnetic Resonance Imaging;Textural Features.},
doi={10.1109/I2CT45611.2019.9033832},
ISSN={},
month={March},}
@INPROCEEDINGS{8451824,
author={Pan, Xiaoxi and Adel, Mouloud and Fossati, Caroline and Gaidon, Thierry and Guedj, Eric},
booktitle={2018 25th IEEE International Conference on Image Processing (ICIP)}, title={Alzheimer'S Disease Diagnosis with FDG-PET Brain Images By Using Multi-Level Features},
year={2018},
volume={},
number={},
pages={366-370},
abstract={FluoroDeoxyGlucose Positron Emission Tomography (FDG- PET) is an important and effective modality used for diagnosing Alzheimer's Disease (AD) or Mild Cognitive Impairment (MCI). In this paper, we develop a novel method by using single modality (FDG- PET) but multi-level features, which considers both region properties and connectivities between regions, to diagnose AD or MCI. First, post-processed FDG-PET images are segmented into 116 Regions of Interest according to Automated Anatomical Labeling atlas. Second, three levels of features are extracted. Then the 2nd-Level feature is decomposed into 3 different sets of features according to a proposed similarity-driven ranking method, which can not only reduce the feature dimension but also increase the classifier's diversity. Last, after feeding the 3 levels of features to different classifiers, the majority voting, is applied to make the prediction. Experiments on ADNI database show that the proposed method outperforms other FDG-PET-based classification algorithms.},
keywords={Feature extraction;Dementia;Magnetic resonance imaging;Positron emission tomography;Symmetric matrices;Image segmentation;Feature selection;Multi-level feature representation;Ensemble classification;FDG-PET;Alzheimer's Disease},
doi={10.1109/ICIP.2018.8451824},
ISSN={2381-8549},
month={Oct},}


@INPROCEEDINGS{9337006,
author={Sheela, A},
booktitle={2020 International Conference on Power, Energy, Control and Transmission Systems (ICPECTS)}, title={Segmentation of Brain Tumor in Deep Learning},
year={2020},
volume={},
number={},
pages={1-7},
abstract={MR imaging plays a crucial function for spotting brain tumors in earlier degree for giving appropriate treatment. Accurate segmentation of MR imaging entails big quantity of records for quick analysis of brain tumor and proven top notch benefits in scientific picture analysis. Segmentation makes use of many strategies for class that includes support vector gadget and random woodland classifiers. The PET image and the MRI brain pictures images are merged in handling the wavelet transforms. In current device, Stationary Wavelet remodel method (SWT) had been used. The present machine ends in over lapping, less accuracy and excessive noise. Therefore, we advocate a gadget that utilizes discrete wavelet remodel (DWT) and Deep Belief Neural network(DBN) to enhance capability and much less time intake. After assembling and applying moving towards, we acquired a terrific combined result by using adjusting structural data in gray count (GM) area and patching the spectral data in white count number (WM) location. For testing and contrast we have used three datasets: everyday axial, regular coronal, Alzheimer's disorder mind pictures. On the whole presentation of our fusion approach in requisites of spectral discrepancy (SD) and average gradient (AG) achieved to be higher at each visually and quantitatively. Segmentation makes use of many strategies for class that includes support vector gadget and random woodland classifiers. The PET image and the MRI brain pictures images are merged in handling the wavelet transforms. In current device, Stationary Wavelet remodel method (SWT) had been used. The present machine ends in over lapping, less accuracy and excessive noise. Therefore, we advocate a gadget that utilizes discrete wavelet remodel (DWT) and Deep Belief Neural network(DBN) to enhance capability and much less time intake. After assembling and applying moving towards, we acquired a terrific combined result by using adjusting structural data in gray count (GM) area and patching the spectral data in white count number (WM) location. For testing and contrast we have used three datasets: everyday axial, regular coronal, Alzheimer's disorder mind pictures. On the whole presentation of our fusion approach in requisites of spectral discrepancy (SD) and average gradient (AG) achieved to be higher at each visually and quantitatively.},
keywords={Image segmentation;Lapping;Magnetic resonance imaging;Support vector machine classification;Discrete wavelet transforms;Tumors;Testing},
doi={10.1109/ICPECTS49113.2020.9337006},
ISSN={},
month={Dec},}
@INPROCEEDINGS{8856498,
author={priyanka, N. Ahana and Kavitha, G.},
booktitle={2019 41st Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)}, title={Study of Tissue Variation and Analysis of MR Brain Images using Optimized Multilevel Threshold and Deep CNN Features in Neurodegenerative Disorders},
year={2019},
volume={},
number={},
pages={2773-2776},
abstract={Dementia is a degenerative irreversible disorder that globally causes a high socio-economic burden. The pathology progression of mild cognitive impairment (MCI) and Alzheimer diseases (AD) are correlated with each other. There is a need to examine the pathology variation to discriminate the disorder to provide appropriate treatment strategies. This study investigates about the brain tissue variations to identify the subtle change in progression. The considered normal, MCI and AD magnetic resonance (MR) images are obtained from Alzheimer's disease Neuroimaging Initiative (ADNI). In this work, multilevel Tsallis based grey wolf optimization (GWO) is used to segment the brain tissues. Then the feature is extracted from segmented white matter (WM), grey matter (GM) and cerebro spinal fluid (CSF) using convolution neural network (CNN). The obtained deep features are given to principal component analysis (PCA) to obtain a prominent feature set for normal, MCI and AD. Further the tissue variation of optimized deep features is analyzed using support vector machine (SVM). The results shows that Tsallis based GWO perform reliable tissue segmentation for normal, MCI and AD. The deep features are able to observe discrimination than the fully considered feature set. Finally, the classifier result shows distinct tissue variation among normal, MCI and AD subjects. Further the prominent features give a classification accuracy of 77%, 80.22% and 78.7% for WM, GM and CSF respectively. This concludes that GM variation is a close biological substrate of dementia progressive condition than the effects of time or aging. Thus, the proposed framework can be used as an effective system for diagnosis of progression in neurodegenerative disorders.},
keywords={Feature extraction;Image segmentation;Principal component analysis;Support vector machines;Diseases;Brain;Convolution},
doi={10.1109/EMBC.2019.8856498},
ISSN={1558-4615},
month={July},}
@INPROCEEDINGS{9102776,
author={Weng, Ziqiao and Meng, Jingjing and Ding, Zhaohua and Yuan, Junsong},
booktitle={2020 IEEE International Conference on Multimedia and Expo (ICME)}, title={S3F: A Multi-View Slow-Fast Network For Alzheimer’s Disease Diagnosis},
year={2020},
volume={},
number={},
pages={1-6},
abstract={Alzheimer's disease (AD) is the most common form of dementia in the elderly. As early detection and diagnosis is imperative for the intervention and prevention of its progression into more detrimental stages, pioneering works have been proposed that use the resting-state functional MRI (rs-fMRI) to identify early mild cognitive impairment (EMCI) based on various convolutional neural networks (CNNs). However the accuracy is not satisfactory. In this paper, we propose a multi-view model based on the SlowFast network, a recently proposed model for video recognition. The rs-fMRI data are treated as videos from three perspectives (i.e. coronal, horizontal and sagittal, corresponding to three anatomical planes in human body) and the jointly learned hierarchical representations are fused in the fully connected layer. We examine our model on a publicly accessible Alzheimer's Disease Neuroimaging Initiative (ADNI) database. Our method significantly outperforms other competing methods and achieves state-of-the-art accuracy. Besides, we also provide a baseline on the classification task over all clinical phases of AD.},
keywords={Dementia;Magnetic resonance imaging;Three-dimensional displays;Brain modeling;Task analysis;Positron emission tomography;Alzheimer’s disease;resting-state functional MRI;convolutional neural networks},
doi={10.1109/ICME46284.2020.9102776},
ISSN={1945-788X},
month={July},}
@INPROCEEDINGS{9377399,
author={Jahanshiri, Zahra and Abadeh, Mohammad Saniee and Sajedi, Hedieh},
booktitle={2021 15th International Conference on Ubiquitous Information Management and Communication (IMCOM)}, title={Brain Age Estimation based on Brain MRI by an Ensemble of Deep Networks},
year={2021},
volume={},
number={},
pages={1-6},
abstract={Estimation of biological brain age is one of the topics that has been much discussed in recent years. One of the most important reasons for this is the possibility of early detection of neurodegenerative disorders such as Alzheimer's and Parkinson's with Brain Age Estimation (BAE). Brain imaging is one of the most important data to estimate the biological age of the brain. Because the brain's natural aging follows a particular pattern, it enables researchers and physicians to predict the human brain's age from its degeneration. Some studies have been done on 2D or 3D brain images data for this purpose. In this study, an ensemble structure, including 3D and 2D Convolutional Neural Networks (CNNs), is used to BAE. The proposed ensemble CNN (ECNN) method obtained a Mean Absolute Error (MAE) of 3.57 years, which is better than the previous studies.},
keywords={Three-dimensional displays;Magnetic resonance imaging;Two dimensional displays;Estimation;Brain modeling;Feature extraction;Biology;Brain Age Estimation;biological age;Deep Learning (DL);T1-weighted image;Convolutional Neural Network (CNN)},
doi={10.1109/IMCOM51814.2021.9377399},
ISSN={},
month={Jan},}
@ARTICLE{9187697,
author={Pan, Xiaoxi and Phan, Trong-Le and Adel, Mouloud and Fossati, Caroline and Gaidon, Thierry and Wojak, Julien and Guedj, Eric},
journal={IEEE Transactions on Medical Imaging}, title={Multi-View Separable Pyramid Network for AD Prediction at MCI Stage by 18F-FDG Brain PET Imaging},
year={2021},
volume={40},
number={1},
pages={81-92},
abstract={Alzheimer's Disease (AD), one of the main causes of death in elderly people, is characterized by Mild Cognitive Impairment (MCI) at prodromal stage. Nevertheless, only part of MCI subjects could progress to AD. The main objective of this paper is thus to identify those who will develop a dementia of AD type among MCI patients. 18F-FluoroDeoxyGlucose Positron Emission Tomography (18F-FDG PET) serves as a neuroimaging modality for early diagnosis as it can reflect neural activity via measuring glucose uptake at resting-state. In this paper, we design a deep network on 18F-FDG PET modality to address the problem of AD identification at early MCI stage. To this end, a Multi-view Separable Pyramid Network (MiSePyNet) is proposed, in which representations are learned from axial, coronal and sagittal views of PET scans so as to offer complementary information and then combined to make a decision jointly. Different from the widely and naturally used 3D convolution operations for 3D images, the proposed architecture is deployed with separable convolution from slice-wise to spatial-wise successively, which can retain the spatial information and reduce training parameters compared to 2D and 3D networks, respectively. Experiments on ADNI dataset show that the proposed method can yield better performance than both traditional and deep learning-based algorithms for predicting the progression of Mild Cognitive Impairment, with a classification accuracy of 83.05%.},
keywords={Three-dimensional displays;Feature extraction;Positron emission tomography;Dementia;Two dimensional displays;Magnetic resonance imaging;Neuroimaging;Separable convolution;slice-wise CNN;spatial-wise CNN;¹⁸F-FDG PET;mild cognitive impairment},
doi={10.1109/TMI.2020.3022591},
ISSN={1558-254X},
month={Jan},}
@INPROCEEDINGS{8417262,
author={Aderghal, Karim and Khvostikov, Alexander and Krylov, Andrei and Benois-Pineau, Jenny and Afdel, Karim and Catheline, Gwenaelle},
booktitle={2018 IEEE 31st International Symposium on Computer-Based Medical Systems (CBMS)}, title={Classification of Alzheimer Disease on Imaging Modalities with Deep CNNs Using Cross-Modal Transfer Learning},
year={2018},
volume={},
number={},
pages={345-350},
abstract={A recent imaging modality Diffusion Tensor Imaging completes information used from Structural MRI in studies of Alzheimer disease. A large number of recent studies has explored pathologic staging of Alzheimer disease using the Mean Diffusivity maps extracted from the Diffusion Tensor Imaging modality. The Deep Neural Networks are seducing tools for classification of subjects' imaging data in computer-aided diagnosis of Alzheimer's disease. The major problem here is the lack of a publicly available large amount of training data in both modalities. The lack number of training data yields over-fitting phenomena. We propose a method of a cross-modal transfer learning: from Structural MRI to Diffusion Tensor Imaging modality. Models pre-trained on a structural MRI dataset with domain-depended data augmentation are used as initialization of network parameters to train on Mean Diffusivity data. The method shows a reduction of the over-fitting phenomena, improves learning performance, and thus increases the accuracy of prediction. Classifiers are then fused by a majority vote resulting in augmented scores of classification between Normal Control, Alzheimer Patients and Mild Cognitive Impairment subjects on a subset of ADNI dataset.},
keywords={Alzheimer's disease;Diffusion tensor imaging;Training;Hippocampus;Biomedical imaging;Multi-Modal;Alzheimer’s Disease;Hippocampus;Mild Cognitive Impairment;Convolutional Neural Networks;Transfer Learning;Deep Learning;Medical Imaging},
doi={10.1109/CBMS.2018.00067},
ISSN={2372-9198},
month={June},}
@ARTICLE{9268103,
author={Han, Ruizhi and Chen, C. L. Philip and Liu, Zhulin},
journal={IEEE Access}, title={A Novel Convolutional Variation of Broad Learning System for Alzheimer’s Disease Diagnosis by Using MRI Images},
year={2020},
volume={8},
number={},
pages={214646-214657},
abstract={Alzheimer's disease (AD) is a serious chronic health problem that causes great pain and loss to patients and their families. Its early and accurate diagnosis would achieve significant progress on the prevention and treatment of the disease. Magnetic Resonance Imaging (MRI) is a commonly used technique in nuclear medical diagnostics. However, it is still a challenging problem to diagnose AD, Control Normal (CN), and Mild Cognitive Impairment (MCI) because of the complex structures of MRI. In this paper, diagnosing models for MRI images are proposed to identify the various stages of AD based on the Broad Learning Systems (BLS), as well as its convolutional variants. To verify the validity of the proposed models, experiments on MRI images collected from the ADNI website are tested and evaluated. The results show that our algorithms outperform the other state-of-the-art algorithms for various tasks with better accuracy and less training times. Finally, the cross-domain learning ability of the proposed algorithms is verified on an independent AD dataset.},
keywords={Magnetic resonance imaging;Alzheimer's disease;Medical diagnostic imaging;Feature extraction;Classification algorithms;Training;Prediction algorithms;Alzheimer’s disease;broad learning system;convolutional neural network;image classification;magnetic resonance imaging},
doi={10.1109/ACCESS.2020.3040340},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{9362863,
author={CV, Renjith and Wagaj, SC.},
booktitle={2020 2nd International Conference on Advances in Computing, Communication Control and Networking (ICACCCN)}, title={MRI Brain Disease Detection using Enhanced Landmark based Deep Feature Learning},
year={2020},
volume={},
number={},
pages={277-282},
abstract={For brain diseases like Alzheimer's disease (AD) detection, several studies have been proposed in the last two decades by various biomarkers, but the accurate detection and retrieval is still a research problem. To overcome the challenges of state-of-art techniques of automatic brain disease detection using MRI images, novel Enhanced Landmark based Deep Feature Learning (ELDFL) proposed in this paper consist of phases like pre-processing, landmark estimation, the hybrid features learning and normalization, classification and retrieval. The raw brain MRI image is first pre-processed using noise removing filters and contrast enhancement functions followed by the landmark estimation. In the hybrid features learning phase, we automatically extract patch-based features from landmarks followed by the texture features to form the hybrid deep learning-based features. The min-max normalization technique is applied to extracted features to enhance the performances. The proposed hybrid feature, learning-based Convolution Neural Network (CNN) generates the trained model of training MRI datasets which is further used by the Long-Short Term Memory (LSTM) classifier to classify the input test MRI brain image either into AD class or Normal Control (NC) class followed by the retrieval of relevant images. The experimental results show the proposed model improved the performance of image retrieval and classification compared to the state of art method.},
keywords={Deep learning;Magnetic resonance imaging;Image retrieval;Estimation;Feature extraction;Brain modeling;Diseases;Alzheimer’s disease;brain disease;MRI;deep learning;features normalization;image retrieval},
doi={10.1109/ICACCCN51052.2020.9362863},
ISSN={},
month={Dec},}
@INPROCEEDINGS{9313341,
author={Tufail, Ahsan Bin and Ma, Yong-Kui and Zhang, Qiu-Na and Zhao, Lei},
booktitle={2020 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)}, title={Joint Multiclass Classification of the subjects of Alzheimer’s and Parkinson’s Diseases through Neuroimaging Modalities and Convolutional Neural Networks},
year={2020},
volume={},
number={},
pages={2840-2846},
abstract={Alzheimer's disease (AD) is the most widespread type of dementia defined by an accumulation of amyloid-$\beta$ proteins, the formation of tau plaques as well as the loss of neurons. On the other hand, Parkinson's disease (PD) is defined by the loss of dopaminergic neurons in the substantia nigra pars compacta within the midbrain. AD and PD are affecting millions of elderly people worldwide which highlights the need for their early diagnosis for the welfare of subjects diagnosed with these neurodegenerative disorders. A large number of autopsy confirmed PD subjects have sufficient postmortem plaque and tangle pathology to meet criteria for a second diagnosis of AD. Neuroimaging modalities such as Positron Emission Tomography (PET) and Single Photon Emission Computed Tomography (SPECT) are routinely used by clinicians to diagnose the initial stages of these two diseases. Together with these neuroimaging modalities, deep learning techniques are widely used in medical settings and have the potential to aid clinicians in the early diagnosis of these two diseases. In this work, we deployed a 3D Convolutional Neural Network (CNN) forjoint feature extraction and multiclass classification of both AD and PD brain images in the spatial and frequency domains using PET and SPECT imaging modalities discriminating between AD, PD and Normal Control (NC) classes. We used Discrete Cosine Transform (DCT) as the frequency domain method and deployed random weak Gaussian blurring and random zooming in/out augmentation methods in both spatial and frequency domains. Based on our experiments and deployment of cross-validation approach for optimal hyperparameters selection, we found the performance of AD/NC(SPECT)/PD classification with random weak Gaussian blurred augmentation in the spatial domain to be the best and that of AD/NC(SPECT)/PD classification with combined augmentations in the frequency domain to be the worst while spatial domain methods outperformed their frequency domain counterparts.},
keywords={Multiclass Classification;Convolutional Neural Networks;Alzheimer’s Disease;Parkinson’s Disease;Positron Emission Tomography;Single Photon Emission Computed Tomography},
doi={10.1109/BIBM49941.2020.9313341},
ISSN={},
month={Dec},}
@INPROCEEDINGS{8697386,
author={Lodha, Priyanka and Talele, Ajay and Degaonkar, Kishori},
booktitle={2018 Fourth International Conference on Computing Communication Control and Automation (ICCUBEA)}, title={Diagnosis of Alzheimer's Disease Using Machine Learning},
year={2018},
volume={},
number={},
pages={1-4},
abstract={Machine learning is being widely used in various medical fields. Advances in medical technologies have given access to better data for identifying symptoms of various diseases in early stages. Alzheimer's disease is chronic condition that leads to degeneration of brain cells leading at memory enervation. Patients with cognitive mental problems such as confusion and forgetfulness, also other symptoms including behavioral and psychological problems are further suggested having CT, MRI, PET, EEG, and other neuroimaging techniques. The aim of this paper is making use of machine learning algorithms to process this data obtained by neuroimaging technologies for detection of Alzheimer's in its primitive stage.},
keywords={Machine learning algorithms;Alzheimer's disease;Support vector machines;Boosting;Classification algorithms;Linear Regression;Machine Learning algorithm;Alzheimer's disease symptoms;Random Forest;Gradient Boosting Algorithm;Neural Network},
doi={10.1109/ICCUBEA.2018.8697386},
ISSN={},
month={Aug},}
@INPROCEEDINGS{9336962,
author={T, Kirthiga Devi and G, Maragatham and S, Janani and K, Dhanush Kumar},
booktitle={2020 International Conference on Power, Energy, Control and Transmission Systems (ICPECTS)}, title={Deep learning to predict Alzheimer's disease from neuroimaging of MRI analysis : A systematic study},
year={2020},
volume={},
number={},
pages={1-9},
abstract={Alzheimer's disease causes memory loss and greatly affects the patient's quality of life. WHO recognizes it as a health priority. There are 45 million patients and worldwide and every year there are 10 million new cases. The projected rate estimates 82 million patients in 2030 and 132 million in 2050. Deep learning Algorithms, specifically convolutional networks, has quickly turned into a strategy of decision for examining medicinal pictures. This paper surveys the real deep learning ideas relevant to medicinal image analyzing more than 300 commitments to the field, the majority of which showed up in the most recent years. This system lets us upload a brain MRI image and tells us whether or not that person has Alzheimer's disease. Currently, doctors and radiologists read the MRI image and detect the disease. But doctors are humans, prone to error. Also, what differentiates doctors is not their knowledge. It's determines how they approach the problem to interpret the health model which will support them. Radiologists regularly disagree of their respective interpretations of medical images - false positives and false negatives. AI can do what no radiologist can! - AI has the ability to learn from hundreds of thousands of medical images & is estimated to be upto 10% more accurate than an average radiologist. This accuracy gap will only keep increasing with time, with cheaper computing power and more data in the future.},
keywords={Deep learning;Magnetic resonance imaging;Medical services;Alzheimer's disease;Artificial intelligence;Medical diagnostic imaging;Diseases},
doi={10.1109/ICPECTS49113.2020.9336962},
ISSN={},
month={Dec},}
@ARTICLE{8672088,
author={Shi, Yinghuan and Suk, Heung-Il and Gao, Yang and Lee, Seong-Whan and Shen, Dinggang},
journal={IEEE Transactions on Neural Networks and Learning Systems}, title={Leveraging Coupled Interaction for Multimodal Alzheimer’s Disease Diagnosis},
year={2020},
volume={31},
number={1},
pages={186-200},
abstract={As the population becomes older worldwide, accurate computer-aided diagnosis for Alzheimer's disease (AD) in the early stage has been regarded as a crucial step for neurodegeneration care in recent years. Since it extracts the low-level features from the neuroimaging data, previous methods regarded this computer-aided diagnosis as a classification problem that ignored latent featurewise relation. However, it is known that multiple brain regions in the human brain are anatomically and functionally interlinked according to the current neuroscience perspective. Thus, it is reasonable to assume that the extracted features from different brain regions are related to each other to some extent. Also, the complementary information between different neuroimaging modalities could benefit multimodal fusion. To this end, we consider leveraging the coupled interactions in the feature level and modality level for diagnosis in this paper. First, we propose capturing the feature-level coupled interaction using a coupled feature representation. Then, to model the modality-level coupled interaction, we present two novel methods: 1) the coupled boosting (CB) that models the correlation of pairwise coupled-diversity on both inconsistently and incorrectly classified samples between different modalities and 2) the coupled metric ensemble (CME) that learns an informative feature projection from different modalities by integrating the intrarelation and interrelation of training samples. We systematically evaluated our methods with the AD neuroimaging initiative data set. By comparison with the baseline learning-based methods and the state-of-the-art methods that are specially developed for AD/MCI (mild cognitive impairment) diagnosis, our methods achieved the best performance with accuracy of 95.0% and 80.7% (CB), 94.9% and 79.9% (CME) for AD/NC (normal control), and MCI/NC identification, respectively.},
keywords={Feature extraction;Magnetic resonance imaging;Neuroimaging;Measurement;Kernel;Training;Brain modeling;Computer-aided AD/MCI diagnosis;coupled boosting (CB);coupled feature (CFR) representation;coupled metric ensemble (CME)},
doi={10.1109/TNNLS.2019.2900077},
ISSN={2162-2388},
month={Jan},}
@ARTICLE{9253576,
author={Zhu, Tian and Cao, Chongfeng and Wang, Zhishun and Xu, Guangrun and Qiao, Jianping},
journal={IEEE Access}, title={Anatomical Landmarks and DAG Network Learning for Alzheimer’s Disease Diagnosis},
year={2020},
volume={8},
number={},
pages={206063-206073},
abstract={The accurate diagnosis and prediction for individuals is crucial in computer-aided diagnosis of Alzheimer's disease (AD). The existing structural magnetic resonance imaging based classification methods of AD diagnosis mainly focus on the voxel level, region level and patch level morphological pattern analysis. However, most of these methods extract features with high dimension which may lead to overfitting problem. Besides, the interaction of different patches is not considered in the classifier ensemble. In this article, we propose a novel anatomical landmarks and directed acyclic graph (DAG) network feature learning based classification algorithm for the diagnosis of AD individuals. First, the anatomical feature patches of gray matter image are identified by the morphological and statistical analysis. Second, a simple and efficient DAG convolutional neural network is proposed to extract the discriminative deep features of image representation. Especially, the deep features are obtained by fusing feature maps of different network levels which contain semantic high-level and high-resolution low-level features. Finally, support vector machine and deep features are utilized to construct the classification model and predict the individual of AD. Experiments on three public datasets including ADNI-1, ADNI-2 and MIRIAD demonstrate that the proposed method can effectively improve the classification performance compared with the state-of-the-art methods for AD diagnosis.},
keywords={Feature extraction;Support vector machines;Diseases;Alzheimer's disease;Magnetic resonance imaging;Testing;Kernel;Alzheimer’s disease;structural magnetic resonance image;anatomical landmarks;directed acyclic graph network;classification},
doi={10.1109/ACCESS.2020.3037107},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{8856500,
author={Abrol, Anees and Fu, Zening and Du, Yuhui and Calhoun, Vince D.},
booktitle={2019 41st Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)}, title={Multimodal Data Fusion of Deep Learning and Dynamic Functional Connectivity Features to Predict Alzheimer’s Disease Progression *},
year={2019},
volume={},
number={},
pages={4409-4413},
abstract={Early prediction of diseased brain conditions is critical for curing illness and preventing irreversible neuronal dysfunction and loss. Generically regarding the different neuroimaging modalities as filtered, complementary insights of brain's anatomical and functional organization, multimodal data fusion could be hypothesized to enhance the predictive power as compared to a unimodal prediction of disease progression. More recently, deep learning (DL) based methods on structural MRI (sMRI) data have outperformed classical machine learning approaches in several neuroimaging applications including diagnostic classification and prediction. Similarly, functional MRI (fMRI) features estimated using a dynamic (i.e. time-varying) functional connectivity (FC) approach have been found to be more discriminative and predictive of the clinical diagnosis than those based on the static FC approach. Motivated by this, we introduce a novel multimodal data fusion framework featuring deep residual learning of non-linear sMRI features and dynamic FC (dFC) based extraction of fMRI features to predict the subset of individuals with mild cognitive impairments who would progress to Alzheimer's disease within a time-period of three years from the baseline scanning sessions. Our cross-validated results from the developed multimodal (sMRI-fMRI) data fusion framework demonstrate a significant improvement in performance over the unimodal prediction analyses with the fMRI (p = 7.03 x 10-7) and sMRI (p = 6.72 x 10-4) modalities. As such, the findings in this work highlight the benefits of combining multiple neuroimaging data modalities via data fusion, corroborate the predictive value of the tested DL and dFC features and argue in favor of exploration of similar approaches to learn neuroanatomical and functional alterations in the neuroimaging data.},
keywords={Functional magnetic resonance imaging;Diseases;Feature extraction;Correlation;Support vector machines;Data integration;Neuroimaging},
doi={10.1109/EMBC.2019.8856500},
ISSN={1558-4615},
month={July},}
@INPROCEEDINGS{8615775,
author={Menikdiwela, Medhani and Nguyen, Chuong and Shaw, Marnie},
booktitle={2018 Digital Image Computing: Techniques and Applications (DICTA)}, title={Deep Learning on Brain Cortical Thickness Data for Disease Classification},
year={2018},
volume={},
number={},
pages={1-5},
abstract={Deep learning has been applied to learn and classify brain disease using volumetric MRI scans with an accuracy approaching or even exceeding that of a human expert. This is typically done by applying convolutional neural networks to slices of a 3D brain image volume. Each slice of the brain volume, however, represents only a small cross-sectional area of the cortical layer. On the other hand, convolutional neural networks are less well developed for 3D volumes. Therefore we sought to apply deep networks to the 2D cortical surface, for the purpose of classifying Alzheimer's disease (AD). AD is known to affect the thickness and geometry of the cortical surface of the brain. Although the cortical surface has a complex geometry, here we present a novel data processing method to feed the information of an entire cortical surface into existing deep networks for more accurate early disease detection. A brain 3D MRI volume is registered and its cortical surface is flattened to a 2D plane. The flattened distributions of the thickness, curvature and surface area are combined into an RBG image which can be readily fed to existing deep networks. In this paper, the ADNI dataset of brain MRI scans are used and flattened cortical images are applied to different deep networks including ResNet and Inception. Two pre-clinical stages of AD are considered; stable mild cognitive impairment (MCIs) and converting mild cognitive impairment (MCIc). Experiments show that using flattened cortical images consistently leads to higher accuracy compared to using brain slices with the same network architecture. Specifically, the highest accuracy of 81% is achieved by Inception with flattened cortical images, as compared to 68% by the same network on brain slices and 75.9% accuracy by the best method in the literature which also used a deep network on brain slices. Our results indicate that flattened cortical images can be used to learn and classify AD with high accuracy.},
keywords={Magnetic resonance imaging;Diseases;Surface treatment;Brain;Deep learning;Two dimensional displays;Three-dimensional displays;MRI;MCI;Cortical thickness sheet;CNN;ResNet;Inception;Transfer Learning},
doi={10.1109/DICTA.2018.8615775},
ISSN={},
month={Dec},}
@ARTICLE{8727482,
author={Ren, Fujia and Yang, Chenhui and Qiu, Qi and Zeng, Nianyin and Cai, Chunting and Hou, Chaoqun and Zou, Quan},
journal={IEEE Access}, title={Exploiting Discriminative Regions of Brain Slices Based on 2D CNNs for Alzheimer’s Disease Classification},
year={2019},
volume={7},
number={},
pages={181423-181433},
abstract={Convolutional neural networks (CNNs)-based classifiers improve the accuracy of diagnosis and prediction for Alzheimer's disease (AD). However, exploiting specific brain regions with the AD is essential to understand pathological alteration in the AD and monitor its progression. This paper aims to construct novel AD classification models which have a good performance and interpretation on AD diagnosis. We propose the three classifiers including a simple broaden plain CNNs (SBPCNNs), a major slice-assemble CNNs (SACNNs) and a multi-slice CNNs (MSCNNs), which record the slice positions but have fewer parameters. Specifically, we integrate the ranking and the random forest methods to find the discriminative region that is consistent with domain knowledge about the AD. The results of the visualization explanation of pixel and slice level deliver a clearer understanding of the AD to specialists. The experimental results indicate that the proposed models are meaningful for AD classification.},
keywords={Convolution;Brain modeling;Solid modeling;Alzheimer's disease;Computational modeling;Alzheimer’s disease;CNNs-based classification;structural magnetic resonance imaging (sMRI);visual explanation},
doi={10.1109/ACCESS.2019.2920241},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{9312091,
author={Nadimpalli, Aakash Varma and Srivastava, Abhilash and Nersisson, Ruban},
booktitle={2020 IEEE 4th Conference on Information Communication Technology (CICT)}, title={Convolutional Neural Net based Dementia and Tumour Classification from MRI Brain Images},
year={2020},
volume={},
number={},
pages={1-6},
abstract={The main purpose of this project is to make the medical scan examination process more efficient economically and also with respect to time. Moreover, Medicinal errors influence one of each 10 patients around the globe. Specialists took an investigation at concentrates that analysed the restorative demise rate data from 2010 to 2018 and extrapolated that in excess of 250,000 deaths for every year had begun from a helpful mix-up, which implies 9.5% of all deaths consistently alone in the US. This framework that we have proposed diminishes the odds of this human blunder caused in the field of prescription. The target of this venture or framework is to make a Web application which is an entry that can be accessed freely by anybody around the globe. Honestly by making the framework open source we are intending to go past the requirements that we have now and making it available to others to both build up the framework and utilise the framework free of expense. We have received a procedure by the help of open source structures. This framework that we have proposed diminishes the odds of this human blunder caused in the field of prescription. The model proposed in this paper have gone a bit more technically advanced and computerised this procedure of distinguishing irregularities inside the cerebrum with the assistance of Artificial Intelligence. The objective of this project or system is to make a web application which is a portal that can be accessed freely by anyone around the world. The technology which has been deployed for the system to become automated by making the system learn and predicting on its own is Convolutional Neural Network.},
keywords={Servers;Alzheimer's disease;Convolution;Tumors;Medical services;Magnetic resonance imaging;Feature extraction;Automation;CT;Machine Learning;Medical Imaging;MRI;Neural Networks},
doi={10.1109/CICT51604.2020.9312091},
ISSN={},
month={Dec},}
@INPROCEEDINGS{9233674,
author={Niu, Jiaxi and Tang, Xiaoying},
booktitle={2020 IEEE International Conference on Mechatronics and Automation (ICMA)}, title={3D Residual Dense Convolutional Network for Diagnosis of Alzheimer’s Disease and Mild Cognitive Impairment},
year={2020},
volume={},
number={},
pages={1581-1586},
abstract={Alzheimer's disease (AD) is a common and incurable dementia, so it is particularly important to correctly distinguish AD from normal people. In recent years, the development of deep learning has pointed out a new direction for the study of AD classification. This paper proposes a 3D residual densely connected convolutional network for AD and mild cognitive impairment (MCI) diagnosis. First, the Residual Dense Block (RDB) is used to expand the information flow to avoid the disappearance of gradients. Then we use the global feature fusion method to comprehensively consider the shallow and deep features to improve the accuracy of classification. This paper mainly uses the MRI data of the ADNI dataset for experiments to prove the superior performance of the proposed model.},
keywords={Alzheimer's disease;3D convolutional neurol network;Residual dense connection;Deep learning},
doi={10.1109/ICMA49215.2020.9233674},
ISSN={2152-744X},
month={Oct},}
@INPROCEEDINGS{9006364,
author={Onga, Yuto and Fujiyama, Shingo and Arai, Hayato and Chayama, Yusuke and Iyatomi, Hitoshi and Oishi, Kenichi},
booktitle={2019 IEEE International Conference on Big Data (Big Data)}, title={Efficient feature embedding of 3D brain MRI images for content-based image retrieval with deep metric learning},
year={2019},
volume={},
number={},
pages={3764-3769},
abstract={Increasing numbers of MRI brain scans, improvements in image resolution, and advancements in MRI acquisition technology are causing significant increases in the demand for and burden on radiologists' efforts in terms of reading and interpreting brain MRIs. Content-based image retrieval (CBIR) is an emerging technology for reducing this burden by supporting the reading of medical images. High dimensionality is a major challenge in developing a CBIR system that is applicable for 3D brain MRIs. In this study, we propose a system called disease-oriented data concentration with metric learning (DDCML). In DDCML, we introduce deep metric learning to a 3D convolutional autoencoder (CAE). Our proposed DDCML scheme achieves a high dimensional compression rate (4096:1) while preserving the disease-related anatomical features that are important for medical image classification. The low-dimensional representation obtained by DDCML improved the clustering performance by 29.1% compared to plain 3D-CAE in terms of discriminating Alzheimer's disease patients from healthy subjects, and successfully reproduced the relationships of the severity of disease categories that were not included in the training.},
keywords={Magnetic resonance imaging;Diseases;Measurement;Three-dimensional displays;Pathology;Medical diagnostic imaging;Dimension Reduction;CAE;Metric Learning},
doi={10.1109/BigData47090.2019.9006364},
ISSN={},
month={Dec},}
@ARTICLE{9381587,
author={Zhang, Xin and Han, Liangxiu and Zhu, Wenyong and Sun, Liang and Zhang, Daoqiang},
journal={IEEE Journal of Biomedical and Health Informatics}, title={An Explainable 3D Residual Self-Attention Deep Neural Network For Joint Atrophy Localization and Alzheimer's Disease Diagnosis using Structural MRI},
year={2021},
volume={},
number={},
pages={1-1},
abstract={Computer-aided early diagnosis of Alzheimer's disease (AD) and its prodromal form mild cognitive impairment (MCI) based on structure Magnetic Resonance Imaging (sMRI) has provided a cost-effective and objective way for early prevention and treatment of disease progression, leading to improved patient care. In this work, we have proposed a novel computer-aided approach for early diagnosis of AD by introducing an explainable 3D Residual Attention Deep Neural Network (3D ResAttNet) for end-to-end learning from sMRI scans. Different from the existing approaches, the novelty of our approach is three-fold: 1) A Residual Self-Attention Deep Neural Network has been proposed to capture local, global and spatial information of MR images to improve diagnostic performance; 2) An explanation method using Gradient-based Localization Class Activation mapping (Grad-CAM) has been introduced to improve the explainable of the proposed method; 3) This work has provided a full end-to-end learning solution for automated disease diagnosis. Our proposed 3D ResAttNet method has been evaluated on a large cohort of subjects from real datasets for two changeling classification tasks (i.e., Alzheimer's disease (AD) vs. Normal cohort (NC) and progressive MCI (pMCI) vs. stable MCI (sMCI)). The experimental results show that the proposed approach has a competitive advantage over the state-of-the-art models in terms of accuracy performance and generalizability. The explainable mechanism in our approach is able to identify and highlight the contribution of the important brain parts (e.g., hippocampus, lateral ventricle and most parts of the cortex) for transparent decisions.},
keywords={Feature extraction;Three-dimensional displays;Diseases;Brain modeling;Magnetic resonance imaging;Deep learning;Alzheimer's disease;Deep learning;3D CNN;MRI brain scans;Model Explanation/Explainable Artificial Intelligence},
doi={10.1109/JBHI.2021.3066832},
ISSN={2168-2208},
month={},}
@ARTICLE{8754722,
author={Yue, Lulu and Gong, Xiaoliang and Li, Jie and Ji, Hongfei and Li, Maozhen and Nandi, Asoke K.},
journal={IEEE Access}, title={Hierarchical Feature Extraction for Early Alzheimer’s Disease Diagnosis},
year={2019},
volume={7},
number={},
pages={93752-93760},
abstract={Mild cognitive impairment (MCI) is the early stage of Alzheimer's disease (AD). In this paper, we propose a novel voxel-based hierarchical feature extraction (VHFE) method for the early AD diagnosis. First, we parcellate the whole brain into 90 regions of interests (ROIs) based on an automated anatomical labeling (AAL) template. To split the uninformative data, we select the informative voxels in each ROI with a baseline of their values and arrange them into a vector. Then, the first stage features are selected based on the correlation of the voxels between different groups. Next, the brain feature maps of each subject made up of the fetched voxels are fed into a convolutional neural network (CNN) to learn the deeply hidden features. Finally, to validate the effectiveness of the proposed method, we test it with the subset of the AD neuroimaging (ADNI) database. The testing results demonstrate that the proposed method is robust with a promising performance in comparison with the state-of-the-art methods.},
keywords={Feature extraction;Correlation;Alzheimer's disease;Magnetic resonance imaging;Convolutional neural networks;Databases;Alzheimer’s disease;convolutional neural network;hierarchical feature extraction;mild cognitive impairment},
doi={10.1109/ACCESS.2019.2926288},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{8955006,
author={Kavitha, Muthusubash and Yudistira, Novanto and Kurita, Takio},
booktitle={2019 IEEE 11th International Workshop on Computational Intelligence and Applications (IWCIA)}, title={Multi instance learning via deep CNN for multi-class recognition of Alzheimer's disease},
year={2019},
volume={},
number={},
pages={89-94},
abstract={In recent years, number of classification techniques for Alzheimer's disease (AD) have been developed that produced methods based on the use of hand-crafted machine learning and obscure deep learning models. This study proposed a new classification framework based on the combination of Unet-like 2D convolutional neural networks (CNN) and multinomial logistic regression classifier, which learns the intra-slice for multi-class classification after the selection of the 3D positron emission tomography (PET) image into a sequence of 2D slices. The CNNs are performed to generate the attention features of the brain while the logistic regression incorporated to learn those specifically localized features of various classes for AD classification. At the end of the network, we used a average pooling layer before the softmax for four-class classification problem. It can efficiently generate a flexible class of transformations and that can be trained end-to-end by back propagation. The results indicated that the proposed multi-instance learning (MIL) learns region of interest (ROI) itself and thus that could help to efficiently identify the precise patterns for AD. The proposed combined Unet-like CNN with multinomial regression classifier approach achieved highest accuracy of 97.9% and 96.7% on the classification of AD and MCI, respectively. It is much higher than the performances of the conventional methods in the literature.},
keywords={Logistics;Convolution;Feature extraction;Alzheimer's disease;Imaging;Brain modeling;Multi-instance;convolution;regression;attention;multi-class},
doi={10.1109/IWCIA47330.2019.8955006},
ISSN={1883-3977},
month={Nov},}
@INPROCEEDINGS{8785801,
author={Wang, Shaoyu and Yi, Lirong and Chen, Qiang and Meng, Zhaoxin and Dong, Huawei and He, Zhi},
booktitle={2019 IEEE 8th Joint International Information Technology and Artificial Intelligence Conference (ITAIC)}, title={Edge-aware Fully Convolutional Network with CRF-RNN Layer for Hippocampus Segmentation},
year={2019},
volume={},
number={},
pages={803-806},
abstract={Automatic segmentation of hippocampus in MR images is a vital step towards the development of computer-aided diagnosis systems. Owing to the quite ambiguous edges of hippocampus, recent deep learning approaches applied on hippocampus segmentation, without attaching importance to the edge information, have a restriction on producing accurate edges. This paper presents a method to automatically segment hippocampus using a novel edge-aware fully convolutional network (FCN) ending with a dense conditional random field (CRF) layer. This method achieves a more precise edge segmentation by incorporation edge information into the loss function. Validation results on the ANDI dataset and NITRC dataset show that the proposed method produces hippocampus segmentation results of high quality, scores an average dice similarity coefficient up to 87.31% and performs better than the state-of-the-art approaches. Our method may contribute to clinical diagnosis of probable Alzheimer's Disease.},
keywords={Image segmentation;Hippocampus;Image edge detection;Shape;Biomedical imaging;Diseases;FCN;CRF;hippocampus;automatic segmentation;edge-aware},
doi={10.1109/ITAIC.2019.8785801},
ISSN={},
month={May},}
@INPROCEEDINGS{9286657,
author={Ostertag, Cecilia and Beurton-Aimar, Marie and Visani, Muriel and Urruty, Thierry and Bertet, Karell},
booktitle={2020 Tenth International Conference on Image Processing Theory, Tools and Applications (IPTA)}, title={Predicting Brain Degeneration with a Multimodal Siamese Neural Network *},
year={2020},
volume={},
number={},
pages={1-6},
abstract={To study neurodegenerative diseases, longitudinal studies are carried on volunteer patients. During a time span of several months to several years, they go through regular medical visits to acquire data from different modalities, such as biological samples, cognitive tests, structural and functional imaging. These variables are heterogeneous but they all depend on the patient's health condition, meaning that there are possibly unknown relationships between all modalities. Some information may be specific to some modalities, others may be complementary, and others may be redundant. Some data may also be missing. In this work we present a neural network architecture for multimodal learning, able to use imaging and clinical data from two time points to predict the evolution of a neurodegenerative disease, and robust to missing values. Our multimodal network achieves 92.5% accuracy and an AUC score of 0.978 over a test set of 57 subjects. We also show the superiority of the multimodal architecture, for up to 37.5% of missing values in test set subjects' clinical measurements, compared to a model using only the clinical modality.},
keywords={Training;Recurrent neural networks;Magnetic resonance imaging;Image processing;Tools;Biological neural networks;Diseases;deep learning;multimoda;siamese networks;Alzheimer’s disease},
doi={10.1109/IPTA50016.2020.9286657},
ISSN={2154-512X},
month={Nov},}
@ARTICLE{9003258,
author={Song, Xuegang and Elazab, Ahmed and Zhang, Yuexin},
journal={IEEE Access}, title={Classification of Mild Cognitive Impairment Based on a Combined High-Order Network and Graph Convolutional Network},
year={2020},
volume={8},
number={},
pages={42816-42827},
abstract={Detection of early stages of Alzheimer's disease (AD) (i.e., mild cognitive impairment (MCI)) is important because it can delay or prevent progression to AD. The current researches of MCI classification are mainly based on static low-order functional connectivity network (FCN) and image information. However, static FCN cannot reflect time-varying dynamic behavior, low-order FCN overlooks inter-region interactions, and ignoring non-image information is not suitable especially when the size of dataset is small. In this paper, a method based on a combined high-order network and graph convolutional network (GCN) is proposed. The combined high-order network combines static, dynamic and high-level information to construct FCN while GCN is used to include non-image information to improve classifier's performance. Firstly, dynamic FCNs and static FCN are constructed by using a sliding window approach. Secondly, dynamic high-order FCNs and static high-order FCN based on the topographical similarity are then constructed. Thirdly, a novel combination method is proposed to utilize dynamic high-order FCNs and static high-order FCN to form a combined high-order FCN. Fourthly, features of the combined high-order FCNs are extracted by using a recursive feature elimination method. Lastly, after inputting extracted features into the GCN, in which MCI-graph establishes interactions between individuals and populations by using non-image information, the GCN outputs the binary classification results. Experimental results on Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset (adni.loni.ucla.edu) show that our framework has good performance.},
keywords={Feature extraction;Microsoft Windows;Time series analysis;Windows;Diseases;Sociology;Mild cognitive impairment;binary classification;combined high-order network;graph convolutional network},
doi={10.1109/ACCESS.2020.2974997},
ISSN={2169-3536},
month={},}
@ARTICLE{8786257,
author={Afzal, Sitara and Maqsood, Muazzam and Nazir, Faria and Khan, Umair and Aadil, Farhan and Awan, Khalid M and Mehmood, Irfan and Song, Oh-Young},
journal={IEEE Access}, title={A Data Augmentation-Based Framework to Handle Class Imbalance Problem for Alzheimer’s Stage Detection},
year={2019},
volume={7},
number={},
pages={115528-115539},
abstract={Alzheimer's Disease (AD) is the most common form of dementia. It gradually increases from mild stage to severe, affecting the ability to perform common daily tasks without assistance. It is a neurodegenerative illness, presently having no specified cure. Computer-Aided Diagnostic Systems have played an important role to help physicians to identify AD. However, the diagnosis of AD into its four stages; No Dementia, Very Mild Dementia, Mild Dementia, and Moderate Dementia remains an open research area. Deep learning assisted computer-aided solutions are proved to be more useful because of their high accuracy. However, the most common problem with deep learning architecture is that large training data is required. Furthermore, the samples should be evenly distributed among the classes to avoid the class imbalance problem. The publicly available dataset (OASIS) has serious class imbalance problem. In this research, we employed a transfer learning-based technique using data augmentation for 3D Magnetic Resonance Imaging (MRI) views from OASIS dataset. The accuracy of the proposed model utilizing a single view of the brain MRI is 98.41% while using 3D-views is 95.11%. The proposed system outperformed the existing techniques for Alzheimer disease stages.},
keywords={Magnetic resonance imaging;Brain modeling;Feature extraction;Data models;Dementia;Deep learning;Transfer learning;AlexNet;convolutional neural network;Alzheimer’s disease;augmentation},
doi={10.1109/ACCESS.2019.2932786},
ISSN={2169-3536},
month={},}
@ARTICLE{8723315,
author={Hong, Xin and Lin, Rongjie and Yang, Chenhui and Zeng, Nianyin and Cai, Chunting and Gou, Jin and Yang, Jane},
journal={IEEE Access}, title={Predicting Alzheimer’s Disease Using LSTM},
year={2019},
volume={7},
number={},
pages={80893-80901},
abstract={Alzheimer's Disease (AD) is a chronic neurodegenerative disease. Early diagnosis will considerably decrease the risk of further deterioration. Unfortunately, current studies mainly focus on classifying the states of disease in its current stage, instead of predicting the possible development of the disease. Long short-term memory (LSTM) is a special kind of recurrent neural network, which might be able to connect previous information to the present task. Noticing that the temporal data for a patient are potentially meaningful for predicting the development of the disease, we propose a predicting model based on LSTM. Therefore an LSTM network, with fully connected layer and activation layers, is built to encode the temporal relation between features and the next stage of Alzheimer's Disease. The Experiments show that our model outperforms most of the existing models.},
keywords={Alzheimer's disease;Magnetic resonance imaging;Biological neural networks;Logic gates;Predictive models;Time series analysis;Alzheimer’s Disease;Prediction;LSTM;Time Sequence;Magnetic Resonance Imaging},
doi={10.1109/ACCESS.2019.2919385},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{8913880,
author={Cheah, Wen-Ting and Chang, Wei-Der and Hwang, Jwu-Jia and Hong, Sheng-Yi and Fu, Li-Chen and Chang, Yu-Ling},
booktitle={2019 IEEE International Conference on Systems, Man and Cybernetics (SMC)}, title={A Screening System for Mild Cognitive Impairment Based on Neuropsychological Drawing Test and Neural Network},
year={2019},
volume={},
number={},
pages={3543-3548},
abstract={Alzheimer's disease and the other type of dementia have become one of the most serious global issues and the fifth leading cause of death worldwide nowadays. Therefore, early detection of the disease is crucial in order to improve the quality of life of the patients and to decrease the burden of their caregiver and clinicians. Mild cognitive impairment (MCI) is a prodromal stage of progressing to Alzheimer's disease which should be focus on. In this paper, we have proposed a screening system based on the Rey-osterrieth Complex Figure, a neuropsychological test, that can automatically assist the clinicians to detect whether the subject is MCI or not. A data-driven deep learning approach is implemented in this work. Convolution autoencoder is designed initially to extract features from the input image. The features learned by the encoder are then used for further training the classifier. In order to validate the performance of our work, 59 MCI subjects and 59 healthy controls are recruited under the approval of institutional review board from the National Taiwan University Hospital. The performance of our proposed model is evaluated by using 10-fold cross-validation and it is repeated five times. As a result, a mean area under the receiver operating characteristic curve score of 0.851 and 0.810 of accuracy are achieved.},
keywords={Dementia;Convolution;Magnetic resonance imaging;Feature extraction;Training;Biological neural networks;Mild cognitive impairment;screening system;convolution neural network},
doi={10.1109/SMC.2019.8913880},
ISSN={2577-1655},
month={Oct},}
@INPROCEEDINGS{9302550,
author={Rana, Sijan S and Ma, Xinhui and Pang, Wei and Wolverson, Emma},
booktitle={2020 IEEE/ACM International Conference on Big Data Computing, Applications and Technologies (BDCAT)}, title={A Multi-Modal Deep Learning Approach to the Early Prediction of Mild Cognitive Impairment Conversion to Alzheimer’s Disease},
year={2020},
volume={},
number={},
pages={9-18},
abstract={Mild cognitive impairment (MCI) has been described as the intermediary stage before Alzheimer's Disease - many people however remain stable or even demonstrate improvement in cognition. Early detection of progressive MCI (pMCI) therefore can be utilised in identifying at-risk individuals and directing additional medical treatment in order to revert conversion to AD as well as provide psychosocial support for the person and their family. This paper presents a novel solution in the early detection of pMCI people and classification of AD risk within MCI people. We proposed a model, MudNet, to utilise deep learning in the simultaneous prediction of progressive/stable MCI classes and time-to-AD conversion where high-risk pMCI people see conversion to AD within 24 months and low-risk people greater than 24 months. MudNet is trained and validated using baseline clinical and volumetric MRI data (n = 559 scans) from participants of the Alzheimer's Disease Neuroimaging Initiative (ADNI). The model utilises T1-weighted structural MRIs alongside clinical data which also contains neuropsychological (RAVLT, ADAS-11, ADAS-13, ADASQ4, MMSE) tests as inputs. The averaged results of our model indicate a binary accuracy of 69.8% for conversion predictions and a categorical accuracy of 66.9% for risk classifications.},
keywords={Magnetic resonance imaging;Alzheimer's disease;Feature extraction;Brain modeling;Deep learning;Data models;Training;Deep learning;Convolutional neural network;Alzheimer’s disease;Mild cognitive impairment;ADNI},
doi={10.1109/BDCAT50828.2020.00013},
ISSN={},
month={Dec},}
@INPROCEEDINGS{8946094,
author={Xu, Mingchang and Liu, Zhenbing and Wang, Zimin and Sun, Long and Liang, Zhibin},
booktitle={2019 International Conference on Cyber-Enabled Distributed Computing and Knowledge Discovery (CyberC)}, title={The Diagnosis of Alzheimer's Disease Based on Enhanced Residual Neutral Network},
year={2019},
volume={},
number={},
pages={405-411},
abstract={Alzheimer's disease (AD) is a neurodegenerativesickness. Recently, the end-to-end process of using neural net-works to classify patterns has gradually replaced the tediousprocess of manually extracting features. The residual neural net-work (ResNet) can effectively avoid gradient explosion, gradientdisappearance and network degradation. For AD, this paperattempts to apply ResNet to the diagnosis. Although the ResNetworks better compared with the machine learning methods. How-ever, the performance of Mild Cognitive Impairment (MCI) andNormal Control (NC) recognition is poor due to the insignificantdifference in magnetic resonance imaging (MRI) brain imagefeatures. In this paper, the selective kernel network (SKNet) andchannel shuffle are introduced in the Resnet network, and anenhanced Resnet (EResNet) is proposed to accurately diagnosethe AD symptoms. The method solves the influence of the multiplescales of input information on the network through SKNet, andevenly disturbs the channel feature through the channel shuffle, so that the network can fully utilize the feature information ofthe input image to improve the network identification capability. To evaluate the performance of the EResNet, MRI images of thebrain were used to diagnosis of AD. The classification accuracyin AD / MCI and MCI / NC control groups reached 96.47% and90.70%. The experimental results show that the proposed modelpresents a good performance on AD classification.},
keywords={Convolution;Feature extraction;Magnetic resonance imaging;Neural networks;Diseases;Kernel;Biomedical imaging;Alzheimer's disease;ResNet;SKNet;channe shuffle},
doi={10.1109/CyberC.2019.00076},
ISSN={},
month={Oct},}
@INPROCEEDINGS{8634735,
author={Wang, Ruyue and Li, Hanhui and Lan, Rushi and Luo, Suhuai and Luo, Xiaonan},
booktitle={2018 7th International Conference on Digital Home (ICDH)}, title={Hierarchical Ensemble Learning for Alzheimer's Disease Classification},
year={2018},
volume={},
number={},
pages={224-229},
abstract={In this paper, we propose to tackle the problem of Alzheimer's Disease (AD) classification by a novel Hierarchical Ensemble Learning (HEL) framework. Given an MRI image of a subject, our method will divide it into multiple slices, and generate the classification result in a coarse-to-fine way: First, for each slice, multiple pre-trained deep neural networks are adopted to extract features, and classiflers trained with each type of these features are used to generate the coarse predictions; Second, we employ ensemble learning on the coarse results to generate a refined result for each slice; At last, the given subject is classified based on the refined results aggregated from all slices. Using pre-trained networks for feature extraction can reduce the computational costs of training significantly, and the ensemble of multiple features and predicted results from slices can increase the classification accuracy effectively. Hence, our method can achieve the balance between efficiency and effectiveness. Experimental results show that the HEL framework can obtain notable performance gains with respect to various features and classifiers.},
keywords={Feature extraction;Magnetic resonance imaging;Training;Alzheimer's disease;Computational efficiency;Biological neural networks;Alzheimer's Disease, Classification, Ensemble Learning},
doi={10.1109/ICDH.2018.00047},
ISSN={},
month={Nov},}
@INPROCEEDINGS{9005971,
author={Guo, Jiaming and Qiu, Wei and Li, Xiang and Zhao, Xuandong and Guo, Ning and Li, Quanzheng},
booktitle={2019 IEEE International Conference on Big Data (Big Data)}, title={Predicting Alzheimer’s Disease by Hierarchical Graph Convolution from Positron Emission Tomography Imaging},
year={2019},
volume={},
number={},
pages={5359-5363},
abstract={Imaging-based early diagnosis of Alzheimer Disease (AD) has become an effective approach, especially by using nuclear medicine imaging techniques such as Positron Emission Topography (PET). In various literature it has been found that PET images can be better modeled as signals (e.g. uptake of florbetapir) defined on a network (non-Euclidean) structure which is governed by its underlying graph patterns of pathological progression and metabolic connectivity. In order to effectively apply deep learning framework for PET image analysis to overcome its limitation on Euclidean grid, we develop a solution for 3D PET image representation and analysis under a generalized, graph-based CNN architecture (PETNet), which analyzes PET signals defined on a group-wise inferred graph structure. Computations in PETNet are defined in non-Euclidean, graph (network) domain, as it performs feature extraction by convolution operations on spectral-filtered signals on the graph and pooling operations based on hierarchical graph clustering. Effectiveness of the PETNet is evaluated on the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset, which shows improved performance over both deep learning and other machine learning-based methods.},
keywords={Convolution;Positron emission tomography;Machine learning;Task analysis;Kernel;Diseases;Positron Emission Topography;Graph Convolution Network},
doi={10.1109/BigData47090.2019.9005971},
ISSN={},
month={Dec},}
@ARTICLE{9025260,
author={Shaw, Richard and Sudre, Carole H. and Varsavsky, Thomas and Ourselin, Sébastien and Cardoso, M. Jorge},
journal={IEEE Transactions on Medical Imaging}, title={A k-Space Model of Movement Artefacts: Application to Segmentation Augmentation and Artefact Removal},
year={2020},
volume={39},
number={9},
pages={2881-2892},
abstract={Patient movement during the acquisition of magnetic resonance images (MRI) can cause unwanted image artefacts. These artefacts may affect the quality of clinical diagnosis and cause errors in automated image analysis. In this work, we present a method for generating realistic motion artefacts from artefact-free magnitude MRI data to be used in deep learning frameworks, increasing training appearance variability and ultimately making machine learning algorithms such as convolutional neural networks (CNNs) more robust to the presence of motion artefacts. By modelling patient movement as a sequence of randomly-generated, `demeaned', rigid 3D affine transforms, we resample artefact-free volumes and combine these in k-space to generate motion artefact data. We show that by augmenting the training of semantic segmentation CNNs with artefacts, we can train models that generalise better and perform more reliably in the presence of artefact data, with negligible cost to their performance on clean data. We show that the performance of models trained using artefact data on segmentation tasks on real-world test-retest image pairs is more robust. We also demonstrate that our augmentation model can be used to learn to retrospectively remove certain types of motion artefacts from real MRI scans. Finally, we show that measures of uncertainty obtained from motion augmented CNN models reflect the presence of artefacts and can thus provide relevant information to ensure the safe usage of deep learning extracted biomarkers in a clinical pipeline.},
keywords={Three-dimensional displays;Transforms;Machine learning;Solid modeling;Image segmentation;Magnetic resonance imaging;Data models;MRI;motion artefacts;deep learning;segmentation;data augmentation;artefact correction;uncertainty},
doi={10.1109/TMI.2020.2972547},
ISSN={1558-254X},
month={Sep.},}
@ARTICLE{9380155,
author={Yu, Wen and Lei, Baiying and Ng, Michael K. and Cheung, Albert C. and Shen, Yanyan and Wang, Shuqiang},
journal={IEEE Transactions on Neural Networks and Learning Systems}, title={Tensorizing GAN With High-Order Pooling for Alzheimer's Disease Assessment},
year={2021},
volume={},
number={},
pages={1-15},
abstract={It is of great significance to apply deep learning for the early diagnosis of Alzheimer's disease (AD). In this work, a novel tensorizing GAN with high-order pooling is proposed to assess mild cognitive impairment (MCI) and AD. By tensorizing a three-player cooperative game-based framework, the proposed model can benefit from the structural information of the brain. By incorporating the high-order pooling scheme into the classifier, the proposed model can make full use of the second-order statistics of holistic magnetic resonance imaging (MRI). To the best of our knowledge, the proposed Tensor-train, High-order pooling and Semisupervised learning-based GAN (THS-GAN) is the first work to deal with classification on MR images for AD diagnosis. Extensive experimental results on Alzheimer's disease neuroimaging initiative (ADNI) data set are reported to demonstrate that the proposed THS-GAN achieves superior performance compared with existing methods, and to show that both tensor-train and high-order pooling can enhance classification performance. The visualization of generated samples also shows that the proposed model can generate plausible samples for semisupervised learning purpose.},
keywords={Feature extraction;Gallium nitride;Generative adversarial networks;Diseases;Brain modeling;Magnetic resonance imaging;Generators;Alzheimer's disease (AD);high-order pooling;magnetic resonance (MR) images;semisupervised generative adversarial network (SS-GAN);tensor decomposition.},
doi={10.1109/TNNLS.2021.3063516},
ISSN={2162-2388},
month={},}
@INPROCEEDINGS{9288036,
author={Achilleos, K.G. and Leandrou, S. and Prentzas, N. and Kyriacou, P.A. and Kakas, A.C. and Pattichis, C.S.},
booktitle={2020 IEEE 20th International Conference on Bioinformatics and Bioengineering (BIBE)}, title={Extracting Explainable Assessments of Alzheimer’s disease via Machine Learning on brain MRI imaging data},
year={2020},
volume={},
number={},
pages={1036-1041},
abstract={A plethora of machine learning and deep learning methods are used for the assessment of Alzheimer's Disease (AD) from brain structural changes as seen in Magnetic Resonance Imaging (MRI) with highly satisfactory results. However, these models are black-box and lack an explicit declarative knowledge representation and thus there is a difficulty in generating the underlying explanatory imaging structures. The objective of this study was to investigate the usefulness of rule extraction in the assessment of AD using decision trees (DT) and random forests (RF) algorithms and integrating the extracted rules within an argumentation-based reasoning framework in order to make the results easy to interpret and explain. The DT and RF algorithms were applied on brain MRI images acquired from normal controls (NC) and AD subjects. The KNIME analytics platform was used to compute the DT and the R project was used for the RF. The argumentation model implemented in the Gorgias framework achieved an average accuracy of 91%, exhibiting improved results compared to the models of DT and RF. The overall performance of all models in this study is in agreement with other studies. In addition, the explanations given by our approach for the various possible predictions provide a more useful and complete assessment of the state of the patient/case at hand. This study demonstrated the usefulness of rule extraction in the assessment of AD based on MRI features and the positive results of the use of the argumentation based symbolic reasoning for composing and interpreting the ML results.},
keywords={Radio frequency;Analytical models;Magnetic resonance imaging;Computational modeling;Feature extraction;Brain modeling;Diseases;Alzheimer’s disease;decision trees;random forests;quantitative MRI;Explainable AI;Argumentation},
doi={10.1109/BIBE50027.2020.00175},
ISSN={2471-7819},
month={Oct},}
@INPROCEEDINGS{9313422,
author={Li, Hong-Dong and Guo, Rui and Li, Junjian and Wang, Jianxin and Pan, Yi and Liu, Jin},
booktitle={2020 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)}, title={Joint Learning of Primary and Secondary Labels based on Multi-scale Representation for Alzheimer’s Disease Diagnosis},
year={2020},
volume={},
number={},
pages={637-642},
abstract={The cause of Alzheimer's disease (AD) is insufficient to understand so far, and its diagnosis is challenging in clinical practice. Recently, the convolutional neural network (CNN) model has shown impressive performance in medical image analysis. Combining CNN with magnetic resonance imaging (MRI) image has excellent potential for AD diagnosis. However, it is still a challenging task. To address the challenge, we propose a joint learning method based on multi-scale representation (JL-MSR). The multi-scale representation is proposed to obtain more feature maps by the multi-scale atrous convolutions. Furthermore, in order to use the intrinsic relationship between diagnostic results and clinical scores, we propose a joint learning strategy using the diagnosis result as the primary label and the Mini-Mental State Examination (MMSE) score as the secondary label to joint training. The proposed method is evaluated on a dataset of 417 subjects (including 188 AD and 229 health controls (HC)) from the Alzheimer's Disease Neuroimaging Initiative (ADNI). The experimental results show that our proposed method achieves an accuracy of 88.1% and an area under the receiver operating characteristic (ROC) curve (AUC) value of 0.942 for AD diagnosis, respectively. Compared with a state-of-the-art method in AD diagnosis, our proposed method performs better, and has potential in clinical diagnosis.},
keywords={Magnetic resonance imaging;Convolution;Diseases;Three-dimensional displays;Clinical diagnosis;Alzheimer's disease;Tools;Alzheimer’s Disease Diagnosis;Atrous Convolution;Multi-scale Representation;Joint Learning},
doi={10.1109/BIBM49941.2020.9313422},
ISSN={},
month={Dec},}
@ARTICLE{9072551,
author={Panigrahy, Chinmaya and Seal, Ayan and Mahato, Nihar Kumar},
journal={IEEE Signal Processing Letters}, title={MRI and SPECT Image Fusion Using a Weighted Parameter Adaptive Dual Channel PCNN},
year={2020},
volume={27},
number={},
pages={690-694},
abstract={Pulse coupled neural network (PCNN) is widely used in image fusion framework due to its global coupling and pulse synchronization of neurons. However, its manual setting of parameters and inability to process multiple images affect the fusion performance. In this letter, a novel weighted parameter adaptive dual channel PCNN (WPADCPCNN) based medical fusion method is proposed in non-subsampled shearlet transform domain to fuse the magnetic resonance imaging and single-photon emission computed tomography images of AIDS dementia complex and Alzheimer's disease patients. The parameters of the proposed WPADCPCNN model are estimated from its inputs using fractal dimension. The high-pass sub-bands are fused using the WPADCPCNN model whereas the low-pass sub-bands are merged using a new weighted multi-scale morphological gradients based rule. Experimental results demonstrate that the proposed method outperforms some of the state-of-the-art methods in terms of both visual quality and objective assessment.},
keywords={Neurons;Single photon emission computed tomography;Magnetic resonance imaging;Image fusion;Transforms;Medical diagnostic imaging;Fractal dimension;medical image fusion;non-subsampled shearlet transform;weighted parameter adaptive dual channel pulse coupled neural network},
doi={10.1109/LSP.2020.2989054},
ISSN={1558-2361},
month={},}
@INPROCEEDINGS{9289829,
author={Kadhim, Karrar A. and Mohamed, Farhan and Khudhair, Zaid Nidhal and Alkawaz, Mohammed Hazim},
booktitle={2020 IEEE Conference on Big Data and Analytics (ICBDA)}, title={Classification and Predictive Diagnosis Earlier Alzheimer’s Disease Using MRI Brain Images},
year={2020},
volume={},
number={},
pages={45-50},
abstract={In order to avoid Alzheimer's disease (AD) progression, diagnosis is necessary beforehand. Specialists would then begin preventive care as quickly as possible. They require fast and accurate evaluation at the earliest and most challenging stage to detect in the diagnosis of AD. The main objectives of this paper are to review previous studies into a better approach that automatically recognizes the occurrence of disease in unusually used pictures of sagittal magnetic resonance (MRI) images. The approach uses the MRI brain to identify and distinguish characteristics using a range of characteristics recognition techniques. This paper presented a summary of research papers on Alzheimer's Disease published in reputable journals from 2017 to 2020 and focused on exploring different strategies related to the latest tools used in early diagnosis, which may help researchers to understand current algorithms and techniques in this field and eventually develop new and more efficient algorithms.},
keywords={Image recognition;Magnetic resonance imaging;Magnetic resonance;Tools;Prediction algorithms;Classification algorithms;Diseases;dementia;Alzheimer’s disease;MRI Imaging;CNN;services},
doi={10.1109/ICBDA50157.2020.9289829},
ISSN={},
month={Nov},}
@INPROCEEDINGS{9207359,
author={Thapa, Surendrabikram and Singh, Priyanka and Jain, Deepak Kumar and Bharill, Neha and Gupta, Akshansh and Prasad, Mukesh},
booktitle={2020 International Joint Conference on Neural Networks (IJCNN)}, title={Data-Driven Approach based on Feature Selection Technique for Early Diagnosis of Alzheimer’s Disease},
year={2020},
volume={},
number={},
pages={1-8},
abstract={Alzheimer's disease (AD) is a neurodegenerative disorder resulting in memory loss and cognitive decline caused due to the death of brain cells. It is the most common form of dementia and accounts for 60-80% of all dementia cases. There is no single test for diagnosis of AD, the doctors rely on medical history, neuropsychological assessments, computed tomography (CT) or magnetic resonance imaging (MRI) scan of the brain, etc. to confirm a diagnosis. In terms of the treatment, currently, there is neither a cure nor any way to slow the progression of AD. However, for people with mild or moderate stages of this disease, there are some medications available to temporarily reduce symptoms and help to improve quality of life. Hence, early diagnosis of AD is extremely crucial for overall better management of the disease. The researches have shown some relation between neuropsychological scores and atrophies of the brain. This can be leveraged for the early diagnosis of AD. This paper makes use of feature selection techniques to extract the most important features in the diagnosis of AD. This paper demonstrates the need to combine neuropsychological scores like mini-mental state examination (MMSE) with MRI features to provide better decisional space for early diagnosis of AD. Through the experiments, including MMSE along with other features are found to improve the classification of AD, significantly.},
keywords={Feature extraction;Magnetic resonance imaging;Machine learning algorithms;Dementia;Classification algorithms;Hippocampus;Alzheimer’s disease;neuropsychological scores;feature selection;mini-mental state examination},
doi={10.1109/IJCNN48605.2020.9207359},
ISSN={2161-4407},
month={July},}
@ARTICLE{9133262,
author={Zhao, Yan and Ma, Baoqiang and Jiang, Pengbo and Zeng, Debin and Wang, Xuetong and Li, Shuyu},
journal={IEEE Journal of Biomedical and Health Informatics}, title={Prediction of Alzheimer's Disease Progression with Multi-Information Generative Adversarial Network},
year={2021},
volume={25},
number={3},
pages={711-719},
abstract={Alzheimer's disease (AD) is a chronic neurodegenerative disease, and its long-term progression prediction is definitely important. The structural Magnetic Resonance Imaging (sMRI) can be used to characterize the cortical atrophy that is closely coupled with clinical symptoms in AD and its prodromal stages. Many existing methods have focused on predicting the cognitive scores at future time-points using a set of morphological features derived from sMRI. The 3D sMRI can provide more massive information than the cognitive scores. However, very few works consider to predict an individual brain MRI image at future time-points. In this article, we propose a disease progression prediction framework that comprises a 3D multi-information generative adversarial network (mi-GAN) to predict what one's whole brain will look like with an interval, and a 3D DenseNet based multi-class classification network optimized with a focal loss to determine the clinical stage of the estimated brain. The mi-GAN can generate high-quality individual 3D brain MRI image conditioning on the individual 3D brain sMRI and multi-information at the baseline time-point. Experiments are implemented on the Alzheimer's Disease Neuroimaging Initiative (ADNI). Our mi-GAN shows the state-of-the-art performance with the structural similarity index (SSIM) of 0.943 between the real MRI images at the fourth year and the generated ones. With mi-GAN and focal loss, the pMCI vs. sMCI accuracy achieves 6.04% improvement in comparison with conditional GAN and cross entropy loss.},
keywords={Three-dimensional displays;Diseases;Magnetic resonance imaging;Brain modeling;Solid modeling;Generative adversarial networks;Alzheimer's disease;multi-information generative adversarial network;multi-class classification;disease progression},
doi={10.1109/JBHI.2020.3006925},
ISSN={2168-2208},
month={March},}
@INPROCEEDINGS{8404980,
author={Kazemi, Yosra and Houghten, Sheridan},
booktitle={2018 IEEE Conference on Computational Intelligence in Bioinformatics and Computational Biology (CIBCB)}, title={A deep learning pipeline to classify different stages of Alzheimer's disease from fMRI data},
year={2018},
volume={},
number={},
pages={1-8},
abstract={Alzheimer's disease (AD) is an irreversible, progressive neurological disorder that causes memory and thinking skill loss. Many different methods and algorithms have been applied to extract patterns from neuroimaging data in order to distinguish different stages of Alzheimer's disease (AD). However, the similarity of the brain patterns in older adults and in different stages makes the classification of different stages a challenge for researchers. In this paper, convolutional neuronal network architecture AlexNet was applied to fMRI datasets to classify different stages of the disease. We classified five different stages of Alzheimer's using a deep learning algorithm. The method successfully classified normal healthy control (NC), significant memory concern (SMC), early mild cognitive impair (EMCI), late cognitive mild impair (LMCI), and Alzheimer's disease (AD). The model was implemented using GPU high performance computing. Before applying any classification, the fMRI data were strictly preprocessed. Then, low to high level features were extracted and learned using the AlexNet model. Our experiments show significant improvement in classification. The average accuracy of the model was 97.63%. We then tested our model on test datasets to evaluate the accuracy of the model per class, obtaining an accuracy of 94.97% for AD, 95.64% for EMCI, 95.89% for LMCI, 98.34% for NC, and 94.55% for SMC.},
keywords={Dementia;Functional magnetic resonance imaging;Feature extraction;Machine learning;Timing;Smoothing methods},
doi={10.1109/CIBCB.2018.8404980},
ISSN={},
month={May},}
@INPROCEEDINGS{8363832,
author={Senanayake, Upul and Sowmya, Arcot and Dawes, Laughlin},
booktitle={2018 IEEE 15th International Symposium on Biomedical Imaging (ISBI 2018)}, title={Deep fusion pipeline for mild cognitive impairment diagnosis},
year={2018},
volume={},
number={},
pages={1394-1997},
abstract={Deep learning has allowed scientists to make significant improvements in tasks that were once considered difficult in disparate domains. Medical imaging is one of those domains where traditional analysis entailed multiple preprocessing steps and feature extraction or handcrafting of individual features for specific applications. Deep learning allows one to simplify this analysis pipeline into an end-to-end framework as it can handle the feature extraction phase without having to handcraft features. We leverage this characteristic of deep learning and present an architecture where multiple information modalities of different complexities can be fused together seamlessly and co-optimized to create a robust classifier. The performance of this fusion pipeline is demonstrated on Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset where discrimination between Alzheimer's Disease, Mild Cognitive Impairment and cognitively normal individuals using 3D magnetic resonance imaging and neuropsychological measures is presented.},
keywords={Pipelines;Three-dimensional displays;Machine learning;Dementia;Convolution;Biomedical imaging;Deep Learning;Convolutional Neural Networks;Mild Cognitive Impairment;Alzheimer's Disease},
doi={10.1109/ISBI.2018.8363832},
ISSN={1945-8452},
month={April},}
@INPROCEEDINGS{9393286,
author={Zubair, Laiba and Irtaza, Syed Aun and Nida, Nudrat and Haq, Noman ul},
booktitle={2021 International Bhurban Conference on Applied Sciences and Technologies (IBCAST)}, title={Alzheimer and Mild Cognitive disease Recognition Using Automated Deep Learning Techniques},
year={2021},
volume={},
number={},
pages={310-315},
abstract={Alzheimer disease is becoming a primary reason for death, so early detection of this disease is significant. This disease is dangerous as the patient's average survival rate lies within eleven years; therefore, earlier diagnosis can save lives and improve the mortality rate. The precise cause of Alzheimer disease is still unknown; however, earlier diagnosis can control the conversion of mild cognitive impairment (MCI) into Alzheimer disease (AD). With time the condition worsens and no proper cure of disease found yet. The aim is to reduce the disease's growth, reduce the signs, address behaviour problems and improve the lifestyle. However, some short-lived treatments can reduce the risk of conversion into AD at an early stage. In this paper, a new deep learning technique is proposed; which predict and classify the disease more precisely by using structural MRI images. Convolutional neural network (CNN) were applied on slices of MRI images of ADNI dataset. CNN performance was evaluated, and it gives higher accuracy in classifying the AD, CN and MCI. The proposed technique gives remarkable results compared to the existing techniques because the model is generated using the Bayesian optimization algorithm and network morphism. Our proposed method's testing accuracy gives 99.3%, which noticeably shows our technique's effectiveness.},
keywords={Deep learning;Magnetic resonance imaging;Classification algorithms;Bayes methods;Alzheimer's disease;Optimization;Diseases;Alzheimer disease;Cognitive normal;mild cognitive impairment;Magnetic resonance image;Deep learning},
doi={10.1109/IBCAST51254.2021.9393286},
ISSN={2151-1411},
month={Jan},}
@ARTICLE{8767919,
author={Chaddad, Ahmad and Toews, Matthew and Desrosiers, Christian and Niazi, Tamim},
journal={IEEE Access}, title={Deep Radiomic Analysis Based on Modeling Information Flow in Convolutional Neural Networks},
year={2019},
volume={7},
number={},
pages={97242-97252},
abstract={This paper proposes a novel image feature set based on a principled information theoretic analysis of the convolutional neural network (CNN). The output of convolutional filters is modeled as a random variable conditioned on the object class and network filter bank. The conditional entropy (CENT) of filter outputs is shown in theory and experiments to be a highly compact and class-informative feature that can be computed from the CNN feature maps and used to obtain higher classification accuracy than the original CNN itself. Experiments involve three binary classification tasks using the 3D brain MRI data: Alzheimer's disease (AD) versus healthy controls (HC), young versus old age, and male versus female, where the area under the curve (AUC) values for the CENT feature classification (93.9%, 96.7%, and 71.9%) are significantly higher than the softmax output of the original CNN classifier trained for the task (81.6%, 79.4%, and 63.1%). A statistical analysis based on the Wilcoxon test identifies CENT features with significant links to brain labels, which could potentially serve as diagnostic biomarkers.},
keywords={Entropy;Random variables;Information theory;Task analysis;Deep learning;Computer architecture;Entropy;information flow;deep learning;radiomics},
doi={10.1109/ACCESS.2019.2930238},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{8983088,
author={Yagis, Ekin and De Herrera, Alba G. Seco and Citi, Luca},
booktitle={2019 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)}, title={Generalization Performance of Deep Learning Models in Neurodegenerative Disease Classification},
year={2019},
volume={},
number={},
pages={1692-1698},
abstract={Over the past decade, machine learning gained considerable attention from the scientific community and has progressed rapidly as a result. Given its ability to detect subtle and complicated patterns, deep learning (DL) has been utilized widely in neuroimaging studies for medical data analysis and automated diagnostics with varying degrees of success. In this paper, we question the remarkable accuracies of the best performing models by assessing generalization performance of the state-of-the-art convolutional neural network (CNN) models on the classification of two most common neurodegenerative diseases, namely Alzheimer's Disease (AD) and Parkinson's Disease (PD) using MRI. We demonstrate the impact of the data division strategy on the model performances by comparing the results derived from two different split approaches. We first evaluated the performance of the CNN models by dividing the dataset at the subject level in which all of the MRI slices of a patient are put into either training or test set. We then observed that pooling together all slices prior to applying cross-validation, as erroneously done in a number of previous studies, leads to inflated accuracies by as much as 26% for the classification of the diseases.},
keywords={Parkinson's Disease;Alzheimer's Disease;Deep Learning;Transfer Learning;VGG16;Resnet50;MRI;Neuroimaging},
doi={10.1109/BIBM47256.2019.8983088},
ISSN={},
month={Nov},}
@ARTICLE{8495001,
author={Chaddad, Ahmad and Desrosiers, Christian and Niazi, Tamim},
journal={IEEE Access}, title={Deep Radiomic Analysis of MRI Related to Alzheimer’s Disease},
year={2018},
volume={6},
number={},
pages={58213-58221},
abstract={Alzheimer's disease (AD) is the most common form of dementia, causing progressive impairment of memory and cognitive functions. Radiomic features obtained from brain MRI have shown a great potential as non-invasive biomarkers for this disease; however, their usefulness has not yet been explored for individual brain regions. In this paper, we hypothesize that distinct regions are affected differently by AD and, thus, that shape or texture changes occurring in separate regions can be expressed by different radiomic features. Moreover, to improve the classification of AD and healthy control (HC) subjects, we propose novel features based on the entropy of the convolution neural network (CNN) feature maps. The proposed approach is evaluated comprehensively using the Open Access Series of Imaging Studies database. Our experiments assess the significance of 45 different radiomic features from individual subcortical regions, via the Wilcoxon test. We also use the random forest classifier to identify the subcortical regions that best differentiate AD patients from HC subjects. Our analysis identified the features derived from several subcortical regions that show significant differences between AD and HC (corrected p <; 0.01). Specifically, we found correlation and volume features from the hippocampus (AUC = 81.19% - 84.09%) and amygdala (AUC = 79.70% - 80.27%) regions to have the greatest discriminative power. Furthermore, the proposed entropy features derived from CNN layers yielded the highest classification AUC of 92.58%, compared to 84.45% for the combined radiomic features of all subcortical. These results suggest that the proposed CNN entropy features could be used as an effective biomarker for AD.},
keywords={Feature extraction;Magnetic resonance imaging;Entropy;Dementia;Hippocampus;Three-dimensional displays;Alzheimer’s;radiomics;classification},
doi={10.1109/ACCESS.2018.2871977},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{8916372,
author={Liu, Jin and Zeng, Dejiao and Lu, Mingming and Wang, Jianxin},
booktitle={2019 Seventh International Conference on Advanced Cloud and Big Data (CBD)}, title={Mild Cognitive Impairment Identification Based on Multi-View Graph Convolutional Networks},
year={2019},
volume={},
number={},
pages={309-314},
abstract={Though reversing the pathology of Alzheimer's disease (AD) has so far not been possible, a more tractable goal may be the prevention or slowing of the disease in its earliest stage, such as mild cognitive impairment (MCI). However, it is still challenge to identify patients with MCI in clinical practice. To address this challenge, we propose a new MCI identification method based on multi-view graph convolutional networks (MVGCNs). Firstly, we extract multiple morphological features based on multi-atlas from the imaging data of each subject. Then, we construct multiple population graphs (PGs) based on all experimental subjects using morphological features and non-imaging data of each subject. Afterwards, to obtain more discriminant features for MCI identification, multi-view graph convolutional networks are proposed for PGs based on each atlas. Finally, a new ensemble learning method is proposed to perform MCI identification task. Our proposed method is evaluated on 1449 subjects (including 301 subjects with AD, 779 subjects with MCI and 369 subjects with cognitively normal (CN)) from Alzheimer's Disease Neuroimaging Initiative (ADNI). Experimental results show that our proposed method achieves an accuracy of 90.8% for MCI/CN classification, and an accuracy of 88.6% for MCI/AD classification, respectively. Overall, our proposed method is effective and promising for automatic diagnosis of MCI in clinical practice.},
keywords={Magnetic resonance imaging;Feature extraction;Dementia;Sociology;Statistics;MCI identification;Multi-view feature representation;Graph convolutional networks;View pooling;Ensemble learning},
doi={10.1109/CBD.2019.00062},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{8678976,
author={Maria, Aileni Raluca and Bogdan, Hurezeanu and Sever, Pasca},
booktitle={2018 10th International Conference on Electronics, Computers and Artificial Intelligence (ECAI)}, title={Wavelet Transform for Seizures Detection in EEG Records},
year={2018},
volume={},
number={},
pages={1-6},
abstract={In this paper, we propose an algorithm based on wavelet transform for seizures detection in EEG records. Epilepsy is a disorder that affects about 1% of the population. Seizure detection is important in patient monitoring and in diagnostic. For this work were used records from 23 channels EEG scalp. The method consists in signal processing by using DWT (discrete wavelet transforms). The signals were passed through low pass filter and decomposed using high-pass filter. The outputs are the detail coefficients and approximation coefficients. The decomposition was repeated for increasing the frequency resolution, approximation coefficients were decomposed with high and low-pass filters. After signal processing for seizure detection we used neural network for classify the EEG seizure segments by finding the onset and offset points.},
keywords={Electroencephalography;Epilepsy;Pathology;Sleep;Alzheimer's disease;EEG;seizure;wavelet;signals;neural network},
doi={10.1109/ECAI.2018.8678976},
ISSN={},
month={June},}
@INPROCEEDINGS{9078929,
author={Alasal, Sanaa Abu and AL Bashabsheh, Emran and Najadat, Hassan},
booktitle={2020 11th International Conference on Information and Communication Systems (ICICS)}, title={Overview of Positron Emission Tomography (PET) for Brain Functions Degeneration Classification},
year={2020},
volume={},
number={},
pages={277-282},
abstract={Positron Emission Tomography scans show metabolic changes that occur in an organ or tissue at the cellular level. This is important because at the cellular level the disease always starts. Computed Tomography scans and Magnetic Resonance Images are not able to reveal cell-level problems. So, Positron Emission Tomography scans can detect changes in the cells very early, but the others detect changes as a disease affects the organs or tissue structure. Since it rises, Positron Emission Tomography gained a serious role in the diagnosis and treatment of brain disorders such as Alzheimer's disease, Parkinson's and Dementia, in addition to tumors. Because of the high level of chemical activity that exists in abnormal tissues such as cancer cells, these cells will show up as bright spots on these scans. This can play a major role in the diagnostic process if modern image processing methods are used to identify bright areas, as it will assist specialists in the diagnostic process and monitor the pathological condition during the treatment period. In this paper we summarize the most prominent methods used in processing positron images, starting from the traditional stages through to machine learning techniques and then to deep learning that occupies a large area in recent days.},
keywords={PET-scans;Alzheimer’s;Parkinson’s;MCI;Brain tumor},
doi={10.1109/ICICS49469.2020.239500},
ISSN={2573-3346},
month={April},}
@INPROCEEDINGS{8910066,
author={Padole, Himanshu and Joshi, S.D. and Gandhi, Tapan K.},
booktitle={2018 2nd European Conference on Electrical Engineering and Computer Science (EECS)}, title={Early Detection of Alzheimer's Disease using Graph Signal Processing on Neuroimaging Data},
year={2018},
volume={},
number={},
pages={302-306},
abstract={Brain imaging signals obtained using different imaging modalities mostly reside on irregular structures. While most of the classical signal processing methods are designed for signals having a regular structure, a new field of signal processing called Graph Signal Processing (GSP) is growing rapidly which deals with the irregularly structured data. So, GSP has become a natural choice for many brain image analysis applications. In this paper, we consider the problem of detection of Alzheimer's Disease (AD) in the early stages using fMRI data obtained from ADNI dataset. Firstly, we extract efficient discriminating features from resting state fMRI data using our novel hypothesis which is based on the outcomes of two neurological experiments carried out independently. Then we classify these graph signals by designing a classifier based on recently proposed graph convolutional neural network (GCNN). GCNN is the generalization of convolutional neural network (CNN) to the irregular domain using the concepts of GSP. We constructed brain graphs using different connectivity measures and compared the performance obtained using these graphs to find the best suitable connectivity measure for our application. Our proposed model outperforms state-of-the-art AD detection methods with a classification accuracy of 92.44%. This improvement can be associated with the fact that we first extracted highly discriminating features using graph frequency analysis performed with suitably constructed graphs and then applied properly designed GCNN classifier to classify the input graph signals.},
keywords={Laplace equations;Feature extraction;Brain modeling;Convolution;Diseases;Alzheimer's Disease, Graph Signal Processing, Graph Fourier Transform, Graph Convolutional Neural Network},
doi={10.1109/EECS.2018.00062},
ISSN={},
month={Dec},}
@ARTICLE{9380278,
author={Basheer, Shakila and Bhatia, Surbhi and Sakri, Sapiah Binti},
journal={IEEE Access}, title={Computational Modeling of Dementia Prediction Using Deep Neural Network: Analysis on OASIS Dataset},
year={2021},
volume={9},
number={},
pages={42449-42462},
abstract={Alzheimer is a progressive disease and it is the most prevalent neurodegenerative disorder. It is believed that the people with mild cognitive impairment are at high risk of developing this disease. According to the annual report released by the Alzheimer’s Association®2020, Alzheimer is the sixth leading cause of death in the United States. Thus, there is a need of educating people about this disease, reducing the risks by militating the necessary precautions to disseminate its affect by diagnosing it at early stages. It is also important to propose some recent advancement in this research which can help in early prediction of the disease using machine learning techniques. This paper intends to develop the novel algorithm by proposing changes in the designing of capsule network for best prediction results and making the model computationally efficient. The research is conducted on the Open Access Series of Imaging Studies (OASIS) dataset with dimensions (373 X 15) to diagnose the labels into two groups, as demented and non-demented. The novelty lies in conducting the in-depth research in identifying the importance of features, correlation study between factors and density of data showing status of factors by studying hierarchical examination of all the data points available using exploratory data analysis. Several optimization functions are conducted on the variables and feature selection is done to make the model faster and more accurate. The claims have been validated by showing the correlation accuracy at several iterations and layers with an admissible accuracy of 92.39%. The model is compared with state-of-art deep learning classifiers taken as benchmarks using different performance metrics. The ablation study is conducted on the proposed model using OASIS dataset to justify the predictions of the model.},
keywords={Feature extraction;Deep learning;Magnetic resonance imaging;Machine learning;Predictive models;Neuroimaging;Prediction algorithms;Dementia;Alzheimer’s disease;neural network models;machine learning;deep learning;convolutional neural networks;capsule networks},
doi={10.1109/ACCESS.2021.3066213},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{9206875,
author={Roychowdhury, Shoumik and Roychowdhury, Shounak},
booktitle={2020 International Joint Conference on Neural Networks (IJCNN)}, title={A Modular Framework to Predict Alzheimer’s Disease Progression Using Conditional Generative Adversarial Networks},
year={2020},
volume={},
number={},
pages={1-8},
abstract={Alzheimer's disease (AD) is a chronic neurodegenerative disease that worsens over time. The number of AD cases is growing, around 3 million new US cases each year. Although state-of-the-art research shows promise, predicting the disease's rate of progression for a case by case basis remains a challenging problem. Current methods of predicting the progression of AD can delay treatment and lead to misdiagnosis. We propose a novel approach to simulate the rate of progression of AD and the atrophy of the brain over time. We seek to achieve this by generating synthetic magnetic resonance (MR) images via a series of Conditional Deep Convolutional Generative Adversarial Neural Networks (CDCGANs) and then analyze them by computing the fractal dimensionality of the cortical brain ribbons. This paper shows the feasibility of this proposal by cascading CDCGANs that simulate different stages of AD. It is possible to extend by a tandem of CDCGANs that would simulate the different stages of the disease. MR images used here are from ADNI(Alzheimer's Disease Neuroimaging Initiative). The atrophy is measure using fractal dimension (box-counting method)of the cortical ribbon(CR). A decreasing fractal dimension is a confirmation that the disease progress over time.},
keywords={Fractals;Generative adversarial networks;Tensile stress;Generators;Gallium nitride;Dementia},
doi={10.1109/IJCNN48605.2020.9206875},
ISSN={2161-4407},
month={July},}
@INPROCEEDINGS{8451295,
author={Kumar, Pulkit and Nagar, Pravin and Arora, Chetan and Gupta, Anubha},
booktitle={2018 25th IEEE International Conference on Image Processing (ICIP)}, title={U-Segnet: Fully Convolutional Neural Network Based Automated Brain Tissue Segmentation Tool},
year={2018},
volume={},
number={},
pages={3503-3507},
abstract={Automated brain tissue segmentation into white matter (WM), gray matter (GM), and cerebro-spinal fluid (CSF) from magnetic resonance images (MRI) is helpful in the diagnosis of neuro-disorders such as epilepsy, Alzheimer's, multiple sclerosis, etc. However, thin GM structures at the periphery of cortex and smooth transitions on tissue boundaries such as between GM and WM, or WM and CSF pose difficulty in building a reliable segmentation tool. This paper proposes a Fully Convolutional Neural Network (FCN) tool, that is a hybrid of two widely used deep learning segmentation architectures SegNet and U-Net, for improved brain tissue segmentation. We propose a skip connection inspired from U-Net, in the SegNet architetcure, to incorporate fine multiscale information for better tissue boundary identification. We show that the proposed U-SegNet architecture, improves segmentation performance, as measured by average dice ratio, to 89.74% on the widely used IBSR dataset consisting of T-1 weighted MRI volumes of 18 subjects.},
keywords={Image segmentation;Training;Brain;Magnetic resonance imaging;Task analysis;Three-dimensional displays;Computer architecture},
doi={10.1109/ICIP.2018.8451295},
ISSN={2381-8549},
month={Oct},}
@INPROCEEDINGS{9098419,
author={Ahmed, Olfa Ben and Fezzani, Seifeddine and Guillevin, Carole and Fezai, Lobna and Naudin, Mathieu and Gianelli, Benoit and Fernandez-Maloigne, Christine},
booktitle={2020 IEEE 17th International Symposium on Biomedical Imaging (ISBI)}, title={DeepMRS: An End-to-End Deep Neural Network for Dementia Disease Detection using MRS Data},
year={2020},
volume={},
number={},
pages={1459-1463},
abstract={Alzheimer`s disease (AD) is the most common form of dementia. Neuroimaging data is an integral part of the clinical assessment providing a way for clinicians to detect brain abnormalities for AD diagnosis. Anatomical MRI has been widely used to assess structural brain atrophy for AD detection and prediction. In addition to structural changes, metabolic changes in some brain regions such as the Posterior Cingulate Cortex (PCC) could be a good bio-marker for an early AD detection. Recently, proton Magnetic Resonance Spectroscopy (1H-MRS) have been proved to be effective to reveal a wealth of brain metabolic information. In this paper, we propose an end-to-end deep leaning Network for early AD and Normal Control (NC) subjects classification using 1H-MRS raw data from the PCC area. This work is the first investigation of 1H - MRS data with deep-learning technique for early AD detection. Data of 135 subjects, collected in Poitiers university hospital, are used to learn the proposed DeepMRS network. Our classification of patients with early AD versus NC subjects achieves an AUC of 94,74%, a sensitivity of 100% and a specificity of 89,47% demonstrating a promising early dementia detection performance.},
keywords={Magnetic resonance imaging;Machine learning;Dementia;Training;Spectroscopy;Hippocampus},
doi={10.1109/ISBI45749.2020.9098419},
ISSN={1945-8452},
month={April},}
@ARTICLE{8669968,
author={Kuijf, Hugo J. and Biesbroek, J. Matthijs and De Bresser, Jeroen and Heinen, Rutger and Andermatt, Simon and Bento, Mariana and Berseth, Matt and Belyaev, Mikhail and Cardoso, M. Jorge and Casamitjana, Adrià and Collins, D. Louis and Dadar, Mahsa and Georgiou, Achilleas and Ghafoorian, Mohsen and Jin, Dakai and Khademi, April and Knight, Jesse and Li, Hongwei and Lladó, Xavier and Luna, Miguel and Mahmood, Qaiser and McKinley, Richard and Mehrtash, Alireza and Ourselin, Sébastien and Park, Bo-Yong and Park, Hyunjin and Park, Sang Hyun and Pezold, Simon and Puybareau, Elodie and Rittner, Leticia and Sudre, Carole H. and Valverde, Sergi and Vilaplana, Verónica and Wiest, Roland and Xu, Yongchao and Xu, Ziyue and Zeng, Guodong and Zhang, Jianguo and Zheng, Guoyan and Chen, Christopher and van der Flier, Wiesje and Barkhof, Frederik and Viergever, Max A. and Biessels, Geert Jan},
journal={IEEE Transactions on Medical Imaging}, title={Standardized Assessment of Automatic Segmentation of White Matter Hyperintensities and Results of the WMH Segmentation Challenge},
year={2019},
volume={38},
number={11},
pages={2556-2568},
abstract={Quantification of cerebral white matter hyperintensities (WMH) of presumed vascular origin is of key importance in many neurological research studies. Currently, measurements are often still obtained from manual segmentations on brain MR images, which is a laborious procedure. The automatic WMH segmentation methods exist, but a standardized comparison of the performance of such methods is lacking. We organized a scientific challenge, in which developers could evaluate their methods on a standardized multi-center/-scanner image dataset, giving an objective comparison: the WMH Segmentation Challenge. Sixty T1 + FLAIR images from three MR scanners were released with the manual WMH segmentations for training. A test set of 110 images from five MR scanners was used for evaluation. The segmentation methods had to be containerized and submitted to the challenge organizers. Five evaluation metrics were used to rank the methods: 1) Dice similarity coefficient; 2) modified Hausdorff distance (95th percentile); 3) absolute log-transformed volume difference; 4) sensitivity for detecting individual lesions; and 5) F1-score for individual lesions. In addition, the methods were ranked on their inter-scanner robustness; 20 participants submitted their methods for evaluation. This paper provides a detailed analysis of the results. In brief, there is a cluster of four methods that rank significantly better than the other methods, with one clear winner. The inter-scanner robustness ranking shows that not all the methods generalize to unseen scanners. The challenge remains open for future submissions and provides a public platform for method evaluation.},
keywords={Image segmentation;Three-dimensional displays;Manuals;White matter;Biomedical imaging;Radiology;Magnetic resonance imaging (MRI);brain;evaluation and performance;segmentation},
doi={10.1109/TMI.2019.2905770},
ISSN={1558-254X},
month={Nov},}
@ARTICLE{8105819,
author={Chang, Herng-Hua and Li, Cheng-Yuan and Gallogly, Audrey Haihong},
journal={IEEE Transactions on Biomedical Engineering}, title={Brain MR Image Restoration Using an Automatic Trilateral Filter With GPU-Based Acceleration},
year={2018},
volume={65},
number={2},
pages={400-413},
abstract={Objective: Noise reduction in brain magnetic resonance (MR) images has been a challenging and demanding task. This study develops a new trilateral filter that aims to achieve robust and efficient image restoration. Methods: Extended from the bilateral filter, the proposed algorithm contains one additional intensity similarity funct-ion, which compensates for the unique characteristics of noise in brain MR images. An entropy function adaptive to intensity variations is introduced to regulate the contributions of the weighting components. To hasten the computation, parallel computing based on the graphics processing unit (GPU) strategy is explored with emphasis on memory allocations and thread distributions. To automate the filtration, image texture feature analysis associated with machine learning is investigated. Among the 98 candidate features, the sequential forward floating selection scheme is employed to acquire the optimal texture features for regularization. Subsequently, a two-stage classifier that consists of support vector machines and artificial neural networks is established to predict the filter parameters for automation. Results: A speedup gain of 757 was reached to process an entire MR image volume of 256 × 256 × 256 pixels, which completed within 0.5 s. Automatic restoration results revealed high accuracy with an ensemble average relative error of 0.53 ± 0.85% in terms of the peak signal-to-noise ratio. Conclusion: This self-regulating trilateral filter outperformed many state-of-the-art noise reduction methods both qualitatively and quantitatively. Significance: We believe that this new image restoration algorithm is of potential in many brain MR image processing applications that require expedition and automation.},
keywords={Image restoration;Filtering algorithms;Wiener filters;Signal to noise ratio;Filtering;Automation;GPU;image restoration;MRI;neural networks;SVM;texture feature;trilateral filter},
doi={10.1109/TBME.2017.2772853},
ISSN={1558-2531},
month={Feb},}
@INPROCEEDINGS{9315758,
author={Kaur, Sukhpal and Aggarwal, Himanshu and Rani, Rinkle},
booktitle={2020 Sixth International Conference on Parallel, Distributed and Grid Computing (PDGC)}, title={Neurological disease prediction using ensembled Machine Learning Model},
year={2020},
volume={},
number={},
pages={410-414},
abstract={Alzheimer's disease is irreparable neurological damage caused to the cognitive functioning of the human body. A previous diagnosis of Alzheimer's will help to deal with the cure of this disease. Studies supporting the ailment have applied many mathematical and machine learning models. Magnetic resonance imaging is a normal procedure involved in the clinical diagnosis of the disease. However, there are a few challenges to its diagnosis due to variations in its MRI samples and their stability concerning the healthy people. Presently, to assess fundamental brain shifts in magneto resonance imaging (MRI), deep learning methods have been used. Because of its excellent performance in automatic features processing a convolution neural network has become popular with a variety of multilayer perceptrons. Moreover, Ensemble Learning (EL) proved its advantages by integrating several models into the learning system's robustness. Here, we propose a collaborative technique concerning Ensemble learning designed for classifying healthy or Alzheimer's disease people with the help of MR images. We carried out detailed experiments to demonstrate our approach to the open-access sequence of image datasets that outperformed a comparative approach.},
keywords={Diseases;Alzheimer's disease;Magnetic resonance imaging;Training;Testing;Computational modeling;Handheld computers;Alzheimer's disease;Transfer Learning;Ensemble Learning;VGG-16;Machine learning},
doi={10.1109/PDGC50313.2020.9315758},
ISSN={2573-3079},
month={Nov},}
@ARTICLE{9373391,
author={He, Yuru and Cao, Shuangliang and Zhang, Hongyan and Sun, Hao and Wang, Fanghu and Zhu, Huobiao and Lv, Wenbing and Lu, Lijun},
journal={IEEE Access}, title={Dynamic PET Image Denoising With Deep Learning-Based Joint Filtering},
year={2021},
volume={9},
number={},
pages={41998-42012},
abstract={Dynamic positron emission tomography (PET) imaging usually suffers from high statistical noise due to low counts of the short frames. This study aims to improve the image quality of the short frames by utilizing information from other modality. We develop a deep learning-based joint filtering framework for simultaneously incorporating information from longer acquisition PET frames and high-resolution magnetic resonance (MR) images into the short frames. The network inputs are noisy PET images and corresponding MR images while the outputs are linear coefficients of spatially variant linear representation model. The composite of all dynamic frames is used as training label in each sample, and it is down-sampled to 1/10th of counts as the training input. L1-norm combined with two gradient-based regularizations constitute the loss function during training. Ten realistic dynamic PET/MR phantoms based on BrainWeb are used for pre-training and eleven clinical subjects from Alzheimer’s Disease Neuroimaging Initiative further for fine-tuning. Simulation results show that the proposed method can reduce the statistical noise while preserving image details and achieve quantitative enhancements compared with Gaussian, guided filter, and convolutional neural network trained with the mean squared error. The clinical results perform better than others in terms of the mean activity and standard deviation. All of the results indicate that the proposed deep learning-based joint filtering framework is of great potential for dynamic PET image denoising.},
keywords={Positron emission tomography;Training;Convolution;Image edge detection;Nonlinear filters;Maximum likelihood detection;Artificial neural networks;Positron emission tomography;convolution neural network;denoising;spatially variant linear representation model;joint filtering},
doi={10.1109/ACCESS.2021.3064926},
ISSN={2169-3536},
month={},}
@ARTICLE{9203784,
author={Li, Jialiang and Yao, Zhaomin and Duan, Meiyu and Liu, Shuai and Li, Fei and Zhu, Haiyang and Xia, Zhiqiang and Huang, Lan and Zhou, Fengfeng},
journal={IEEE Access}, title={MuscNet, a Weighted Voting Model of Multi-Source Connectivity Networks to Predict Mild Cognitive Impairment Using Resting-State Functional MRI},
year={2020},
volume={8},
number={},
pages={174023-174031},
abstract={The neurological disorder mild cognitive impairment (MCI) demonstrates minor impacts on the patient's daily activities and may be ignored as the status of normal aging. But some of the MCI patients may further develop into severe statuses like Alzheimer's disease (AD). The brain functional connectivity network (BFCN) was usually constructed from the resting-state functional magnetic resonance imaging (rs-fMRI) data. This technology has been widely used to detect the neurodegenerative dementia and to reveal the intrinsic mechanism of neural activities. The BFCN edge was usually determined by the pairwise correlation between the brain regions. This study proposed a weighted voting model of multi-source connectivity networks (MuscNet) by integrating multiple BFCNs of different correlation coefficients. Our model was further improved by removing redundant features. The experimental data demonstrated that different BFCNs contributed complementary information to each other and MuscNet outperformed the existing models on detecting MCI patients. The previous study suggested the existence of multiple solutions with similarly good performance for a machine learning problem. The proposed model MuscNet utilized a weighted voting strategy to slightly outperform the existing studies, suggesting an effective way to fuse multiple base models. The reason may need further theoretical investigations about why different base models contribute to each other for the MCI prediction.},
keywords={Correlation;Correlation coefficient;Brain modeling;Measurement;Dementia;Time series analysis;Mild cognitive impairment;Alzheimer’s disease;resting-state functional MRI;brain functional connectivity network;multi-source connectivity network;weighted voting model;MuscNet},
doi={10.1109/ACCESS.2020.3025828},
ISSN={2169-3536},
month={},}
@ARTICLE{9050815,
author={Zhang, Zehua and Ding, Jiaqi and Xu, Junhai and Tang, Jijun and Guo, Fei},
journal={IEEE Journal of Biomedical and Health Informatics}, title={Multi-Scale Time-Series Kernel-Based Learning Method for Brain Disease Diagnosis},
year={2021},
volume={25},
number={1},
pages={209-217},
abstract={The functional magnetic resonance imaging (fMRI) is a noninvasive technique for studying brain activity, such as brain network analysis, neural disease automated diagnosis and so on. However, many existing methods have some drawbacks, such as limitations of graph theory, lack of global topology characteristic, local sensitivity of functional connectivity, and absence of temporal or context information. In addition to many numerical features, fMRI time series data also cover specific contextual knowledge and global fluctuation information. Here, we propose multi-scale time-series kernel-based learning model for brain disease diagnosis, based on Jensen-Shannon divergence. First, we calculate correlation value within and between brain regions over time. In addition, we extract multi-scale synergy expression probability distribution (interactional relation) between brain regions. Also, we produce state transition probability distribution (sequential relation) on single brain regions. Then, we build time-series kernel-based learning model based on Jensen-Shannon divergence to measure similarity of brain functional connectivity. Finally, we provide an efficient system to deal with brain network analysis and neural disease automated diagnosis. On Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset, our proposed method achieves accuracy of 0.8994 and AUC of 0.8623. On Major Depressive Disorder (MDD) dataset, our proposed method achieves accuracy of 0.9166 and AUC of 0.9263. Experiments show that our proposed method outperforms other existing excellent neural disease automated diagnosis approaches. It shows that our novel prediction method performs great accurate for identification of brain diseases as well as existing outstanding prediction tools.},
keywords={Time series analysis;Probability distribution;Functional magnetic resonance imaging;Diseases;Kernel;Correlation;Brain;Functional magnetic resonance imaging;time-series kernel;disease diagnosis;alzheimeris disease;major depressive disorder;Jensen-Shannon divergence},
doi={10.1109/JBHI.2020.2983456},
ISSN={2168-2208},
month={Jan},}
@ARTICLE{8119531,
author={Ju, Ronghui and Hu, Chenhui and zhou, pan and Li, Quanzheng},
journal={IEEE/ACM Transactions on Computational Biology and Bioinformatics}, title={Early Diagnosis of Alzheimer's Disease Based on Resting-State Brain Networks and Deep Learning},
year={2019},
volume={16},
number={1},
pages={244-257},
abstract={Computerized healthcare has undergone rapid development thanks to the advances in medical imaging and machine learning technologies. Especially, recent progress on deep learning opens a new era for multimedia based clinical decision support. In this paper, we use deep learning with brain network and clinical relevant text information to make early diagnosis of Alzheimer's Disease (AD). The clinical relevant text information includes age, gender, and $ApoE$ gene of the subject. The brain network is constructed by computing the functional connectivity of brain regions using resting-state functional magnetic resonance imaging (R-fMRI) data. A targeted autoencoder network is built to distinguish normal aging from mild cognitive impairment, an early stage of AD. The proposed method reveals discriminative brain network features effectively and provides a reliable classifier for AD detection. Compared to traditional classifiers based on R-fMRI time series data, about 31.21 percent improvement of the prediction accuracy is achieved by the proposed deep learning method, and the standard deviation reduces by 51.23 percent in the best case that means our prediction model is more stable and reliable compared to the traditional methods. Our work excavates deep learning's advantages of classifying high-dimensional multimedia data in medical services, and could help predict and prevent AD at an early stage.},
keywords={Machine learning;Feature extraction;Brain;Dementia;Correlation;Brain network;deep learning;early diagnosis;Alzheimer's disease},
doi={10.1109/TCBB.2017.2776910},
ISSN={1557-9964},
month={Jan},}
@ARTICLE{8328840,
author={Bhaumik, Dulal and Jie, Fei and Nordgren, Rachel and Bhaumik, Runa and Sinha, Bikas K.},
journal={IEEE Transactions on Medical Imaging}, title={A Mixed-Effects Model for Detecting Disrupted Connectivities in Heterogeneous Data},
year={2018},
volume={37},
number={11},
pages={2381-2389},
abstract={The human brain is an amazingly complex network. Aberrant activities in this network can lead to various neurological disorders such as multiple sclerosis, Parkinson's disease, Alzheimer's disease, and autism. functional magnetic resonance imaging has emerged as an important tool to delineate the neural networks affected by such diseases, particularly autism. In this paper, we propose a special type of mixed-effects model together with an appropriate procedure for controlling false discoveries to detect disrupted connectivities for developing a neural network in whole brain studies. Results are illustrated with a large data set known as autism brain imaging data exchange which includes 361 subjects from eight medical centers.},
keywords={Autism;Functional magnetic resonance imaging;Data models;Feature extraction;Analytical models;Brain modeling;Electronic mail;False discovery rate;functional magnetic resonance imaging;mixed-effects models},
doi={10.1109/TMI.2018.2821655},
ISSN={1558-254X},
month={Nov},}
@INPROCEEDINGS{8363631,
author={Mostapha, Mahmoud and Kim, SunHyung and Wu, Guorong and Zsembik, Leo and Pizer, Stephen and Styner, Martin},
booktitle={2018 IEEE 15th International Symposium on Biomedical Imaging (ISBI 2018)}, title={Non-Euclidean, convolutional learning on cortical brain surfaces},
year={2018},
volume={},
number={},
pages={527-530},
abstract={In recent years there have been many studies indicating that multiple cortical features, extracted at each surface vertex, are promising in the detection of various neurodevelopmental and neurodegenerative diseases. However, with limited datasets, it is challenging to train stable classifiers with such high-dimensional surface data. This necessitates a feature reduction that is commonly accomplished via regional volumetric morphometry from standard brain atlases. However, current regional summaries are not specific to the given age or pathology that is studied, which runs the risk of losing relevant information that can be critical in the classification process. To solve this issue, this paper proposes a novel data-driven approach by extending convolutional neural networks (CNN) for use on non-Euclidean manifolds such as cortical surfaces. The proposed network learns the most powerful features and brain regions from the extracted large dimensional feature space; thus creating a new feature space in which the dimensionality is reduced and feature distributions are better separated. We demonstrate the usability of the proposed surface-CNN framework in an example study classifying Alzheimers disease patients versus normal controls. The high performance in the cross-validation diagnostic results shows the potential of our proposed prediction system.},
keywords={Feature extraction;Kernel;Surface reconstruction;Surface treatment;Manifolds;Diseases;Level measurement;MRI;Cortical Surfaces;Alzheimer's Disease;Deep Learning;Convolutional Neural Network},
doi={10.1109/ISBI.2018.8363631},
ISSN={1945-8452},
month={April},}
@ARTICLE{8540933,
author={Li, Yang and Yang, Hao and Lei, Baiying and Liu, Jingyu and Wee, Chong-Yaw},
journal={IEEE Transactions on Medical Imaging}, title={Novel Effective Connectivity Inference Using Ultra-Group Constrained Orthogonal Forward Regression and Elastic Multilayer Perceptron Classifier for MCI Identification},
year={2019},
volume={38},
number={5},
pages={1227-1239},
abstract={Mild cognitive impairment (MCI) detection is important, such that appropriate interventions can be imposed to delay or prevent its progression to severe stages, including Alzheimer's disease (AD). Brain connectivity network inferred from the functional magnetic resonance imaging data has been prevalently used to identify the individuals with MCI/AD from the normal controls. The capability to detect the causal or effective connectivity is highly desirable for understanding directed functional interactions between brain regions and further helping the detection of MCI. In this paper, we proposed a novel sparse constrained effective connectivity inference method and an elastic multilayer perceptron classifier for MCI identification. Specifically, a ultra-group constrained structure detection algorithm is first designed to identify the parsimonious topology of the effective connectivity network, in which the weak derivatives of the observable data are considered. Second, based on the identified topology structure, an effective connectivity network is then constructed by using an ultra-orthogonal forward regression algorithm to minimize the shrinking effect of the group constraint-based method. Finally, the effective connectivity network is validated in MCI identification using an elastic multilayer perceptron classifier, which extracts lower to higher level information from initial input features and hence improves the classification performance. Relatively high classification accuracy is achieved by the proposed method when compared with the state-of-the-art classification methods. Furthermore, the network analysis results demonstrate that MCI patients suffer a rich club effect loss and have decreased connectivity among several brain regions. These findings suggest that the proposed method not only improves the classification performance but also successfully discovers critical disease-related neuroimaging biomarkers.},
keywords={Feature extraction;Time series analysis;Functional magnetic resonance imaging;Diseases;Multilayer perceptrons;Classification algorithms;Data mining;Functional imaging;brain;computer-aided detection and diagnosis;connectivity analysis;machine learning},
doi={10.1109/TMI.2018.2882189},
ISSN={1558-254X},
month={May},}
@INPROCEEDINGS{8615774,
author={Alam, Saruar and Hamey, Len and Ho-Shon, Kevin},
booktitle={2018 Digital Image Computing: Techniques and Applications (DICTA)}, title={Impact of MRI Protocols on Alzheimer's Disease Detection},
year={2018},
volume={},
number={},
pages={1-8},
abstract={Alzheimer's disease (AD) can be detected using magnetic resonance imaging (MRI) based features and supervised classifiers. The subcortical and ventricular volumes change for AD patients. These volumes can be extracted from MRI by tools such as FreeSurfer and the multi-atlas-based likelihood fusion (MALF) algorithm. Studies use MRI from many medical imaging centers. However, individual centers typically use distinctive MRI protocols for brain scanning. The protocol differences include different scanner models with various operating parameters. Some scanner models have different field strengths. A key factor in classifying multicentric MR subject images having different protocols is how different scanner models affect the extraction of feature, and the subsequent classification performance of a supervised classifier. We have investigated the classification performance of FreeSurfer and MALF based volume features together with Radial Basis Function Support Vector Machine and Extreme Learning Machine across different imaging protocols. We have also investigated for both FreeSurfer and MALF, which brain regions are most effective for the detection of the disease under different protocols. Our study result indicates marginal differences in classification performance across scanner models with the same or different field strengths when differentiating AD, Mild Cognitive Impairment, and Normal Controls. We have also observed differences in ranking order of the most effective brain regions.},
keywords={Magnetic resonance imaging;Protocols;Feature extraction;Brain modeling;Support vector machines;Dementia;AD;MCI;CN;MALF;ROI;FreeSurfer},
doi={10.1109/DICTA.2018.8615774},
ISSN={},
month={Dec},}
@ARTICLE{8253440,
author={Liu, Mingxia and Zhang, Jun and Nie, Dong and Yap, Pew-Thian and Shen, Dinggang},
journal={IEEE Journal of Biomedical and Health Informatics}, title={Anatomical Landmark Based Deep Feature Representation for MR Images in Brain Disease Diagnosis},
year={2018},
volume={22},
number={5},
pages={1476-1485},
abstract={Most automated techniques for brain disease diagnosis utilize hand-crafted (e.g., voxel-based or region-based) biomarkers from structural magnetic resonance (MR) images as feature representations. However, these hand-crafted features are usually high-dimensional or require regions-of-interest defined by experts. Also, because of possibly heterogeneous property between the hand-crafted features and the subsequent model, existing methods may lead to sub-optimal performances in brain disease diagnosis. In this paper, we propose a landmark-based deep feature learning (LDFL) framework to automatically extract patch-based representation from MRI for automatic diagnosis of Alzheimer's disease. We first identify discriminative anatomical landmarks from MR images in a data-driven manner, and then propose a convolutional neural network for patch-based deep feature learning. We have evaluated the proposed method on subjects from three public datasets, including the Alzheimer's disease neuroimaging initiative (ADNI-1), ADNI-2, and the minimal interval resonance imaging in alzheimer's disease (MIRIAD) dataset. Experimental results of both tasks of brain disease classification and MR image retrieval demonstrate that the proposed LDFL method improves the performance of disease classification and MR image retrieval.},
keywords={Feature extraction;Training;Dementia;Testing;Image retrieval;Anatomical landmarks;convolutional neural network;classification;image retrieval;brain disease diagnosis},
doi={10.1109/JBHI.2018.2791863},
ISSN={2168-2208},
month={Sep.},}
@ARTICLE{8695110,
author={Gao, Fei and Wu, Teresa and Chu, Xianghua and Yoon, Hyunsoo and Xu, Yanzhe and Patel, Bhavika},
journal={IEEE Journal of Biomedical and Health Informatics}, title={Deep Residual Inception Encoder–Decoder Network for Medical Imaging Synthesis},
year={2020},
volume={24},
number={1},
pages={39-49},
abstract={Image synthesis is a novel solution in precision medicine for scenarios where important medical imaging is not otherwise available. The convolutional neural network (CNN) is an ideal model for this task because of its powerful learning capabilities through the large number of layers and trainable parameters. In this research, we propose a new architecture of residual inception encoder- decoder neural network (RIED-Net) to learn the nonlinear mapping between the input images and targeting output images. To evaluate the validity of the proposed approach, it is compared with two models from the literature: synthetic CT deep convolutional neural network (sCT-DCNN) and shallow CNN, using both an institutional mammogram dataset from Mayo Clinic Arizona and a public neuroimaging dataset from the Alzheimer's Disease Neuroimaging Initiative. Experimental results show that the proposed RIED-Net outperforms the two models on both datasets significantly in terms of structural similarity index, mean absolute percent error, and peak signal-to-noise ratio.},
keywords={Image segmentation;Biomedical imaging;Task analysis;Image generation;Magnetic resonance imaging;Tumors;Deep learning;image synthesis;inception;medical imaging and residual net},
doi={10.1109/JBHI.2019.2912659},
ISSN={2168-2208},
month={Jan},}
@INPROCEEDINGS{9098641,
author={Ma, Xin and Wu, Guorong and Kim, Won Hwa},
booktitle={2020 IEEE 17th International Symposium on Biomedical Imaging (ISBI)}, title={Enriching Statistical Inferences on Brain Connectivity for Alzheimer's Disease Analysis via Latent Space Graph Embedding},
year={2020},
volume={},
number={},
pages={1685-1689},
abstract={We develop a graph node embedding Deep Neural Network that leverages statistical outcome measure and graph structure given in the data. The objective is to identify regions of interests (ROIs) in the brain that are affected by topological changes of brain connectivity due to specific neurodegenerative diseases by enriching statistical group analysis. We tackle this problem by learning a latent space where statistical inference can be made more effectively. Our experiments on a large-scale Alzheimer's Disease dataset show promising result identifying ROIs that show statistically significant group differences separating even early and late Mild Cognitive Impairment (MCI) groups whose effect sizes are very subtle.},
keywords={Dementia;Brain modeling;Imaging;Biological neural networks;Indexes;Transforms;Brain Connectivity;Alzheimer's Disease;Group Analysis;Statistical Inference},
doi={10.1109/ISBI45749.2020.9098641},
ISSN={1945-8452},
month={April},}
@ARTICLE{8412571,
author={Li, Lexin and Kang, Jian and Lockhart, Samuel N. and Adams, Jenna and Jagust, William J.},
journal={IEEE Transactions on Medical Imaging}, title={Spatially Adaptive Varying Correlation Analysis for Multimodal Neuroimaging Data},
year={2019},
volume={38},
number={1},
pages={113-123},
abstract={In this paper, we study a central problem in multimodal neuroimaging analysis, i.e., identification of significantly correlated brain regions between multiple imaging modalities. We propose a spatially varying correlation model and the associated inference procedure, which improves substantially over the common alternative solutions of voxel-wise and region-wise analysis. Compared with voxel-wise analysis, our method aggregates voxels with similar correlations into regions, takes into account spatial continuity of correlations at nearby voxels, and enjoys a much higher detection power. Compared with region-wise analysis, our method does not rely on any pre-specified brain region map, but instead finds homogenous correlation regions adaptively given the data. We applied our method to a multimodal positron emission tomography study, and found brain regions with significant correlation between tau and glucose metabolism that voxel-wise or region-wise analysis failed to identify. Our findings conform and lend additional support to prior hypotheses about how the two pathological proteins of Alzheimer's disease, tau and amyloid, interact with glucose metabolism in the aging human brain.},
keywords={Correlation;Positron emission tomography;Magnetic resonance imaging;Neuroimaging;Sugar;Biochemistry;Alzheimer’s disease;graph partition;multimodal neuroimaging;positron emission tomography;varying coefficient model},
doi={10.1109/TMI.2018.2857221},
ISSN={1558-254X},
month={Jan},}
@ARTICLE{9151874,
author={Gonzalez, Hector A. and Muzaffar, Shahzad and Yoo, Jerald and Elfadel, Ibrahim M.},
journal={IEEE Access}, title={BioCNN: A Hardware Inference Engine for EEG-Based Emotion Detection},
year={2020},
volume={8},
number={},
pages={140896-140914},
abstract={EEG-based emotion classifiers have the potential of significantly improving the social integration of patients suffering from neurological disorders such as Amyotrophic Lateral Sclerosis or the acute stages of Alzheimer's disease. Emotion classifiers have historically used software on general-purpose computers and operating under off-line conditions. Yet the wearability of such classifiers is a must if they are to enable the socialization of critical-care patients. Such wearability requires the use of low-power hardware accelerators that would enable near real-time classification and extended periods of operations. In this article, we architect, design, implement, and test a handcrafted, hardware Convolutional Neural Network, named BioCNN, optimized for EEG-based emotion detection and other bio-medical applications. The EEG signals are generated using a low-cost, off-the-shelf device, namely, Emotiv Epoc+, and then denoised and pre-processed ahead of their use by BioCNN. For training and testing, BioCNN uses three repositories of emotion classification datasets, including the publicly available DEAP and DREAMER datasets, along with an original dataset collected in-house from 5 healthy subjects using standard visual stimuli. A subject-specific training approach is used under TensorFlow to train BioCNN, which is implemented using the Digilent Atlys Board with a low-cost Spartan-6 FPGA. The experimental results show a competitive energy efficiency of 11 GOps/W, a throughput of 1.65 GOps that is in line with the real-time specification of a wearable device, and a latency of less than 1 ms, which is smaller than the 150 ms required for human interaction times. Its emotion inference accuracy is competitive with the top software-based emotion detectors.},
keywords={Electroencephalography;Hardware;Feature extraction;Real-time systems;Engines;Training;Machine learning;Emotion recognition;EEG;FPGA;machine learning;hardware accelerator;edge AI;convolutional neural networks;hardware parallelism;pipelining},
doi={10.1109/ACCESS.2020.3012900},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{9344912,
author={Hu, Shengye and Yu, Wen and Chen, Zhuo and Wang, Shuqiang},
booktitle={2020 IEEE 6th International Conference on Computer and Communications (ICCC)}, title={Medical Image Reconstruction Using Generative Adversarial Network for Alzheimer Disease Assessment with Class-Imbalance Problem},
year={2020},
volume={},
number={},
pages={1323-1327},
abstract={One of the most challenging problem faced with medical image analysis is the lack of some modality images. In this work, we propose an effective data augmentation method that uses the generative adversarial network to reconstruct the missing PET images. A densely connected convolutional network is developed as the classification model to make the binary classification. The experiments on ADNI class-imbalanced dataset demonstrate that add the reconstructed images can significantly improve the classification performance of the densely connected model and effectively deal with the class-imbalanced challenge. The influence of different noisy dimensions is also detailedly discussed in term of maximum mean discrepancy and structural similarity metric. The proposed method will make some contribution to other clinical class-imbalanced datasets.},
keywords={Computational modeling;Generative adversarial networks;Noise measurement;Alzheimer's disease;Image reconstruction;Medical diagnostic imaging;Diseases;deep learning;medical image analysis;generative adversarial network},
doi={10.1109/ICCC51575.2020.9344912},
ISSN={},
month={Dec},}
@INPROCEEDINGS{8803334,
author={Rashed, Essam A. and Gomez-Tames, Jose and Hirata, Akimasa},
booktitle={2019 IEEE International Conference on Image Processing (ICIP)}, title={Generation of Head Models for Brain Stimulation Using Deep Convolution Networks},
year={2019},
volume={},
number={},
pages={2621-2625},
abstract={Transcranial magnetic stimulation (TMS) is a non-invasive clinical technique used for treatment of several neurological diseases such as depression, Alzheimer's disease and Parkinson's disease. However, it is always challenging to accurately adjust the electric field on different specific brain regions due to the requirement of several stimulation parameters' optimizations. A major factor of brain induced electric field is the inter-subject variability, therefore a computer simulation is frequently used to simulate different TMS setups using anatomical models generated from MR images of the examined subject. Human head models are generated by segmentation of MR images into different anatomical tissues with a uniform electric conductivity value for each tissue. This process is time-consuming and requires a special experience to segment a relatively large number of tissues.In this paper, we propose a deep convolution network for human head segmentation that is convenient for simulation of electrical field distribution, such as TMS. The proposed network is used to generate head models and is evaluated using TMS simulation studies. Results indicate that the head models generated using the proposed network demonstrate strong matching results with those achieved from manually segmented ones.},
keywords={Head;Brain modeling;Image segmentation;Magnetic heads;Computational modeling;Computer architecture;Magnetic resonance imaging;Transcranial magnetic stimulation;image segmentation;deep learning;convolution neural networks},
doi={10.1109/ICIP.2019.8803334},
ISSN={2381-8549},
month={Sep.},}
@ARTICLE{8727911,
author={Khan, Naimul Mefraz and Abraham, Nabila and Hon, Marcia},
journal={IEEE Access}, title={Transfer Learning With Intelligent Training Data Selection for Prediction of Alzheimer’s Disease},
year={2019},
volume={7},
number={},
pages={72726-72735},
abstract={Detection of Alzheimer's disease (AD) from neuroimaging data such as MRI through machine learning has been a subject of intense research in recent years. The recent success of deep learning in computer vision has progressed such research. However, common limitations with such algorithms are reliance on a large number of training images, and the requirement of careful optimization of the architecture of deep networks. In this paper, we attempt solving these issues with transfer learning, where the state-of-the-art VGG architecture is initialized with pre-trained weights from large benchmark datasets consisting of natural images. The network is then fine-tuned with layer-wise tuning, where only a pre-defined group of layers are trained on MRI images. To shrink the training data size, we employ image entropy to select the most informative slices. Through experimentation on the ADNI dataset, we show that with the training size of 10 to 20 times smaller than the other contemporary methods, we reach the state-of-the-art performance in AD vs. NC, AD vs. MCI, and MCI vs. NC classification problems, with a 4% and a 7% increase in accuracy over the state-of-the-art for AD vs. MCI and MCI vs. NC, respectively. We also provide a detailed analysis of the effect of the intelligent training data selection method, changing the training size, and changing the number of layers to be fine-tuned. Finally, we provide class activation maps (CAM) that demonstrate how the proposed model focuses on discriminative image regions that are neuropathologically relevant and can help the healthcare practitioner in interpreting the model's decision-making process.},
keywords={Training;Computer architecture;Training data;Convolution;Feature extraction;Alzheimer's disease;Deep learning;transfer learning;convolutional neural network;Alzheimer’s},
doi={10.1109/ACCESS.2019.2920448},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{8623946,
author={Jabason, Emimal and Ahmad, M. Omair and S Swamy, M. N.},
booktitle={2018 IEEE 61st International Midwest Symposium on Circuits and Systems (MWSCAS)}, title={Deep Structural and Clinical Feature Learning for Semi-Supervised Multiclass Prediction of Alzheimer’s Disease},
year={2018},
volume={},
number={},
pages={791-794},
abstract={Although there is no cure for Alzheimer's disease (AD), the early accurate prediction of clinical status plays a significant role in preventing, treating, and slowing down the progression of the disease. However, the absence of a single test and the complexity of AD create delays in diagnosis. In recent years, diagnosis of AD using different biomarkers through machine learning techniques has been the hottest research in the medical field. However, a common bottleneck of the diagnostic performance is overfitting due to having lot of irrelevant features in the training data. In view of this fact, we propose a novel classification framework which uses unsupervised autoencoder network to select the subset from given structural and clinical features by exploring the linear and nonlinear relationship among them followed by a supervised multinomial logistic layer to automatically identify the patients having AD, mild cognitive impairment (MCI), and cognitively normal (CN) clinical status. Through experimental results on Alzheimer's disease neuroimaging initiative (ADNI) database, it is shown that the proposed classification algorithm achieves better performance in terms of accuracy, sensitivity, and specificity in 5-fold cross validation when compared to the state-of-the-art methods.},
keywords={Alzheimer's disease;Feature extraction;Magnetic resonance imaging;Sensitivity;Biomarkers;Databases;Alzheimer’s disease (AD), Structural magnetic resonance imaging (MRI), Neurophysiological test, Unsupervised feature selection, Supervised classification, Deep learning},
doi={10.1109/MWSCAS.2018.8623946},
ISSN={1558-3899},
month={Aug},}
@INPROCEEDINGS{9098445,
author={Ramon-Julvez, Ubaldo and Hernandez, Monica and Mayordomo, Elvira and Adni},
booktitle={2020 IEEE 17th International Symposium on Biomedical Imaging (ISBI)}, title={Analysis of the Influence of Diffeomorphic Normalization in the Prediction of Stable VS Progressive MCI Conversion with Convolutional Neural Networks},
year={2020},
volume={},
number={},
pages={1120-1124},
abstract={We study the effect of the selection of diffeomorphic normalization in the performance of Spasov's deep-learning system for the problem of progressive MCI vs stable MCI discrimination. We considered different degrees of normalization (no, affine and non-rigid normalization) and two diffeomorphic registration methods (ANTS and BL PDE-LDDMM) with different image similarity metrics (SSD, NCC, and lNCC) yielding qualitatively different deformation models and quantitatively different degrees of registration accuracy. BL PDE-LDDMM NCC achieved the best performing accuracy with median values of 89%. Surprisingly, the accuracy of no and affine normalization was also among the highest, indicating that the deep-learning system is powerful enough to learn accurate models for pMCI vs sMCI discrimination without the need for normalization. However, the best sensitivity values were obtained by BL PDE-LDDMM SSD and NCC with median values of 97% and 94% while the sensitivity of the remaining methods stayed under 88%.},
keywords={Magnetic resonance imaging;Streaming media;Dementia;Tools;Biomarkers;CNNs;multi-task learning;diffeomorphic normalization;Alzheimer's;pMCI vs sMCI},
doi={10.1109/ISBI45749.2020.9098445},
ISSN={1945-8452},
month={April},}
@ARTICLE{9151307,
author={Lian, Chunfeng and Liu, Mingxia and Pan, Yongsheng and Shen, Dinggang},
journal={IEEE Transactions on Cybernetics}, title={Attention-Guided Hybrid Network for Dementia Diagnosis With Structural MR Images},
year={2020},
volume={},
number={},
pages={1-12},
abstract={Deep-learning methods (especially convolutional neural networks) using structural magnetic resonance imaging (sMRI) data have been successfully applied to computer-aided diagnosis (CAD) of Alzheimer's disease (AD) and its prodromal stage [i.e., mild cognitive impairment (MCI)]. As it is practically challenging to capture local and subtle disease-associated abnormalities directly from the whole-brain sMRI, most of those deep-learning approaches empirically preselect disease-associated sMRI brain regions for model construction. Considering that such isolated selection of potentially informative brain locations might be suboptimal, very few methods have been proposed to perform disease-associated discriminative region localization and disease diagnosis in a unified deep-learning framework. However, those methods based on task-oriented discriminative localization still suffer from two common limitations, that is: 1) identified brain locations are strictly consistent across all subjects, which ignores the unique anatomical characteristics of each brain and 2) only limited local regions/patches are used for model training, which does not fully utilize the global structural information provided by the whole-brain sMRI. In this article, we propose an attention-guided deep-learning framework to extract multilevel discriminative sMRI features for dementia diagnosis. Specifically, we first design a backbone fully convolutional network to automatically localize the discriminative brain regions in a weakly supervised manner. Using the identified disease-related regions as spatial attention guidance, we further develop a hybrid network to jointly learn and fuse multilevel sMRI features for CAD model construction. Our proposed method was evaluated on three public datasets (i.e., ADNI-1, ADNI-2, and AIBL), showing superior performance compared with several state-of-the-art methods in both tasks of AD diagnosis and MCI conversion prediction.},
keywords={Feature extraction;Brain modeling;Task analysis;Dementia;Solid modeling;Medical diagnosis;Alzheimer's disease (AD);convolutional neural networks (CNNs);multilevel feature learning;structural MRI;weakly supervised localization},
doi={10.1109/TCYB.2020.3005859},
ISSN={2168-2275},
month={},}
@INPROCEEDINGS{9010384,
author={Chakraborty, Rudrasis and Zhen, Xingjian and Vogt, Nicholas and Bendlin, Barbara and Singh, Vikas},
booktitle={2019 IEEE/CVF International Conference on Computer Vision (ICCV)}, title={Dilated Convolutional Neural Networks for Sequential Manifold-Valued Data},
year={2019},
volume={},
number={},
pages={10620-10630},
abstract={Efforts are underway to study ways via which the power of deep neural networks can be extended to non-standard data types such as structured data (e.g., graphs) or manifold-valued data (e.g., unit vectors or special matrices). Often, sizable empirical improvements are possible when the geometry of such data spaces are incorporated into the design of the model, architecture, and algorithms. Motivated by neuroimaging applications, we study formulations where the data are {\em sequential manifold-valued measurements}. This case is common in brain imaging, where the samples correspond to symmetric positive definite matrices or orientation distribution functions. Instead of a recurrent model which poses computational/technical issues, and inspired by recent results showing the viability of dilated convolutional models for sequence prediction, we develop a dilated convolutional neural network architecture for this task. On the technical side, we show how the modules needed in our network can be derived while explicitly taking the Riemannian manifold structure into account. We show how the operations needed can leverage known results for calculating the weighted Fr\'{e}chet Mean (wFM). Finally, we present scientific results for group difference analysis in Alzheimer's disease (AD) where the groups are derived using AD pathology load: here the model finds several brain fiber bundles that are related to AD even when the subjects are all still cognitively healthy.},
keywords={Convolution;Manifolds;Data models;Machine learning;Kernel;Brain modeling;Geometry},
doi={10.1109/ICCV.2019.01072},
ISSN={2380-7504},
month={Oct},}
@ARTICLE{9162148,
author={Duan, Feng and Huang, Zihao and Sun, Zhe and Zhang, Yu and Zhao, Qibin and Cichocki, Andrzej and Yang, Zhenglu and Solé-Casals, Jordi},
journal={IEEE Transactions on Neural Systems and Rehabilitation Engineering}, title={Topological Network Analysis of Early Alzheimer’s Disease Based on Resting-State EEG},
year={2020},
volume={28},
number={10},
pages={2164-2172},
abstract={Previous studies made progress in the early diagnosis of Alzheimer's disease (AD) using electroencephalography (EEG) without considering EEG connectivity. To fill this gap, we explored significant differences between early AD patients and controls based on frequency domain and spatial properties using functional connectivity in mild cognitive impairment (MCI) and mild AD datasets. Four global metrics, network resilience, connection-level metrics and node versatility were used to distinguish between controls and patients. The results show that the main frequency bands that are different between MCI patients and controls are the θ and low α bands, and the differently affected brain areas are the frontal, left temporal and parietal areas. Compared to MCI patients, in patients with mild AD, the main frequency bands that are different are the low and high α bands, and the main differently affected brain region is a larger right temporal area. Four LOFC bands were used as input to train the ResNet-18 model. For the MCI dataset, the average accuracy of 20 runs was 93.42% and the best accuracy was 98.33%, while for the mild AD dataset, the average accuracy was 98.54% and the best accuracy was 100%. To determine the timing of early treatment and discovering the susceptible patients, and to slow the progression of the disease, we assume that the occurrence of MCI and mild AD and their progression to more serious AD and dementia could be inferred by analyzing the topological structure of the brain network generated by EEG. Our findings provide a novel solution for connectome-based biomarker analysis to improve personalized medicine.},
keywords={Electroencephalography;Dementia;Coherence;Functional magnetic resonance imaging;Correlation;Alzheimer’s disease;functional connectivity;topological properties;network resilience;versatility},
doi={10.1109/TNSRE.2020.3014951},
ISSN={1558-0210},
month={Oct},}
@ARTICLE{8782806,
author={Yang, Jie and Feng, Xinyang and Laine, Andrew F. and Angelini, Elsa D.},
journal={IEEE Journal of Biomedical and Health Informatics}, title={Characterizing Alzheimer's Disease With Image and Genetic Biomarkers Using Supervised Topic Models},
year={2020},
volume={24},
number={4},
pages={1180-1187},
abstract={Neuroimaging and genetic biomarkers have been widely studied from discriminative perspectives towards Alzheimer's disease (AD) classification, since neuroanatomical patterns and genetic variants are jointly critical indicators for AD diagnosis. Generative methods, designed to model common occurring patterns, could potentially advance the understanding of this disease, but have not been fully explored for AD characterization. Moreover, the introduction of a supervised component into the generative process can constrain the model for more discriminative characterization. In this study, we propose an original method based on supervised topic modeling to characterize AD from a generative perspective, yet maintaining discriminative power at differentiating disease populations. Our topic modeling jointly exploits discretized image features and categorical genetic features. Diagnostic information - cognitively normal (CN), mild cognitive impairment (MCI) and AD - is introduced as a supervision variable. Experimental results on the ADNI cohort demonstrate that our model, while achieving competitive discriminative performance, can discover topics revealing both well-known and novel neuroanatomical patterns including temporal, parietal and frontal regions; as well as associations between genetic factors and neuroanatomical patterns.},
keywords={Genetics;Diseases;Biological system modeling;Biomarkers;Sociology;Statistics;Brain modeling;Alzheimer's disease;MRI;genetics;topic modeling;mixed membership model;generative method},
doi={10.1109/JBHI.2019.2928831},
ISSN={2168-2208},
month={April},}
@INPROCEEDINGS{9361894,
author={Chen, DeHua and Zhang, Li and Ma, Chuang},
booktitle={2020 International Conference on Public Health and Data Science (ICPHDS)}, title={A Multimodal Diagnosis Predictive Model of Alzheimer’s Disease with Few-shot Learning},
year={2020},
volume={},
number={},
pages={273-277},
abstract={Alzheimer's disease imposes a significant quality of life and socioeconomic burden on patients, while mild cognitive impairment is considered as the first stage of Alzheimer's disease. Therefore, being able to detect and treat the disease while it is in mild cognitive impairment is essential for effective prevention of Alzheimer's disease. Many scholars have proposed a variety of different AI diagnostic models for Alzheimer's disease. These models are mainly trained based on MRI image data. However, in addition to MRI images, clinical diagnosis data of Alzheimer's disease also includes data of multiple modalities such as MRI text reports and test results of mental and psychological scales. Moreover, in the actual clinical data, there are fewer samples of Alzheimer's disease data and lack of sufficient training samples. This paper proposes a classification and diagnosis method for Alzheimer's patients based on multi-modal feature fusion and small sample learning. Specifically, we use structured MRI image reports and corresponding MRI images as multi-modal input, and then the compressed interactive network is used to explicitly fuse the extracted features at the vector level; finally, the KNN attention pooling layer and the convolutional network are used to construct a small sample learning network to classify the patient diagnosis data. The experimental results show that the accuracy and Fl-score value based on multi-modality are improved by more than 10% compared with single-modality. Using the small sample learning method under the same multimodal data, the accuracy rate increased by 8.2%, and the Fl-score value increased by 8.4%.},
keywords={Training;Magnetic resonance imaging;Psychology;Feature extraction;Data mining;Public healthcare;Diseases;Alzheimer’s disease;multimodal;feature fusion;few-shot learning},
doi={10.1109/ICPHDS51617.2020.00060},
ISSN={},
month={Nov},}
@INPROCEEDINGS{9098443,
author={Zhao, Li and Feng, Xue and Meyer, Craig H. and Alsop, David C.},
booktitle={2020 IEEE 17th International Symposium on Biomedical Imaging (ISBI)}, title={Choroid Plexus Segmentation Using Optimized 3D U-Net},
year={2020},
volume={},
number={},
pages={381-384},
abstract={The choroid plexus is the primary organ that secretes the cerebrospinal fluid. Its structure and function may be associated with the brain drainage pathway and the clearance of amyloid-beta in Alzheimer's Disease. However, choroid plexus segmentation methods have rarely been studied. Therefore, the purpose of this work is to fill the gap using a deep convolutional network. MR images of 10 healthy subjects ( 75.5±8.0 years) were retrospectively selected from the Alzheimer's Disease Neuroimaging Initiative database (ADNI). The benchmark of choroid plexus segmentation was provided by the FreeSurfer package and manual correction. A 3D U-Net was developed and optimized in the patch extraction, augmentation, and loss function. In leave-one-out cross-validations, the optimized U-Net provided superior performance compared to the FreeSurfer results (Dice score 0.732±0.046 vs 0.581±0.093, Jaccard coefficient 0.579±0.057 vs 0.416±0.091, 95% Hausdorff distance 1.871±0.549 vs 7.257±5.038, and sensitivity 0.761 ±0.078 vs 0.539±0.117).},
keywords={Image segmentation;Three-dimensional displays;Manuals;Dementia;Magnetic resonance imaging;Sensitivity;Choroid Plexus;MRI;Segmentation;U-Net;3D},
doi={10.1109/ISBI45749.2020.9098443},
ISSN={1945-8452},
month={April},}
@ARTICLE{9311143,
author={Nguyen, Hoang and Chu, Narisa N.},
journal={IEEE Consumer Electronics Magazine}, title={An Introduction to Deep Learning Research for Alzheimer’s Disease},
year={2021},
volume={10},
number={3},
pages={72-75},
abstract={This tutorial explains the evolving approaches on deep learning (DL) modeling and their dependence on statistically comprehensive datasets as input in various brain scan neuroimages. Powerful visual modalities, e.g., magnetic resonance images and positron emission tomography, can show neural changes during Alzheimer’s disease (AD) development. Computer vision’s recent success has lent impetus to numerous DL modeling publications reporting accuracy above 90%, using AD NeuroImage (ADNI) datasets. However, several limitations exist when using DL for AD image interpretation. Due to the lack of a comprehensive dataset and medical images’ complexity, there is little to no clinical value in such DL approaches. Furthermore, many of the published research results in the field are not comparable in experimenting with the ADNI datasets without well-accepted evaluation criteria. This tutorial describes the fundamentals and gaps in applying DL methodology over ADNI datasets.},
keywords={Deep learning;Two dimensional displays;Diseases;Three-dimensional displays;Feature extraction;Alzheimer's disease;Medical sevices;Tutorials},
doi={10.1109/MCE.2020.3048254},
ISSN={2162-2256},
month={May},}
@ARTICLE{8281011,
author={Mammone, Nadia and Ieracitano, Cosimo and Adeli, Hojjat and Bramanti, Alessia and Morabito, Francesco C.},
journal={IEEE Transactions on Neural Networks and Learning Systems}, title={Permutation Jaccard Distance-Based Hierarchical Clustering to Estimate EEG Network Density Modifications in MCI Subjects},
year={2018},
volume={29},
number={10},
pages={5122-5135},
abstract={In this paper, a novel electroencephalographic (EEG)-based method is introduced for the quantification of brain-electrical connectivity changes over a longitudinal evaluation of mild cognitive impaired (MCI) subjects. In the proposed method, a dissimilarity matrix is constructed by estimating the coupling strength between every pair of EEG signals, Hierarchical clustering is then applied to group the related electrodes according to the dissimilarity estimated on pairs of EEG recordings. Subsequently, the connectivity density of the electrodes network is calculated. The technique was tested over two different coupling strength descriptors: wavelet coherence (WC) and permutation Jaccard distance (PJD), a novel metric of coupling strength between time series introduced in this paper. Twenty-five MCI patients were enrolled within a follow-up program that consisted of two successive evaluations, at time T0 and at time T1, three months later. At T1, four subjects were diagnosed to have converted to Alzheimer's Disease (AD). When applying the PJD-based method, the converted patients exhibited a significantly increased PJD (p <; 0.05), i.e., a reduced overall coupling strength, specifically in delta and theta bands and in the overall range (0.5-32 Hz). In addition, in contrast to stable MCI patients, converted patients exhibited a network density reduction in every subband (delta, theta, alpha, and beta). When WC was used as coupling strength descriptor, the method resulted in a less sensitive and specific outcome. The proposed method, mixing nonlinear analysis to a machine learning approach, appears to provide an objective evaluation of the connectivity density modifications associated to the MCI-AD conversion, just processing noninvasive EEG signals.},
keywords={Electroencephalography;Couplings;Dementia;Coherence;Optical wavelength conversion;Complexity theory;Alzheimer’s Disease (AD);brain connectivity;electroencephalographic (EEG);hierarchical clustering (HC);mild cognitive impairment (MCI);network density;permutation entropy (PE);permutation Jaccard distance (PJD)},
doi={10.1109/TNNLS.2018.2791644},
ISSN={2162-2388},
month={Oct},}
@ARTICLE{8662648,
author={Yu, Haitao and Lei, Xinyu and Song, Zhenxi and Liu, Chen and Wang, Jiang},
journal={IEEE Transactions on Fuzzy Systems}, title={Supervised Network-Based Fuzzy Learning of EEG Signals for Alzheimer's Disease Identification},
year={2020},
volume={28},
number={1},
pages={60-71},
abstract={Accurate identification of Alzheimer's disease (AD) with electroencephalograph (EEG) is crucial in the clinical diagnosis of neurological disorders. However, the effectiveness and accuracy of manually labeling EEG signals are barely satisfactory, due to lacking effective biomarkers. In this paper, we propose a novel machine learning method network-based Takagi-Sugeno-Kang (N-TSK) for AD identification which employs the complex network theory and TSK fuzzy system. With the construction of functional network of AD subjects, the topological features of weighted and unweighted networks are extracted. Taken the network parameters as independent inputs, a fuzzy-system-based TSK model is established and further trained to identify AD EEG signals. Experimental results demonstrate the effectiveness of the proposed scheme in AD identification and ability of N-TSK fuzzy classifiers. The highest accuracy can achieve 97.3% for patients with closed eyes and 94.78% with open eyes. In addition, the performance of weighted N-TSK largely exceeds unweighted N-TSK. By further optimizing the network features utilized in the N-TSK fuzzy classifiers, it is found that local efficiency and clustering coefficient are the most effective factors in AD identification. This work provides a potential tool for identifying neurological disorders from the perspective of functional networks with EEG signal, especially contributing to the diagnosis and identification of AD.},
keywords={Electroencephalography;Electrodes;Brain modeling;Feature extraction;Neurological diseases;Machine learning;Alzheimer's disease (AD);electroencephalograph (EEG);functional network;fuzzy system;supervised learning},
doi={10.1109/TFUZZ.2019.2903753},
ISSN={1941-0034},
month={Jan},}
@INPROCEEDINGS{8971696,
author={Baydargil, Husnu Baris and Park, Jang-Sik and Kang, Do-Young},
booktitle={2019 19th International Conference on Control, Automation and Systems (ICCAS)}, title={Classification of Alzheimer's Disease Using Stacked Sparse Convolutional Autoencoder},
year={2019},
volume={},
number={},
pages={891-895},
abstract={Alzheimer's disease is a neurodegenerative disease that affects the brain structure and its functions. Early and accurate detection of AD through medical imaging may improve lifespan and overall quality of life for patients and their caretakers. In this paper, a specially developed sparse autoencoder is used to accurately detect AD in PET/CT (Positron Emission Tomography/ Computerized Tomography) brain images. Sagittal and coronal images were created from axial images, and those were trained separately to compare classification results. Two-stage training is utilized; first stage, a supervised training to train the classifier to identify the AD, and an unsupervised learning in order to produce an image output. In the created dataset, state-of-the-art classification models are trained and compared to the developed model. A 98.67% accuracy is reached for sagittal images. Detailed information is provided in chapters three and four.},
keywords={Machine learning;Deep learning;Computer vision;Medical imaging;Alzheimer's disease;Convolutional neural networks;Image classification;Sparse autoencoder},
doi={10.23919/ICCAS47443.2019.8971696},
ISSN={2642-3901},
month={Oct},}
@INPROCEEDINGS{8852240,
author={Ieracitano, Cosimo and Mammone, Nadia and Bramanti, Alessia and Marino, Silvia and Hussain, Amir and Morabito, Francesco Carlo},
booktitle={2019 International Joint Conference on Neural Networks (IJCNN)}, title={A Time-Frequency based Machine Learning System for Brain States Classification via EEG Signal Processing},
year={2019},
volume={},
number={},
pages={1-8},
abstract={In the last decades, the use of Machine Learning (ML) algorithms have been widely employed to aid clinicians in the difficult diagnosis of neurological disorders, such as Alzheimer's disease (AD). In this context, here, a data-driven ML system for classifying Electroencephalographic (EEG) segments (i.e. epochs) of patients affected by AD, Mild Cognitive Impairment (MCI) and Healthy Control (HC) individuals, is introduced. Specifically, the proposed ML system consists of evaluating the average Time-Frequency Map (aTFM) related to a 19-channels EEG epoch and extracting some statistical coefficients (i.e. mean, standard deviation, skewness, kurtosis and entropy) from the main five conventional EEG sub-bands (or EEG-rhythms: delta, theta, alpha1, alpha2, beta). Afterwards, the time-frequency features vector is fed into an Autoeconder (AE), a Multi-Layer Perceptron (MLP), a Logistic Regression (LR) and a Support Vector Machine (SVM) based classifier to perform the 2-ways EEG epoch-classification tasks: AD vs HC and AD vs MCI. The performances of the proposed approach have been evaluated on a dataset of 189 EEG signals (63 AD, 63 MCI and 63 HC), recorded during an eye-closed resting condition at IRCCS Centro Neurolesi Bonino Pulejo of Messina (Italy). Experimental results reported that the 1-hidden layer MLP (MLP1) outperformed all the other developed learning systems as well as recently proposed state-of-the-art methods, achieving accuracy rate up to 95.76 % ± 0.0045 and 86.84% ± 0.0098 in AD vs HC and AD vs MCI classification, respectively.},
keywords={Electroencephalography;Time-frequency analysis;Feature extraction;Continuous wavelet transforms;Standards;Support vector machines;Machine learning;Machine learning;Time-Frequency features;EEG recording;Alzheimer’s disease;Mild Cognitive Impairment},
doi={10.1109/IJCNN.2019.8852240},
ISSN={2161-4407},
month={July},}
@INPROCEEDINGS{8669055,
author={Lee, Pilsub and Choi, Myungwon and Kim, Daegyeom and Lee, Suji and Jeong, Hyun-Ghang and Han, Cheol E.},
booktitle={2019 International Conference on Artificial Intelligence in Information and Communication (ICAIIC)}, title={Deep learning based decomposition of brain networks},
year={2019},
volume={},
number={},
pages={349-354},
abstract={A brain network is the essence of the intelligence where it consists of nodes that are anatomically defined brain regions, and edges that connect a pair of brain regions. The diffusion-weighted magnetic resonance (MR) images and the advances in computer-aided tractography algorithms let us know strong association between human brain networks and cognitive functions. Brain regions dedicated to a certain specific cognitive function were spatially clustered and efficiently connected each other; it is called local functional segregation. However, it is not well known that such a local segregation is associated with a certain sub-network which may act as a building block of the brain network. In this work, using a graph auto-encoder, we extracted building blocks of brain networks and investigate whether they are affected by a neurological disease, Alzheimer's disease. We found that the brain network of each person is linear summation of the learned building blocks. Also, the activation levels of these building blocks vary in the normal controls and patients with Alzheimer's disease, showing that network deterioration in the disease group.},
keywords={Diseases;Matrix decomposition;Deep learning;Decoding;Hospitals;Encoding;Data models;brain networks;graph auto-encoder;graph convolutional neural network;Alzheimer’s disease},
doi={10.1109/ICAIIC.2019.8669055},
ISSN={},
month={Feb},}
@INPROCEEDINGS{8857248,
author={Gonzalez, Hector A. and Yoo, Jerald and Elfadel, Ibrahim M.},
booktitle={2019 41st Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)}, title={EEG-based Emotion Detection Using Unsupervised Transfer Learning},
year={2019},
volume={},
number={},
pages={694-697},
abstract={Emotion classification using EEG signal processing has the potential of significantly improving the social integration of patients suffering from neurological disorders such as Amyotrophic Lateral Sclerosis (ALS) or the acute stages of Alzheimer's disease. One important challenge to the implementation of high-fidelity emotion recognition systems is the inadequacy of EEG data in terms of Signal-to-noise ratio (SNR), duration, and subject-to-subject variability. In this paper, we present a novel, integrated framework for semi-generic emotion detection using (1) independent component analysis for EEG preprocessing, (2) EEG subject clustering by unsupervised learning, and (3) a convolutional neural network (CNN) for EEG-based emotion recognition. The training and testing data was built using the combination of two publicly available repositories (DEAP and DREAMER), and a local dataset collected at Khalifa University using the standard International Affective Picture System (IAPS). The CNN classifier with the proposed transfer learning approach achieves an average accuracy of 70.26% for valence and 72.42% for arousal, which are superior to the reported accuracies of all generic (subject-independent) emotion classifiers.},
keywords={Electroencephalography;Training;Task analysis;Manuals;Unsupervised learning;Feature extraction},
doi={10.1109/EMBC.2019.8857248},
ISSN={1558-4615},
month={July},}
@ARTICLE{9411670,
author={Liu, Jinduo and Ji, Junzhong and Xun, Guangxu and Zhang, Aidong},
journal={IEEE Transactions on Neural Networks and Learning Systems}, title={Inferring Effective Connectivity Networks From fMRI Time Series With a Temporal Entropy-Score},
year={2021},
volume={},
number={},
pages={1-14},
abstract={Inferring brain-effective connectivity networks from neuroimaging data has become a very hot topic in neuroinformatics and bioinformatics. In recent years, the search methods based on Bayesian network score have been greatly developed and become an emerging method for inferring effective connectivity. However, the previous score functions ignore the temporal information from functional magnetic resonance imaging (fMRI) series data and may not be able to determine all orientations in some cases. In this article, we propose a novel score function for inferring effective connectivity from fMRI data based on the conditional entropy and transfer entropy (TE) between brain regions. The new score employs the TE to capture the temporal information and can effectively infer connection directions between brain regions. Experimental results on both simulated and real-world data demonstrate the efficacy of our proposed score function.},
keywords={Bayesian network (BN);brain network;effective connectivity;score function;transfer entropy (TE).},
doi={10.1109/TNNLS.2021.3072149},
ISSN={2162-2388},
month={},}
@INPROCEEDINGS{9098353,
author={Barbaroux, Hugo and Feng, Xinyang and Yang, Jie and Laine, Andrew F. and Angelini, Elsa D.},
booktitle={2020 IEEE 17th International Symposium on Biomedical Imaging (ISBI)}, title={Encoding Human Cortex Using Spherical CNNs - A Study on Alzheimer's Disease Classification},
year={2020},
volume={},
number={},
pages={1322-1325},
abstract={In neuroimaging studies, the human cortex is commonly modelled as a sphere to preserve the topological structure of the cortical surface. In this work, we explore the analysis of the human cortex using spherical CNN in an Alzheimer's disease (AD) classification task, using morphometric measures derived from T1-weighted structural MRI. Our results show superior performance in classifying AD versus cognitively normal subjects and in predicting mild cognitive impairment progression within two years. This work demonstrates the feasibility and superiority of the spherical CNN directly applied on the spherical representation in the discriminative analysis of the human cortex and could be readily extended to other imaging modalities and other neurological diseases.},
keywords={Task analysis;Standards;Bandwidth;Computer architecture;Magnetic resonance imaging;Finite element analysis;Dementia;Spherical CNNs;cortex;Alzheimer's disease;structural MRI},
doi={10.1109/ISBI45749.2020.9098353},
ISSN={1945-8452},
month={April},}
@INPROCEEDINGS{9389992,
author={Guo, Huiru and Xing, Longqiang and Luo, Caixia and Chen, Hui},
booktitle={2021 IEEE 2nd International Conference on Big Data, Artificial Intelligence and Internet of Things Engineering (ICBAIE)}, title={AD diagnosis assistant system based on convolutional network},
year={2021},
volume={},
number={},
pages={693-698},
abstract={It has been a hot topic to detect Alzheimer’s disease (AD) from MRI and other neuroimaging data by machine learning in recent years. A large number of deep learning models have been developed, such as alexnet, VGg net, Gan and so on. The common limitation of these models is that they rely on a large number of labeled training images and need deeper network structure to achieve higher accuracy. It is challenging to obtain a large number of labeled data in the field of medical image. Training a suitable medical image classification model from scratch also requires a lot of resources. To solve these problems, in this paper, we try to use convolutional network (CNN) transfer learning for image classification training, select CNN network model, fine tune the network weight layer by layer, modify the last layer of CNN for training on MRI image. In order to reduce the size of training data, we use image entropy to select the most informative slice. Through the experiments on ADNI data sets, compared with other contemporary methods, we achieve 99.89% on the classification of Alzheimer’s disease (AD), Normal Cognitive (NC) and Mild Cognitive Impairment (MCI). Attractively, class activation mapping (CAM) is employed to visualize brain regions related to AD, which further gives the targeted information for AD diagnosis.},
keywords={Training;Magnetic resonance imaging;Transfer learning;Training data;Medical diagnostic imaging;Image classification;Diseases;Alzheimer’s-disease;CAM;Medical image classification},
doi={10.1109/ICBAIE52039.2021.9389992},
ISSN={},
month={March},}
@INPROCEEDINGS{9346408,
author={Adebisi, Abdulyekeen T. and Gonuguntla, Venkateswarlu and Lee, Ho-Won and Veluvolu, Kalyana C.},
booktitle={2020 International Conference on Data Mining Workshops (ICDMW)}, title={Classification of Dementia Associated Disorders Using EEG based Frequent Subgraph Technique},
year={2020},
volume={},
number={},
pages={613-620},
abstract={Dementia associated disorders such as vascular dementia, frontotemporal dementia and Alzheimer dementia lead to cognitive impairment. Discrimination of dementia associated disorders has reamined a challenging task as they have overlapping underlying complex structures and display similar clinical features. In this work, we explore an EEG based frequent subgraph searching technique to characterize stages of brain functional networks of mild cognitive impairment (MCI), Alzheimer's disease (AD) and vascular dementia (VD) subjects in comparison with healthy control (HC) subjects. To identify the frequent subgraph related to dementia, we first formulated the brain functional network based on the phase information of EEG with mutual information as a measure. The whole network is then divided into sub-regions and frequent sub-graph search is performed. The identified frequent subgraphs were employed to discriminate the dementia associated disorders from the data recorded from 10 healthy and 32 dementia subjects in various stages. Results show that the proposed method has the potential to quantify the disease progression using brain functional connectivity and the identified networks can aid in the diagnosis of dementia associated disorders.},
keywords={Phase measurement;Market research;Electroencephalography;Alzheimer's disease;Task analysis;Mutual information;Dementia;EEG;Dementia Associated Disease;Mutual Information (MI);Reactive Band;Functional Connectivity;Brain Functional Network;Frequent Subgraph Search},
doi={10.1109/ICDMW51313.2020.00087},
ISSN={2375-9259},
month={Nov},}
@INPROCEEDINGS{9167551,
author={Chitradevi, D. and Prabha, S.},
booktitle={2020 Sixth International Conference on Bio Signals, Images, and Instrumentation (ICBSII)}, title={Analysis of Alzheimer Disease using Optimization Techniques},
year={2020},
volume={},
number={},
pages={1-5},
abstract={Alzheimer Disease (AD) is a neurodegenerative and most common form of disorder. Most of the researchers are concentrating on AD pathology for the past few decades since it is a major public health disease in the world wide. AD causes neuronal damage in the Brain Internal Regions (BIR) specifically Corpus Callosum (CC), White Matter (WM), Grey Matter (GM), Hippocampus (HC) and ventricle. The neuronal loss makes the changes in anatomical structure of the brain which affects the BIR. Identification of structural difference between the normal controls (NC) and AD of the brain is a challenging process due to its complex networks of nerves. Hence, there is a requirement of segmentation process to extract the BIR. The proposed work focused to segment the CC and ventricle regions using multi-level thresholding methods namely Ant colony Optimization (ACO) and Artificial Bee Colony (ABC) optimization techniques. These methods have been analyzed quantitatively and qualitatively using various measures with ground truth (GT) images. Artificial Bee Colony optimization techniques have been achieved the better accuracy of 93 % than ACO. Deep Learning (DL) classifier has been used to classify normal controls (NC) and AD and acquired the better accuracy of 78% in ABC than ACO. Finally the proposed pipeline provides the clinical evidence for analyzing AD.},
keywords={Image segmentation;Optimization;Dementia;Real-time systems;Machine learning;Histograms;Alzheimer Disease;Brain Internal Regions;Deep Learning;Optimization Techniques},
doi={10.1109/ICBSII49132.2020.9167551},
ISSN={},
month={Feb},}
@INPROCEEDINGS{8759394,
author={Wegmayr, Viktor and Hörold, Maurice and Buhmann, Joachim M.},
booktitle={2019 IEEE 16th International Symposium on Biomedical Imaging (ISBI 2019)}, title={Generative Aging Of Brain MRI For Early Prediction Of MCI-AD Conversion},
year={2019},
volume={},
number={},
pages={1042-1046},
abstract={Automatic diagnosis of Alzheimer's disease (AD) from MR images of the brain promises to yield important information of a patient's disease status or even early prediction of disease onset. This work investigates deep learning based methods to predict conversion of Mild Cognitive Impairment (MCI) to AD based on widely available T1-weighted MR brain images. We present a novel approach breaking up the conversion prediction into a generative and a discriminative step. Using the recently proposed Wasserstein-GAN model, we generate a synthetically aged brain image given a baseline image. The aged image is passed to an MCI/AD discriminator deciding the future disease status. Using only one coronal slice of a patient's baseline T1image, our approach achieves 73% accuracy, 68% precision, and 75% recall on MCI-to-AD conversion prediction at a 48months follow-up.},
keywords={Aging;Brain modeling;Diseases;Generators;Generative adversarial networks;Magnetic resonance imaging;Machine Learning;Brain;MRI;Generative Adversarial Networks;Alzheimer’s Disease;Aging},
doi={10.1109/ISBI.2019.8759394},
ISSN={1945-8452},
month={April},}
@ARTICLE{9075205,
author={Al-Shoukry, Suhad and Rassem, Taha H. and Makbol, Nasrin M.},
journal={IEEE Access}, title={Alzheimer’s Diseases Detection by Using Deep Learning Algorithms: A Mini-Review},
year={2020},
volume={8},
number={},
pages={77131-77141},
abstract={The accurate diagnosis of Alzheimer's disease (AD) plays an important role in patient treatment, especially at the disease's early stages, because risk awareness allows the patients to undergo preventive measures even before the occurrence of irreversible brain damage. Although many recent studies have used computers to diagnose AD, most machine detection methods are limited by congenital observations. AD can be diagnosed-but not predicted-at its early stages, as prediction is only applicable before the disease manifests itself. Deep Learning (DL) has become a common technique for the early diagnosis of AD. Here, we briefly review some of the important literature on AD and explore how DL can help researchers diagnose the disease at its early stages.},
keywords={Dementia;Magnetic resonance imaging;Brain;Single photon emission computed tomography;Biomedical imaging;Alzheimer’s disease;deep learning;early stage detection and diagnosis},
doi={10.1109/ACCESS.2020.2989396},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{8423960,
author={Cruz, Ricardo and Silveira, Margarida and Cardoso, Jaime S.},
booktitle={2018 International Workshop on Pattern Recognition in Neuroimaging (PRNI)}, title={A Class Imbalance Ordinal Method for Alzheimer’s Disease Classification},
year={2018},
volume={},
number={},
pages={1-4},
abstract={The majority of computer-aided diagnosis methods for Alzheimer's disease (AD) from brain images either address only two stages of the disease at a time (and reduce the problem to binary classification) or do not exploit the ordinal nature of the different classes. An exception is the work by Fan et al. [1], which proposed an ordinal method that obtained better performance than traditional multiclass classification. Still, special care should be taken when data is class imbalanced, i.e. when some classes are overly represented when compared to others. Building on top of [1], this work makes use of a recently published ordinal classifier, which transforms the problem into sets of pairwise ranking problems, in order to address the class imbalance in the data [2]. Several methods were experimented with, using a Support Vector Machine as the underlying estimator. The pairwise ranking approach has shown promising results, both for traditional and imbalance metrics.},
keywords={Support vector machines;Dementia;Fans;Magnetic resonance imaging;Biomarkers},
doi={10.1109/PRNI.2018.8423960},
ISSN={},
month={June},}
@ARTICLE{9099858,
author={Jiménez-Mesa, Carmen and Illán, Ignacio Alvarez and Martín-Martín, Alberto and Castillo-Barnes, Diego and Martinez-Murcia, Francisco Jesus and Ramírez, Javier and Górriz, Juan M.},
journal={IEEE Access}, title={Optimized One vs One Approach in Multiclass Classification for Early Alzheimer’s Disease and Mild Cognitive Impairment Diagnosis},
year={2020},
volume={8},
number={},
pages={96981-96993},
abstract={The detection of Alzheimer's Disease in its early stages is crucial for patient care and drugs development. Motivated by this fact, the neuroimaging community has extensively applied machine learning techniques to the early diagnosis problem with promising results. The organization of challenges has helped the community to address different raised problems and to standardize the approaches to the problem. In this work we use the data from international challenge for automated prediction of MCI from MRI data to address the multiclass classification problem. We propose a novel multiclass classification approach that addresses the outlier detection problem, uses pairwise t-test feature selection, project the selected features onto a Partial-Least-Squares multiclass subspace, and applies one-versus-one error correction output codes classification. The proposed method yields to an accuracy of 67% in the multiclass classification, outperforming all the proposals of the competition.},
keywords={Feature extraction;Magnetic resonance imaging;Dementia;Standards;Neuroimaging;Machine learning;Alzheimer’s disease;CAD;error correcting output codes;mild cognitive impairment;multiclass classification;one versus one;partial least squares;random forests;support vector machines},
doi={10.1109/ACCESS.2020.2997736},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{8834630,
author={Fedorov, Alex and Hjelm, R Devon and Abrol, Anees and Fu, Zening and Du, Yuhui and Plis, Sergey and Calhoun, Vince D.},
booktitle={2019 IEEE EMBS International Conference on Biomedical Health Informatics (BHI)}, title={Prediction of Progression to Alzheimer's disease with Deep InfoMax},
year={2019},
volume={},
number={},
pages={1-5},
abstract={Arguably, unsupervised learning plays a crucial role in the majority of algorithms for processing brain imaging. A recently introduced unsupervised approach Deep InfoMax (DIM) is a promising tool for exploring brain structure in a flexible non-linear way. In this paper, we investigate the use of variants of DIM in a setting of progression to Alzheimer's disease in comparison with supervised AlexNet and ResNet inspired convolutional neural networks. As a benchmark, we use a classification task between four groups: patients with stable, and progressive mild cognitive impairment (MCI), with Alzheimer's disease, and healthy controls. Our dataset is comprised of 828 subjects from the Alzheimers Disease Neuroimaging Initiative (ADNI) database. Our experiments highlight encouraging evidence of the high potential utility of DIM in future neuroimaging studies.},
keywords={Three-dimensional displays;Alzheimer's disease;Mutual information;Training;Neuroimaging;Magnetic resonance imaging;CNN;MRI;Deep InfoMax;classification;unsupervised},
doi={10.1109/BHI.2019.8834630},
ISSN={2641-3604},
month={May},}
@ARTICLE{9360738,
author={Assam, Muhammad and Kanwal, Hira and Farooq, Umar and Shah, Said Khalid and Mehmood, Arif and Choi, Gyu Sang},
journal={IEEE Access}, title={An Efficient Classification of MRI Brain Images},
year={2021},
volume={9},
number={},
pages={33313-33322},
abstract={The unprecedented improvements in computing capabilities and the introduction of advanced techniques for the analysis, interpretation, processing, and visualization of images have greatly diversified the domain of medical sciences and resulted in the field of medical imaging. The Magnetic Resonance Imaging (MRI), an advanced imaging technique, is capable of producing high quality images of the human body including the brain for diagnosis purposes. This paper proposes a simple but efficient solution for the classification of MRI brain images into normal, and abnormal images containing disorders and injuries. It uses images with brain tumor, acute stroke and alzheimer, besides normal images, from the public dataset developed by harvard medical school, for evaluation purposes. The proposed model is a four step process, in which the steps are named: 1). Pre-processing, 2). Features Extraction, 3). Features Reduction, and 4). Classification. Median filter, being one of the best algorithms, is used for the removal of noise such as salt and pepper, and unwanted components such as scalp and skull, in the pre-processing step. During this stage, the images are converted from gray scale to colored images for further processing. In second step, it uses Discrete Wavelet Transform (DWT) technique to extract different features from the images. In third stage, Color Moments (CMs) are used to reduce the number of features and get an optimal set of characteristics. Images with the optimal set of features are passed to different classifiers for the classification of images. The Feed Forward - ANN (FF-ANN), an individual classifier, which was given a 65% to 35% split ratio for training and testing, and hybrid classifiers called: Random Subspace with Random Forest (RSwithRF) and Random Subspace with Bayesian Network (RSwithBN), which used 10-Fold cross validation technique, resulted in 95.83%, 97.14% and 95.71% accurate classification, in corresponding order. These promising results show that the proposed method is robust and efficient, in comparison with, existing classification methods in terms of accuracy with smaller number of optimal features.},
keywords={Feature extraction;Magnetic resonance imaging;Discrete wavelet transforms;Support vector machines;Image color analysis;Transforms;Principal component analysis;Color moments (CMs);feed forward artificial neural network (FF-ANN);random subspace;random forest;baysnet;principle component analysis (PCA);discrete wavelet transforms (DWT)},
doi={10.1109/ACCESS.2021.3061487},
ISSN={2169-3536},
month={},}
@ARTICLE{9380560,
author={Armanious, Karim and Abdulatif, Sherif and Shi, Wenbin and Salian, Shashank and Küstner, Thomas and Weiskopf, Daniel and Hepp, Tobias and Gatidis, Sergios and Yang, Bin},
journal={IEEE Transactions on Medical Imaging}, title={Age-Net: An MRI-Based Iterative Framework for Brain Biological Age Estimation},
year={2021},
volume={},
number={},
pages={1-1},
abstract={The concept of biological age (BA) - although important in clinical practice - is hard to grasp mainly due to the lack of a clearly defined reference standard. For specific applications, especially in pediatrics, medical image data are used for BA estimation in a routine clinical context. Beyond this young age group, BA estimation is mostly restricted to whole-body assessment using non-imaging indicators such as blood biomarkers, genetic and cellular data. However, various organ systems may exhibit different aging characteristics due to lifestyle and genetic factors. Thus, a whole-body assessment of the BA does not reflect the deviations of aging behavior between organs. To this end, we propose a new imaging-based framework for organ-specific BA estimation. In this initial study we focus mainly on brain MRI. As a first step, we introduce a chronological age (CA) estimation framework using deep convolutional neural networks (Age-Net). We quantitatively assess the performance of this framework in comparison to existing state-of-the-art CA estimation approaches. Furthermore, we expand upon Age-Net with a novel iterative data-cleaning algorithm to segregate atypical-aging patients (BA ≉ CA) from the given population. We hypothesize that the remaining population should approximate the true BA behavior. We apply the proposed methodology on a brain magnetic resonance image (MRI) dataset containing healthy individuals as well as Alzheimer’s patients with different dementia ratings. We demonstrate the correlation between the predicted BAs and the expected cognitive deterioration in Alzheimer’s patients. A statistical and visualization-based analysis has provided evidence regarding the potential and current challenges of the proposed methodology.},
keywords={Estimation;Aging;Biological systems;Magnetic resonance imaging;Biomedical imaging;Three-dimensional displays;Genetics;Biological age estimation;deep learning;chronological age;magnetic resonance imaging},
doi={10.1109/TMI.2021.3066857},
ISSN={1558-254X},
month={},}

@ARTICLE{9390181,
author={Rodrigues, Pedro Miguel and Bispo, Bruno Catarino and Garrett, Carolina and Alves, Dílio and Teixeira, João Paulo and Freitas, Diamantino},
journal={IEEE Journal of Biomedical and Health Informatics}, title={Lacsogram: a New EEG Tool to Diagnose Alzheimer's Disease},
year={2021},
volume={},
number={},
pages={1-1},
abstract={This work proposes the application of a new electroencephalogram (EEG) signal processing tool - the lacsogram - to characterize the Alzheimer's disease (AD) activity and to assist on its diagnosis at different stages: Mild Cognitive Impairment (MCI), Mild and Moderate AD (ADM) and Advanced AD (ADA). Statistical analyzes are performed to lacstral distances between conventional EEG subbands to find measures capable of discriminating AD in all stages and characterizing the AD activity in each electrode. Cepstral distances are used for comparison. Comparing all AD stages and Controls (C), the most important significances are the lacstral distances between subbands and (p=0.0014<0.05). The topographic maps show significant differences in parietal, temporal and frontal regions as AD progresses. Machine learning models with a leave-one-out cross-validation process are applied to lacstral/cepstral distances to develop an automatic method for diagnosing AD. The following classification accuracies are obtained with an artificial neural network: 95.55% for All vs All, 98.06% for C vs MCI, 95.99% for C vs ADM, 93.85% for MCI vs ADM-ADA. In C vs MCI, C vs ADM and MCI vs ADM-ADA, the proposed method outperforms the state-of-art methods by 5%, 1%, and 2%, respectively. In All vs All, it outperforms the state-of-art EEG and non-EEG methods by 6% and 2%, respectively. These results indicate that the proposed method represents an improvement in diagnosing AD.},
keywords={Electroencephalography;Diseases;Sensitivity;Feature extraction;Electronic mail;Tools;Proteins;Alzheimer's disease;Mild-cognitive impairment;diagnose;artificial neural networks;cepstrum;lacsogram},
doi={10.1109/JBHI.2021.3069789},
ISSN={2168-2208},
month={},}
@INPROCEEDINGS{9362425,
author={P, Vijina and M, Jayasree},
booktitle={2020 International Conference on Power, Instrumentation, Control and Computing (PICC)}, title={A Survey On Recent Approaches In Image Reconstruction},
year={2020},
volume={},
number={},
pages={1-5},
abstract={Image reconstruction is an ongoing research in medical image processing. It is a continuously developing field. The aim is to reconstruct the images from some noise or something else without loss of image quality and accuracy of the reconstructed images. Medical image processing is one of the most trending research area. Medical images are widely used in various applications like medical segmentation, Brain tumor detection, early prediction of Alzheimer's Disease and its variations, etc. The types of medical images are Magnetic Resonance Images(MRI), Positron Emission Tomography(PET), X-Ray images, computerized tomography (CT), single-photon emission CT(SPECT etc. There is a high radiation dose that occurs when taking these types of images for the disease diagnosis and is costly. Also, there exist some limitations in the number of images. This is why we need image reconstruction. Here exact copy of the same images are reconstructed without any loss of image quality and spatial resolution.It also reduces the radiation dose. So image reconstruction is very important and these images can be used in various applications.},
keywords={Image quality;Generative adversarial networks;Biomedical image processing;Gallium nitride;Image reconstruction;Medical diagnostic imaging;X-ray imaging;Medical image processing;Image reconstruction;Statistical image reconstruction;Deep learning based image reconstruction;Fourier based reconstruction;Generative adversarial network},
doi={10.1109/PICC51425.2020.9362425},
ISSN={},
month={Dec},}
@ARTICLE{9051819,
author={Cao, Ping and Sheng, Qiuyang and Fang, Siqi and Li, Xinyi and Ning, Gangmin and Pan, Qing},
journal={IEEE Access}, title={Fusion of Multi-Size Candidate Regions Enhances Two-Stage Hippocampus Segmentation},
year={2020},
volume={8},
number={},
pages={63225-63238},
abstract={The hippocampus plays an important role in the memory and cognition abilities of humans. Precise three-dimensional (3D) segmentation of the hippocampus from magnetic resonance imaging scans is of great importance in the diagnosis of neurological diseases. Conventional automatic segmentation methods poorly achieve satisfactory performance because of the irregular shape and small volume of the hippocampus. We propose a novel two-stage segmentation method, which includes a localization stage and a segmentation stage, to handle the task of the 3D segmentation of the hippocampus. In the localization stage, a novel strategy for localizing multi-size candidate regions was developed to improve the sample balance for the 3D segmentation task. In the segmentation stage, a method which fuses the multi-size candidate regions was proposed to improve the accuracy in predicting the hippocampal boundary, after which we aggregated the segmentation results from three orthogonal views to further improve the performance. Quantitative evaluation was performed on the Alzheimer's Disease Neuroimaging Initiative dataset. The experimental results achieved Dice similarity coefficients of 92.48 ± 0.61% and 92.90 ± 0.51% for the left and right hippocampus, respectively, outperforming state-of-the-art studies in hippocampus segmentation tasks.},
keywords={Hippocampus;Image segmentation;Three-dimensional displays;Magnetic resonance imaging;Task analysis;Two dimensional displays;Morphology;Hippocampus segmentation;hippocampus localization;fully convolutional network;two-stage segmentation},
doi={10.1109/ACCESS.2020.2984661},
ISSN={2169-3536},
month={},}
@ARTICLE{9280341,
author={Ouyang, Jiahong and Zhao, Qingyu and Sullivan, Edith V. and Pfefferbaum, Adolf and Taper, Susan F. and Adeli, Ehsan and Pohl, Kilian M.},
journal={IEEE Journal of Biomedical and Health Informatics}, title={Longitudinal Pooling Consistency Regularization to Model Disease Progression from MRIs},
year={2020},
volume={},
number={},
pages={1-1},
abstract={Many neurological diseases are characterized by gradual deterioration of brain structure and function. Large longitudinal MRI datasets have revealed such deterioration, in part, by applying machine and deep learning to predict diagnosis. A popular approach is to apply Convolutional Neural Networks (CNN) to extract informative features from each visit of the longitudinal MRI and then use those features to classify each visit via Recurrent Neural Networks (RNNs). Such modeling neglects the progressive nature of the disease, which may result in clinically implausible classifications across visits. To avoid this issue, we propose to combine features across visits by coupling feature extraction with a novel longitudinal pooling layer and enforce consistency of the classification across visits in line with disease progression. We evaluate the proposed method on the longitudinal structural MRIs from three neuroimaging datasets: Alzheimer's Disease Neuroimaging Initiative (ADNI, N=404), a dataset composed of 274 normal controls and 329 patients with Alcohol Use Disorder (AUD), and 255 youths from the National Consortium on Alcohol and NeuroDevelopment in Adolescence (NCANDA). In all three experiments our method is superior to other widely used approaches for longitudinal classification thus making a unique contribution towards more accurate tracking of the impact of conditions on the brain. The code is available at https://github.com/ouyangjiahong/longitudinal-pooling.},
keywords={Magnetic resonance imaging;Diseases;Feature extraction;Trajectory;Computational modeling;Biological system modeling;Predictive models;Longitudinal Analysis;Disease Progression;Recurrent Neural Networks},
doi={10.1109/JBHI.2020.3042447},
ISSN={2168-2208},
month={},}
@INPROCEEDINGS{9369797,
author={Woo, Boyeong and Lee, Myungeun},
booktitle={2021 International Conference on Electronics, Information, and Communication (ICEIC)}, title={Comparison of tissue segmentation performance between 2D U-Net and 3D U-Net on brain MR Images},
year={2021},
volume={},
number={},
pages={1-4},
abstract={In this paper, we compare the tissue segmentation performance of the 2D U-Net and 3D U-Net in brain MR images including Alzheimer's disease. The Open Access Series of Imaging Studies dataset used in this experiment consists of a cross-sectional collection of 416 subjects aged 18 to 96. The final segmentations were classified into 4 classes: background, cerebrospinal fluid, gray matter, and white matter. In the experiment, 3D U-Net showed highly stable segmentation results. Particularly, the evaluation of the 2D/3D U-Net segmentation has shown that the 3D U-Net provided higher dice similarity coefficients (94.4±4.5% ~ 95.6±3.0%) and lower Hausdorff distances ( 7.5±3.2mm ~ 12.3±3.9mm) than the 2D U-Net ( 89.6±4.9% ~ 96.22±3.1% and 9.1±5.5mm ~ 14.4±7.4mm). And the 3D U-Net provided a better performance despite having less training examples to learn from. The simple image processing pipeline was an added advantage. However, the number of parameters and the amount of memory required was a major limitation of using 3D U-Net.},
keywords={Training;Image segmentation;Three-dimensional displays;Two dimensional displays;Pipelines;Memory management;Hardware;Deep learning;U-net;2D/3D;brain;MRI;segmentation;Alzheimer's disease},
doi={10.1109/ICEIC51217.2021.9369797},
ISSN={},
month={Jan},}
@INPROCEEDINGS{9206865,
author={Richhariya, B. and Tanveer, M.},
booktitle={2020 International Joint Conference on Neural Networks (IJCNN)}, title={Universum least squares twin parametric-margin support vector machine},
year={2020},
volume={},
number={},
pages={1-8},
abstract={Universum based algorithms involve universum samples in the classification problem to improve the generalization performance. In order to provide prior information about data, we utilized universum data to propose a novel classification algorithm. In this paper, a novel parametric model for universum based twin support vector machine is presented for classification problems. The proposed model is termed as universum least squares twin parametric-margin support vector machine (ULSTPMSVM). The solution of ULSTPMSVM involves a system of linear equations. This makes the ULSTPMSVM efficient w.r.t. training time. In order to verify the performance of the proposed model, various experiments are carried out on real world benchmark datasets. Statistical tests are performed to verify the significance of the proposed method. The proposed ULSTPMSVM performed better than existing algorithms in terms of classification accuracy and training time for most of the datasets. Moreover, an application of proposed ULSTPMSVM is presented for classification of Alzheimer's disease data.},
keywords={Support vector machines;Classification algorithms;Mathematical model;Linear programming;Dementia;Unified modeling language;Universum;twin parametric model;prior knowledge;magnetic resonance imaging;Alzheimer's disease},
doi={10.1109/IJCNN48605.2020.9206865},
ISSN={2161-4407},
month={July},}
@INPROCEEDINGS{8363835,
author={Zhang, Jie and Tu, Yanshuai and Li, Qingyang and Caselli, Richard J. and Thompson, Paul M. and Ye, Jieping and Wang, Yalin},
booktitle={2018 IEEE 15th International Symposium on Biomedical Imaging (ISBI 2018)}, title={Multi-task sparse screening for predicting future clinical scores using longitudinal cortical thickness measures},
year={2018},
volume={},
number={},
pages={1406-1410},
abstract={Cortical thickness estimation performed in-vivo via magnetic resonance imaging (MRI) is an effective measure of brain atrophy in preclinical individuals at high risk for Alzheimer's disease (AD). However, the high dimensionality of individual cortical thickness data coupled with small population samples make it challenging to perform cortical thickness feature selection for AD diagnosis and prognosis. Thus far, there are very few methods that can accurately predict future clinical scores using longitudinal cortical thickness measures. In this paper, we propose an unsupervised dictionary learning algorithm, termed Multi-task Sparse Screening (MSS) that produces improved results over previous methods within this problem domain. Specifically, we formulate and solve a multi-task problem using extracted top-p significant features from the Alzheimer's Disease Neuroimaging Initiative (ADNI) longitudinal data. Empirical studies on publicly available longitudinal data from ADNI dataset (N = 2797) demonstrate improved correlation coefficients and root mean square errors, when compared to other algorithms.},
keywords={Dictionaries;Imaging;Sparse matrices;Neuroimaging;Dementia;Feature extraction;Alzheimer's Disease;Cortical Thickness;Group Lasso;Multi-task;Dictionary Learning},
doi={10.1109/ISBI.2018.8363835},
ISSN={1945-8452},
month={April},}
@INPROCEEDINGS{9037793,
author={Ostertag, Cecilia and Beurton-Aimar, Marie and Urruty, Thierry},
booktitle={10th International Conference on Pattern Recognition Systems (ICPRS-2019)}, title={3D-SiameseNet to analyze brain MRI},
year={2019},
volume={},
number={},
pages={18-23},
abstract={Prediction of the cognitive evolution of a person susceptible to develop a neurodegenerative disorder is crucial to provide an appropriate treatment as soon as possible. In this paper we propose a 3D siamese network designed to extract features from whole-brain 3D MRI images. We show that it is possible to extract meaningful features using convolution layers, reducing the need of classical image processing operations such as segmentation or pre-computing features such as cortical thickness. To lead this study we used the Alzheimer's Disease Neuroimaging Initiative (ADNI), a public data base of 3D MRI brain images. A set of 247 subjects has been extracted, all of the subjects having 2 images in a range of 12 months. In order to measure the evolution of the patients states we have compared these 2 images. Our work has been inspired at the beginning by an article of Bhagwat et al. in 2018, who have proposed a siamese network to predict the status of patients but without any convolutional layers and reducing the MRI images to a vector of features extracted from predefined ROIs. We show that our network achieves an accuracy of 90% in the classification of cognitively declining VS stable patients. This result has been obtained without the help of a cognitive score and with a small number of patients comparing to the current datasets size claimed in deep learning domain.},
keywords={deep learning;siamese network;brain MRI;neurodegenerative disease;convolutional neural network},
doi={10.1049/cp.2019.0242},
ISSN={},
month={July},}
@INPROCEEDINGS{9302244,
author={Aydemir, Önder and Naser, Amir and Öztürk, Mehmet},
booktitle={2020 28th Signal Processing and Communications Applications Conference (SIU)}, title={Classification of EEG Signals Recorded While Imagining Odors with Effective Band Pass Filter Parameters},
year={2020},
volume={},
number={},
pages={1-4},
abstract={Technological advances in medicine allow us to learn more about human physiology, anatomy, endocrinology and neurology. In this way, many diseases can be diagnosed early and treatment processes can be closely monitored. On the one hand, the advancing technology allows us to demonstrate how the human brain reacts to various environmental stimuli. In this study, electroencephalography (EEG) technique was used to record the reactions of the brain to the imagination of cloves and mint odors. The distinguishability of brain responses to these odors was tested using pixel means of gray-level images obtained from Burg-based color spectrogram images. By using pixel means as an attribute, a classification accuracy of 82.5% was obtained with k-nearest neighbor. The results showed that the EEG signals that can occur when the brain imagines different odors can be distinguished.},
keywords={Electroencephalography;Sleep;Olfactory;Deep learning;Biosensors;Biomedical monitoring;Alzheimer's disease;odor;electroencephalogram;close;mint;classification;feature extraction},
doi={10.1109/SIU49456.2020.9302244},
ISSN={2165-0608},
month={Oct},}
@ARTICLE{9171577,
author={Er, Fusun and Goularas, Dionysis},
journal={IEEE/ACM Transactions on Computational Biology and Bioinformatics}, title={Predicting the prognosis of MCI patients using longitudinal MRI data},
year={2020},
volume={},
number={},
pages={1-1},
abstract={The aim of this study is to develop a computer-aided diagnosis system with a deep-learning approach for distinguishing "Mild Cognitive Impairment (MCI) due to Alzheimer's Disease (AD)" patients among a list of MCI patients. In this system we are using the power of longitudinal data extracted from magnetic resonance (MR). For this work, a total of 294 MCI patients were selected from the ADNI database. Among them, 125 patients developed AD during their follow-up and the rest remained stable. The proposed computer-aided diagnosis system (CAD) attempts to identify brain regions that are significant for the prediction of developing AD. The longitudinal data were constructed using a 3D Jacobian-based method aiming to track the brain differences between two consecutive follow-ups. The proposed CAD system distinguishes MCI patients who developed AD from those who remained stable with an accuracy of 87.2%. Moreover, it does not depend on data acquired by invasive methods or cognitive tests. This work demonstrates that the use of data in different time periods contains information that is beneficial for prognosis prediction purposes that outperform similar methods and are slightly inferior only to those systems that use invasive methods or neuropsychological tests.},
keywords={Magnetic resonance imaging;Diseases;Biomarkers;Prognostics and health management;Education;Neuroimaging;Computer aided diagnosis;Convolutional Neural Network;Alzheimer's disease;Voxel-based Morphometry;Pooling},
doi={10.1109/TCBB.2020.3017872},
ISSN={1557-9964},
month={},}
@ARTICLE{8672587,
author={Pang, Shumao and Lu, Zhentai and Jiang, Jun and Zhao, Lei and Lin, Liyan and Li, Xueli and Lian, Tao and Huang, Meiyan and Yang, Wei and Feng, Qianjin},
journal={IEEE Transactions on Medical Imaging}, title={Hippocampus Segmentation Based on Iterative Local Linear Mapping With Representative and Local Structure-Preserved Feature Embedding},
year={2019},
volume={38},
number={10},
pages={2271-2280},
abstract={Hippocampus segmentation plays a significant role in mental disease diagnoses, such as Alzheimer's disease, epilepsy, and so on. Patch-based multi-atlas segmentation (PBMAS) approach is a popular method for hippocampus segmentation and has achieved a promising result. However, the PBMAS approach needs high computation cost due to registration and the segmentation accuracy is subject to the registration accuracy. In this paper, we propose a novel method based on iterative local linear mapping (ILLM) with the representative and local structure-preserved feature embedding to achieve accurate and robust hippocampus segmentation with no need for registration. In the proposed approach, semi-supervised deep autoencoder (SSDA) exploits unsupervised deep autoencoder and local structure-preserved manifold regularization to nonlinearly transform the extracted magnetic resonance (MR) patch to embedded feature manifold, whose adjacent relationship is similar to the signed distance map (SDM) patch manifold. Local linear mapping is used to preliminarily predict SDM patch corresponding to the MR patch. Subsequently, threshold segmentation generates a preliminary segmentation. The ILLM refines the segmentation result iteratively by ensuring the local constraints of embedded feature manifold and SDM patch manifold using a space-constrained dictionary update. Thus, a refined segmentation is obtained with no need for registration. The experiments on 135 subjects from ADNI dataset show that the proposed approach is superior to the state-of-the-art PBMAS and classification-based approaches with mean Dice similarity coefficients of 0.8852 ± 0.0203 and 0.8783 ± 0.0251 for bilateral hippocampus segmentation of 1.5T and 3.0T datasets, respectively.},
keywords={Manifolds;Image segmentation;Hippocampus;Dictionaries;Image reconstruction;Diseases;Training;Deep learning;multi-atlas segmentation;iterative local linear mapping;manifold regularization},
doi={10.1109/TMI.2019.2906727},
ISSN={1558-254X},
month={Oct},}
@INPROCEEDINGS{9024353,
author={Ghafoor, Usman and Yaqub, M. Atif and Hong, Keum-Shik},
booktitle={2019 International Automatic Control Conference (CACS)}, title={Performance evaluation of temporal features for detection of mild cognitive impairment: An fNIRS study},
year={2019},
volume={},
number={},
pages={1-6},
abstract={The following topics are dealt with: control system synthesis; learning (artificial intelligence); mobile robots; motion control; robust control; neural nets; linear systems; feature extraction; automobiles; path planning.},
keywords={Task analysis;Electroencephalography;Diseases;Hemodynamics;Functional magnetic resonance imaging;Spatial resolution;functional near-infrared spectroscopy;mild cognitive impairment;features;Alzheimer disease},
doi={10.1109/CACS47674.2019.9024353},
ISSN={},
month={Nov},}
@INPROCEEDINGS{9201821,
author={Kinoshita, Fumiya and Ono, Rentaro and Ichikawa, Keita and Hirayama, Kosuke and Takada, Masumi and Takada, Hiroki},
booktitle={2020 15th International Conference on Computer Science Education (ICCSE)}, title={A Study of Evaluation of Vision Training System to Prevent Mild Cognitive Impairment},
year={2020},
volume={},
number={},
pages={53-56},
abstract={Scientists have long purported a connection between function vision and dementia: for example, deficits in visuospatial cognition are a common symptom of Alzheimer's disease. Recently, we have seen an increase in the researches aiming to detect dementia early through the quantification of brain processes involved in stereopsis in humans [9]-[10]. In this study, we developed two 3D visual training tasks, involving depth perception and eye movements, and analyzed how regional cerebral hemodynamics changed during their performance utilizing functional near-infrared spectroscopy (fNIRS). The 3D-vision training paradigm comprised two tasks, train the predictive ability and short-term memory and present them using stereoscopic content. This combination resulted in an overall rise in blood flow/neural activation in specific regions throughout the brain, especially those in the parietal and occipital cortex implicated in visuospatial processing and cognition.},
keywords={Task analysis;Dementia;Training;Visualization;Three-dimensional displays;Blood flow;Mild cognitive impairment (MCI);eye movements;3D visual training task;Regional cerebral blood flow;Functional near-infrared spectroscopy (fNIRS)},
doi={10.1109/ICCSE49874.2020.9201821},
ISSN={2473-9464},
month={Aug},}
@ARTICLE{9314203,
author={Xu, Mengjia and Sanz, David Lopez and Garces, Pilar and Maestu, Fernando and Li, Quanzheng and Pantazis, Dimitrios},
journal={IEEE Transactions on Biomedical Engineering}, title={A Graph Gaussian Embedding Method for Predicting Alzheimer's Disease Progression With MEG Brain Networks},
year={2021},
volume={68},
number={5},
pages={1579-1588},
abstract={Characterizing the subtle changes of functional brain networks associated with the pathological cascade of Alzheimer's disease (AD) is important for early diagnosis and prediction of disease progression prior to clinical symptoms. We developed a new deep learning method, termed multiple graph Gaussian embedding model (MG2G), which can learn highly informative network features by mapping high-dimensional resting-state brain networks into a low-dimensional latent space. These latent distribution-based embeddings enable a quantitative characterization of subtle and heterogeneous brain connectivity patterns at different regions, and can be used as input to traditional classifiers for various downstream graph analytic tasks, such as AD early stage prediction, and statistical evaluation of between-group significant alterations across brain regions. We used MG2G to detect the intrinsic latent dimensionality of MEG brain networks, predict the progression of patients with mild cognitive impairment (MCI) to AD, and identify brain regions with network alterations related to MCI.},
keywords={Biomarkers;Magnetic resonance imaging;Diseases;Brain modeling;Proteins;Positron emission tomography;Magnetic heads;Alzheimer's disease;brain networks;magnetoencephalography;mild cognitive impairment;multivariate Gaussian distribution;stochastic graph embedding;uncertainty quantification},
doi={10.1109/TBME.2021.3049199},
ISSN={1558-2531},
month={May},}
@INPROCEEDINGS{8832716,
author={Liu, Yue and Wang, Chuyuan and Wei, Ying},
booktitle={2019 Chinese Control And Decision Conference (CCDC)}, title={Hippocampus Segmentation in MR image based on Atlas Registration and Broad Learning},
year={2019},
volume={},
number={},
pages={2707-2711},
abstract={Automatic segmentation of hippocampus in MRI plays an important role in computer aided diagnosis, which is helpful for early treatments of many diseases such as Alzheimers disease and epilepsy. In this paper, a coarse to fine hippocampus segmentation method is proposed. In coarse segmentation stage, atlas registration is applied to construct probabilistic atlases. In fine segmentation stage, atlas label images and coarse segmentation results are applied to delineate ROI. Furthermore, training samples extracted from ROI are used to train the broad learning model. Experimental results show that the proposed method is competitive with deep learning. The average Dice value achieves 0.83 on hippocampus segmentation, which indicates the superiority of the proposed method.},
keywords={Image segmentation;Hippocampus;Feature extraction;Training;Probabilistic logic;Shape;Deep learning;Hippocampus segmentation;coarse to fine;atlas registration;broad learning},
doi={10.1109/CCDC.2019.8832716},
ISSN={1948-9447},
month={June},}
@ARTICLE{8572804,
author={Ahmed, Md Rishad and Zhang, Yuan and Feng, Zhiquan and Lo, Benny and Inan, Omer T. and Liao, Hongen},
journal={IEEE Reviews in Biomedical Engineering}, title={Neuroimaging and Machine Learning for Dementia Diagnosis: Recent Advancements and Future Prospects},
year={2019},
volume={12},
number={},
pages={19-33},
abstract={Dementia, a chronic and progressive cognitive declination of brain function caused by disease or impairment, is becoming more prevalent due to the aging population. A major challenge in dementia is achieving accurate and timely diagnosis. In recent years, neuroimaging with computer-aided algorithms have made remarkable advances in addressing this challenge. The success of these approaches is mostly attributed to the application of machine learning techniques for neuroimaging. In this review paper, we present a comprehensive survey of automated diagnostic approaches for dementia using medical image analysis and machine learning algorithms published in the recent years. Based on the rigorous review of the existing works, we have found that, while most of the studies focused on Alzheimer's disease, recent research has demonstrated reasonable performance in the identification of other types of dementia remains a major challenge. Multimodal imaging analysis deep learning approaches have shown promising results in the diagnosis of these other types of dementia. The main contributions of this review paper are as follows. 1) Based on the detailed analysis of the existing literature, this paper discusses neuroimaging procedures for dementia diagnosis. 2) It systematically explains the most recent machine learning techniques and, in particular, deep learning approaches for early detection of dementia.},
keywords={Dementia;Magnetic resonance imaging;Neuroimaging;Biomedical imaging;Machine learning;Dementia;neuroimaging;computer-aided diagnosis (CAD);image processing;machine learning;deep learning},
doi={10.1109/RBME.2018.2886237},
ISSN={1941-1189},
month={},}
@INPROCEEDINGS{8972091,
author={Wang, Xulong and Qi, Jun and Yang, Yun and Yang, Po},
booktitle={2019 IEEE 17th International Conference on Industrial Informatics (INDIN)}, title={A Survey of Disease Progression Modeling Techniques for Alzheimer's Diseases},
year={2019},
volume={1},
number={},
pages={1237-1242},
abstract={Modeling and predicting progression of chronic diseases like Alzheimer's disease (AD) has recently received much attention. Traditional approaches in this field mostly rely on harnessing statistical methods into processing medical data like genes, MRI images, demographics, etc. Latest advances of machine learning techniques grant another chance of training disease progression models for AD. This trend leads on exploring and designing new machine learning techniques towards multi-modality medical and health dataset for predicting occurrences and modeling progression of AD. This paper aims at giving a systemic survey on summarizing and comparing several mainstream techniques for AD progression modeling, and discuss the potential and limitations of these techniques in practical applications. We summarize three key techniques for modeling AD progression: multi-task model, time series model and deep learning. In particular, we discuss the basic structural elements of most representative multi-task learning algorithms, and analyze a multi-task disease prediction model based on longitudinal time. Lastly, some potential future research direction is given.},
keywords={Alzheimer's disease;disease progression;regression model;multi-task learning},
doi={10.1109/INDIN41052.2019.8972091},
ISSN={2378-363X},
month={July},}
@ARTICLE{8950467,
author={Biffi, Carlo and Cerrolaza, Juan J. and Tarroni, Giacomo and Bai, Wenjia and de Marvao, Antonio and Oktay, Ozan and Ledig, Christian and Le Folgoc, Loic and Kamnitsas, Konstantinos and Doumou, Georgia and Duan, Jinming and Prasad, Sanjay K. and Cook, Stuart A. and O’Regan, Declan P. and Rueckert, Daniel},
journal={IEEE Transactions on Medical Imaging}, title={Explainable Anatomical Shape Analysis Through Deep Hierarchical Generative Models},
year={2020},
volume={39},
number={6},
pages={2088-2099},
abstract={Quantification of anatomical shape changes currently relies on scalar global indexes which are largely insensitive to regional or asymmetric modifications. Accurate assessment of pathology-driven anatomical remodeling is a crucial step for the diagnosis and treatment of many conditions. Deep learning approaches have recently achieved wide success in the analysis of medical images, but they lack interpretability in the feature extraction and decision processes. In this work, we propose a new interpretable deep learning model for shape analysis. In particular, we exploit deep generative networks to model a population of anatomical segmentations through a hierarchy of conditional latent variables. At the highest level of this hierarchy, a two-dimensional latent space is simultaneously optimised to discriminate distinct clinical conditions, enabling the direct visualisation of the classification space. Moreover, the anatomical variability encoded by this discriminative latent space can be visualised in the segmentation space thanks to the generative properties of the model, making the classification task transparent. This approach yielded high accuracy in the categorisation of healthy and remodelled left ventricles when tested on unseen segmentations from our own multi-centre dataset as well as in an external validation set, and on hippocampi from healthy controls and patients with Alzheimer's disease when tested on ADNI data. More importantly, it enabled the visualisation in three-dimensions of both global and regional anatomical features which better discriminate between the conditions under exam. The proposed approach scales effectively to large populations, facilitating high-throughput analysis of normal anatomy and pathology in large-scale studies of volumetric imaging.},
keywords={Shape;Pathology;Three-dimensional displays;Task analysis;Deep learning;Medical diagnostic imaging;Shape analysis;explainable deep learning;generative modeling;MRI},
doi={10.1109/TMI.2020.2964499},
ISSN={1558-254X},
month={June},}
@INPROCEEDINGS{9105974,
author={Lai, Zhengfeng and Guo, Runlin and Xu, Wenda and Hu, Zin and Mifflin, Kelsey and Dugger, Brittany N. and Chuah, Chen-Nee and Cheung, Sen-ching},
booktitle={2020 IEEE International Conference on Multimedia Expo Workshops (ICMEW)}, title={Automated grey and white matter segmentation in digitized Aβ human brain tissue slide images},
year={2020},
volume={},
number={},
pages={1-6},
abstract={Neuropathologists assess vast brain areas to identify diverse and subtly differentiated morphologies. Alzheimer's disease pathologies have different density distributions in grey matter (GM) and white matter (WM), making the task of separating GM and WM necessary to neuropathologic deep phenotyping. Standard methods of segmentation typically require manual annotations, where a trained observer traces the boundaries of GM and WM on digitized tissue slide images using software like Aperio ImageScope or QuPath. This method can be time-consuming and can prevent the analysis of large amounts of slides in a scalable way. In this paper, we propose a CNN-based approach to automatically segment GM and WM in ultra-high-resolution whole slide images (WSIs) by transforming the segmentation problem into a classification problem. Contrary to the traditional image processing segmentation method, our technique is flexible, robust, and efficient with the accuracy of 77.43% in GM and 79.42% in WM on our hold-out WSIs.},
keywords={Image segmentation;Training;Image resolution;Alzheimer's disease;Computer architecture;Pipelines;Neuropathology;Image Segmentation;Convolutional Neural Networks;Ultra-high Resolution},
doi={10.1109/ICMEW46912.2020.9105974},
ISSN={},
month={July},}
@ARTICLE{9039644,
author={Raj, R. Joshua Samuel and Shobana, S. Jeya and Pustokhina, Irina Valeryevna and Pustokhin, Denis Alexandrovich and Gupta, Deepak and Shankar, K.},
journal={IEEE Access}, title={Optimal Feature Selection-Based Medical Image Classification Using Deep Learning Model in Internet of Medical Things},
year={2020},
volume={8},
number={},
pages={58006-58017},
abstract={Internet of Medical Things (IoMT) is the collection of medical devices and related applications which link the healthcare IT systems through online computer networks. In the field of diagnosis, medical image classification plays an important role in prediction and early diagnosis of critical diseases. Medical images form an indispensable part of a patient's health record which can be applied to control, handle and treat the diseases. But, classification of images is a challenging task in computer-based diagnostics. In this research article, we have introduced a improved classifier i.e., Optimal Deep Learning (DL) for classification of lung cancer, brain image, and Alzheimer's disease. The researchers proposed the Optimal Feature Selection based Medical Image Classification using DL model by incorporating preprocessing, feature selection and classification. The main goal of the paper is to derive an optimal feature selection model for effective medical image classification. To enhance the performance of the DL classifier, Opposition-based Crow Search (OCS) algorithm is proposed. The OCS algorithm picks the optimal features from pre-processed images, here Multi-texture, grey level features were selected for the analysis. Finally, the optimal features improved the classification result and increased the accuracy, specificity and sensitivity in the diagnosis of medical images. The proposed results were implemented in MATLAB and compared with existing feature selection models and other classification approaches. The proposed model achieved the maximum performance in terms of accuracy, sensitivity and specificity being 95.22%, 86.45 % and 100% for the applied set of images.},
keywords={Medical diagnostic imaging;Feature extraction;Deep learning;Solid modeling;Cancer;IoMT;classification;deep learning;medical image;features;Crow search algorithm;optimization},
doi={10.1109/ACCESS.2020.2981337},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{9098716,
author={Farazi, Mohammad and Zhan, Liang and Lepore, Natasha and Thompson, Paul M. and Wang, Yalin},
booktitle={2020 IEEE 17th International Symposium on Biomedical Imaging (ISBI)}, title={A Univariate Persistent Brain Network Feature Based on the Aggregated Cost of Cycles from the Nested Filtration Networks},
year={2020},
volume={},
number={},
pages={1-5},
abstract={A threshold-free feature in brain network analysis can help circumvent the curse of arbitrary network thresholding for binary network conversions. Here, Persistent Homology is the inspiration for defining a new aggregation cost based on the number of cycles, or for tracking the first Betti number in a nested filtration network within the graph. Our theoretical analysis shows that the proposed aggregated cost of cycles (ACC) is monotonically increasing and thus we define a univariate persistent feature based on the shape of ACC. The proposed statistic has advantages compared to the First Betti Number Plot (BNP1), which only tracks the total number of cycles at each filtration. We show that our method is sensitive to both the topology of modular networks and the difference in the number of cycles in a network. Our method outperforms its counterparts in a synthetic dataset, while in a realworld one it achieves results comparable with the BNP1. Our proposed framework enriches univariate measures for discovering brain network dissimilarities for better categorization of distinct stages in Alzheimer's Disease (AD).},
keywords={Topology;Indexes;Network topology;Diffusion tensor imaging;Shape;Biomedical imaging;Brain network analysis;Persistent Homology;Aggregated Cost;Graph Theory},
doi={10.1109/ISBI45749.2020.9098716},
ISSN={1945-8452},
month={April},}
@INPROCEEDINGS{9098462,
author={Yushkevich, Paul A. and de Onzoño Martin, Maria Mercedes Iñiguez and Ittyerah, Ranjit and Lim, Sydney and Lavery, Madigan and Wang, Jiancong and Hung, Ling Yu and Vergnet, Nicolas and Ravikumar, Sadhana and Xie, Long and Dong, Mengjin and DeFlores, Robin and Cui, Salena and McCollum, Lauren and Ohm, Daniel T. and Robinson, John L. and Schuck, Theresa and Grossman, Murray and Tisdall, M. Dylan and Prabhakaran, Karthik and Mizsei, Gabor and Das, Sandhitsu R. and Artacho-Pérula, Emilio and del Mar Arroyo Jiménez, María and López, Mónica Muñoz and Rabal, María Pilar Marcos and Romero, Francisco Javier Molina and Lee, Edward B. and Trojanowski, John Q. and Wisse, Laura E.M. and Wolk, David A. and Irwin, David J. and Insausti, Ricardo},
booktitle={2020 IEEE 17th International Symposium on Biomedical Imaging (ISBI)}, title={3D Mapping of TAU Neurofibrillary Tangle Pathology in the Human Medial Temporal Lobe},
year={2020},
volume={},
number={},
pages={1312-1316},
abstract={Tau protein neurofibrillary tangles (NFT) are linked to neuronal and synaptic loss and cognitive decline in Alzheimer's disease (AD) and related dementias. In AD, NFT pathology is known to spread through the cortex in a characteristic pattern, starting in the medial temporal lobe. However, the exact 3D pattern of NFT progression has not been described, and capturing this pattern quantitatively can help inform in vivo AD imaging biomarkers. We present a computational framework for generating 3D maps of NFT load from ex vivo MRI and serial histology. Weakly supervised deep learning is used to detect NFTs on histology slides prepared with an anti-tau immunohistochemistry stain, and a multi-stage registration pipeline that leverages 3D printing is used for histology-MRI alignment. Derived maps of NFT density are strongly concordant with manual NFT counting, as well as categorical NFT severity ratings used for clinical diagnosis.},
keywords={Magnetic resonance imaging;Three-dimensional displays;Pathology;Diseases;Manuals;White matter},
doi={10.1109/ISBI45749.2020.9098462},
ISSN={1945-8452},
month={April},}
@ARTICLE{9381098,
author={Kolbeinsson, Arinbjörn and Kossaifi, Jean and Panagakis, Yannis and Bulat, Adrian and Anandkumar, Animashree and Tzoulaki, Ioanna and Matthews, Paul M.},
journal={IEEE Journal of Selected Topics in Signal Processing}, title={Tensor Dropout for Robust Learning},
year={2021},
volume={15},
number={3},
pages={630-640},
abstract={CNNs achieve high levels of performance by leveraging deep, over-parametrized neural architectures, trained on large datasets. However, they exhibit limited generalization abilities outside their training domain and lack robustness to corruptions such as noise and adversarial attacks. To improve robustness and obtain more computationally and memory efficient models, better inductive biases are needed. To provide such inductive biases, tensor layers have been successfully proposed to leverage multi-linear structure through higher-order computations. In this paper, we propose tensor dropout, a randomization technique that can be applied to tensor factorizations, such as those parametrizing tensor layers. In particular, we study tensor regression layers, parametrized by low-rank weight tensors and augmented with our proposed tensor dropout. We empirically show that our approach improves generalization for image classification on ImageNet and CIFAR-100. We also establish state-of-the-art accuracy for phenotypic trait prediction on the largest available dataset of brain MRI (U.K. Biobank), where multi-linear structure is paramount. In all cases, we demonstrate superior performance and significantly improved robustness, both to noisy inputs and to adversarial attacks. We establish the theoretical validity of our approach and the regularizing effect of tensor dropout by demonstrating the link between randomized tensor regression with tensor dropout and deterministic regularized tensor regression.},
keywords={Tensors;Training;Robustness;Magnetic resonance imaging;Perturbation methods;Diseases;Deep learning;Deep learning;randomized tensor regression;robustness;stochastic regularization;tensor dropout;tensor methods;tensor regression;tensor regression layers},
doi={10.1109/JSTSP.2021.3064182},
ISSN={1941-0484},
month={April},}
@ARTICLE{9324935,
author={Chu, N. Nan},
journal={IEEE Consumer Electronics Magazine}, title={The IEEE Brain Data Bank Challenge 2020},
year={2021},
volume={10},
number={3},
pages={8-9},
abstract={The 2020 Brain Data Bank (BDB) Challenge reached its closure on December 5, 2020, in a virtual conference format, due to COVID-19. Having 88 registrants (roughly 20% medical, non-IEEE, and the rest primarily IEEE engineering professionals) from 10 countries, the BDBC-Finale program consisted of presentations from 5 selected teams resulting from 3 preliminary runs earlier in 2020. The program was further enriched with a National Institute of Aging (NIA) Keynote on US funding sources and a Special Panel on Codesigning with an End-User, Prof. Justin Yerbury, who has been suffering from motor neuron disease since 2016. The theme for 2020 was the Aging Brain, making use of large brain records, (1) Alzheimer’'s Disease NeuroImaging (ADNI) containing magnetic resonance imaging (MRI), positron emission tomography, CerebroSpinal Fluid images, and clinical data (~3 TB), and (2) ElectroEncephaloGraphy (EEG) corpus (48–350 GB) to examine brain degeneration ending in Alzheimer's Disease (AD). Individual teams specified selected brain datasets to apply deep learning/machine learning techniques for the detection of elderly brain impairment. Other approaches to understand AD were also presented in terms of fMRI-based functional connectivity alteration, and experiments in rehabilitation using turmeric administered rats after bulbectomy. The author discuses the gains from these BDB Challenge presentations.},
keywords={},
doi={10.1109/MCE.2021.3051928},
ISSN={2162-2256},
month={May},}

