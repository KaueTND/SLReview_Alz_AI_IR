
@ARTICLE{Eken2021,
author={Eken, A.},
title={Assessment of flourishing levels of individuals by using resting-state fNIRS with different functional connectivity measures},
journal={Biomedical Signal Processing and Control},
year={2021},
volume={68},
doi={10.1016/j.bspc.2021.102645},
art_number={102645},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104083704&doi=10.1016%2fj.bspc.2021.102645&partnerID=40&md5=0798675e0728edb1acc5fe7af7cf69ce},
abstract={Flourishing is an important criterion for assessing well-being, however, controversy remains, especially while assessing it with self-report measures. Therefore, to understand the underlying neural mechanisms of well-being, researchers often use neuroimaging techniques. However, previous neuroimaging studies using conventional statistical approaches provided answers in an average sense rather than individual answers. In this study, we used machine learning algorithms to classify highly flourishing from normally flourishing individuals using a publicly available resting-state functional near-infrared spectroscopy (rs-fNIRS) dataset collected from 43 participants to obtain an answer for individual level. We utilized both the Pearson's correlation (CC) and the Dynamic Time Warping (DTW) algorithm to estimate functional connectivity matrices from the rs-fNIRS data on the temporo-parieto-occipital region and used them as input for machine learning algorithms. Our results showed that we were able to classify flourishing individuals with 90 % accuracy with AUC 0.90 and 0.93 using Nearest Neighbor and Radial Basis Kernel Support Vector Machine using oxyhemoglobin concentration change with Pearson's correlation (CC – ΔHbO) and deoxy hemoglobin concentration change with dynamic time warping (DTW – ΔHb). This finding suggests that temporo-parieto-occipital region-based resting-state functional connectivity might be a potential biomarker to identify the levels of flourishing and using both connectivity measures might allow us to find different potential biomarkers. © 2021 Elsevier Ltd},
document_type={Article},
source={Scopus},
}

@ARTICLE{Shamsi2021,
author={Shamsi, E. and Ahmadi-Pajouh, M.A. and Seifi Ala, T.},
title={Higuchi fractal dimension: An efficient approach to detection of brain entrainment to theta binaural beats},
journal={Biomedical Signal Processing and Control},
year={2021},
volume={68},
doi={10.1016/j.bspc.2021.102580},
art_number={102580},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103326410&doi=10.1016%2fj.bspc.2021.102580&partnerID=40&md5=aa21593b3bed54af268a077aca2ee6cc},
abstract={Binaural beats (BBs) are two pure tones with a small frequency difference (i.e., beat) separately presented to each ear. They cause the beat perception in the brain. BBs are used in both clinical and basic science applications. Studies in BB literature have mainly focused on linear analysis of the brain signals. Even though these approaches have produced promising findings, there may still be some facets left to be considered, which cannot be studied by linear measures. BBs entrain the brain and generate synchronous responses. Previous studies have proved that increasing brain synchronicity reduced its complexity measured by fractal dimension (FD). In this study, Higuchi fractal dimension (HFD) was used to test whether: 1) BB stimulation decreases the electroencephalogram (EEG) complexity, and 2) HFD is a reliable alternative to its common linear counterpart (i.e., relative power of the band in which the beat frequency lies) in terms of the brain entrainment detection. Results revealed that 3-min BB stimulation significantly decreased the HFD in temporal and parietal lobes, which was about half the time required to probe any changes in EEG power. Moreover, there was significant negative correlation between the relative power and HFD in these regions. In comparison to the relative power, HFD produced mostly higher classification accuracies and areas under empirical receiver operating characteristic (ROC) curve in these lobes. Our findings suggest that HFD can be a reliable replacement for relative power in terms of entrainment detection and response classification. © 2021 Elsevier Ltd},
document_type={Article},
source={Scopus},
}

@ARTICLE{Valero2021,
author={Valero, M. and Li, F. and Zhao, L. and Zhang, C. and Garrido, J. and Han, Z.},
title={Vibration sensing-based human and infrastructure safety/health monitoring: A survey},
journal={Digital Signal Processing: A Review Journal},
year={2021},
volume={114},
doi={10.1016/j.dsp.2021.103037},
art_number={103037},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103783746&doi=10.1016%2fj.dsp.2021.103037&partnerID=40&md5=909094b35b5434b5802b8aae8535ba43},
abstract={Current sensor technologies enable the passive and continuous monitoring of human behaviors as well as infrastructures to ensure personal safety and assess individual health state. One passive technology that has the potential of gathering personal data is the vibration sensor. In this paper, we carry out an extensive survey of the current vibration-based sensing technologies for human and infrastructure safety as well as health monitoring. These technologies utilize structural and bodies vibration as a source of data, and they can be incorporated in wearable or non-wearable devices. Furthermore, the vibration sensing technology utilizes low-cost and low-power sensors, which make it attractive for indoor and outdoor monitoring. We have classified the technologies into five categories: vibration-based sensing for assessing human health, recognizing personal behavior, inferring occupancy information, evaluating personal safety, and monitoring infrastructure health. In each category, we also classify the approaches that utilize single and multiple sensors. Moreover, we discuss the different types of signal processing and machine learning techniques that are applied to each approach. © 2021 Elsevier Inc.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Zhang2021,
author={Zhang, X. and Yao, L. and Wang, X. and Monaghan, J. and Mcalpine, D. and Zhang, Y.},
title={A survey on deep learning-based non-invasive brain signals: recent advances and new frontiers},
journal={Journal of Neural Engineering},
year={2021},
volume={18},
number={3},
doi={10.1088/1741-2552/abc902},
art_number={031002},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103312855&doi=10.1088%2f1741-2552%2fabc902&partnerID=40&md5=420f1832733a92b49be8e1e412d5bd2c},
abstract={Brain signals refer to the biometric information collected from the human brain. The research on brain signals aims to discover the underlying neurological or physical status of the individuals by signal decoding. The emerging deep learning techniques have improved the study of brain signals significantly in recent years. In this work, we first present a taxonomy of non-invasive brain signals and the basics of deep learning algorithms. Then, we provide the frontiers of applying deep learning for non-invasive brain signals analysis, by summarizing a large number of recent publications. Moreover, upon the deep learning-powered brain signal studies, we report the potential real-world applications which benefit not only disabled people but also normal individuals. Finally, we discuss the opening challenges and future directions. © 2021 IOP Publishing Ltd.},
document_type={Review},
source={Scopus},
}

@ARTICLE{Hermessi2021,
author={Hermessi, H. and Mourali, O. and Zagrouba, E.},
title={Multimodal medical image fusion review: Theoretical background and recent advances},
journal={Signal Processing},
year={2021},
volume={183},
doi={10.1016/j.sigpro.2021.108036},
art_number={108036},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101535728&doi=10.1016%2fj.sigpro.2021.108036&partnerID=40&md5=337858ba547662bb411361fb02429e01},
abstract={Multimodal medical image fusion consists in combining two or more images of the same or different modalities aiming to improve the image content, and preserve information. The rapid advance in medical imaging techniques (Computed Tomography (CT), Positron Emission Tomography (PET), Magnetic Resonance Imaging (MRI), Single Photon Emission Computed Tomography (SPECT)) has attracted researcher's attention to fuse different modalities in order to assist experts decision making during the aided-diagnosis pipeline. Moreover, the fused results may help boosting other tasks such as classification, detection and segmentation. The main objective of this work is to provide a comprehensive overview of medical image fusion methods with theoretical background and recent advances. To do so, we present a detailed literature panorama of medical image fusion. The pixel-level, feature-level and decision-level fusion methods are highlighted and discussed with several approaches in each category. Theories behind fusion algorithms are explored aiming to address challenges and limitations of each classes. Therefore, we propose an experimental analysis of fusion performance given by different categories to guide the discussion. By summarizing the existing fusion classes, we discuss merits and demerits of each category to provide some recommendations for future research directions. Finally, performance evaluation metrics are presented to draw conclusions and perspectives. © 2021 Elsevier B.V.},
document_type={Review},
source={Scopus},
}

@ARTICLE{Yousefzadeh2021,
author={Yousefzadeh, M. and Hosseini, S.A. and Farnaghi, M.},
title={Spatiotemporally explicit earthquake prediction using deep neural network},
journal={Soil Dynamics and Earthquake Engineering},
year={2021},
volume={144},
doi={10.1016/j.soildyn.2021.106663},
art_number={106663},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101374483&doi=10.1016%2fj.soildyn.2021.106663&partnerID=40&md5=cdeaa41574f8338c3693f2e9f9bee800},
abstract={Due to the complexity of predicting future earthquakes, machine learning algorithms have been used by several researchers to increase the Accuracy of the forecast. However, the concentration of previous studies has chiefly been on the temporal rather than spatial parameters. Additionally, the less correlated variables were typically eliminated in the feature analysis and did not enter the model. This study introduces and investigates the effect of spatial parameters on four ML algorithms' performance for predicting the magnitude of future earthquakes in Iran as one of the most earthquake-prone countries in the world. We compared the performances of conventional methods of Support Vector Machine (SVM), Decision Tree (DT), and a Shallow Neural Network (SNN) with the contemporary Deep Neural Network (DNN) method for predicting the magnitude of the biggest upcoming earthquake in the next week. Information Gain analysis, Accuracy, Sensitivity, Positive Predictive Value, Negative Predictive Value, and Specificity measures were exploited to investigate the outcome of using a new parameter, called Fault Density, calculated using Kernel Density Estimation and Bivariate Moran's I, on the performance of the earthquake prediction, in comparison to other commonly used parameters. We discussed the behavior of the four models while dealing with different combinations of parameters and different classes of earthquake magnitudes. The results showed promising performance of the proposed parameter for the earthquakes of high magnitudes, especially using SVM and DNN models. © 2021 The Author(s)},
document_type={Article},
source={Scopus},
}

@ARTICLE{Mayya2021374,
author={Mayya, V. and Sowmya Kamath, S. and Krishnan, G.S. and Gangavarapu, T.},
title={Multi-channel, convolutional attention based neural model for automated diagnostic coding of unstructured patient discharge summaries},
journal={Future Generation Computer Systems},
year={2021},
volume={118},
pages={374-391},
doi={10.1016/j.future.2021.01.013},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100018423&doi=10.1016%2fj.future.2021.01.013&partnerID=40&md5=8e4bd783b9513bedb99a1a237b528ac5},
abstract={Effective coding of patient records in hospitals is an essential requirement for epidemiology, billing, and managing insurance claims. The prevalent practice of manual coding, carried out by trained medical coders, is error-prone and time-consuming. Mitigating this labor-intensive process by developing diagnostic coding systems built on patients’ Electronic Medical Records (EMRs) is vital. However, developing nations with low digitization rates have limited availability of structured EMRs, thereby necessitating a need for systems that leverage unstructured data sources. Despite the rich clinical information available in such unstructured data, modeling them is complex, owing to the variety and sparseness of diagnostic codes, complex structural and temporal nature of summaries, and prolific use of medical jargon. This work proposes a context-attentive network to facilitate automatic diagnostic code assignment as a multi-label classification problem. The proposed model facilitates information aggregation across a patient's discharge summary via multi-channel, variable-sized convolutional filters to extract multi-granular snippets. The attention mechanism enables selecting vital segments in those snippets that map to the clinical codes. The model's superior performance underscores its effectiveness compared to the state-of-the-art on the MIMIC-III database. Additionally, experimental validation using the CodiEsp dataset exhibited the model's interpretability and explainability. © 2021 Elsevier B.V.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Liu20211,
author={Liu, C. and Ji, H. and Qiu, A.},
title={Fast vertex-based graph convolutional neural network and its application to brain images},
journal={Neurocomputing},
year={2021},
volume={434},
pages={1-10},
doi={10.1016/j.neucom.2020.12.097},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100154715&doi=10.1016%2fj.neucom.2020.12.097&partnerID=40&md5=5335d1bea70b548349f1c1b71f8f4c7d},
abstract={This paper proposes a vertex-based graph convolutional neural network (vertex-CNN) for analyzing structured data on graphs. We represent graphs using semi-regular triangulated meshes in which each vertex has 6 connected neighbors. We generalize classical CNN defined on equi-spaced grids to that defined on semi-regular triangulated meshes by introducing main building blocks of the CNN, including convolution, down-sampling, and pooling, on a vertex domain. By exploiting the regularity of semi-regular meshes in terms of vertex connections, the proposed vertex-CNN keeps the inherent properties of classical CNN in a Euclidean space, such as shift-invariance and down-sampling at a rate of 2, 4, etc. We employ brain images from Alzheimer's Disease Neuroimaging Initiative (ADNI) (n = 6767) and extract cortical features (e.g., cortical thickness, surface area, curvature, Jacobian, sulcal depth, and volume) for the classification of healthy controls (CON), patients with mild cognitive impairment (MCI) and Alzheimer's disease (AD). Based on cortical thickness, we show that the proposed vertex-CNN is near 3 times faster and performs significantly better in the classification performance of CON, MCI, and AD than an existing graph CNN defined on the graph spectral domain given in Defferrard (2016). Moreover, we examine the robustness of a multi-channel implementation of vertex-CNN on 6 cortical measures for the MCI and AD classification. Finally, we show a promising finding of the prediction accuracy from MCI to AD as a function of years before the onset of AD. Our experiments demonstrate the fast computation and promising classification performance of the vertex-CNN. © 2021 Elsevier B.V.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Abbasi2021177,
author={Abbasi, R. and Chen, J. and Al-Otaibi, Y. and Rehman, A. and Abbas, A. and Cui, W.},
title={RDH-based dynamic weighted histogram equalization using for secure transmission and cancer prediction},
journal={Multimedia Systems},
year={2021},
volume={27},
number={2},
pages={177-189},
doi={10.1007/s00530-020-00718-w},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098758044&doi=10.1007%2fs00530-020-00718-w&partnerID=40&md5=6e6ec47e0f5c0a0b72da408eb0def4f2},
abstract={Image contrast enhancement is a prerequisite and plays a very important role in many image processing field like medical imaging, face recognition, computer-vision, and satellite imaging. In this paper we proposed reversible data hiding based Limited Dynamic Weighted Histogram Equalization techniques for Abnormal Tumor regions which improve the contrast, transmit the hidden secret information, preserve its brightness intensity and original appearance of the image. We have implemented Otsu’s method to segment the input image into two sub-histogram regions of interest (ROI) and non-region of interest; furthermore, the sub-histograms ROI region equalized independently without of over-enhancement and any loss of hidden and diagnostic data. Our proposed method is more efficient to precisely preserve the brightness of the image and extract the secret information with contrast image reversibly; besides, different classifiers are used to classify the brain cancer to check the performance of our proposed method. © 2021, Springer-Verlag GmbH Germany, part of Springer Nature.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Esposito2021,
author={Esposito, C.M. and Buoli, M. and Ciappolino, V. and Agostoni, C. and Brambilla, P.},
title={The role of cholesterol and fatty acids in the etiology and diagnosis of autism spectrum disorders},
journal={International Journal of Molecular Sciences},
year={2021},
volume={22},
number={7},
doi={10.3390/ijms22073550},
art_number={3550},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103119310&doi=10.3390%2fijms22073550&partnerID=40&md5=db7a0693d995ddbff7080f89eb42a7e9},
abstract={Autism spectrum disorders (ASDs) are a group of neurodevelopmental disorders whose pathogenesis seems to be related to an imbalance of excitatory and inhibitory synapses, which leads to disrupted connectivity during brain development. Among the various biomarkers that have been evaluated in the last years, metabolic factors represent a bridge between genetic vulnerability and environmental aspects. In particular, cholesterol homeostasis and circulating fatty acids seem to be involved in the pathogenesis of ASDs, both through the contribute in the stabilization of cell membranes and the modulation of inflammatory factors. The purpose of the present review is to summarize the available data about the role of cholesterol and fatty acids, mainly long‐chain ones, in the onset of ASDs. A bibliographic research on the main databases was performed and 36 studies were included in our review. Most of the studies document a correlation between ASDs and hypocholesterolemia, while the results concerning circulating fatty acids are less univocal. Even though further studies are necessary to confirm the available data, the metabolic biomarkers open to new treatment options such as the modulation of the lipid pattern through the diet. © by the authors. Licensee MDPI, Basel, Switzerland.},
document_type={Review},
source={Scopus},
}

@ARTICLE{Guerrero-Ibañez2021,
author={Guerrero-Ibañez, J. and Contreras-Castillo, J. and Zeadally, S.},
title={Deep learning support for intelligent transportation systems},
journal={Transactions on Emerging Telecommunications Technologies},
year={2021},
volume={32},
number={3},
doi={10.1002/ett.4169},
art_number={e4169},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097015420&doi=10.1002%2fett.4169&partnerID=40&md5=86f5443472bff75e7d8df1ca118e5dcb},
abstract={Intelligent Transportation Systems (ITS) help improve the ever-increasing vehicular flow and traffic efficiency in urban traffic to reduce the number of accidents. The generation of massive amounts of data generated by all the digital devices connected to the transportation network enables the creation of datasets to perform an in-depth analysis of the data using deep learning methods. Such methods can help predict traffic performance, automated traffic light management, lane detection, and identifying objects near vehicles to increase the safety and efficiency of ITS. We discuss some of the challenges that need to be solved to achieve seamless integration between ITS and deep learning methods to address issues such as (1) improving traffic flow/transportation logistics, (2) predicting best routes for the transportation of goods, (3) optimal fuel consumption, (4) intelligent environmental conditions perception, (5) traffic speed management, and accident prevention. © 2020 John Wiley & Sons, Ltd.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Bokade2021,
author={Bokade, R. and Navato, A. and Ouyang, R. and Jin, X. and Chou, C.-A. and Ostadabbas, S. and Mueller, A.V.},
title={A cross-disciplinary comparison of multimodal data fusion approaches and applications: Accelerating learning through trans-disciplinary information sharing},
journal={Expert Systems with Applications},
year={2021},
volume={165},
doi={10.1016/j.eswa.2020.113885},
art_number={113885},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090352328&doi=10.1016%2fj.eswa.2020.113885&partnerID=40&md5=ca0e8db2ef4c51482acd21a3f7dbf06d},
abstract={Multimodal data fusion (MMDF) is the process of combining disparate data streams (of different dimensionality, resolution, type, etc.) to generate information in a form that is more understandable or usable. Despite the explosion of data availability in recent decades, as yet there is no well-developed theoretical basis for multimodal data fusion, i.e., no way to determine a priori which approach is best suited to combine an arbitrary set of available data to achieve a stated goal for a given application. This has resulted in exploration of a wide variety of approaches across numerous domains but as yet very little integration of conclusions at a meta (cross-disciplinary) level. In response, this manuscript poses the following questions: (1) How convergent (or divergent) are approaches within single disciplines? (2) How similar are the challenges posed across different disciplines, i.e., might there be opportunity for successes in MMDF achieved in one field to inform progress in other areas as well? and (3) Where are the outstanding gaps in MMDF research, and what does this imply as targets for high impact research in the coming years? To begin to answer these questions, an apples-to-apples comparison of the literature of nine stakeholder-centric engineering domains (civil engineering, transportation, energy, environmental engineering, food engineering, critical care (healthcare), neuroscience, manufacturing/automation, and robotics) was created by quantifying the numbers and dimensionalities of modalities and sensors in each published project and classifying the algorithms used and purposes for which they are used. Within disciplines, it is shown there is often a tendency for use of similar methodologies, both in choice of level of fusion and data algorithm class. Yet this analysis also reveals that many problem types (defined by data dimensionality, modality number and type, and fusion purpose) are shared across different domains and are approached differently in those domains, e.g., transportation problems have similar characteristics to critical care, food science, robotics, and civil engineering. Of the disciplines studied, most (>75%) share problem characteristics with 3–5 others; to support leveraging these resources, lookup tables indexed by data dimensions, number of modalities, etc. are provided as a starting point for cross-disciplinary MMDF literature searches for new applications. Critical gaps identified are (1) a drop off of the number of published studies with increasing number of distinct modalities and (2) a dearth of publications tackling challenges with high dimensionality inputs, especially time-series 2D and 3D data. These gaps may point to topics where algorithm development will be fruitful to enable future solutions as video and other high-dimensionality sensors decrease in price. Finally, the lack of a shared vocabulary across disciplines makes analyses like the one conducted here challenging, as does the often implicit incorporation of expert knowledge into design; therefore progress toward a better leveraging of the current state of knowledge and toward a theoretical MMDF framework depends critically on improved cross-disciplinary communication and coordination on this topic. © 2020 Elsevier Ltd},
document_type={Review},
source={Scopus},
}

@ARTICLE{Feng2021,
author={Feng, Y. and Xiao, W. and Wu, T. and Zhang, J. and Xiang, J. and Guo, H.},
title={An automatic identification method for the blink artifacts in the magnetoencephalography with machine learning},
journal={Applied Sciences (Switzerland)},
year={2021},
volume={11},
number={5},
doi={10.3390/app11052415},
art_number={2415},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102947558&doi=10.3390%2fapp11052415&partnerID=40&md5=a2eb09d46e89677443db134c6fda31f7},
abstract={Magnetoencephalography (MEG) detects very weak magnetic fields originating from the neurons so as to study human brain functions. The original detected MEG data always include in-terference generated by blinks, which can be called blink artifacts. Blink artifacts could cover the MEG signal we are interested in, and therefore need to be removed. Commonly used artifact clean-ing algorithms are signal space projection (SSP) and independent component analysis (ICA). These algorithms need to locate the blink artifacts, which is typically done with the identification of the blink signals in the electrooculogram (EOG). The EOG needs to be measured by electrodes placed near the eye. In this work, a new algorithm is proposed for automatic and on-the-fly identification of the blink artifacts from the original detected MEG data based on machine learning; specifically, the artificial neural network (ANN).Seven hundred and one blink artifacts contained in eight MEG signal data sets are harnessed to verify the effect of the proposed blink artifacts identification algo-rithm. The results show that the method can recognize the blink artifacts from the original detected MEG data, providing a feasible MEG data-processing approach that can potentially be implemented automatically and simultaneously with MEG data measurement. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Balakrishnan2021,
author={Balakrishnan, R. and Valdés Hernández, M.D.C. and Farrall, A.J.},
title={Automatic segmentation of white matter hyperintensities from brain magnetic resonance images in the era of deep learning and big data – A systematic review},
journal={Computerized Medical Imaging and Graphics},
year={2021},
volume={88},
doi={10.1016/j.compmedimag.2021.101867},
art_number={101867},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099710372&doi=10.1016%2fj.compmedimag.2021.101867&partnerID=40&md5=7ad3720afd696e7f562a9a784a8635f4},
abstract={Background: White matter hyperintensities (WMH), of presumed vascular origin, are visible and quantifiable neuroradiological markers of brain parenchymal change. These changes may range from damage secondary to inflammation and other neurological conditions, through to healthy ageing. Fully automatic WMH quantification methods are promising, but still, traditional semi-automatic methods seem to be preferred in clinical research. We systematically reviewed the literature for fully automatic methods developed in the last five years, to assess what are considered state-of-the-art techniques, as well as trends in the analysis of WMH of presumed vascular origin. Method: We registered the systematic review protocol with the International Prospective Register of Systematic Reviews (PROSPERO), registration number - CRD42019132200. We conducted the search for fully automatic methods developed from 2015 to July 2020 on Medline, Science direct, IEE Explore, and Web of Science. We assessed risk of bias and applicability of the studies using QUADAS 2. Results: The search yielded 2327 papers after removing 104 duplicates. After screening titles, abstracts and full text, 37 were selected for detailed analysis. Of these, 16 proposed a supervised segmentation method, 10 proposed an unsupervised segmentation method, and 11 proposed a deep learning segmentation method. Average DSC values ranged from 0.538 to 0.91, being the highest value obtained from an unsupervised segmentation method. Only four studies validated their method in longitudinal samples, and eight performed an additional validation using clinical parameters. Only 8/37 studies made available their methods in public repositories. Conclusions: We found no evidence that favours deep learning methods over the more established k-NN, linear regression and unsupervised methods in this task. Data and code availability, bias in study design and ground truth generation influence the wider validation and applicability of these methods in clinical research. © 2021 The Authors},
document_type={Review},
source={Scopus},
}

@ARTICLE{Agarwal2021511,
author={Agarwal, M. and Saba, L. and Gupta, S.K. and Johri, A.M. and Khanna, N.N. and Mavrogeni, S. and Laird, J.R. and Pareek, G. and Miner, M. and Sfikakis, P.P. and Protogerou, A. and Sharma, A.M. and Viswanathan, V. and Kitas, G.D. and Nicolaides, A. and Suri, J.S.},
title={Wilson disease tissue classification and characterization using seven artificial intelligence models embedded with 3D optimization paradigm on a weak training brain magnetic resonance imaging datasets: a supercomputer application},
journal={Medical and Biological Engineering and Computing},
year={2021},
volume={59},
number={3},
pages={511-533},
doi={10.1007/s11517-021-02322-0},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100587485&doi=10.1007%2fs11517-021-02322-0&partnerID=40&md5=4c18e00fda3f671a9b16786ee2a0a561},
abstract={Wilson’s disease (WD) is caused by copper accumulation in the brain and liver, and if not treated early, can lead to severe disability and death. WD has shown white matter hyperintensity (WMH) in the brain magnetic resonance scans (MRI) scans, but the diagnosis is challenging due to (i) subtle intensity changes and (ii) weak training MRI when using artificial intelligence (AI). Design and validate seven types of high-performing AI-based computer-aided design (CADx) systems consisting of 3D optimized classification, and characterization of WD against controls. We propose a “conventional deep convolution neural network” (cDCNN) and an “improved DCNN” (iDCNN) where rectified linear unit (ReLU) activation function was modified ensuring “differentiable at zero.” Three-dimensional optimization was achieved by recording accuracy while changing the CNN layers and augmentation by several folds. WD was characterized using (i) CNN-based feature map strength and (ii) Bispectrum strengths of pixels having higher probabilities of WD. We further computed the (a) area under the curve (AUC), (b) diagnostic odds ratio (DOR), (c) reliability, and (d) stability and (e) benchmarking. Optimal results were achieved using 9 layers of CNN, with 4-fold augmentation. iDCNN yields superior performance compared to cDCNN with accuracy and AUC of 98.28 ± 1.55, 0.99 (p < 0.0001), and 97.19 ± 2.53%, 0.984 (p < 0.0001), respectively. DOR of iDCNN outperformed cDCNN fourfold. iDCNN also outperformed (a) transfer learning–based “Inception V3” paradigm by 11.92% and (b) four types of “conventional machine learning–based systems”: k-NN, decision tree, support vector machine, and random forest by 55.13%, 28.36%, 15.35%, and 14.11%, respectively. The AI-based systems can potentially be useful in the early WD diagnosis. [Figure not available: see fulltext.]. © 2021, International Federation for Medical and Biological Engineering.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Safi2021,
author={Safi, M.S. and Safi, S.M.M.},
title={Early detection of Alzheimer's disease from EEG signals using Hjorth parameters},
journal={Biomedical Signal Processing and Control},
year={2021},
volume={65},
doi={10.1016/j.bspc.2020.102338},
art_number={102338},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098198908&doi=10.1016%2fj.bspc.2020.102338&partnerID=40&md5=566423b671346196143de4b63d812e75},
abstract={Background: Alzheimer's disease (AD) is a progressive neurodegenerative disorder of the brain that ultimately results in the death of neurons and dementia. The prevalence of the disease in the world is increasing rapidly. In recent years, many studies have been done to automatically detect this disease from brain signals. Method: In this paper, the Hjorth parameters are used along with other common features to improve the AD detection accuracy from EEG signals in early stages. Also different signal decomposition methods including filtering into brain frequency bands, discrete wavelet transform (DWT) and empirical mode decomposition (EMD), and various classification algorithms including support vector machine (SVM), K-nearest neighbors (KNN) and regularized linear discriminant analysis (RLDA) are evaluated. Results: After preprocessing and extracting the discriminative features from EEG signals for 35 healthy, 31 mild AD, and 20 moderate AD subjects, the performance of different decomposition methods and different classifiers was evaluated before and after combining Hjorth parameters. Conclusions: It was shown that combining Hjorth parameters to the common features improved the accuracy of detection and by using DWT method for signal decomposition and the KNN algorithm for classification the highest accuracy is obtained as 97.64%. © 2020 Elsevier Ltd},
document_type={Article},
source={Scopus},
}

@ARTICLE{Abuhmed2021,
author={Abuhmed, T. and El-Sappagh, S. and Alonso, J.M.},
title={Robust hybrid deep learning models for Alzheimer's progression detection},
journal={Knowledge-Based Systems},
year={2021},
volume={213},
doi={10.1016/j.knosys.2020.106688},
art_number={106688},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099654736&doi=10.1016%2fj.knosys.2020.106688&partnerID=40&md5=36cb65e0c966fffa759423cdd5a2c579},
abstract={The prevalence of Alzheimer's disease (AD) in the growing elderly population makes accurately predicting AD progression crucial. Due to AD's complex etiology and pathogenesis, an effective and medically practical solution is a challenging task. In this paper, we developed and evaluated two novel hybrid deep learning architectures for AD progression detection. These models are based on the fusion of multiple deep bidirectional long short-term memory (BiLSTM) models. The first architecture is an interpretable multitask regression model that predicts seven crucial cognitive scores for the patient 2.5 years after their last observations. The predicted scores are used to build an interpretable clinical decision support system based on a glass-box model. This architecture aims to explore the role of multitasking models in producing more stable, robust, and accurate results. The second architecture is a hybrid model where the deep features extracted from the BiLSTM model are used to train multiple machine learning classifiers. The two architectures were comprehensively evaluated using different time series modalities of 1371 subjects participated in the study of the Alzheimer's disease neuroimaging initiative (ADNI). The extensive, real-world experimental results over ADNI data help establish the effectiveness and practicality of the proposed deep learning models. © 2020 Elsevier B.V.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Castillo20211,
author={Castillo, D. and Lakshminarayanan, V. and Rodríguez-Álvarez, M.J.},
title={Mr images, brain lesions, and deep learning},
journal={Applied Sciences (Switzerland)},
year={2021},
volume={11},
number={4},
pages={1-41},
doi={10.3390/app11041675},
art_number={1675},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100916330&doi=10.3390%2fapp11041675&partnerID=40&md5=b0249f499f504f29889396f4699fa798},
abstract={Medical brain image analysis is a necessary step in computer-assisted/computer-aided diagnosis (CAD) systems. Advancements in both hardware and software in the past few years have led to improved segmentation and classification of various diseases. In the present work, we review the published literature on systems and algorithms that allow for classification, identification, and detection of white matter hyperintensities (WMHs) of brain magnetic resonance (MR) images, specifically in cases of ischemic stroke and demyelinating diseases. For the selection criteria, we used bibliometric networks. Of a total of 140 documents, we selected 38 articles that deal with the main objectives of this study. Based on the analysis and discussion of the revised documents, there is constant growth in the research and development of new deep learning models to achieve the highest accuracy and reliability of the segmentation of ischemic and demyelinating lesions. Models with good performance metrics (e.g., Dice similarity coefficient, DSC: 0.99) were found; however, there is little practical application due to the use of small datasets and a lack of reproducibility. Therefore, the main conclusion is that there should be multidisciplinary research groups to overcome the gap between CAD developments and their deployment in the clinical environment. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Urooj20211,
author={Urooj, S. and Singh, S.P. and Malibari, A. and Alrowais, F. and Kalathil, S.},
title={Early detection of Alzheimer’s disease using polar harmonic transforms and optimized wavelet neural network},
journal={Applied Sciences (Switzerland)},
year={2021},
volume={11},
number={4},
pages={1-14},
doi={10.3390/app11041574},
art_number={1574},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100964598&doi=10.3390%2fapp11041574&partnerID=40&md5=b80878615b495ba35a4786be90bf7041},
abstract={Effective and accurate diagnosis of Alzheimer’s disease (AD), as well as early-stage detec-tion, has gained more and more attention in recent years. For AD classification, we propose a new hybrid method for early detection of Alzheimer’s disease (AD) using Polar Harmonic Transforms (PHT) and Self-adaptive Differential Evolution Wavelet Neural Network (SaDE-WNN). The orthog-onal moments are used for feature extraction from the grey matter tissues of structural Magnetic Resonance Imaging (MRI) data. Irrelevant features are removed by the feature selection process through evaluating the in-class and among-class variance. In recent years, WNNs have gained attention in classification tasks; however, they suffer from the problem of initial parameter tuning, parameter setting. We proposed a WNN with the self-adaptation technique for controlling the Differential Evolution (DE) parameters, i.e., the mutation scale factor (F) and the cross-over rate (CR). Experimental results on the Alzheimer’s disease Neuroimaging Initiative (ADNI) database indicate that the proposed method yields the best overall classification results between AD and mild cognitive impairment (MCI) (93.7% accuracy, 86.0% sensitivity, 98.0% specificity, and 0.97 area under the curve (AUC)), MCI and healthy control (HC) (92.9% accuracy, 95.2% sensitivity, 88.9% specificity, and 0.98 AUC), and AD and HC (94.4% accuracy, 88.7% sensitivity, 98.9% specificity and 0.99 AUC). © 2021 by the authors. Licensee MDPI, Basel, Switzerland.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Gams20211,
author={Gams, M. and Kolenik, T.},
title={Relations between electronics, artificial intelligence and information society through information society rules},
journal={Electronics (Switzerland)},
year={2021},
volume={10},
number={4},
pages={1-16},
doi={10.3390/electronics10040514},
art_number={514},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101088483&doi=10.3390%2felectronics10040514&partnerID=40&md5=28520ebfaea5daafacceef670d7e65ef},
abstract={This paper presents relations between information society (IS), electronics and artificial intelligence (AI) mainly through twenty‐four IS laws. The laws not only make up a novel collection, currently non‐existing in the literature, but they also highlight the core boosting mechanism for the progress of what is called the information society and AI. The laws mainly describe the exponential growth in a particular field, be it the processing, storage or transmission capabilities of electronic devices. Other rules describe the relations to production prices and human interaction. Overall, the IS laws illustrate the most recent and most vibrant part of human history based on the unprece-dented growth of device capabilities spurred by human innovation and ingenuity. Although there are signs of stalling, at the same time there are still many ways to prolong the fascinating progress of electronics that stimulates the field of artificial intelligence. There are constant leaps in new areas, such as the perception of real‐world signals, where AI is already occasionally exceeding human capabilities and will do so even more in the future. In some areas where AI is presumed to be inca-pable of performing even at a modest level, such as the production of art or programming software, AI is making progress that can sometimes reflect true human skills. Maybe it is time for AI to boost the progress of electronics in return. © 2021 by the author. Licensee MDPI, Basel, Switzerland.},
document_type={Review},
source={Scopus},
}

@ARTICLE{Qin20211,
author={Qin, W. and Kojima, S. and Yamazaki, Y. and Morishita, S. and Hotta, K. and Inoue, T. and Tsubaki, A.},
title={Relationship between the difference in oxygenated hemoglobin concentration changes in the left and right prefrontal cortex and cognitive function during moderate-intensity aerobic exercise},
journal={Applied Sciences (Switzerland)},
year={2021},
volume={11},
number={4},
pages={1-16},
doi={10.3390/app11041643},
art_number={1643},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100925625&doi=10.3390%2fapp11041643&partnerID=40&md5=63fe79bf59a6fd05daec3dbbc4a0b209},
abstract={Previous studies have indicated that changes in oxygenated hemoglobin concentration (O2Hb) in the prefrontal cortex (PFC) are associated with changes in cognitive function. Therefore, the present study aimed to explore the effect of differences in O2Hb levels in the left and right PFC (L-PFC and R-PFC, respectively) on cognitive function after exercise. This study included 12 healthy male college students. The exercise regimen consisted of 4 min of warm-up and rest each, followed by 20 min of moderate-intensity exercise and 20 min of post-exercise rest. Participants underwent the 2-back cognitive test thrice (pre-exercise, post-exercise, and after the 20 min post-exercise rest period), and their reaction times were recorded. O2Hb levels in the PFC were monitored using functional near-infrared spectroscopy. We analyzed the correlations between changes in postexercise reaction times and differences in peak O2Hb levels (L-PFC minus R-PFC), area under the curve for O2Hb changes, and increases in the O2Hb slope during exercise. Peak O2Hb, area under the curve (AUC) for O2Hb change, and increase in the slope of O2Hb were significantly correlated with changes in reaction time. These findings provide insight into the mechanism by which O2Hb differences between the L-PFC and R-PFC affect cognitive function. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Wang2021351,
author={Wang, J. and Zhu, H. and Wang, S.-H. and Zhang, Y.-D.},
title={A Review of Deep Learning on Medical Image Analysis},
journal={Mobile Networks and Applications},
year={2021},
volume={26},
number={1},
pages={351-380},
doi={10.1007/s11036-020-01672-7},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095414599&doi=10.1007%2fs11036-020-01672-7&partnerID=40&md5=f79f1fafde0d6ae0cf787425a2d7d06c},
abstract={Compared with common deep learning methods (e.g., convolutional neural networks), transfer learning is characterized by simplicity, efficiency and its low training cost, breaking the curse of small datasets. Medical image analysis plays an indispensable role in both scientific research and clinical diagnosis. Common medical image acquisition methods include Computer Tomography (CT), Magnetic Resonance Imaging (MRI), Ultrasound (US), X-Ray, etc. Although these medical imaging methods can be applied for non-invasive qualitative and quantitative analysis of patients—compared with image datasets in other computer vision fields such like faces—medical images, especially its labeling, is still scarce and insufficient. Therefore, more and more researchers adopted transfer learning for medical image processing. In this study, after reviewing one hundred representative papers from IEEE, Elsevier, Google Scholar, Web of Science and various sources published from 2000 to 2020, a comprehensive review is presented, including (i) structure of CNN, (ii) background knowledge of transfer learning, (iii) different types of strategies performing transfer learning, (iv) application of transfer learning in various sub-fields of medical image analysis, and (v) discussion on the future prospect of transfer learning in the field of medical image analysis. Through this review paper, beginners could receive an overall and systematic knowledge of transfer learning application in medical image analysis. And policymaker of related realm will benefit from the summary of the trend of transfer learning in medical imaging field and may be encouraged to make policy positive to the future development of transfer learning in the field of medical image analysis. © 2020, Springer Science+Business Media, LLC, part of Springer Nature.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Ullah20211,
author={Ullah, A. and Rehman, S.U. and Tu, S. and Mehmood, R.M. and Fawad and Ehatisham-Ul-haq, M.},
title={A hybrid deep CNN model for abnormal arrhythmia detection based on cardiac ECG signal},
journal={Sensors (Switzerland)},
year={2021},
volume={21},
number={3},
pages={1-13},
doi={10.3390/s21030951},
art_number={951},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100103555&doi=10.3390%2fs21030951&partnerID=40&md5=cb5af2bf09631de5d72c0255cd9792c4},
abstract={Electrocardiogram (ECG) signals play a vital role in diagnosing and monitoring patients suffering from various cardiovascular diseases (CVDs). This research aims to develop a robust algorithm that can accurately classify the electrocardiogram signal even in the presence of environmental noise. A one-dimensional convolutional neural network (CNN) with two convolutional layers, two down-sampling layers, and a fully connected layer is proposed in this work. The same 1D data was transformed into two-dimensional (2D) images to improve the model’s classification accuracy. Then, we applied the 2D CNN model consisting of input and output layers, three 2D-convolutional layers, three down-sampling layers, and a fully connected layer. The classification accuracy of 97.38% and 99.02% is achieved with the proposed 1D and 2D model when tested on the publicly available Massachusetts Institute of Technology-Beth Israel Hospital (MIT-BIH) arrhythmia database. Both proposed 1D and 2D CNN models outperformed the corresponding state-of-the-art classification algorithms for the same data, which validates the proposed models’ effectiveness. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Nazari2021,
author={Nazari, M. and Shiri, I. and Zaidi, H.},
title={Radiomics-based machine learning model to predict risk of death within 5-years in clear cell renal cell carcinoma patients},
journal={Computers in Biology and Medicine},
year={2021},
volume={129},
doi={10.1016/j.compbiomed.2020.104135},
art_number={104135},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096832673&doi=10.1016%2fj.compbiomed.2020.104135&partnerID=40&md5=10fe40fde125f1d43dcddf3b98f9ed99},
abstract={Purpose: The aim of this study was to develop radiomics–based machine learning models based on extracted radiomic features and clinical information to predict the risk of death within 5 years for prognosis of clear cell renal cell carcinoma (ccRCC) patients. Methods: According to image quality and clinical data availability, we eventually selected 70 ccRCC patients that underwent CT scans. Manual volume-of-interest (VOI) segmentation of each image was performed by an experienced radiologist using the 3D slicer software package. Prior to feature extraction, image pre-processing was performed on CT images to extract different image features, including wavelet, Laplacian of Gaussian, and resampling of the intensity values to 32, 64 and 128 bin levels. Overall, 2544 3D radiomics features were extracted from each VOI for each patient. Minimum Redundancy Maximum Relevance (MRMR) algorithm was used as feature selector. Four classification algorithms were used, including Generalized Linear Model (GLM), Support Vector Machine (SVM), K-nearest Neighbor (KNN) and XGBoost. We used the Bootstrap resampling method to create validation sets. Area under the receiver operating characteristic (ROC) curve (AUROC), accuracy, sensitivity, and specificity were used to assess the performance of the classification models. Results: The best single performance among 8 different models was achieved by the XGBoost model using a combination of radiomic features and clinical information (AUROC, accuracy, sensitivity, and specificity with 95% confidence interval were 0.95–0.98, 0.93–0.98, 0.93–0.96 and ~1.0, respectively). Conclusions: We developed a robust radiomics-based classifier that is capable of accurately predicting overall survival of RCC patients for prognosis of ccRCC patients. This signature may help identifying high-risk patients who require additional treatment and follow up regimens. © 2020 The Author(s)},
document_type={Article},
source={Scopus},
}

@ARTICLE{Li2021,
author={Li, J. and Bian, C. and Luo, H. and Chen, D. and Cao, L. and Liang, H.},
title={Multi-dimensional persistent feature analysis identifies connectivity patterns of resting-state brain networks in Alzheimer's disease},
journal={Journal of Neural Engineering},
year={2021},
volume={18},
number={1},
doi={10.1088/1741-2552/abc7ef},
art_number={016012},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101685841&doi=10.1088%2f1741-2552%2fabc7ef&partnerID=40&md5=de4a94fa1f497d2b9daf6f1169ebd7e3},
abstract={Objective. The characterization of functional brain network is crucial to understanding the neural mechanisms associated with Alzheimer's disease (AD) and mild cognitive impairment (MCI). Some studies have shown that graph theoretical analysis could reveal changes of the disease-related brain networks by thresholding edge weights. But the choice of threshold depends on ambiguous cognitive conditions, which leads to the lack of interpretability. Recently, persistent homology (PH) was proposed to record the persistence of topological features of networks across every possible thresholds, reporting a higher sensitivity than graph theoretical features in detecting network-level biomarkers of AD. However, most research on PH focused on zero-dimensional features (persistence of connected components) reflecting the intrinsic topology of the brain network, rather than one-dimensional features (persistence of cycles) with an interesting neurobiological communication pattern. Our aim is to explore the multi-dimensional persistent features of brain networks in the AD and MCI patients, and further to capture valuable brain connectivity patterns. Approach. We characterized the change rate of the connected component numbers across graph filtration using the functional derivative curves, and examined the persistence landscapes that vectorize the persistence of cycle structures. After that, the multi-dimensional persistent features were validated in disease identification using a K-nearest neighbor algorithm. Furthermore, a connectivity pattern mining framework was designed to capture the disease-specific brain structures. Main results. We found that the multi-dimensional persistent features can identify statistical group differences, quantify subject-level distances, and yield disease-specific connectivity patterns. Relatively high classification accuracies were received when compared with graph theoretical features. Significance. This work represents a conceptual bridge linking complex brain network analysis and computational topology. Our results can be beneficial for providing a complementary objective opinion to the clinical diagnosis of neurodegenerative diseases. © 2021 IOP Publishing Ltd.},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Saadat2021,
author={Saadat, M.N. and Kabir, H. and Shuaib, M. and Nassr, R.M. and Husen, M.N. and Osman, H.},
title={Research Issues State of the Art Challenges in Event Detection},
journal={Proceedings of the 2021 15th International Conference on Ubiquitous Information Management and Communication, IMCOM 2021},
year={2021},
doi={10.1109/IMCOM51814.2021.9377431},
art_number={9377431},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103741748&doi=10.1109%2fIMCOM51814.2021.9377431&partnerID=40&md5=57d18fbeeacd4072e5f115ca61d18b24},
abstract={Event detection is a cutting-edge problem in video image processing which is not that straight forward to solve. Hence, we perform a thorough search for state of the art in solving the issues in this area. There are many applications of event detection in this age of cybercrime. We target to propose a best solution to outperform existing research and make a positive development in it. We have discussed quite a long list of existing literature reviews in this hope that it would help us and anyone else working on the same as a guideline and one stop reading. © 2021 IEEE.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Ieracitano2021,
author={Ieracitano, C. and Mammone, N. and Hussain, A. and Morabito, F.C.},
title={A novel explainable machine learning approach for EEG-based brain-computer interface systems},
journal={Neural Computing and Applications},
year={2021},
doi={10.1007/s00521-020-05624-w},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102240913&doi=10.1007%2fs00521-020-05624-w&partnerID=40&md5=814cfb70c9b64a81fa84e9c796caa114},
abstract={Electroencephalographic (EEG) recordings can be of great help in decoding the open/close hand’s motion preparation. To this end, cortical EEG source signals in the motor cortex (evaluated in the 1-s window preceding movement onset) are extracted by solving inverse problem through beamforming. EEG sources epochs are used as source-time maps input to a custom deep convolutional neural network (CNN) that is trained to perform 2-ways classification tasks: pre-hand close (HC) versus resting state (RE) and pre-hand open (HO) versus RE. The developed deep CNN works well (accuracy rates up to 89.65 ± 5.29 % for HC versus RE and 90.50 ± 5.35 % for HO versus RE), but the core of the present study was to explore the interpretability of the deep CNN to provide further insights into the activation mechanism of cortical sources during the preparation of hands’ sub-movements. Specifically, occlusion sensitivity analysis was carried out to investigate which cortical areas are more relevant in the classification procedure. Experimental results show a recurrent trend of spatial cortical activation across subjects. In particular, the central region (close to the longitudinal fissure) and the right temporal zone of the premotor together with the primary motor cortex appear to be primarily involved. Such findings encourage an in-depth study of cortical areas that seem to play a key role in hand’s open/close preparation. © 2021, The Author(s), under exclusive licence to Springer-Verlag London Ltd. part of Springer Nature.},
document_type={Article},
source={Scopus},
}

@ARTICLE{AsgariTaghanaki2021137,
author={Asgari Taghanaki, S. and Abhishek, K. and Cohen, J.P. and Cohen-Adad, J. and Hamarneh, G.},
title={Deep semantic segmentation of natural and medical images: a review},
journal={Artificial Intelligence Review},
year={2021},
volume={54},
number={1},
pages={137-178},
doi={10.1007/s10462-020-09854-1},
note={cited By 10},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086426579&doi=10.1007%2fs10462-020-09854-1&partnerID=40&md5=cbc6198261503a1ce7e3dcae7ec32ae8},
abstract={The semantic image segmentation task consists of classifying each pixel of an image into an instance, where each instance corresponds to a class. This task is a part of the concept of scene understanding or better explaining the global context of an image. In the medical image analysis domain, image segmentation can be used for image-guided interventions, radiotherapy, or improved radiological diagnostics. In this review, we categorize the leading deep learning-based medical and non-medical image segmentation solutions into six main groups of deep architectural, data synthesis-based, loss function-based, sequenced models, weakly supervised, and multi-task methods and provide a comprehensive review of the contributions in each of these groups. Further, for each group, we analyze each variant of these groups and discuss the limitations of the current approaches and present potential future research directions for semantic image segmentation. © 2020, Springer Nature B.V.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Toğaçar2021,
author={Toğaçar, M. and Cömert, Z. and Ergen, B.},
title={Enhancing of dataset using DeepDream, fuzzy color image enhancement and hypercolumn techniques to detection of the Alzheimer's disease stages by deep learning model},
journal={Neural Computing and Applications},
year={2021},
doi={10.1007/s00521-021-05758-5},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101064034&doi=10.1007%2fs00521-021-05758-5&partnerID=40&md5=92518bf8fb570451ea3a1f7cb1742475},
abstract={Alzheimer's disease (AD), which occurs as a result of the loss of cognitive functions in the brain, causes near-forgetfulness in the case and dementia in subsequent processes. Dataset consists of MR images containing four phases of AD. The dataset was re-enhanced separately with DeepDream, fuzzy color image enhancement, hypercolumn techniques. Visual Geometry Group-16 (VGG-16) deep learning model is used in the enhancing process and deep features are combined. Linear Regression is used for the selection of efficient features. The Support Vector Machine is preferred as a classifier. With the proposed approach, the classification achievement was obtained as 100% in Mild Dementia, 99.94% in Moderate Dementia, 100% in non-Dementia, 99.94% in Very Mild Dementia. The overall accuracy was 99.94%. The proposed approach increased the prediction success in detecting Alzheimer's stages by re-enhancing MR images. Thus, an efficient early diagnosis model was realized at an affordable cost for individuals likely to progress with dementia. © 2021, The Author(s), under exclusive licence to Springer-Verlag London Ltd. part of Springer Nature.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Al-Saegh2021,
author={Al-Saegh, A. and Dawwd, S.A. and Abdul-Jabbar, J.M.},
title={Deep learning for motor imagery EEG-based classification: A review},
journal={Biomedical Signal Processing and Control},
year={2021},
volume={63},
doi={10.1016/j.bspc.2020.102172},
art_number={102172},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092148803&doi=10.1016%2fj.bspc.2020.102172&partnerID=40&md5=47b040a01ad4fd164c1a2df282720a1c},
abstract={Objectives: The availability of large and varied Electroencephalogram (EEG) datasets, rapidly advances and inventions in deep learning techniques, and highly powerful and diversified computing systems have all permitted to easily analyzing those datasets and discovering vital information within. However, the classification process of EEG signals and discovering vital information should be robust, automatic, and with high accuracy. Motor Imagery (MI) EEG has attracted us due to its significant applications in daily life. Methods: This paper attempts to achieve those goals throughout a systematic review of the state-of-the-art studies within this field of research. The process began by intensely surfing the well-known specialized digital libraries and, as a result, 40 related papers were gathered. The papers were scrutinized upon multiple noteworthy technical issues, among them deep neural network architecture, input formulation, number of MI EEG tasks, and frequency range of interest. Outcomes: Deep neural networks build robust and automated systems for the classification of MI EEG recordings by exploiting the whole input data throughout learning salient features. Specifically, convolutional neural networks (CNN) and hybrid-CNN (h-CNN) are the dominant architectures with high performance in comparison to public datasets with other types of architectures. The MI related datasets, input formulation, frequency ranges, and preprocessing and regularization methods were also reviewed. Inferences: This review gives the required preliminaries in developing MI EEG-based BCI systems. The review process of the published articles in the last five years aims to help in choosing the appropriate deep neural network architecture and other hyperparameters for developing those systems. © 2020 Elsevier Ltd},
document_type={Review},
source={Scopus},
}

@ARTICLE{Alshwaheen20213894,
author={Alshwaheen, T.I. and Hau, Y.W. and Ass'Ad, N. and Abualsamen, M.M.},
title={A Novel and Reliable Framework of Patient Deterioration Prediction in Intensive Care Unit Based on Long Short-Term Memory-Recurrent Neural Network},
journal={IEEE Access},
year={2021},
volume={9},
pages={3894-3918},
doi={10.1109/ACCESS.2020.3047186},
art_number={9306748},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098801643&doi=10.1109%2fACCESS.2020.3047186&partnerID=40&md5=8bc14fceda4cfcecbfd8aee791eff4c7},
abstract={The clinical investigation explored that early recognition and intervention are crucial for preventing clinical deterioration in patients in Intensive Care units (ICUs). Deterioration of patients is predictable and can be preventable if early risk factors are recognized and developed in the clinical setting. Timely detection of deterioration in ICU patients may also lead to better health management. In this paper, a new model was proposed based on Long Short-Term Memory-Recurrent Neural Network (LSTM-RNN) to predict deterioration of ICU patients. An optimisation model based on a modified genetic algorithm (GA) has also been proposed in this study to optimize the observation window, prediction window, and the number of neurons in hidden layers to increase accuracy, AUROC, and minimize test loss. The experimental results demonstrate that the prediction model proposed in this study acquired a significantly better classification performance compared with many other studies that used deep learning models in their works. Our proposed model was evaluated for two tasks: mortality and sudden transfer of patients to ICU. Our results show that the proposed model could predict deterioration before one hour of onset and outperforms other models. In this study, the proposed predictive model is implemented using the state-of-the-art graphical processing unit (GPU) virtual machine provided by Google Colaboratory. Moreover, the study uses a novel time-series approach, which is minute-by-minute. This novel approach enables the proposed model to obtain highly accurate results (i.e., an AUROC of 0.933 and an accuracy of 0.921). This study utilizes the individual and combined effectiveness of different types of variables (i.e., vital signs, laboratory measurements, GCS, and demographic data). In this study, data was extracted from MIMIC-III database. The ad-hoc frameworks proposed by previous studies can be improved by the novel and reliable prediction framework proposed in this research, which will result in predictions of more accurate performance. The proposed predictive model could reduce the required observation window (i.e., a reduction of 83%) for the prediction task while improving the performance. In fact, the proposed significant small size of observation window could obtain higher results which outperformed all previous works that utilize different sizes of observation window (i.e., 48 hours and 24 hours). Moreover, this research demonstrates the ability of the proposed predictive model to achieve accurate results (>80%) on 'raw' data in an experimental work. This shows that the rule-based pre-processing of clinical features is unnecessary for deep learning predictive models. © 2013 IEEE.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Assam202133313,
author={Assam, M. and Kanwal, H. and Farooq, U. and Shah, S.K. and Mehmood, A. and Choi, G.S.},
title={An Efficient Classification of MRI Brain Images},
journal={IEEE Access},
year={2021},
volume={9},
pages={33313-33322},
doi={10.1109/ACCESS.2021.3061487},
art_number={9360738},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101757812&doi=10.1109%2fACCESS.2021.3061487&partnerID=40&md5=66826c54c4950442ef2f70835ad0f005},
abstract={The unprecedented improvements in computing capabilities and the introduction of advanced techniques for the analysis, interpretation, processing, and visualization of images have greatly diversified the domain of medical sciences and resulted in the field of medical imaging. The Magnetic Resonance Imaging (MRI), an advanced imaging technique, is capable of producing high quality images of the human body including the brain for diagnosis purposes. This paper proposes a simple but efficient solution for the classification of MRI brain images into normal, and abnormal images containing disorders and injuries. It uses images with brain tumor, acute stroke and alzheimer, besides normal images, from the public dataset developed by harvard medical school, for evaluation purposes. The proposed model is a four step process, in which the steps are named: 1). Pre-processing, 2). Features Extraction, 3). Features Reduction, and 4). Classification. Median filter, being one of the best algorithms, is used for the removal of noise such as salt and pepper, and unwanted components such as scalp and skull, in the pre-processing step. During this stage, the images are converted from gray scale to colored images for further processing. In second step, it uses Discrete Wavelet Transform (DWT) technique to extract different features from the images. In third stage, Color Moments (CMs) are used to reduce the number of features and get an optimal set of characteristics. Images with the optimal set of features are passed to different classifiers for the classification of images. The Feed Forward - ANN (FF-ANN), an individual classifier, which was given a 65% to 35% split ratio for training and testing, and hybrid classifiers called: Random Subspace with Random Forest (RSwithRF) and Random Subspace with Bayesian Network (RSwithBN), which used 10-Fold cross validation technique, resulted in 95.83%, 97.14% and 95.71% accurate classification, in corresponding order. These promising results show that the proposed method is robust and efficient, in comparison with, existing classification methods in terms of accuracy with smaller number of optimal features. © 2013 IEEE.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Mahmud2021,
author={Mahmud, M. and Kaiser, M.S. and McGinnity, T.M. and Hussain, A.},
title={Deep Learning in Mining Biological Data},
journal={Cognitive Computation},
year={2021},
volume={13},
number={1},
doi={10.1007/s12559-020-09773-x},
note={cited By 8},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097659677&doi=10.1007%2fs12559-020-09773-x&partnerID=40&md5=c809dd686f687664939490894fc3d887},
abstract={Recent technological advancements in data acquisition tools allowed life scientists to acquire multimodal data from different biological application domains. Categorized in three broad types (i.e. images, signals, and sequences), these data are huge in amount and complex in nature. Mining such enormous amount of data for pattern recognition is a big challenge and requires sophisticated data-intensive machine learning techniques. Artificial neural network-based learning systems are well known for their pattern recognition capabilities, and lately their deep architectures—known as deep learning (DL)—have been successfully applied to solve many complex pattern recognition problems. To investigate how DL—especially its different architectures—has contributed and been utilized in the mining of biological data pertaining to those three types, a meta-analysis has been performed and the resulting resources have been critically analysed. Focusing on the use of DL to analyse patterns in data from diverse biological domains, this work investigates different DL architectures’ applications to these data. This is followed by an exploration of available open access data sources pertaining to the three data types along with popular open-source DL tools applicable to these data. Also, comparative investigations of these tools from qualitative, quantitative, and benchmarking perspectives are provided. Finally, some open research challenges in using DL to mine biological data are outlined and a number of possible future perspectives are put forward. © 2020, The Author(s).},
document_type={Review},
source={Scopus},
}

@ARTICLE{Khan202137622,
author={Khan, P. and Kader, M.F. and Islam, S.M.R. and Rahman, A.B. and Kamal, M.S. and Toha, M.U. and Kwak, K.-S.},
title={Machine Learning and Deep Learning Approaches for Brain Disease Diagnosis: Principles and Recent Advances},
journal={IEEE Access},
year={2021},
volume={9},
pages={37622-37655},
doi={10.1109/ACCESS.2021.3062484},
art_number={9363896},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101861719&doi=10.1109%2fACCESS.2021.3062484&partnerID=40&md5=62ac4366bdbdbefd8768a65aacee2198},
abstract={Brain is the controlling center of our body. With the advent of time, newer and newer brain diseases are being discovered. Thus, because of the variability of brain diseases, existing diagnosis or detection systems are becoming challenging and are still an open problem for research. Detection of brain diseases at an early stage can make a huge difference in attempting to cure them. In recent years, the use of artificial intelligence (AI) is surging through all spheres of science, and no doubt, it is revolutionizing the field of neurology. Application of AI in medical science has made brain disease prediction and detection more accurate and precise. In this study, we present a review on recent machine learning and deep learning approaches in detecting four brain diseases such as Alzheimer's disease (AD), brain tumor, epilepsy, and Parkinson's disease. 147 recent articles on four brain diseases are reviewed considering diverse machine learning and deep learning approaches, modalities, datasets etc. Twenty-two datasets are discussed which are used most frequently in the reviewed articles as a primary source of brain disease data. Moreover, a brief overview of different feature extraction techniques that are used in diagnosing brain diseases is provided. Finally, key findings from the reviewed articles are summarized and a number of major issues related to machine learning/deep learning-based brain disease diagnostic approaches are discussed. Through this study, we aim at finding the most accurate technique for detecting different brain diseases which can be employed for future betterment. © 2013 IEEE.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Munir2021189,
author={Munir, K. and Frezza, F. and Rizzi, A.},
title={Deep learning for brain tumor segmentation},
journal={Studies in Computational Intelligence},
year={2021},
volume={908},
pages={189-201},
doi={10.1007/978-981-15-6321-8_11},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090878367&doi=10.1007%2f978-981-15-6321-8_11&partnerID=40&md5=fca32ceed0a50dc34f3e9bfb20d87207},
abstract={Brain tumors are considered to be one of the most lethal types of tumor. Accurate segmentation of brain MRI is an important task for the analysis of neurological diseases. The mortality rate of brain tumors is increasing according to World Health Organization. Detection at early stages of brain tumors can increase the expectation of the patients’ survival. Concerning artificial intelligence approaches for clinical diagnosis of brain tumors, there is an increasing interest in segmentation approaches based on deep learning because of its ability of self-learning over large amounts of data. Deep learning is nowadays a very promising approach to develop effective solution for clinical diagnosis. This chapter provides at first some basic concepts and techniques behind brain tumor segmentation. Then the imaging techniques used for brain tumor visualization are described. Later on, the dataset and segmentation methods are discussed. © The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd 2021.},
document_type={Book Chapter},
source={Scopus},
}

@ARTICLE{Gibson2021155,
author={Gibson, M. and Percival, B. and Grootveld, M. and Woodason, K. and Leenders, J. and Nwosu, K. and Kamerlin, S.C.L. and Wilson, P.B.},
title={Chapter 5: Applications of Computational Intelligence Techniques in Chemical and Biochemical Analysis},
journal={RSC Theoretical and Computational Chemistry Series},
year={2021},
volume={2021-January},
number={20},
pages={155-201},
doi={10.1039/9781788015882-00155},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098624746&doi=10.1039%2f9781788015882-00155&partnerID=40&md5=d3eb216fab784bda1c62c6b74e099e69},
abstract={This chapter provides an overview of AI methods as applied to selected areas of analytical chemistry and bioanalysis. We first present a brief historical perspective prior to discussing the applications of ML in chemistry, developing this to neural networks, swarm optimisation methods and additional data treatment and analysis methodologies. We present component analysis techniques and random forest with examples from the literature and offer a perspective on the future of such applications, with advances in computing power and quantum computing methodologies. © The Royal Society of Chemistry 2021.},
document_type={Book Chapter},
source={Scopus},
}

@ARTICLE{Chen2021,
author={Chen, X. and Tao, X. and Wang, F.L. and Xie, H.},
title={Global research on artificial intelligence-enhanced human electroencephalogram analysis},
journal={Neural Computing and Applications},
year={2021},
doi={10.1007/s00521-020-05588-x},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099104931&doi=10.1007%2fs00521-020-05588-x&partnerID=40&md5=b0e0d69b5f95cc828be585dfa6845096},
abstract={The application of artificial intelligence (AI) technologies in assisting human electroencephalogram (EEG) analysis has become an active scientific field. This study aims to present a comprehensive review of the research field of AI-enhanced human EEG analysis. Using bibliometrics and topic modeling, research articles concerning AI-enhanced human EEG analysis collected from the Web of Science database during the period 2009–2018 were analyzed. After examining 2053 research articles published around the world, it was found that the annual number of articles had significantly grown from 78 to 468, with the USA and China being the most influential and prolific. The results of the keyword analysis showed that “electroencephalogram,” “brain–computer interface,” “classification,” “support vector machine,” “electroencephalography,” and “signal” were the most frequently used. The results of topic modeling and evolution analyses highlighted several important issues, including epileptic seizure detection, brain–machine interface, EEG classification, mental disorders, emotion, and alcoholism and anesthesia. The findings suggest that such visualization and analysis of the research articles could provide a comprehensive overview of the field for communities of practice and inquiry worldwide. © 2021, The Author(s), under exclusive licence to Springer-Verlag London Ltd. part of Springer Nature.},
document_type={Review},
source={Scopus},
}

@ARTICLE{Okagbue202123,
author={Okagbue, H.I. and Oguntunde, P.E. and Obasi, E.C.M. and Adamu, P.I. and Opanuga, A.A.},
title={Diagnosing malaria from some symptoms: a machine learning approach and public health implications},
journal={Health and Technology},
year={2021},
volume={11},
number={1},
pages={23-37},
doi={10.1007/s12553-020-00488-5},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093970107&doi=10.1007%2fs12553-020-00488-5&partnerID=40&md5=91de6b6fe0a099216df709cc8732f59a},
abstract={Malaria is a leading cause of death in Nigeria and remains a public health concern because of the increasing resistance of the disease to antimalarial drugs. Pregnant women and children under five years of age are the most vulnerable. Efforts to eradicate malaria is often frustrated due to some various sociodemographic factors and medical factors. One of the vital therapeutic factors is misdiagnosis. Hence, the paper applied different data mining models to diagnose malaria using fifteen symptoms of patients that attended a hospital in Nigeria. The data were obtained from a peer reviewed data article that comprises 337 subjects at Federal Polytechnic Ilaro Medical Centre, Ogun State. The independent variables are 15 symptoms, age, and sex, while the target or dependent is the outcome. The outcome is the result of the diagnosis, which is positive for negative for malaria. Eight machine learning tools were applied to the data on the Orange Software platform. Weak non-significant correlations were obtained between the 15 symptoms and the outcome, and hence no pattern was observed. However, the application of data mining tools revealed a hidden pattern that correctly predicted the outcome using the subjects' symptoms, age, and sex. 6 out of the 8 machine learning models were adjudged to perform well using different performance metrics. The Adaptive boosting model gave a percent 100% precision in the classification, and logistic regression was the least. Furthermore, a percent performance of Adaboost implies that the model correctly predicted all the 221 true negatives and 116 true positives with a misclassification (misdiagnosis) of zero. Classify using only the 15 symptoms reduced the predictive accuracy of the 6 models. Nevertheless, Adaboost performance was the best with a classification accuracy of 98.2%, precision of 96.6%, and an error rate of just 1.8%. Again, logistic regression performance was the least. The present work has presented a strong relationship between age and sex and the outcome. Adaboost model can be used to design decision support systems or rapid diagnostic tools that utilise the internet or mobile devices as platforms in the diagnosis of malaria. The application of the present work as potentials in reduction of misdiagnosis incidences, reducing the mortality due to malaria and improving the overall public health of people residing in malaria endemic areas. © 2020, IUPESM and Springer-Verlag GmbH Germany, part of Springer Nature.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Chicco20211,
author={Chicco, D. and Tötsch, N. and Jurman, G.},
title={The matthews correlation coefficient (Mcc) is more reliable than balanced accuracy, bookmaker informedness, and markedness in two-class confusion matrix evaluation},
journal={BioData Mining},
year={2021},
volume={14},
pages={1-22},
doi={10.1186/s13040-021-00244-z},
art_number={13},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102146890&doi=10.1186%2fs13040-021-00244-z&partnerID=40&md5=95c57c3cc7325a2a739e119c960b495e},
abstract={Evaluating binary classifications is a pivotal task in statistics and machine learning, because it can influence decisions in multiple areas, including for example prognosis or therapies of patients in critical conditions. The scientific community has not agreed on a general-purpose statistical indicator for evaluating two-class confusion matrices (having true positives, true negatives, false positives, and false negatives) yet, even if advantages of the Matthews correlation coefficient (MCC) over accuracy and F1 score have already been shown. In this manuscript, we reaffirm that MCC is a robust metric that summarizes the classifier performance in a single value, if positive and negative cases are of equal importance. We compare MCC to other metrics which value positive and negative cases equally: balanced accuracy (BA), bookmaker informedness (BM), and markedness (MK). We explain the mathematical relationships between MCC and these indicators, then show some use cases and a bioinformatics scenario where these metrics disagree and where MCC generates a more informative response. Additionally, we describe three exceptions where BM can be more appropriate: analyzing classifications where dataset prevalence is unrepresentative, comparing classifiers on different datasets, and assessing the random guessing level of a classifier. Except in these cases, we believe that MCC is the most informative among the single metrics discussed, and suggest it as standard measure for scientists of all fields. A Matthews correlation coefficient close to +1, in fact, means having high values for all the other confusion matrix metrics. The same cannot be said for balanced accuracy, markedness, bookmaker informedness, accuracy and F1 score. © The Author(s).},
document_type={Article},
source={Scopus},
}

@ARTICLE{Shi20219557,
author={Shi, Z. and Chu, Y. and Zhang, Y. and Wang, Y. and Wei, D.-Q.},
title={Prediction of blood-brain barrier permeability of compounds by fusing resampling strategies and extreme gradient boosting},
journal={IEEE Access},
year={2021},
volume={9},
pages={9557-9566},
doi={10.1109/ACCESS.2020.3047852},
art_number={9309292},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099099174&doi=10.1109%2fACCESS.2020.3047852&partnerID=40&md5=3aea092dc1ba6c71f24b12717008b095},
abstract={Computer-aided drug design is an efficient method to analyze the development of disease-related drugs. However, developed as binding targets, medicines perform well in cell models and animal models but fail in human models. One main reason for this failure is that the human body has natural barriers, such as the blood-brain barrier, to block exogenous macromolecules. Thus, efficient and accurate predictions of drug molecules that can effectively pass the blood-brain barrier is necessary in developing drug treatments for brain tissue diseases. In this study, 7658 molecular structure features were extracted from 2354 drug molecule SMILE strings using computational methods. By integrating three feature selection algorithms of machine learning, 33 chemical structure features with significantly discriminant performance were screened out and used to construct multiple discriminant models. After a comprehensive comparison, the XGBoost model was selected as the final prediction model. After data preprocessing and parameter optimization, the model achieved 95% accuracy on the training set. To verify the model's stability, we introduced an external data set, which reached 96% accuracy of the model. This study applies new resampling methods and machine learning algorithms, and adjusts the application of resampling methods to obtain new chemical features to construct machine learning predictors. The features may contribute to the significant drug development that integrates biological analysis and machine learning algorithms. © 2013 IEEE.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Dogan20211085,
author={Dogan, S. and Tuncer, T.},
title={A novel statistical decimal pattern-based surface electromyogram signal classification method using tunable q-factor wavelet transform},
journal={Soft Computing},
year={2021},
volume={25},
number={2},
pages={1085-1098},
doi={10.1007/s00500-020-05205-y},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088801246&doi=10.1007%2fs00500-020-05205-y&partnerID=40&md5=8b38dda591576fa5c57b8f0d9d5292ac},
abstract={Surface electromyogram sensors have been widely used to acquire hand gestures signals. Many machine learning and artificial intelligence methods have been presented for automated surface electromyogram signals classification. In this method, a novel surface electromyogram signals recognition method is presented using a novel 1D local descriptor. The proposed descriptor is called as statistical decimal pattern and it is utilized as feature extractor in this study and tunable q-factor wavelet transform is used as pooling in this method. By using tunable q-factor wavelet transform and the proposed statistical decimal pattern, a multileveled learning method is constructed. Ten levels are created by using tunable q-factor wavelet transform. Statistical decimal pattern extracts features from tunable q-factor wavelet transform sub-bands of the raw surface electromyogram signal. Then, the generated features are concatenated, and to select distinctive features, ReliefF and neighborhood component analysis are used together. In the classification phase, k-nearest neighbor classifier with city block distance is chosen. To test performance of the proposed tunable q-factor wavelet transform and the proposed statistical decimal pattern-based surface electromyogram classification method, a freely and publicly published dataset was used. In this dataset, 10 hand gestures were defined. Experimental results clearly shown that the proposed tunable q wavelet transform and statistical decimal pattern-based method achieved 98.0%, 99.79% accuracy rates on two datasets and it outcomes other state-of-the-art methods according to these results. © 2020, Springer-Verlag GmbH Germany, part of Springer Nature.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Albahri2021,
author={Albahri, A.S. and Alwan, J.K. and Taha, Z.K. and Ismail, S.F. and Hamid, R.A. and Zaidan, A.A. and Albahri, O.S. and Zaidan, B.B. and Alamoodi, A.H. and Alsalem, M.A.},
title={IoT-based telemedicine for disease prevention and health promotion: State-of-the-Art},
journal={Journal of Network and Computer Applications},
year={2021},
volume={173},
doi={10.1016/j.jnca.2020.102873},
art_number={102873},
note={cited By 8},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094315932&doi=10.1016%2fj.jnca.2020.102873&partnerID=40&md5=1c18c0292a9c97eea1d607b2f54c4cb4},
abstract={Numerous studies have focused on making telemedicine smart through the Internet of Things (IoT) technology. These works span a wide range of research areas to enhance telemedicine architecture such as network communications, artificial intelligence methods and techniques, IoT wearable sensors and hardware devices, smartphones and cloud computing. Accordingly, several telemedicine applications covering various human diseases have presented their works from a specific perspective and resulted in confusion regarding the IoT characteristics. Although such applications are useful and necessary for improving telemedicine contexts related to monitoring, detection and diagnostics, deriving an overall picture of how IoT characteristics are currently integrated with the telemedicine architecture is difficult. Accordingly, this study complements the academic literature with a systematic review covering all main aspects of advances in IoT-based telemedicine architecture. This study also provides a state-of-the-art telemedicine classification taxonomy under IoT and reviews works in different fields in relation to that classification. To this end, this study checked the ScienceDirect, Institute of Electrical and Electronics Engineers (IEEE) Xplore, and Web of Science databases. A total of 2121 papers were collected from 2014 to July 2020. The retrieved articles were filtered according to the defined inclusion criteria. A final set of 141 articles were selected and classified into two categories, each followed by subcategories and sections. The first category includes an IoT-based telemedicine network that accounts for 24.11% (n = 34/141). The second category includes IoT-based telemedicine healthcare services and applications that account for 75.89% (n = 107/141). This multi-field systematic review has exposed new research opportunities, motivations, recommendations and challenges that need attention for the synergistic integration of interdisciplinary works. This extensive study also lists a set of open issues and provides innovative key solutions along with a systematic review. The classification of diseases under IoT-based telemedicine is divided into 14 groups. Furthermore, the crossover in our taxonomy is demonstrated. The lifecycle of the context of IoT-based telemedicine healthcare applications is mapped for the first time, including the procedure sequencing and definition for each context. We believe that this study is a useful guide for researchers and practitioners in providing direction and valuable information for future research. This study can also address the ambiguity in the trends in IoT-based telemedicine. © 2020 Elsevier Ltd},
document_type={Article},
source={Scopus},
}

@ARTICLE{McGlynn2021,
author={McGlynn, E. and Nabaei, V. and Ren, E. and Galeote-Checa, G. and Das, R. and Curia, G. and Heidari, H.},
title={The Future of Neuroscience: Flexible and Wireless Implantable Neural Electronics},
journal={Advanced Science},
year={2021},
doi={10.1002/advs.202002693},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102283800&doi=10.1002%2fadvs.202002693&partnerID=40&md5=f98102df98229efbb478a8ec605dde47},
abstract={Neurological diseases are a prevalent cause of global mortality and are of growing concern when considering an ageing global population. Traditional treatments are accompanied by serious side effects including repeated treatment sessions, invasive surgeries, or infections. For example, in the case of deep brain stimulation, large, stiff, and battery powered neural probes recruit thousands of neurons with each pulse, and can invoke a vigorous immune response. This paper presents challenges in engineering and neuroscience in developing miniaturized and biointegrated alternatives, in the form of microelectrode probes. Progress in design and topology of neural implants has shifted the goal post toward highly specific recording and stimulation, targeting small groups of neurons and reducing the foreign body response with biomimetic design principles. Implantable device design recommendations, fabrication techniques, and clinical evaluation of the impact flexible, integrated probes will have on the treatment of neurological disorders are provided in this report. The choice of biocompatible material dictates fabrication techniques as novel methods reduce the complexity of manufacture. Wireless power, the final hurdle to truly implantable neural interfaces, is discussed. These aspects are the driving force behind continued research: significant breakthroughs in any one of these areas will revolutionize the treatment of neurological disorders. © 2021 The Authors. Advanced Science published by Wiley-VCH GmbH},
document_type={Review},
source={Scopus},
}

@ARTICLE{Das202010897,
author={Das, S. and Tiwari, M. and Mondal, D. and Sahoo, B.R. and Tiwari, D.K., Phd},
title={Growing tool-kit of photosensitizers for clinical and non-clinical applications},
journal={Journal of Materials Chemistry B},
year={2020},
volume={8},
number={48},
pages={10897-10940},
doi={10.1039/d0tb02085k},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098573982&doi=10.1039%2fd0tb02085k&partnerID=40&md5=a964814fb29c99e21d5b2f3af79cf3a4},
abstract={Photosensitizers are photosensitive molecules utilized in clinical and non-clinical applications by taking advantage of light-mediated reactive oxygen generation, which triggers local and systemic cellular toxicity. Photosensitizers are used for diverse biological applications such as spatio-temporal inactivation of a protein in a living system by chromophore-assisted light inactivation, localized cell photoablation, photodynamic and immuno-photodynamic therapy, and correlative light-electron microscopy imaging. Substantial efforts have been made to develop several genetically encoded, chemically synthesized, and nanotechnologically driven photosensitizers for successful implementation in redox biology applications. Genetically encoded photosensitizers (GEPS) or reactive oxygen species (ROS) generating proteins have the advantage of using them in the living system since they can be manipulated by genetic engineering with a variety of target-specific genes for the precise spatio-temporal control of ROS generation. The GEPS variety is limited but is expanding with a variety of newly emerging GEPS proteins. Apart from GEPS, a large variety of chemically- and nanotechnologically-empowered photosensitizers have been developed with a major focus on photodynamic therapy-based cancer treatment alone or in combination with pre-existing treatment methods. Recently, immuno-photodynamic therapy has emerged as an effective cancer treatment method using smartly designed photosensitizers to initiate and engage the patient's immune system so as to empower the photosensitizing effect. In this review, we have discussed various types of photosensitizers, their clinical and non-clinical applications, and implementation toward intelligent efficacy, ROS efficiency, and target specificity in biological systems. © The Royal Society of Chemistry.},
document_type={Review},
source={Scopus},
}

@ARTICLE{Yıldırım2020,
author={Yıldırım, M.S. and Dandıl, E.},
title={Automatic detection of multiple sclerosis lesions using mask R-CNN on magnetic resonance scans},
journal={IET Image Processing},
year={2020},
volume={14},
number={16},
page_count={14},
doi={10.1049/iet-ipr.2020.1128},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102735681&doi=10.1049%2fiet-ipr.2020.1128&partnerID=40&md5=984e4654480974c2de9cd9648d3a465b},
abstract={Multiple Sclerosis (MS) causes the central nervous system to malfunction due to inflammation surrounding nerve cells. Detection of MS at an early stage is very important to prevent progressive MS attacks. Clinical findings, cerebrospinal fluid examinations, the evoked potentials, magnetic resonance imaging (MRI) findings have an important role in the diagnosis and follow-up of MS. However, many of the findings on MRI may indicate brain disorders other than MS. In addition, the clinical practices accepted by physicians for MS detection are very limited. In this study, a Mask R-CNN based method in two dataset is proposed for the automatic detection of MS lesions on magnetic resonance scans.We also improved the ROI detection stage with RPN in the Mask R-CNN to easily adapt for different lesion sizes. MS lesions in different sizes in the dataset are successfully detected with 84.90% Dice similarity rate and 87.03% precision rates using the proposed method. In addition, volumetric overlap error and lesion-wise true positive rate are obtained as 12.97% and 73.75%, respectively. Moreover, performance tests of the use of different numbers of GPU hardware structures are also performed and the evaluation of its effects on processing speed is performed on experimental studies. © The Institution of Engineering and Technology 2020.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Khachnaoui2020,
author={Khachnaoui, H. and Mabrouk, R. and Khlifa, N.},
title={Machine learning and deep learning for clinical data and PET/SPECT imaging in parkinson’s disease: A review},
journal={IET Image Processing},
year={2020},
volume={14},
number={16},
page_count={9},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102770101&partnerID=40&md5=d415fde9634ee16db024c6f8f1a36810},
abstract={Machine Learning (ML) is a subfield of Artificial Intelligence (AI) that is increasingly applied to several medical diagnosis tasks, including a wide range of diseases. Importantly, various ML models were developed to address the complexity of Parkinson’s Disease (PD) diagnosis. PD is a neurodegenerative disease characterized by motor and non-motor disorders where its syndromes affect the daily lives of patients. Several Computer Aided Diagnosis and Detection (CADD) systems based on hand-crafted ML algorithms achieved promising results in distinguishing PD patients from Healthy Control (HC) subjects and other Parkinsonian syndrome categories using clinical data (e.g., speech and gait impairments) and medical imaging [e.g., Position Emission Tomography (PET) and Single Photon Emission Computed Tomography (SPECT)]. Despite the good performance of hand-crafted ML algorithms, there is still a problem linked to the features’ extraction and selection. In fact, Deep Learning DL has provided an ultimate solution for the features’ extraction and selection related issue. An important number of studies on the diagnosis of PD using DL algorithms were developed recently. This study provides an overview of the application of hand-crafted ML algorithms and DL techniques for PD diagnosis. It also introduces key concepts for understanding the application of ML methods to diagnose PD. © The Institution of Engineering and Technology 2020.},
document_type={Review},
source={Scopus},
}

@CONFERENCE{Yao2020316,
author={Yao, X. and Cheong, H.-R.},
title={Hearing loss classification via stationary wavelet entropy and genetic algorithm},
journal={Proceedings - 2020 IEEE/ACM 13th International Conference on Utility and Cloud Computing, UCC 2020},
year={2020},
pages={316-321},
doi={10.1109/UCC48980.2020.00050},
art_number={9302779},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099558008&doi=10.1109%2fUCC48980.2020.00050&partnerID=40&md5=ece96d66713d240ef39c3944a79bf509},
abstract={The accompanying symptoms of hearing loss is slow and sensory, which makes detecting hearing loss of huge significance to the medical diagnosis and scientific research field. To improve the efficiency of hearing loss classification, we conducted a research on a dataset obtained from magnetic resonance imaging and presented a novel computer aided system based on stationary wavelet entropy, k-fold cross validation, single-hidden-layer feedforward neural network and genetic algorithm. Firstly, the features are extracted from each hearing loss image via stationary wavelet entropy. Then, we used the genetic algorithm to train the single-hidden-layer feedforward neural network. The system reaches an overall sensitivity of 89.89±2.50%, which means the model gives much better performance than manual interpretation. © 2020 IEEE.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Jalali2020271,
author={Jalali, V. and Kaur, D.},
title={A study of classification and feature extraction techniques for brain tumor detection},
journal={International Journal of Multimedia Information Retrieval},
year={2020},
volume={9},
number={4},
pages={271-290},
doi={10.1007/s13735-020-00199-7},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096015208&doi=10.1007%2fs13735-020-00199-7&partnerID=40&md5=f943dab67239951ce2a6b50071934882},
abstract={Medical imaging aids in the analysis of interior parts of the human body such as the functioning of the organs or tissues for early treatment of diseases. Many different types of medical imaging technologies exist, for example, X-ray radiography, magnetic resonance imaging, endoscopy, positron emission tomography, CT scan (computed tomography), and many more. A tumor is an abnormal tissue in the brain which causes damage to the functioning of the cell. Therefore, brain tumor detection is an incredibly tricky task. Manual detection of a tumor is quite risky as it involves the insertion of a needle in the brain. Thus, there is a need for automated brain tumor detection systems. The well-timed detection of the tumor can add to accurate treatment and can increase the survival rate of patients. From machine learning techniques, namely K-nearest neighbor, support vector machine, and more to soft computing techniques, namely artificial neural network, self-organizing map, and others hold a significant stand in detection and categorization of brain tumor. Various methods including deep learning-based classifiers such as convolutional neural network, recurrent neural network, deep belief network (DBN), and others are used to make it easier to detect the tumor. Hybrid classifiers were also used for classification systems such as combining the machine learning approach with soft computing. This study is to summarize and compare the work of various authors on automatic brain tumor detection using medical imaging. Based on the accuracy, specificity, and sensitivity parameters, the results of different techniques are analyzed and compared graphically. © 2020, Springer-Verlag London Ltd., part of Springer Nature.},
document_type={Review},
source={Scopus},
}

@ARTICLE{Maia20201,
author={Maia, M. and Pimentel, J.S. and Pereira, I.S. and Gondim, J. and Barreto, M.E. and Ara, A.},
title={Convolutional support vector models: Prediction of coronavirus disease using chest x-rays},
journal={Information (Switzerland)},
year={2020},
volume={11},
number={12},
pages={1-19},
doi={10.3390/info11120548},
art_number={548},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096635816&doi=10.3390%2finfo11120548&partnerID=40&md5=d743bad999fffc8bb7d83806f1c936fe},
abstract={The disease caused by the new coronavirus (COVID-19) has been plaguing the world for months and the number of cases are growing more rapidly as the days go by. Therefore, finding a way to identify who has the causative virus is impressive, in order to find a way to stop its proliferation. In this paper, a complete and applied study of convolutional support machines will be presented to classify patients infected with COVID-19 using X-ray data and comparing them with traditional convolutional neural network (CNN). Based on the fitted models, it was possible to observe that the convolutional support vector machine with the polynomial kernel (CSVMPol ) has a better predictive performance. In addition to the results obtained based on real images, the behavior of the models studied was observed through simulated images, where it was possible to observe the advantages of support vector machine (SVM) models. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Wang20205637,
author={Wang, Z. and Wang, E. and Zhu, Y.},
title={Image segmentation evaluation: a survey of methods},
journal={Artificial Intelligence Review},
year={2020},
volume={53},
number={8},
pages={5637-5674},
doi={10.1007/s10462-020-09830-9},
note={cited By 6},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083895840&doi=10.1007%2fs10462-020-09830-9&partnerID=40&md5=4294c1fcee047fefcee1f7ba716e0aed},
abstract={Image segmentation is a prerequisite for image processing. There are many methods for image segmentation, and as a result, a great number of methods for evaluating segmentation results have also been proposed. How to effectively evaluate the quality of image segmentation is very important. In this paper, the existing image segmentation quality evaluation methods are summarized, mainly including unsupervised methods and supervised methods. Based on hot issues, the application of metrics in natural, medical and remote sensing image evaluation is further outlined. In addition, an experimental comparison for some methods were carried out and the effectiveness of these methods was ranked. At the same time, the effectiveness of classical metrics for remote sensing and medical image evaluation is also verified. © 2020, Springer Nature B.V.},
document_type={Article},
source={Scopus},
}

@ARTICLE{MinhDang2020,
author={Minh Dang, L. and Min, K. and Wang, H. and Jalil Piran, M. and Hee Lee, C. and Moon, H.},
title={Sensor-based and vision-based human activity recognition: A comprehensive survey},
journal={Pattern Recognition},
year={2020},
volume={108},
doi={10.1016/j.patcog.2020.107561},
art_number={107561},
note={cited By 15},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088636839&doi=10.1016%2fj.patcog.2020.107561&partnerID=40&md5=ac494dd006c1addcceb4376413c6356a},
abstract={Human activity recognition (HAR) technology that analyzes data acquired from various types of sensing devices, including vision sensors and embedded sensors, has motivated the development of various context-aware applications in emerging domains, e.g., the Internet of Things (IoT) and healthcare. Even though a considerable number of HAR surveys and review articles have been conducted previously, the major/overall HAR subject has been ignored, and these studies only focus on particular HAR topics. Therefore, a comprehensive review paper that covers major subjects in HAR is imperative. This survey analyzes the latest state-of-the-art research in HAR in recent years, introduces a classification of HAR methodologies, and shows advantages and weaknesses for methods in each category. Specifically, HAR methods are classified into two main groups, which are sensor-based HAR and vision-based HAR, based on the generated data type. After that, each group is divided into subgroups that perform different procedures, including the data collection, pre-processing methods, feature engineering, and the training process. Moreover, an extensive review regarding the utilization of deep learning in HAR is also conducted. Finally, this paper discusses various challenges in the current HAR topic and offers suggestions for future research. © 2020 Elsevier Ltd},
document_type={Article},
source={Scopus},
}

@ARTICLE{Rashid2020,
author={Rashid, M. and Singh, H. and Goyal, V.},
title={The use of machine learning and deep learning algorithms in functional magnetic resonance imaging—A systematic review},
journal={Expert Systems},
year={2020},
volume={37},
number={6},
doi={10.1111/exsy.12644},
art_number={e12644},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092555310&doi=10.1111%2fexsy.12644&partnerID=40&md5=922109b8cb2aa3a8cf0e9d12d32318b9},
abstract={Functional Magnetic Resonance Imaging (fMRI) is presently one of the most popular techniques for analysing the dynamic states in brain images using various kinds of algorithms. From the last decade, there is an exponential rise in the use of the machine and deep learning algorithms of artificial intelligence for analysing fMRI data. However, it is a big challenge for every researcher to choose a suitable machine or deep learning algorithm for analysing fMRI data due to the availability of a large number of algorithms in the literature. It takes much time for each researcher to know about the various approaches and algorithms which are in use for fMRI data. This paper provides a review in a systematic manner for the present literature of fMRI data that makes use of the machine and deep learning algorithms. The major goals of this review paper are to (a) identify machine learning and deep learning research trends for the implementation of fMRI; (b) identify usage of Machine Learning Algorithms and deep learning in fMRI, and (c) help new researchers based on fMRI to put their new findings appropriately in existing domain of fMRI research. The results of this systematic review identified various fMRI studies and classified them based on fMRI types, mental diseases, use of machine learning and deep learning algorithms. The authors have provided the studies with the best performance of machine learning and deep learning algorithms used in fMRI. The authors believe that this systematic review will help incoming researchers on fMRI in their future works. © 2020 John Wiley & Sons Ltd},
document_type={Review},
source={Scopus},
}

@ARTICLE{DiNicola2020149,
author={Di Nicola, V.},
title={Degenerative osteoarthritis a reversible chronic disease},
journal={Regenerative Therapy},
year={2020},
volume={15},
pages={149-160},
doi={10.1016/j.reth.2020.07.007},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089422761&doi=10.1016%2fj.reth.2020.07.007&partnerID=40&md5=c125f2ec991ba214cfd7412943e0b0c6},
abstract={Osteoarthritis (OA) is the most common chronic musculoskeletal disorder. It can affect any joint and is the most frequent single cause of disability in older adults. OA is a progressive degenerative disease involving the entire joint structure in a vicious circle that includes the capsule-bursa tissue inflammation, synovial fluid modifications, cartilage breakdown and erosions, osteochondral inflammatory damage leading to bone erosion and distortion. Research has identified the initial inflammatory-immunologic process that starts this vicious cycle leading to so-called early OA. Research has also identified the role played in the disease advancement by synoviocytes type A and B, chondrocytes, extracellular matrix, local immune-inflammatory mediators and proteases. This article investigates the joint-resident MSCs that play an essential local homeostatic role and regulate cell turn over and tissue repair. Resident MSCs establish and maintain a local regenerative microenvironment. The understanding of OA physiopathology clarifies the core mechanisms by which minimally invasive interventions might be able to halt and reverse the course of early stage OA. Interventions employing PRP, MSCs and exosomes are considered in this article. © 2020 The Japanese Society for Regenerative Medicine},
document_type={Review},
source={Scopus},
}

@CONFERENCE{Mishkhal2020,
author={Mishkhal, I. and Al-Kareem, S.A. and Saleh, H.H. and Alqayyar, A.},
title={Deep Learning with network of Wearable sensors for preventing the Risk of Falls for Older People},
journal={IOP Conference Series: Materials Science and Engineering},
year={2020},
volume={928},
number={3},
doi={10.1088/1757-899X/928/3/032050},
art_number={032050},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097173624&doi=10.1088%2f1757-899X%2f928%2f3%2f032050&partnerID=40&md5=354e1ea4f329bf5f7a24dfb47df2dc8a},
abstract={Activity recognition (AR) systems for older adults are common in residential health care including hospitals or nursing homes; therefore, numerous solutions and studies presented to improve the performance of the AR systems. Yet, delivering sufficiently robust AR systems from sensor data recorded is a challenging task. AR in a smart environment utilizes large amounts of sensor data to derive effective features from the data to track the activity daily living. This paper maximizes the performance of AR system from using the convolutional neural network (CNN). Here, it analyzes signals from the network sensors distributed in different places in two clinical rooms at the Elizabeth hospital, such as W2ISP and RFID sensors. The proposed approach recognized the daily activities that consider a key to falling cases for older adults at a hospital or a nursing health house. A deep activity CNNets is used to train the effective features of daily activities sensors data then used for recognizing the highest falling risk activities in testing data. This approach used existing data of fourteen healthy older volunteers (ten females and four males) and then compared to other proposed approaches that used the same dataset. The experimental results show that this approach is superior to others. It achieved (96.37±3.63%) in the first clinic room and (98.37±1.63%) in the second clinic room. As the result, this experiment concludes that deep learning methodology is effectively assessing fall risk based on wearable sensors. © 2020 Published under licence by IOP Publishing Ltd.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Jain2020,
author={Jain, A. and Khanna, B. and Dubey, R. and Agarwal, S.},
title={A Comprehensive Study of Artificial Intelligence-based Medical Diagnosis},
journal={2020 IEEE International Conference for Innovation in Technology, INOCON 2020},
year={2020},
doi={10.1109/INOCON50539.2020.9298194},
art_number={9298194},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099588090&doi=10.1109%2fINOCON50539.2020.9298194&partnerID=40&md5=2cf151dff4077be6e08ae23701f57c20},
abstract={Necessity of near-accurate prediction algorithms in the medical diagnosis as well as prognosis fields has been ever-impending and subject to studies on diversified paradigms. The existing data on due course of medical conditions and comprehensible and conspicuous symptoms can be utilized to train an expert system to project plausible present condition(s) of the subject along with predicting the future course of the disease. This paper will focus on assessing various existing techniques of prognosis in the artificial intelligence domain, viz. Neural Networks and Fuzzy Logic, Backpropagation, Clustering, k-Nearest Neighbour, and Natural Language Processing Technique. This paper will also focus on the challenges faced by each of these techniques. © 2020 IEEE.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Liu20208725,
author={Liu, S. and Jiang, W. and Wu, L. and Wen, H. and Liu, M. and Wang, Y.},
title={Real-Time Classification of Rubber Wood Boards Using an SSR-Based CNN},
journal={IEEE Transactions on Instrumentation and Measurement},
year={2020},
volume={69},
number={11},
pages={8725-8734},
doi={10.1109/TIM.2020.3001370},
art_number={9151201},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093966145&doi=10.1109%2fTIM.2020.3001370&partnerID=40&md5=9142cfe6c72c1fc441105ff6a14170d6},
abstract={The classification of wood types plays an important role in many fields, especially in construction industry and furniture manufacturing. In order to manufacture rubber wood furniture with highly uniform color and texture, wood boards of different colors and textures should be classified elaborately. Many traditional methods have been applied in wood classification relying on extracting features using handcrafted descriptors designed by experienced experts, but it is not easy to construct robust features in various conditions. In this article, we present a split-shuffle-residual (SSR)-based CNN that can learn features automatically from wood images for real-time classification of rubber wood boards. Specifically, we introduce an SSR module that combines channel split and shuffle operations with residual structure to reduce the computation cost while maintaining high classification accuracy. In each module, the input is split into two low-dimensional branches, and the channel shuffle operation is used to enable the information communication between the input and the two separated branches, which is regarded as the feature reuse that enlarges network capacity without increasing complexity. The comprehensive experiments demonstrate that our algorithm outperforms other traditional classification methods and the state-of-the-art deep learning classification networks, yielding an accuracy of 94.86%. Furthermore, the analysis of running time indicates that the SSR-based CNN can be employed for wood classification in real time, which takes only 26.55 ms to handle a single image. © 1963-2012 IEEE.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Morid2020,
author={Morid, M.A. and Sheng, O.R.L. and Kawamoto, K. and Abdelrahman, S.},
title={Learning hidden patterns from patient multivariate time series data using convolutional neural networks: A case study of healthcare cost prediction},
journal={Journal of Biomedical Informatics},
year={2020},
volume={111},
doi={10.1016/j.jbi.2020.103565},
art_number={103565},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092704142&doi=10.1016%2fj.jbi.2020.103565&partnerID=40&md5=554583edafcb4c78ded0929307e7342c},
abstract={Objective: To develop an effective and scalable individual-level patient cost prediction method by automatically learning hidden temporal patterns from multivariate time series data in patient insurance claims using a convolutional neural network (CNN) architecture. Methods: We used three years of medical and pharmacy claims data from 2013 to 2016 from a healthcare insurer, where data from the first two years were used to build the model to predict costs in the third year. The data consisted of the multivariate time series of cost, visit and medical features that were shaped as images of patients’ health status (i.e., matrices with time windows on one dimension and the medical, visit and cost features on the other dimension). Patients’ multivariate time series images were given to a CNN method with a proposed architecture. After hyper-parameter tuning, the proposed architecture consisted of three building blocks of convolution and pooling layers with an LReLU activation function and a customized kernel size at each layer for healthcare data. The proposed CNN learned temporal patterns became inputs to a fully connected layer. We benchmarked the proposed method against three other methods: (1) a spike temporal pattern detection method, as the most accurate method for healthcare cost prediction described to date in the literature; (2) a symbolic temporal pattern detection method, as the most common approach for leveraging healthcare temporal data; and (3) the most commonly used CNN architectures for image pattern detection (i.e., AlexNet, VGGNet and ResNet) (via transfer learning). Moreover, we assessed the contribution of each type of data (i.e., cost, visit and medical). Finally, we externally validated the proposed method against a separate cohort of patients. All prediction performances were measured in terms of mean absolute percentage error (MAPE). Results: The proposed CNN configuration outperformed the spike temporal pattern detection and symbolic temporal pattern detection methods with a MAPE of 1.67 versus 2.02 and 3.66, respectively (p < 0.01). The proposed CNN outperformed ResNet, AlexNet and VGGNet with MAPEs of 4.59, 4.85 and 5.06, respectively (p < 0.01). Removing medical, visit and cost features resulted in MAPEs of 1.98, 1.91 and 2.04, respectively (p < 0.01). Conclusions: Feature learning through the proposed CNN configuration significantly improved individual-level healthcare cost prediction. The proposed CNN was able to outperform temporal pattern detection methods that look for a pre-defined set of pattern shapes, since it is capable of extracting a variable number of patterns with various shapes. Temporal patterns learned from medical, visit and cost data made significant contributions to the prediction performance. Hyper-parameter tuning showed that considering three-month data patterns has the highest prediction accuracy. Our results showed that patients’ images extracted from multivariate time series data are different from regular images, and hence require unique designs of CNN architectures. The proposed method for converting multivariate time series data of patients into images and tuning them for convolutional learning could be applied in many other healthcare applications with multivariate time series data. © 2020 Elsevier Inc.},
document_type={Article},
source={Scopus},
}

@ARTICLE{LoVercio2020,
author={Lo Vercio, L. and Amador, K. and Bannister, J.J. and Crites, S. and Gutierrez, A. and MacDonald, M.E. and Moore, J. and Mouches, P. and Rajashekar, D. and Schimert, S. and Subbanna, N. and Tuladhar, A. and Wang, N. and Wilms, M. and Winder, A. and Forkert, N.D.},
title={Supervised machine learning tools: A tutorial for clinicians},
journal={Journal of Neural Engineering},
year={2020},
volume={17},
number={6},
doi={10.1088/1741-2552/abbff2},
art_number={062001},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096850723&doi=10.1088%2f1741-2552%2fabbff2&partnerID=40&md5=327401b81e68ecf650301785d394321e},
abstract={In an increasingly data-driven world, artificial intelligence is expected to be a key tool for converting big data into tangible benefits and the healthcare domain is no exception to this. Machine learning aims to identify complex patterns in multi-dimensional data and use these uncovered patterns to classify new unseen cases or make data-driven predictions. In recent years, deep neural networks have shown to be capable of producing results that considerably exceed those of conventional machine learning methods for various classification and regression tasks. In this paper, we provide an accessible tutorial of the most important supervised machine learning concepts and methods, including deep learning, which are potentially the most relevant for the medical domain. We aim to take some of the mystery out of machine learning and depict how machine learning models can be useful for medical applications. Finally, this tutorial provides a few practical suggestions for how to properly design a machine learning model for a generic medical problem. © 2020 IOP Publishing Ltd.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Wang20201,
author={Wang, S. and Duan, F. and Zhang, M.},
title={Convolution-gru based on independent component analysis for fmri analysis with small and imbalanced samples},
journal={Applied Sciences (Switzerland)},
year={2020},
volume={10},
number={21},
pages={1-17},
doi={10.3390/app10217465},
art_number={7465},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094136214&doi=10.3390%2fapp10217465&partnerID=40&md5=d2eb8e72ebdedffa70263af693a7041e},
abstract={Functional magnetic resonance imaging (fMRI) is a commonly used method of brain research. However, due to the complexity and particularity of the fMRI task, it is difficult to find enough subjects, resulting in a small and, often, imbalanced dataset. A dataset with small samples causes overfitting of the learning model, and the imbalance will make the model insensitive to the minority class, which has been a problem in classification. It is of great significance to classify fMRI data with small and imbalanced samples. In the present study, we propose a 3-step method on a small and imbalanced fMRI dataset from a word-scene memory task. The steps of the method are as follows: (1) An independent component analysis is performed to reduce the dimension of data; (2) The synthetic minority oversampling technique is used to generate new samples of the minority class to balance data; (3) A convolution-Gated Recurrent Unit (GRU) network is used to classify the independent component signals, indicating whether the subjects are performing episodic memory tasks. The accuracy of the proposed method is 72.2%, which improves the classification performance compared with traditional classifiers such as support vector machines (SVM), logistic regression (LGR), linear discriminant analysis (LDA) and k-nearest neighbor (KNN), and this study gives a biomarker for evaluating the reactivation of episodic memory. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Liu2020,
author={Liu, Y. and Lin, Y. and Jia, Z. and Ma, Y. and Wang, J.},
title={Representation based on ordinal patterns for seizure detection in EEG signals},
journal={Computers in Biology and Medicine},
year={2020},
volume={126},
doi={10.1016/j.compbiomed.2020.104033},
art_number={104033},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092907572&doi=10.1016%2fj.compbiomed.2020.104033&partnerID=40&md5=f2479337cf52e070efcbbe6db5b84371},
abstract={EEG signals carry rich information about brain activity and play an important role in the diagnosis and recognition of epilepsy. Numerous algorithms using EEG signals to detect seizures have been developed in recent decades. However, most of them require well-designed features that highly depend on domain-specific knowledge and algorithm expertise. In this study, we introduce the unigram ordinal pattern (UniOP) and bigram ordinal pattern (BiOP) representations to capture the different underlying dynamics of time series, which only assumes that time series derived from different dynamics can be characterized by repeated ordinal patterns. Specifically, we first transform each subsequence in a time series into the corresponding ordinal pattern in terms of the ranking of values and consider the distribution of ordinal patterns of all subsequences as the UniOP representation. Furthermore, we consider the distribution of the cooccurrence of ordinal patterns as the BiOP representation to characterize the contextual information for each ordinal pattern. We then combine the proposed representations with the nearest neighbor algorithm to evaluate its effectiveness on three publicly available seizure datasets. The results on the Bonn EEG dataset demonstrate that this method provides more than 90% accuracy, sensitivity, and specificity in most cases and outperforms several state-of-the-art methods, which proves its ability to capture the key information of the underlying dynamics of EEG time series at healthy, seizure-free, and seizure states. The results on the second dataset are comparable with the state-of-the-art method, showing the good generalization ability of the proposed method. All performance metrics on the third dataset are approximately 89%, which demonstrates that the proposed representations are suitable for large-scale datasets. © 2020 Elsevier Ltd},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Yang20201073,
author={Yang, D. and Huang, R. and Qing, K. and Hong, K.-S.},
title={Exploring the possibility for early detection of Alzheimer's disease with spatial-domain neural images},
journal={International Conference on Control, Automation and Systems},
year={2020},
volume={2020-October},
pages={1073-1078},
doi={10.23919/ICCAS50221.2020.9268361},
art_number={9268361},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098077806&doi=10.23919%2fICCAS50221.2020.9268361&partnerID=40&md5=658553480f549d0144211ae5ce993027},
abstract={Mild cognitive impairment (MCI) is an intermediate stage leading to Alzheimer's disease (AD). Diagnosis for MCI patients at an early stage can reduce the chances of developing into a severe condition for cognition. This study aims to identify the healthy control (HC) and MCI through the neural images in the specific time points during the mental tasks by the convolutional neural network (CNN). The signals were acquired by the functional near-infrared spectroscopy (fNIRS). 15 MCI patients and 9 HC subjects are employed in the experiment to perform the N-back task, Stroop task, and verbal fluency task (VFT), respectively. The neural images were generated by the brain map in the specific time points (i.e., 5 sec, 10 sec, 15 sec, 20 sec, 25 sec, 30 sec, 35 sec, 40 sec, 45 sec, 50 sec, 55 sec, 60 sec, and 65 sec). Four layers CNN were applied to classify the neural images of the different time points for three mental tasks (i.e., N-back, Stroop, and VFT). For evaluating the performance of the classifier, we utilized a 5-fold cross-validation method. The CNN results indicated that all the mental tasks obtained a great performance (i.e., averaged accuracy of N-back: 82.59%, Stroop: 85.03%, and VFT: 82.20%). Especially, the highest accuracy of the Stroop task in the 60-sec time point is 98.57%. Thus, these findings demonstrate that the neural images can be useful for the identification of the MCI. The fNIRS could be a next promising non-invasive neural imaging tool for early detection of AD in the clinical field. © 2020 Institute of Control, Robotics, and Systems - ICROS.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Aydemir2020,
author={Aydemir, O. and Naser, A. and Ozturk, M.},
title={Classification of EEG Signals Recorded while Imagining Odors with Effective Band Pass Filter Parameters [Etkin Bant Geciren Filtre Parametreleri ile Kokularin Hayal Edildigi Sirada Kaydedilen EEG Isaretlerinin Siniflandirilmasi]},
journal={2020 28th Signal Processing and Communications Applications Conference, SIU 2020 - Proceedings},
year={2020},
doi={10.1109/SIU49456.2020.9302244},
art_number={9302244},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100307594&doi=10.1109%2fSIU49456.2020.9302244&partnerID=40&md5=be826aee03acd66a76e307ffd725d781},
abstract={Technological advances in medicine allow us to learn more about human physiology, anatomy, endocrinology and neurology. In this way, many diseases can be diagnosed early and treatment processes can be closely monitored. On the one hand, the advancing technology allows us to demonstrate how the human brain reacts to various environmental stimuli. In this study, electroencephalography (EEG) technique was used to record the reactions of the brain to the imagination of cloves and mint odors. The distinguishability of brain responses to these odors was tested using pixel means of gray-level images obtained from Burg-based color spectrogram images. By using pixel means as an attribute, a classification accuracy of 82.5% was obtained with k-nearest neighbor. The results showed that the EEG signals that can occur when the brain imagines different odors can be distinguished. © 2020 IEEE.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Purwar202027683,
author={Purwar, S. and Tripathi, R. and Barwad, A.W. and Dinda, A.K.},
title={Detection of Mesangial hypercellularity of MEST-C score in immunoglobulin A-nephropathy using deep convolutional neural network},
journal={Multimedia Tools and Applications},
year={2020},
volume={79},
number={37-38},
pages={27683-27703},
doi={10.1007/s11042-020-09304-8},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088700483&doi=10.1007%2fs11042-020-09304-8&partnerID=40&md5=b20d210ee72bf5a7798486332d950807},
abstract={Immunoglobulin A (IgA)-nephropathy (IgAN) is one of the major reasons for renal failure. It provides vital clues to estimate the stage and the proliferation rate of end-stage kidney disease. IgA stage can be estimated with the help of MEST-C score. The manual estimation of MEST-C score from whole slide kidney images is a very tedious and difficult task. This study uses some Convolutional neural networks (CNNs) related models to detect mesangial hypercellularity (M score) in MEST-C. CNN learns the features directly from image data without the requirement of analytical data. CNN is trained efficiently when image data size is large enough for a particular class. In the case of smaller data size, transfer learning can be used efficiently in which CNN is pre-trained on some general images and then on subject images. Since the data set size is small, time spent in collecting large data set is saved. The training time of transfer learning is also reduced because the model is already pre-trained. This research work aims at the detection of mesangial hypercellularity from biopsy images with small data size by utilizing the transfer learning. The dataset used in this research work consists of 138 individual glomerulus (× 20 magnification digital biopsy) images of IgA patients received from All India Institute of Medical Science, Delhi. Here, machine learning (k-nearest neighbour (KNN) and support vector machine (SVM)) classifiers are compared to transfer learning CNN methods. The deep extracted image features are used by machine learning classifiers. The different evaluation parameters have been used for comparing the predictions of basic classifiers to the deep learning model. The research work concludes that the transfer learning deep CNN method can improve the detection of mesangial hypercellularity as compare to KNN, SVM methods when using the small data set. This model could help the pathologists to understand the stages of kidney failure. © 2020, Springer Science+Business Media, LLC, part of Springer Nature.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Zhu2020,
author={Zhu, L. and Su, C. and Zhang, J. and Cui, G. and Cichocki, A. and Zhou, C. and Li, J.},
title={EEG-based approach for recognizing human social emotion perception},
journal={Advanced Engineering Informatics},
year={2020},
volume={46},
doi={10.1016/j.aei.2020.101191},
art_number={101191},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094176001&doi=10.1016%2fj.aei.2020.101191&partnerID=40&md5=2af9ea9868beb42d3c7ae34f85a010a4},
abstract={Social emotion perception plays an important role in our daily social interactions and is involved in the treatments for mental disorders. Hyper-scanning technique enables to measure brain activities simultaneously from two or more persons, which was employed in this study to explore social emotion perception. We analyzed the recorded electroencephalogram (EEG) to explore emotion perception in terms of event related potential (ERP) and phase synchronization, and classified emotion categories based on convolutional neural network (CNN). The results showed that (1) ERP was significantly different among four emotion categories (i.e., anger, disgust, neutral, and happy), but there was no significant difference for ERP in the comparison of rating orders (the order of rating actions of the paired participants); (2) the intra-brain phase lag index (PLI) was higher than the inter-brain PLI but its number of connections exhibiting significant difference was less in all typical frequency bands (from delta to gamma); (3) the emotion classification accuracy of inter-PLI-Conv outperformed that of intra-PLI-Conv for all cases of using each frequency band (five frequency bands totally). In particular, the classification accuracies averaged across all participants in the alpha band were 65.55% and 50.77% (much higher than the chance level) for the inter-PLI-Conv and intra-PLI-Conv, respectively. According to our results, the emotion category of happiness can be classified with a higher performance compared to the other categories. © 2020 Elsevier Ltd},
document_type={Article},
source={Scopus},
}

@ARTICLE{Książek20201512,
author={Książek, W. and Hammad, M. and Pławiak, P. and Acharya, U.R. and Tadeusiewicz, R.},
title={Development of novel ensemble model using stacking learning and evolutionary computation techniques for automated hepatocellular carcinoma detection},
journal={Biocybernetics and Biomedical Engineering},
year={2020},
volume={40},
number={4},
pages={1512-1524},
doi={10.1016/j.bbe.2020.08.007},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092371496&doi=10.1016%2fj.bbe.2020.08.007&partnerID=40&md5=d0151ee6cf3a952fb8f9eb8a77e01151},
abstract={The most common type of liver cancer is hepatocellular carcinoma (HCC), which begins in hepatocytes. The HCC, like most types of cancer, does not show symptoms in the early stages and hence it is difficult to detect at this stage. The symptoms begin to appear in the advanced stages of the disease due to the unlimited growth of cancer cells. So, early detection can help to get timely treatment and reduce the mortality rate. In this paper, we proposes a novel machine learning model using seven classifiers such as K-nearest neighbor (KNN), random forest, Naïve Bayes, and other four classifiers combined to form stacking learning (ensemble) method with genetic optimization helping to select the features for each classifier to obtain highest HCC detection accuracy. In addition to preparing the data and make it suitable for further processing, we performed the normalization techniques. We have used KNN algorithm to fill in the missing values. We trained and evaluated our developed algorithm using 165 HCC patients collected from Coimbra's Hospital and University Centre (CHUC) using stratified cross-validation techniques. There are total of 49 clinically significant features in this dataset, which are divided into two groups such as quantitative and qualitative groups. Our proposed algorithm has achieved the highest accuracy and F1-score of 0.9030 and 0.8857, respectively. The developed model is ready to be tested with huge database and can be employed in cancer screening laboratories to aid the clinicians to make an accurate diagnosis. © 2020 Nalecz Institute of Biocybernetics and Biomedical Engineering of the Polish Academy of Sciences},
document_type={Article},
source={Scopus},
}

@ARTICLE{Tahir20201024,
author={Tahir, A. and Morison, G. and Skelton, D.A. and Gibson, R.M.},
title={A Novel Functional Link Network Stacking Ensemble with Fractal Features for Multichannel Fall Detection},
journal={Cognitive Computation},
year={2020},
volume={12},
number={5},
pages={1024-1042},
doi={10.1007/s12559-020-09749-x},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088823147&doi=10.1007%2fs12559-020-09749-x&partnerID=40&md5=049766f2cedd7c1d9ad46cdb366c3eef},
abstract={Falls are a major health concern and result in high morbidity and mortality rates in older adults with high costs to health services. Automatic fall classification and detection systems can provide early detection of falls and timely medical aid. This paper proposes a novel Random Vector Functional Link (RVFL) stacking ensemble classifier with fractal features for classification of falls. The fractal Hurst exponent is used as a representative of fractal dimensionality for capturing irregularity of accelerometer signals for falls and other activities of daily life. The generalised Hurst exponents along with wavelet transform coefficients are leveraged as input feature space for a novel stacking ensemble of RVFLs composed with an RVFL neural network meta-learner. Novel fast selection criteria are presented for base classifiers founded on the proposed diversity indicator, obtained from the overall performance values during the training phase. The proposed features and the stacking ensemble provide the highest classification accuracy of 95.71% compared with other machine learning techniques, such as Random Forest (RF), Artificial Neural Network (ANN) and Support Vector Machine. The proposed ensemble classifier is 2.3× faster than a single Decision Tree and achieves the highest speedup in training time of 317.7× and 198.56× compared with a highly optimised ANN and RF ensemble, respectively. The significant improvements in training times of the order of 100× and high accuracy demonstrate that the proposed RVFL ensemble is a prime candidate for real-time, embedded wearable device–based fall detection systems. © 2020, The Author(s).},
document_type={Article},
source={Scopus},
}

@ARTICLE{Wani20201873,
author={Wani, I.M. and Arora, S.},
title={Computer-aided diagnosis systems for osteoporosis detection: a comprehensive survey},
journal={Medical and Biological Engineering and Computing},
year={2020},
volume={58},
number={9},
pages={1873-1917},
doi={10.1007/s11517-020-02171-3},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086871577&doi=10.1007%2fs11517-020-02171-3&partnerID=40&md5=fb9a1901ba0dbe22dbe79d7a9d054a9b},
abstract={Computer-aided diagnosis (CAD) has revolutionized the field of medical diagnosis. They assist in improving the treatment potentials and intensify the survival frequency by early diagnosing the diseases in an efficient, timely, and cost-effective way. The automatic segmentation has led the radiologist to successfully segment the region of interest to improve the diagnosis of diseases from medical images which is not so efficiently possible by manual segmentation. The aim of this paper is to survey the vision-based CAD systems especially focusing on the segmentation techniques for the pathological bone disease known as osteoporosis. Osteoporosis is the state of the bones where the mineral density of bones decreases and they become porous, making the bones easily susceptible to fractures by small injury or a fall. The article covers the image acquisition techniques for acquiring the medical images for osteoporosis diagnosis. The article also discusses the advanced machine learning paradigms employed in segmentation for osteoporosis disease. Other image processing steps in osteoporosis like feature extraction and classification are also briefly described. Finally, the paper gives the future directions to improve the osteoporosis diagnosis and presents the proposed architecture. [Figure not available: see fulltext.]. © 2020, International Federation for Medical and Biological Engineering.},
document_type={Review},
source={Scopus},
}

@ARTICLE{Zhou2020,
author={Zhou, X. and Ling, B.W.-K. and Li, C. and Zhao, K.},
title={Epileptic seizure detection via logarithmic normalized functional values of singular values},
journal={Biomedical Signal Processing and Control},
year={2020},
volume={62},
doi={10.1016/j.bspc.2020.102086},
art_number={102086},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088646411&doi=10.1016%2fj.bspc.2020.102086&partnerID=40&md5=601f433f9656ec3e7d023061abb89495},
abstract={Electroencephalograms (EEGs) play a significant role in both the detection and the prediction of the epileptic seizures. This paper proposes to employ the logarithmic normalized functional singular values as the features for performing the classification of both the two class problem (normal and seizure set) and the three class problem (normal, seizure free and seizure set). Here, the EEGs are taken from two well known datasets. First, each EEG is decomposed via the singular spectrum analysis (SSA) to obtain the singular values. Then, the logarithmic normalized functional values of these singular values are calculated to form the feature vectors for performing the classification of the epileptic seizure. Next, different classifiers including the support vector machine (SVM), the k nearest neighbor classifier, the extreme learning machine (ELM) and the artificial neural network (ANN) are employed for performing the classification. Finally, a ten fold cross validation procedure is employed to ensure the reliability and the stability of the classifiers. The computer numerical simulation results show that the k nearest neighbor classifier achieves the best performance compared to other classifiers for performing both the two class epileptic classification and the three class epileptic classification. Our proposed method also achieves the higher classification accuracies compared to the case without performing the logarithmic normalized operation. Moreover, the performance of our proposed method is evaluated on the original EEGs under the white noise environment at different signal to noise ratios. Similar results are obtained. © 2020 Elsevier Ltd},
document_type={Article},
source={Scopus},
}

@ARTICLE{Çinarer2020,
author={Çinarer, G. and Gürsel, B. and Haşim, A.},
title={Prediction of glioma grades using deep learning with wavelet radiomic features},
journal={Applied Sciences (Switzerland)},
year={2020},
volume={10},
number={18},
doi={10.3390/APP10186296},
art_number={6296},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091735137&doi=10.3390%2fAPP10186296&partnerID=40&md5=00ac208adb90344b3a869285b00a52df},
abstract={Gliomas are the most common primary brain tumors. They are classified into 4 grades (Grade I-II-III-IV) according to the guidelines of the World Health Organization (WHO). The accurate grading of gliomas has clinical significance for planning prognostic treatments, pre-diagnosis, monitoring and administration of chemotherapy. The purpose of this study is to develop a deep learning-based classification method using radiomic features of brain tumor glioma grades with deep neural network (DNN). The classifier was combined with the discrete wavelet transform (DWT) the powerful feature extraction tool. This study primarily focuses on the four main aspects of the radiomic workflow, namely tumor segmentation, feature extraction, analysis, and classification. We evaluated data from 121 patients with brain tumors (Grade II, n = 77; Grade III, n = 44) from The Cancer Imaging Archive, and 744 radiomic features were obtained by applying low sub-band and high sub-band 3D wavelet transform filters to the 3D tumor images. Quantitative values were statistically analyzed with MannWhitney U tests and 126 radiomic features with significant statistical properties were selected in eight different wavelet filters. Classification performances of 3D wavelet transform filter groups were measured using accuracy, sensitivity, F1 score, and specificity values using the deep learning classifier model. The proposed model was highly effective in grading gliomas with 96.15% accuracy, 94.12% precision, 100% recall, 96.97% F1 score, and 98.75% Area under the ROC curve. As a result, deep learning and feature selection techniques with wavelet transform filters can be accurately applied using the proposed method in glioma grade classification. © 2020 by the authors.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Semyachkina-Glushkovskaya20201,
author={Semyachkina-Glushkovskaya, O. and Postnov, D. and Penzel, T. and Kurths, J.},
title={Sleep as a novel biomarker and a promising therapeutic target for cerebral small vessel disease: A review focusing on alzheimer’s disease and the blood-brain barrier},
journal={International Journal of Molecular Sciences},
year={2020},
volume={21},
number={17},
pages={1-15},
doi={10.3390/ijms21176293},
art_number={6293},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090226311&doi=10.3390%2fijms21176293&partnerID=40&md5=d788d42874450371d1200f6af03a8c40},
abstract={Cerebral small vessel disease (CSVD) is a leading cause of cognitive decline in elderly people and development of Alzheimer’s disease (AD). Blood–brain barrier (BBB) leakage is a key pathophysiological mechanism of amyloidal CSVD. Sleep plays a crucial role in keeping health of the central nervous system and in resistance to CSVD. The deficit of sleep contributes to accumulation of metabolites and toxins such as beta-amyloid in the brain and can lead to BBB disruption. Currently, sleep is considered as an important informative platform for diagnosis and therapy of AD. However, there are no effective methods for extracting of diagnostic information from sleep characteristics. In this review, we show strong evidence that slow wave activity (SWA) (0–0.5 Hz) during deep sleep reflects glymphatic pathology, the BBB leakage and memory deficit in AD. We also discuss that diagnostic and therapeutic targeting of SWA in AD might lead to be a novel era in effective therapy of AD. Moreover, we demonstrate that SWA can be pioneering non-invasive and bed–side technology for express diagnosis of the BBB permeability. Finally, we review the novel data about the methods of detection and enhancement of SWA that can be biomarker and a promising therapy of amyloidal CSVD and CSVD associated with the BBB disorders. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.},
document_type={Review},
source={Scopus},
}

@ARTICLE{Balhaddad2020481,
author={Balhaddad, A.A. and Garcia, I.M. and Ibrahim, M.S. and Rolim, J.P.M.L. and Gomes, E.A.B. and Martinho, F.C. and Collares, F.M. and Xu, H. and Melo, M.A.S.},
title={Prospects on nano-based platforms for antimicrobial photodynamic therapy against oral biofilms},
journal={Photobiomodulation, Photomedicine, and Laser Surgery},
year={2020},
volume={38},
number={8},
pages={481-496},
doi={10.1089/photob.2020.4815},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089406864&doi=10.1089%2fphotob.2020.4815&partnerID=40&md5=ce5b8376b922a355dc3d4ae7f5a9bb60},
abstract={Objective: This review clusters the growing field of nano-based platforms for antimicrobial photodynamic therapy (aPDT) targeting pathogenic oral biofilms and increase interactions between dental researchers and investigators in many related fields. Background data: Clinically relevant disinfection of dental tissues is difficult to achieve with aPDT alone. It has been found that limited penetrability into soft and hard dental tissues, diffusion of the photosensitizers, and the small light absorption coefficient are contributing factors. As a result, the effectiveness of aPDT is reduced in vivo applications. To overcome limitations, nanotechnology has been implied to enhance the penetration and delivery of photosensitizers to target microorganisms and increase the bactericidal effect. Materials and methods: The current literature was screened for the various platforms composed of photosensitizers functionalized with nanoparticles and their enhanced performance against oral pathogenic biofilms. Results: The evidence-based findings from the up-to-date literature were promising to control the onset and the progression of dental biofilm-triggered diseases such as dental caries, endodontic infections, and periodontal diseases. The antimicrobial effects of aPDT with nano-based platforms on oral bacterial disinfection will help to advance the design of combination strategies that increase the rate of complete and durable clinical response in oral infections. Conclusions: There is enthusiasm about the potential of nano-based platforms to treat currently out of the reach pathogenic oral biofilms. Much of the potential exists because these nano-based platforms use unique mechanisms of action that allow us to overcome the challenging of intra-oral and hard-tissue disinfection. © Copyright 2020, Mary Ann Liebert, Inc., publishers 2020.},
document_type={Review},
source={Scopus},
}

@ARTICLE{Hussain2020,
author={Hussain, E. and Mahanta, L.B. and Das, C.R. and Choudhury, M. and Chowdhury, M.},
title={A shape context fully convolutional neural network for segmentation and classification of cervical nuclei in Pap smear images},
journal={Artificial Intelligence in Medicine},
year={2020},
volume={107},
doi={10.1016/j.artmed.2020.101897},
art_number={101897},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086079448&doi=10.1016%2fj.artmed.2020.101897&partnerID=40&md5=18529e4fd2e3b4a375779ec466993f1e},
abstract={Pap smear is often employed as a screening test for diagnosing cervical pre-cancerous and cancerous lesions. Accurate identification of dysplastic changes amongst the cervical cells in a Pap smear image is thus essential for rapid diagnosis and prognosis. Manual pathological observations used in clinical practice require exhaustive analysis of thousands of cell nuclei in a whole slide image to visualize the dysplastic nuclear changes which make the process tedious and time-consuming. Automated nuclei segmentation and classification exist but are challenging to overcome issues like nuclear intra-class variability and clustered nuclei separation. To address such challenges, we put forward an application of instance segmentation and classification framework built on an Unet architecture by adding residual blocks, densely connected blocks and a fully convolutional layer as a bottleneck between encoder-decoder blocks for Pap smear images. The number of convolutional layers in the standard Unet has been replaced by densely connected blocks to ensure feature reuse-ability property while the introduction of residual blocks in the same attempts to converge the network more rapidly. The framework provides simultaneous nuclei instance segmentation and also predicts the type of nucleus class as belonging to normal and abnormal classes from the smear images. It works by assigning pixel-wise labels to individual nuclei in a whole slide image which enables identifying multiple nuclei belonging to the same or different class as individual distinct instances. Introduction of a joint loss function in the framework overcomes some trivial cell level issues on clustered nuclei separation. To increase the robustness of the overall framework, the proposed model is preceded with a stacked auto-encoder based shape representation learning model. The proposed model outperforms two state-of-the-art deep learning models Unet and Mask_RCNN with an average Zijdenbos similarity index of 97 % related to segmentation along with binary classification accuracy of 98.8 %. Experiments on hospital-based datasets using liquid-based cytology and conventional pap smear methods along with benchmark Herlev datasets proved the superiority of the proposed method than Unet and Mask_RCNN models in terms of the evaluation metrics under consideration. © 2020 Elsevier B.V.},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Silva2020126,
author={Silva, F.H.S. and Medeiros, A.G. and Ohata, E.F. and Reboucas Filho, P.P.},
title={Classification of electroencephalogram signals for detecting predisposition to alcoholism using computer vision and transfer learning},
journal={Proceedings - IEEE Symposium on Computer-Based Medical Systems},
year={2020},
volume={2020-July},
pages={126-131},
doi={10.1109/CBMS49503.2020.00031},
art_number={9182916},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091167854&doi=10.1109%2fCBMS49503.2020.00031&partnerID=40&md5=f659d85114ed2d27d838cc6808f89a76},
abstract={Recent statistics have shown that the main difficulty in detecting alcoholism is the unreliability of the information presented by patients with addiction; this hampers early diagnosis and reduces the effectiveness of treatment. However, electroencephalogram (EEG) exams can contribute with more reliable data for this analysis. This paper proposes a new approach for the automatic diagnosis of patients with alcoholism. It offers a method for examining the EEG signals from a two-dimensional perspective according to changes in the neural activity, highlighting the influence of high and low-frequency signals. This approach combines Transfer Learning and Con-volutional Neural Networks (CNN) to EEG signals analysis. The methodology to evaluate our proposal used 21 combinations of the classification traditional methods and 35 combinations of recent CNN architectures used as feature extractors combined with the following classical classifiers: Gaussian Naive Bayes, K-Nearest Neighbor (k-NN), Multilayer Perceptron (MLP), Random Forest (RF) and Support Vector Machine (SVM). CNN MobileNet combined with SVM achieved the best results in Accuracy (95.33%), Precision (95.68%), F1-Score (95.24%), and Recall (95.00%). This combination outperformed traditional methods by up to 8%. Thus, this approach is applicable as a classification stage for computer-aided diagnoses, useful for the triage of patients, and clinical support for the early diagnosis of this disease. © 2020 IEEE.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Koh2020106,
author={Koh, J.E.W. and Jahmunah, V. and Pham, T.-H. and Oh, S.L. and Ciaccio, E.J. and Acharya, U.R. and Yeong, C.H. and Fabell, M.K.M. and Rahmat, K. and Vijayananthan, A. and Ramli, N.},
title={Automated detection of Alzheimer's disease using bi-directional empirical model decomposition},
journal={Pattern Recognition Letters},
year={2020},
volume={135},
pages={106-113},
doi={10.1016/j.patrec.2020.03.014},
note={cited By 6},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084110530&doi=10.1016%2fj.patrec.2020.03.014&partnerID=40&md5=963508502f179ff8e399253117b134ea},
abstract={The build-up of beta-amyloid and rapid spread of tau proteins in the brain cause the death of neurons, leading to Alzheimer's disease (AD). AD is a form of dementia, and the symptoms include memory loss and decision-making difficulties. Current advanced diagnostic modalities are costly or unable to detect the histopathological features of AD. Hence a computational intelligence tool (CIT) for AD diagnosis is proposed in this study. The magnetic resonance images (MRI) of the brain are pre-processed using an adaptive histogram, and decomposed into four IMFS using bidirectional empirical mode decomposition (BEMD). Local binary patterns (LBP) are then computed per IMF, and the histograms are concatenated. Adaptive synthetic sampling (ADASYN) is applied to balance the dataset and Student's t-test is utilized for selection of highly significant features, within each fold for ten-fold validation. Amongst other classifiers, SVM-Poly 1 and random forest(RF) were employed for classification, yielding the highest accuracy of 93.9% each. Our study concludes that the recommended CIT is useful for the automatic classification of AD versus normal MRI imagery in hospitals. © 2020},
document_type={Article},
source={Scopus},
}

@ARTICLE{Cai2020127,
author={Cai, H. and Qu, Z. and Li, Z. and Zhang, Y. and Hu, X. and Hu, B.},
title={Feature-level fusion approaches based on multimodal EEG data for depression recognition},
journal={Information Fusion},
year={2020},
volume={59},
pages={127-138},
doi={10.1016/j.inffus.2020.01.008},
note={cited By 18},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079327800&doi=10.1016%2fj.inffus.2020.01.008&partnerID=40&md5=634bd81780c7c5931cc0b472c183e75a},
abstract={This study aimed to construct a novel multimodal model by fusing different electroencephalogram (EEG) data sources, which were under neutral, negative and positive audio stimulation, to discriminate between depressed patients and normal controls. The EEG data of different modalities were fused using a feature-level fusion technique to construct a depression recognition model. The EEG signals of 86 depressed patients and 92 normal controls were recorded simultaneously while receiving different audio stimuli. Then, from the EEG signals of each modality, linear and nonlinear features were extracted and selected to obtain features of each modality. In addition, a linear combination technique was used to fuse the EEG features of different modalities to build a global feature vector and find several powerful features. Furthermore, genetic algorithms were used to perform feature weighting to improve the overall performance of the recognition framework. The classification accuracy of each classifier, namely the k-nearest neighbor (KNN), decision tree (DT), and support vector machine (SVM), was compared, and the results were encouraging. The highest classification accuracy of 86.98% was obtained by the KNN classifier in the fusion of positive and negative audio stimuli, demonstrating that the fusion modality could achieve higher depression recognition accuracy rate compared with the individual modality schemes. This study may provide an additional tool for identifying depression patients. © 2020},
document_type={Article},
source={Scopus},
}

@ARTICLE{Mesejo2020,
author={Mesejo, P. and Martos, R. and Ibáñez, O. and Novo, J. and Ortega, M.},
title={A Survey on artificial intelligence techniques for biomedical image analysis in skeleton-based forensic human identification},
journal={Applied Sciences (Switzerland)},
year={2020},
volume={10},
number={14},
doi={10.3390/app10144703},
art_number={4703},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088645652&doi=10.3390%2fapp10144703&partnerID=40&md5=584526d8e04e87cab9210cd92ccd6368},
abstract={This paper represents the first survey on the application of AI techniques for the analysis of biomedical images with forensic human identification purposes. Human identification is of great relevance in today's society and, in particular, in medico-legal contexts. As consequence, all technological advances that are introduced in this field can contribute to the increasing necessity for accurate and robust tools that allow for establishing and verifying human identity. We first describe the importance and applicability of forensic anthropology in many identification scenarios. Later, we present the main trends related to the application of computer vision, machine learning and soft computing techniques to the estimation of the biological profile, the identification through comparative radiography and craniofacial superimposition, traumatism and pathology analysis, as well as facial reconstruction. The potentialities and limitations of the employed approaches are described, and we conclude with a discussion about methodological issues and future research. © 2020 by the authors.},
document_type={Review},
source={Scopus},
}

@ARTICLE{Annunziata20201,
author={Annunziata, F. and Pinna, C. and Dallavalle, S. and Tamborini, L. and Pinto, A.},
title={An overview of coumarin as a versatile and readily accessible scaffold with broad-ranging biological activities},
journal={International Journal of Molecular Sciences},
year={2020},
volume={21},
number={13},
pages={1-83},
doi={10.3390/ijms21134618},
art_number={4618},
note={cited By 10},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087126932&doi=10.3390%2fijms21134618&partnerID=40&md5=192924c838e6c9894e7225b5db6d6d71},
abstract={Privileged structures have been widely used as an effective template for the research and discovery of high value chemicals. Coumarin is a simple scaffold widespread in Nature and it can be found in a considerable number of plants as well as in some fungi and bacteria. In the last years, these natural compounds have been gaining an increasing attention from the scientific community for their wide range of biological activities, mainly due to their ability to interact with diverse enzymes and receptors in living organisms. In addition, coumarin nucleus has proved to be easily synthetized and decorated, giving the possibility of designing new coumarin-based compounds and investigating their potential in the treatment of various diseases. The versatility of coumarin scaffold finds applications not only in medicinal chemistry but also in the agrochemical field as well as in the cosmetic and fragrances industry. This review is intended to be a critical overview on coumarins, comprehensive of natural sources, metabolites, biological evaluations and synthetic approaches. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.},
document_type={Review},
source={Scopus},
}

@ARTICLE{Onofrey2020127,
author={Onofrey, J.A. and Staib, L.H. and Huang, X. and Zhang, F. and Papademetris, X. and Metaxas, D. and Rueckert, D. and Duncan, J.S.},
title={Sparse Data-Driven Learning for Effective and Efficient Biomedical Image Segmentation},
journal={Annual Review of Biomedical Engineering},
year={2020},
volume={22},
pages={127-153},
doi={10.1146/annurev-bioeng-060418-052147},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086052462&doi=10.1146%2fannurev-bioeng-060418-052147&partnerID=40&md5=3b2a39eb9a6e2673471e12f4a78eb877},
abstract={Sparsity is a powerful concept to exploit for high-dimensional machine learning and associated representational and computational efficiency. Sparsity is well suited for medical image segmentation. We present a selection of techniques that incorporate sparsity, including strategies based on dictionary learning and deep learning, that are aimed at medical image segmentation and related quantification. © 2020 by Annual Reviews. All rights reserved.},
document_type={Review},
source={Scopus},
}

@ARTICLE{Yamanakkanavar20201,
author={Yamanakkanavar, N. and Choi, J.Y. and Lee, B.},
title={MRI segmentation and classification of human brain using deep learning for diagnosis of alzheimer’s disease: A survey},
journal={Sensors (Switzerland)},
year={2020},
volume={20},
number={11},
pages={1-31},
doi={10.3390/s20113243},
art_number={3243},
note={cited By 5},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086142676&doi=10.3390%2fs20113243&partnerID=40&md5=8d804a5d87720ac8fca793a890fa2d30},
abstract={Many neurological diseases and delineating pathological regions have been analyzed, and the anatomical structure of the brain researched with the aid of magnetic resonance imaging (MRI). It is important to identify patients with Alzheimer’s disease (AD) early so that preventative measures can be taken. A detailed analysis of the tissue structures from segmented MRI leads to a more accurate classification of specific brain disorders. Several segmentation methods to diagnose AD have been proposed with varying complexity. Segmentation of the brain structure and classification of AD using deep learning approaches has gained attention as it can provide effective results over a large set of data. Hence, deep learning methods are now preferred over state-of-the-art machine learning methods. We aim to provide an outline of current deep learning-based segmentation approaches for the quantitative analysis of brain MRI for the diagnosis of AD. Here, we report how convolutional neural network architectures are used to analyze the anatomical brain structure and diagnose AD, discuss how brain MRI segmentation improves AD classification, describe the stateof-the-art approaches, and summarize their results using publicly available datasets. Finally, we provide insight into current issues and discuss possible future research directions in building a computer-aided diagnostic system for AD. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.},
document_type={Review},
source={Scopus},
}

@ARTICLE{Abiyev2020,
author={Abiyev, R. and Arslan, M. and Idoko, J.B. and Sekeroglu, B. and Ilhan, A.},
title={Identification of epileptic eeg signals using convolutional neural networks},
journal={Applied Sciences (Switzerland)},
year={2020},
volume={10},
number={12},
doi={10.3390/APP10124089},
art_number={4089},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087514083&doi=10.3390%2fAPP10124089&partnerID=40&md5=69826bc9a69dd16626f2d975142f4ffd},
abstract={Epilepsy is one of the chronic neurological disorders that is characterized by a sudden burst of excess electricity in the brain. This abnormality appears as a seizure, the detection of which is an important research topic. An important tool used to study brain activity features, neurological disorders and particularly epileptic seizures, is known as electroencephalography (EEG). The visual inspection of epileptic abnormalities in EEG signals by neurologists is time-consuming. Different scientific approaches have been used to accurately detect epileptic seizures from EEG signals, and most of those approaches have obtained good performance. In this study, deep learning based on convolutional neural networks (CNN) was considered to increase the performance of the identification system of epileptic seizures. We applied a cross-validation technique in the design phase of the system. For efficiency, comparative results between other machine-learning approaches and deep CNNs have been obtained. The experiments were performed using standard datasets. The results obtained indicate the efficiency of using CNN in the detection of epilepsy. © 2020 by the authors.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Zhang2020894,
author={Zhang, X.-Y. and Liu, C.-L. and Suen, C.Y.},
title={Towards Robust Pattern Recognition: A Review},
journal={Proceedings of the IEEE},
year={2020},
volume={108},
number={6},
pages={894-922},
doi={10.1109/JPROC.2020.2989782},
art_number={9103349},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086049705&doi=10.1109%2fJPROC.2020.2989782&partnerID=40&md5=93271bd3d02a8a9511cfd82a452b99fa},
abstract={The accuracies for many pattern recognition tasks have increased rapidly year by year, achieving or even outperforming human performance. From the perspective of accuracy, pattern recognition seems to be a nearly solved problem. However, once launched in real applications, the high-accuracy pattern recognition systems may become unstable and unreliable due to the lack of robustness in open and changing environments. In this article, we present a comprehensive review of research toward robust pattern recognition from the perspective of breaking three basic and implicit assumptions: closed-world assumption, independent and identically distributed assumption, and clean and big data assumption, which form the foundation of most pattern recognition models. Actually, our brain is robust at learning concepts continually and incrementally, in complex, open, and changing environments, with different contexts, modalities, and tasks, by showing only a few examples, under weak or noisy supervision. These are the major differences between human intelligence and machine intelligence, which are closely related to the above three assumptions. After witnessing the significant progress in accuracy improvement nowadays, this review paper will enable us to analyze the shortcomings and limitations of current methods and identify future research directions for robust pattern recognition. © 1963-2012 IEEE.},
document_type={Review},
source={Scopus},
}

@ARTICLE{Chen20201988,
author={Chen, M.T. and Mahmood, F. and Sweer, J.A. and Durr, N.J.},
title={GANPOP: Generative Adversarial Network Prediction of Optical Properties from Single Snapshot Wide-Field Images},
journal={IEEE Transactions on Medical Imaging},
year={2020},
volume={39},
number={6},
pages={1988-1999},
doi={10.1109/TMI.2019.2962786},
art_number={8943974},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077308211&doi=10.1109%2fTMI.2019.2962786&partnerID=40&md5=388fb09bba7af27cc98ebfa36d81102e},
abstract={We present a deep learning framework for wide-field, content-aware estimation of absorption and scattering coefficients of tissues, called Generative Adversarial Network Prediction of Optical Properties (GANPOP). Spatial frequency domain imaging is used to obtain ground-truth optical properties at 660 nm from in vivo human hands and feet, freshly resected human esophagectomy samples, and homogeneous tissue phantoms. Images of objects with either flat-field or structured illumination are paired with registered optical property maps and are used to train conditional generative adversarial networks that estimate optical properties from a single input image. We benchmark this approach by comparing GANPOP to a single-snapshot optical property (SSOP) technique, using a normalized mean absolute error (NMAE) metric. In human gastrointestinal specimens, GANPOP with a single structured-light input image estimates the reduced scattering and absorption coefficients with 60% higher accuracy than SSOP while GANPOP with a single flat-field illumination image achieves similar accuracy to SSOP. When applied to both in vivo and ex vivo swine tissues, a GANPOP model trained solely on structured-illumination images of human specimens and phantoms estimates optical properties with approximately 46% improvement over SSOP, indicating adaptability to new, unseen tissue types. Given a training set that appropriately spans the target domain, GANPOP has the potential to enable rapid and accurate wide-field measurements of optical properties. © 1982-2012 IEEE.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Hakimi2020,
author={Hakimi, N. and Jodeiri, A. and Mirbagheri, M. and Setarehdan, S.K.},
title={Proposing a convolutional neural network for stress assessment by means of derived heart rate from functional near infrared spectroscopy},
journal={Computers in Biology and Medicine},
year={2020},
volume={121},
doi={10.1016/j.compbiomed.2020.103810},
art_number={103810},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084553687&doi=10.1016%2fj.compbiomed.2020.103810&partnerID=40&md5=0c67d0471fe687cadba9bb3d1655d0b9},
abstract={Background: Stress is known as one of the major factors threatening human health. A large number of studies have been performed in order to either assess or relieve stress by analyzing the brain and heart-related signals. Method: In this study, a method based on the Convolutional Neural Network (CNN) approach is proposed to assess stress induced by the Montreal Imaging Stress Task. The proposed model is trained on the heart rate signal derived from functional Near-Infrared Spectroscopy (fNIRS), which is referred to as HRF. In this regard, fNIRS signals of 20 healthy volunteers were recorded using a configuration of 23 channels located on the prefrontal cortex. The proposed deep learning system consists of two main parts where in the first part, the one-dimensional convolutional neural network is employed to build informative activation maps, and then in the second part, a stack of deep fully connected layers is used to predict the stress existence probability. Thereafter, the employed CNN method is compared with the Dense Neural Network, Support Vector Machine, and Random Forest regarding various classification metrics. Results: Results clearly showed the superiority of CNN over all other methods. Additionally, the trained HRF model significantly outperforms the model trained on the filtered fNIRS signals, where the HRF model could achieve 98.69 ± 0.45% accuracy, which is 10.09% greater than the accuracy obtained by the fNIRS model. Conclusions: Employment of the proposed deep learning system trained on the HRF measurements leads to higher stress classification accuracy than the accuracy reported in the existing studies where the same experimental procedure has been done. Besides, the proposed method suggests better stability with lower variation in prediction. Furthermore, its low computational cost opens up the possibility to be applied in real-time monitoring of stress assessment. © 2020},
document_type={Article},
source={Scopus},
}

@ARTICLE{Tan20206435,
author={Tan, M. and Zhang, S. and Wu, L.},
title={Mutual kNN based spectral clustering},
journal={Neural Computing and Applications},
year={2020},
volume={32},
number={11},
pages={6435-6442},
doi={10.1007/s00521-018-3836-z},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055995276&doi=10.1007%2fs00521-018-3836-z&partnerID=40&md5=2db2a7670d470d34f7f0f4eade4a5725},
abstract={The key step of spectral clustering is learning the affinity matrix to measure the similarity among data points. This paper proposes a new spectral clustering method, which uses mutual k nearest neighbor to obtain the affinity matrix by removing the influence of noise. Then, the characteristics of high-dimensional data are self-represented to ensure local important information of data by using affinity matrix in standardized processing. Furthermore, we also use the normalization method to further improve the performance of clustering. Experimental analysis on eight benchmark data sets showed that our proposed method outperformed the state-of-the-art clustering methods in terms of clustering performance such as cluster accuracy and normalized mutual information. © 2018, Springer-Verlag London Ltd., part of Springer Nature.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Güven20208367,
author={Güven, A. and Altınkaynak, M. and Dolu, N. and İzzetoğlu, M. and Pektaş, F. and Özmen, S. and Demirci, E. and Batbat, T.},
title={Combining functional near-infrared spectroscopy and EEG measurements for the diagnosis of attention-deficit hyperactivity disorder},
journal={Neural Computing and Applications},
year={2020},
volume={32},
number={12},
pages={8367-8380},
doi={10.1007/s00521-019-04294-7},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068834729&doi=10.1007%2fs00521-019-04294-7&partnerID=40&md5=f08dbb38fe36cd137e1a6fee36eef9e3},
abstract={Recently multimodal neuroimaging which combines signals from different brain modalities has started to be considered as a potential to improve the accuracy of diagnosis. The current study aimed to explore a new method for discriminating attention-deficit hyperactivity disorder (ADHD) patients and control group by means of simultaneous measurement of electroencephalography (EEG) and functional near-infrared spectroscopy (fNIRS). Twenty-three pre-medicated combined type ADHD children and 21 healthy children were included in the study. Nonlinear brain dynamics of subjects were obtained from EEG signal using Higuchi fractal dimensions and Lempel–Ziv complexity, latency and amplitude values of P3 wave obtained from auditory evoked potentials and frontal cortex hemodynamic responses calculated from fNIRS. Lower complexity values, prolonged P3 latency and reduced P3 amplitude values were found in ADHD children. fNIRS indicated that the control subjects exhibited higher right prefrontal activation than ADHD children. Features are analyzed, looking for the best classification accuracy and finally machine learning techniques, namely Support Vector Machines, Naïve Bayes and Multilayer Perception Neural Network, are introduced for EEG signals alone and for combination of fNIRS and EEG signals. Naive Bayes provided the best classification with an accuracy rate of 79.54% and 93.18%, using EEG and EEG-fNIRS systems, respectively. Our findings demonstrate that utilization of information by combining features obtained from fNIRS and EEG improves the classification accuracy. As a conclusion, our method has indicated that EEG-fNIRS multimodal neuroimaging is a promising method for ADHD objective diagnosis. © 2019, Springer-Verlag London Ltd., part of Springer Nature.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Guo2020191,
author={Guo, Y. and Wu, Z. and Shen, D.},
title={Learning longitudinal classification-regression model for infant hippocampus segmentation},
journal={Neurocomputing},
year={2020},
volume={391},
pages={191-198},
doi={10.1016/j.neucom.2019.01.108},
note={cited By 11},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064680496&doi=10.1016%2fj.neucom.2019.01.108&partnerID=40&md5=a80fa16f6d8d13eb54d3179d4d9b5cef},
abstract={Hippocampus plays an important role in the memory and spatial navigation function of human brain. Study on its growth and change during first year of life would assist the investigation of early brain development as well as the biomarker for neurological disorders. With the help of Magnetic Resonance (MR) imaging techniques, infant brain at different development stage can be acquired with multiple imaging modalities. In this situation, the longitudinal segmentation of infant hippocampus is highly demanded and feasible for the clinical studies regarding to the hippocampal volume changes. However, since the brain structures undergo dynamic appearance, structural changes and various tissue contrast during the first year of life, substantial challenges will be imposed for ensuring the robustness and accuracy of automatic hippocampus segmentation algorithms. In addition, most of the existing hippocampus segmentation methods generally handle each brain development stage independently without considering the potential longitudinal consistency among different stages. In view of the above factors, we propose a longitudinal classification-regression model for segmenting hippocampus in infant brain MRIs. Generally, our model proceeds on a per-timepoint basis, guided by the output of latter timepoint towards the infant hippocampus in the previous timepoint. The key ingredient of our method is a combination of longitudinal context, static context and appearance learning strategies under the classification-regression forest architecture. Specifically, the longitudinal context is borrowed from the mask of prior-timepoint estimation and the static context is from the current-timepoint estimation. Furthermore, we implement the proposed model in a multi-scale and iterative manner to improve the efficiency and effectiveness. The proposed method is evaluated on segmenting infant hippocampi from T1-weighted brain MR images acquired at the age of 2 weeks, 3 months, 6 months, 9 months, and 12 months. Experimental results demonstrate that our method achieves better performance in segmentation accuracy over the state-of-the-art classification and regression random forest model. © 2019 Elsevier B.V.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Abdulrahman2020,
author={Abdulrahman, S.A. and Khalifa, W. and Roushdy, M. and Salem, A.-B.M.},
title={Comparative study for 8 computational intelligence algorithms for human identification},
journal={Computer Science Review},
year={2020},
volume={36},
doi={10.1016/j.cosrev.2020.100237},
art_number={100237},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086180417&doi=10.1016%2fj.cosrev.2020.100237&partnerID=40&md5=d594bf19678f9941b56c5816158a2118},
abstract={The biometric system includes the algorithms, procedures, and devices which are utilized for the purpose of recognizing individuals according to their behavioral and physiological features. The approaches of Computational Intelligence (CI) are utilized extensively to establish biometric-based identities as well as overcoming non-idealities usually exist in samples. The objective of this paper is to analyze and evaluate the various computational intelligence (CI) approaches for the human identification based on biometrics. The study includes 8 top CI algorithms, namely; k-Nearest Neighbor(K-NN), Artificial Neural Networks (ANNs), Support vector machines (SVMs), Fuzzy Discernibility Matrix (FDM), Naïve Bayes (NB), k-means, Decision Trees (DTs), and Genetic algorithms (GAs). Also the study provides the technical characteristics and features of these algorithms as well as finds advantages and disadvantages of these methods. The analyzed algorithms can be selected according to quantity and quality of data presented at work. © 2020 Elsevier Inc.},
document_type={Review},
source={Scopus},
}

@ARTICLE{Rajinikanth2020,
author={Rajinikanth, V. and Raj, A.N.J. and Thanaraj, K.P. and Naik, G.R.},
title={A customized VGG19 network with concatenation of deep and handcrafted features for brain tumor detection},
journal={Applied Sciences (Switzerland)},
year={2020},
volume={10},
number={10},
doi={10.3390/app10103429},
art_number={3429},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085699438&doi=10.3390%2fapp10103429&partnerID=40&md5=f74fb0d4825bba64ef9c9647e14b925f},
abstract={Brain tumor (BT) is one of the brain abnormalities which arises due to various reasons. The unrecognized and untreated BT will increase the morbidity and mortality rates. The clinical level assessment of BT is normally performed using the bio-imaging technique, and MRI-assisted brain screening is one of the universal techniques. The proposed work aims to develop a deep learning architecture (DLA) to support the automated detection of BT using two-dimensional MRI slices. This work proposes the following DLAs to detect the BT: (i) implementing the pre-trained DLAs, such as AlexNet, VGG16, VGG19, ResNet50 and ResNet101 with the deep-features-based SoftMax classifier; (ii) pre-trained DLAs with deep-features-based classification using decision tree (DT), k nearest neighbor (KNN), SVM-linear and SVM-RBF; and (iii) a customized VGG19 network with serially-fused deep-features and handcrafted-features to improve the BT detection accuracy. The experimental investigation was separately executed using Flair, T2 and T1C modality MRI slices, and a ten-fold cross validation was implemented to substantiate the performance of proposed DLA. The results of this work confirm that the VGG19 with SVM-RBF helped to attain better classification accuracy with Flair (>99%), T2 (>98%), T1C (>97%) and clinical images (>98%). © 2020 by the authors.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Parker2020223,
author={Parker, A. and Poole, J. and Dagnall, N.},
title={Saccade-induced retrieval enhancement and the recovery of perceptual item-specific information},
journal={Cognitive Processing},
year={2020},
volume={21},
number={2},
pages={223-237},
doi={10.1007/s10339-019-00943-w},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076928834&doi=10.1007%2fs10339-019-00943-w&partnerID=40&md5=d42095cd8f9c59428dad0641b25fcebb},
abstract={Saccade-induced retrieval enhancement (SIRE) effects refer to the finding that memory can be enhanced when a short period of saccadic eye movements takes place prior to retrieval. Previous published work testifies to this eye movement advantage, but no work has yet examined if SIRE effects can be found when retrieval demands are high as a result of testing non-studied memoranda that are identical in name/conceptual codes, similar in perceptual features, but differ in terms of perceptual—item-specific information. The results indicate SIRE effects can be found under such conditions and are independent of encoding orientation (intentional vs. incidental). More particularly, SIRE effects manifested themselves in terms of the retrieval of item-specific detail and recollection (vs. familiarity). In terms of the latter, recollection but not familiarity was enhanced by eye movements. These findings are considered in the context of extant theories of SIRE and related research. © 2019, Marta Olivetti Belardinelli and Springer-Verlag GmbH Germany, part of Springer Nature.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Goceri2020882,
author={Goceri, E.},
title={CapsNet topology to classify tumours from brain images and comparative evaluation},
journal={IET Image Processing},
year={2020},
volume={14},
number={5},
pages={882-889},
doi={10.1049/iet-ipr.2019.0312},
note={cited By 6},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083236001&doi=10.1049%2fiet-ipr.2019.0312&partnerID=40&md5=d49afa2b17d9e4fd22b6dc8cbf178f5d},
abstract={Visual evaluation of many magnetic resonance images is a difficult task. Therefore, computer-assisted brain tumor classification techniques have been proposed. These techniques have several drawbacks or limitations. Capsule based neural networks are new approaches that can preserve spatial relationships of learned features using dynamic routing algorithm. By this way, not only performance of tumor recognition increases but also sampling efficiency and generalisation capability improves. Therefore, in this work, a Capsule Network (CapsNet) is used to achieve fully automated classification of tumors from brain magnetic resonance images. In this work, prevalent three types of tumors (pituitary, glioma and meningioma) have been handled. The main contributions in this paper are as follows: 1) A comprehensive review on CapsNet based methods is presented. 2) A new CapsNet topology is designed by using a Sobolev gradient-based optimisation, expectation-maximisation based dynamic routing and tumor boundary information. 3) The network topology is applied to categorise three types of brain tumors. 4) Comparative evaluations of the results obtained by other methods are performed. According to the experimental results, the proposed CapsNet based technique can achieve extraction of desired features from image data sets and provides tumor classification automatically with 92.65% accuracy. © The Institution of Engineering and Technology 2019.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Gudigar2020,
author={Gudigar, A. and Raghavendra, U. and Hegde, A. and Kalyani, M. and Ciaccio, E.J. and Rajendra Acharya, U.},
title={Brain pathology identification using computer aided diagnostic tool: A systematic review},
journal={Computer Methods and Programs in Biomedicine},
year={2020},
volume={187},
doi={10.1016/j.cmpb.2019.105205},
art_number={105205},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075552852&doi=10.1016%2fj.cmpb.2019.105205&partnerID=40&md5=63140623646a988acea678fb9f346f11},
abstract={Computer aided diagnostic (CAD) has become a significant tool in expanding patient quality-of-life by reducing human errors in diagnosis. CAD can expedite decision-making on complex clinical data automatically. Since brain diseases can be fatal, rapid identification of brain pathology to prolong patient life is an important research topic. Many algorithms have been proposed for efficient brain pathology identification (BPI) over the past decade. Constant refinement of the various image processing algorithms must take place to expand performance of the automatic BPI task. In this paper, a systematic survey of contemporary BPI algorithms using brain magnetic resonance imaging (MRI) is presented. A summarization of recent literature provides investigators with a helpful synopsis of the domain. Furthermore, to enhance the performance of BPI, future research directions are indicated. © 2019 Elsevier B.V.},
document_type={Review},
source={Scopus},
}

@ARTICLE{Liu2020462,
author={Liu, G.-D. and Li, Y.-C. and Zhang, W. and Zhang, L.},
title={A Brief Review of Artificial Intelligence Applications and Algorithms for Psychiatric Disorders},
journal={Engineering},
year={2020},
volume={6},
number={4},
pages={462-467},
doi={10.1016/j.eng.2019.06.008},
note={cited By 6},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072049509&doi=10.1016%2fj.eng.2019.06.008&partnerID=40&md5=02b5400f4363dedfa5e321d557a69de8},
abstract={A number of brain research projects have recently been carried out to study the etiology and mechanisms of psychiatric disorders. Although psychiatric disorders are part of the brain sciences, psychiatrists still diagnose them based on subjective experience rather than by gaining insights into the pathophysiology of the diseases. Therefore, it is urgent to have a clear understanding of the etiology and pathogenesis of major psychiatric diseases, which can help in the development of effective treatments and interventions. Artificial intelligence (AI)-based applications are being quickly developed for psychiatric research and diagnosis, but there is no systematic review that summarizes their applications. For this reason, this study briefly reviews three main brain observation techniques used to study psychiatric disorders—namely, magnetic resonance imaging (MRI), electroencephalography (EEG), and kinesics diagnoses—along with related AI applications and algorithms. Finally, we discuss the challenges, opportunities, and future study directions of AI-based applications. © 2020 THE AUTHORS},
document_type={Review},
source={Scopus},
}

@ARTICLE{Yao2020,
author={Yao, D. and Zhan, X. and Zhan, X. and Kwoh, C.K. and Li, P. and Wang, J.},
title={A random forest based computational model for predicting novel lncRNA-disease associations},
journal={BMC Bioinformatics},
year={2020},
volume={21},
number={1},
doi={10.1186/s12859-020-3458-1},
art_number={126},
note={cited By 5},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082524304&doi=10.1186%2fs12859-020-3458-1&partnerID=40&md5=aad56fc55d088b98efba112e79414b59},
abstract={Background: Accumulated evidence shows that the abnormal regulation of long non-coding RNA (lncRNA) is associated with various human diseases. Accurately identifying disease-associated lncRNAs is helpful to study the mechanism of lncRNAs in diseases and explore new therapies of diseases. Many lncRNA-disease association (LDA) prediction models have been implemented by integrating multiple kinds of data resources. However, most of the existing models ignore the interference of noisy and redundancy information among these data resources. Results: To improve the ability of LDA prediction models, we implemented a random forest and feature selection based LDA prediction model (RFLDA in short). First, the RFLDA integrates the experiment-supported miRNA-disease associations (MDAs) and LDAs, the disease semantic similarity (DSS), the lncRNA functional similarity (LFS) and the lncRNA-miRNA interactions (LMI) as input features. Then, the RFLDA chooses the most useful features to train prediction model by feature selection based on the random forest variable importance score that takes into account not only the effect of individual feature on prediction results but also the joint effects of multiple features on prediction results. Finally, a random forest regression model is trained to score potential lncRNA-disease associations. In terms of the area under the receiver operating characteristic curve (AUC) of 0.976 and the area under the precision-recall curve (AUPR) of 0.779 under 5-fold cross-validation, the performance of the RFLDA is better than several state-of-the-art LDA prediction models. Moreover, case studies on three cancers demonstrate that 43 of the 45 lncRNAs predicted by the RFLDA are validated by experimental data, and the other two predicted lncRNAs are supported by other LDA prediction models. Conclusions: Cross-validation and case studies indicate that the RFLDA has excellent ability to identify potential disease-associated lncRNAs. © 2020 The Author(s).},
document_type={Article},
source={Scopus},
}

@BOOK{Singh20201,
author={Singh, B. and Sharma, R.V.},
title={Secondary metabolites of medicinal plants: Ethnopharmacological properties, biological activity and production strategies},
journal={Secondary Metabolites of Medicinal Plants: Ethnopharmacological Properties, Biological Activity and Production Strategies},
year={2020},
pages={1-1508},
doi={10.1002/9783527825578},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099561599&doi=10.1002%2f9783527825578&partnerID=40&md5=66da694717aa016fe32b6fcbf64042cd},
abstract={Covers the structurally diverse secondary metabolites of medicinal plants, including their ethnopharmacological properties, biological activity, and production strategies Secondary metabolites of plants are a treasure trove of novel compounds with potential pharmaceutical applications. Consequently, the nature of these metabolites as well as strategies for the targeted expression and/or purification is of high interest. Regarding their biological and pharmacological activity and ethnopharmacological properties, this book offers a comprehensive treatment of 100 plant species, including Abutilon, Aloe, Cannabis, Capsicum, Jasminum, Malva, Phyllanthus, Stellaria, Thymus, Vitis, Zingiber, and more. It also discusses the cell culture conditions and various strategies used for enhancing the production of targeted metabolites in plant cell cultures. Secondary Metabolites of Medicinal Plants: Ethnopharmacological Properties, Biological Activity and Production Strategies is presented in four parts. Part I provides a complete introduction to the subject. Part II looks at the ethnomedicinal and pharmacological properties, chemical structures, and culture conditions of secondary metabolites. The third part examines the many strategies of secondary metabolites production, including: biotransformation; culture conditions; feeding of precursors; genetic transformation; immobilization; and oxygenation. The last section concludes with an overview of everything learned.-Provides information on cell culture conditions and targeted extraction of secondary metabolites confirmed by relevant literature -Presents the structures of secondary metabolites of 100 plant species together with their biological and pharmacological activity -Discusses plant species regarding their distribution, habitat, and ethnopharmacalogical properties-Presents strategies of secondary metabolites production, such as organ culture, pH, elicitation, hairy root cultures, light, and mutagenesis Secondary Metabolites of Medicinal Plants is an important book for students, professionals, and biotechnologists interested in the biological and pharmacological activity and ethnopharmacological properties of plants. © 2020 Wiley-VCH Verlag GmbH & Co. KGaA. All rights reserved.},
document_type={Book},
source={Scopus},
}

@ARTICLE{Molaei2020,
author={Molaei, S. and Shiri Ahmad Abadi, M.E.},
title={Maintaining filter structure: A Gabor-based convolutional neural network for image analysis},
journal={Applied Soft Computing},
year={2020},
volume={88},
doi={10.1016/j.asoc.2019.105960},
art_number={105960},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077086465&doi=10.1016%2fj.asoc.2019.105960&partnerID=40&md5=48c0c667f629cb7a53db9f63366f6430},
abstract={In image segmentation and classification tasks, utilizing filters based on the target object improves performance and requires less training data. We use the Gabor filter as initialization to gain more discriminative power. Considering the mechanism of the error backpropagation procedure to learn the data, after a few updates, filters will lose their initial structure. In this paper, we modify the updating rule in Gradient Descent to maintain the properties of Gabor filters. We use the Left Ventricle (LV) segmentation task and handwritten digit classification task to evaluate our proposed method. We compare Gabor initialization with random initialization and transfer learning initialization using convolutional autoencoders and convolutional networks. We experimented with noisy data and we reduced the amount of training data to compare how different methods of initialization can deal with these matters. The results show that the pixel predictions for the segmentation task are highly correlated with the ground truth. In the classification task, in addition to Gabor and random initialization, we initialized the network using pre-trained weights obtained from a convolutional Autoencoder using two different data sets and pre-trained weights obtained from a convolutional neural network. The experiments confirm the out-performance of Gabor filters comparing to the other initialization method even when using noisy inputs and a lesser amount of training data. © 2019 Elsevier B.V.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Frank2020,
author={Frank, M. and Drikakis, D. and Charissis, V.},
title={Machine-learning methods for computational science and engineering},
journal={Computation},
year={2020},
volume={8},
number={1},
doi={10.3390/computation8010015},
art_number={15},
note={cited By 6},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081747508&doi=10.3390%2fcomputation8010015&partnerID=40&md5=e1d3b7133e7356f63b774bc84ba7a0cc},
abstract={The re-kindled fascination in machine learning (ML), observed over the last few decades, has also percolated into natural sciences and engineering. ML algorithms are now used in scientific computing, as well as in data-mining and processing. In this paper, we provide a review of the state-of-the-art in ML for computational science and engineering. We discuss ways of using ML to speed up or improve the quality of simulation techniques such as computational fluid dynamics, molecular dynamics, and structural analysis. We explore the ability of ML to produce computationally efficient surrogate models of physical applications that circumvent the need for the more expensive simulation techniques entirely. We also discuss how ML can be used to process large amounts of data, using as examples many different scientific fields, such as engineering, medicine, astronomy and computing. Finally, we review how ML has been used to create more realistic and responsive virtual reality applications. © 2020 by the authors.},
document_type={Review},
source={Scopus},
}

@ARTICLE{Brunese2020,
author={Brunese, L. and Mercaldo, F. and Reginelli, A. and Santone, A.},
title={An ensemble learning approach for brain cancer detection exploiting radiomic features},
journal={Computer Methods and Programs in Biomedicine},
year={2020},
volume={185},
doi={10.1016/j.cmpb.2019.105134},
art_number={105134},
note={cited By 24},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074154276&doi=10.1016%2fj.cmpb.2019.105134&partnerID=40&md5=b49995e5dfb88c8f9c39aff032446979},
abstract={Background and Objective: The brain cancer is one of the most aggressive tumour: the 70% of the patients diagnosed with this malignant cancer will not survive. Early detection of brain tumours can be fundamental to increase survival rates. The brain cancers are classified into four different grades (i.e., I, II, III and IV) according to how normal or abnormal the brain cells look. The following work aims to recognize the different brain cancer grades by analysing brain magnetic resonance images. Methods: A method to identify the components of an ensemble learner is proposed. The ensemble learner is focused on the discrimination between different brain cancer grades using non invasive radiomic features. The considered radiomic features are belonging to five different groups: First Order, Shape, Gray Level Co-occurrence Matrix, Gray Level Run Length Matrix and Gray Level Size Zone Matrix. We evaluate the features effectiveness through hypothesis testing and through decision boundaries, performance analysis and calibration plots thus we select the best candidate classifiers for the ensemble learner. Results: We evaluate the proposed method with 111,205 brain magnetic resonances belonging to two freely available data-sets for research purposes. The results are encouraging: we obtain an accuracy of 99% for the benign grade I and the II, III and IV malignant brain cancer detection. Conclusion: The experimental results confirm that the ensemble learner designed with the proposed method outperforms the current state-of-the-art approaches in brain cancer grade detection starting from magnetic resonance images. © 2019 Elsevier B.V.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Moghadasi202038,
author={Moghadasi, M. and Fazekas, G.},
title={Multiple sclerosis lesion detection via machine learning algorithm based on converting 3D to 2D MRI images},
journal={Infocommunications Journal},
year={2020},
volume={12},
number={1},
pages={38-44},
doi={10.36244/ICJ.2020.1.6},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086004244&doi=10.36244%2fICJ.2020.1.6&partnerID=40&md5=95bbe847d0ccb8ad02e7522bf9efebcd},
abstract={In the twenty first century, there have been various scientific discoveries which have helped in addressing some of the fundamental health issues. Specifically, the discovery of machines which are able to assess the internal conditions of individuals has been a significant boost in the medical field. This paper or case study is the continuation of a previous research which aimed to create artificial models using support vector machines (SVM) to classify MS and normal brain MRI images, analyze the effectiveness of these models and their potential to use them in Multiple Sclerosis (MS) diagnosis. In the previous study presented at the Cognitive InfoCommunication (CogInfoCom 2019) conference, we intend to show that 3D images can be converted into 2D and by considering machine learning techniques and SVM tools. The previous paper concluded that SVM is a potential method which can be involved during MS diagnosis, however, in order to confirm this statement more research and other potentially effective methods should be included in the research and need to be tested. First, this study continues the research of SVM used for classification and Cellular Learning Automata (CLA), then it expands the research to other method such as Artificial Neural Networks (ANN) and k-Nearest Neighbor (k-NN) and then compares the results of these. © 2020 Scientific Association for Infocommunications. All rights reserved.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Lazli2020,
author={Lazli, L. and Boukadoum, M. and Mohamed, O.A.},
title={A survey on computer-aided diagnosis of brain disorders through MRI based on machine learning and data mining methodologies with an emphasis on Alzheimer disease diagnosis and the contribution of the multimodal fusion},
journal={Applied Sciences (Switzerland)},
year={2020},
volume={10},
number={5},
doi={10.3390/app10051894},
art_number={1894},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082082517&doi=10.3390%2fapp10051894&partnerID=40&md5=4e4bb51b8a96d1ba4ad846559dc4b99f},
abstract={Computer-aided diagnostic (CAD) systems use machine learning methods that provide a synergistic effect between the neuroradiologist and the computer, enabling an efficient and rapid diagnosis of the patient's condition. As part of the early diagnosis of Alzheimer's disease (AD), which is a major public health problem, the CAD system provides a neuropsychological assessment that helps mitigate its effects. The use of data fusion techniques by CAD systems has proven to be useful, they allow for the merging of information relating to the brain and its tissues from MRI, with that of other types of modalities. This multimodal fusion refines the quality of brain images by reducing redundancy and randomness, which contributes to improving the clinical reliability of the diagnosis compared to the use of a single modality. The purpose of this article is first to determine the main steps of the CAD system for brain magnetic resonance imaging (MRI). Then to bring together some research work related to the diagnosis of brain disorders, emphasizing AD. Thus the most used methods in the stages of classification and brain regions segmentation are described, highlighting their advantages and disadvantages. Secondly, on the basis of the raised problem, we propose a solution within the framework of multimodal fusion. In this context, based on quantitative measurement parameters, a performance study of multimodal CAD systems is proposed by comparing their effectiveness with those exploiting a single MRI modality. In this case, advances in information fusion techniques in medical imagery are accentuated, highlighting their advantages and disadvantages. The contribution of multimodal fusion and the interest of hybrid models are finally addressed, as well as the main scientific assertions made, in the field of brain disease diagnosis. © 2020 by the authors.},
document_type={Review},
source={Scopus},
}

@ARTICLE{Xiao2020796,
author={Xiao, L. and Stephen, J.M. and Wilson, T.W. and Calhoun, V.D. and Wang, Y.-P.},
title={A Manifold Regularized Multi-Task Learning Model for IQ Prediction from Two fMRI Paradigms},
journal={IEEE Transactions on Biomedical Engineering},
year={2020},
volume={67},
number={3},
pages={796-806},
doi={10.1109/TBME.2019.2921207},
art_number={8731721},
note={cited By 5},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074683316&doi=10.1109%2fTBME.2019.2921207&partnerID=40&md5=1364cd895af12a242a1b16ff254c359c},
abstract={Objective: Multi-modal brain functional connectivity (FC) data have shown great potential for providing insights into individual variations in behavioral and cognitive traits. The joint learning of multi-modal data can utilize intrinsic association, and thus can boost learning performance. Although several multi-task based learning models have already been proposed by viewing feature learning on each modality as one task, most of them ignore the structural information inherent across the modalities, which may play an important role in extracting discriminative features. Methods: In this paper, we propose a new manifold regularized multi-task learning model by simultaneously considering between-subject and between-modality relationships. Specifically, the l{2,1}-norm (i.e., group-sparsity) regularizer is enforced to jointly select a few common features across different modalities. A novelly designed manifold regularizer is further imposed as a crucial underpinning to preserve the structural information both within and between modalities. Such designed regularizers will make our model more adaptive to realistic neuroimaging data, which are usually of small sample size but high dimensional features. Results: Our model is validated on the Philadelphia Neurodevelopmental Cohort dataset, where our modalities are regarded as two types of functional MRI (fMRI) data collected under two paradigms. We conduct experimental studies on fMRI-based FC network data in two task conditions for intelligence quotient (IQ) prediction. The results show that our proposed model can not only achieve improved prediction performance, but also yield a set of IQ-relevant biomarkers. Conclusion and Significance: This paper develops a new multi-task learning model, enabling the discovery of significant biomarkers that may account for a proportion of the variance in human intelligence. © 1964-2012 IEEE.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Zhang2020,
author={Zhang, J. and Tan, L. and Tao, X. and Pham, T. and Chen, B.},
title={Relational intelligence recognition in online social networks-A survey},
journal={Computer Science Review},
year={2020},
volume={35},
doi={10.1016/j.cosrev.2019.100221},
art_number={100221},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083112402&doi=10.1016%2fj.cosrev.2019.100221&partnerID=40&md5=bbc9e5286d5c03ae08df02114e35686f},
abstract={Information networks today play an important, fundamental role in regulating real life activities. However, many methods developed on this framework lack the capacity to adequately represent sophistication contained within the information it carries. As a result, they suffer from problems such as inaccuracies, reliability and performance. We define relational intelligence as a combination of affective (Cambria, 2016; 2015 [1,2]; Hidalgo et al., 2015 [3]), sentimental (Ferrara and Yang, 2015 [4]; Wang et al., 2013 [5]; Madhoushi et al., 2015 [6]) and ethical (Vayena et al., 2015 [7]; Nunan and Di Domenico, 2013 [8]; Anderson and Guyton, 2013 [9]) developments reflected in the evolving patterns of online social structures. These developments involve the ability of actors to adaptively regulate emotions, values, interest and demands between each other in an online social scene. In this paper, we provide a state-of-the-art overview of approaches used in recognizing relational intelligence-with special focus given to Online Social Networks (OSNs). The important core processes of data mining, identification (extraction), detection (labeling), classification, prediction and learning which empower machine recognition tasks will be discussed in detail. In addition, widely affected applications like recommending, ranking, influence, topic modeling, evolution, etc. will also be introduced along with their basic concepts uncovered to a detailed degree. We also include some discussions on more advanced topics that point to further interesting future research directions. © 2020 Elsevier Inc.},
document_type={Review},
source={Scopus},
}

@ARTICLE{Naeser2020115,
author={Naeser, M.A. and Ho, M.D. and Martin, P.I. and Hamblin, M.R. and Koo, B.-B.},
title={Increased Functional Connectivity Within Intrinsic Neural Networks in Chronic Stroke Following Treatment with Red/Near-Infrared Transcranial Photobiomodulation: Case Series with Improved Naming in Aphasia},
journal={Photobiomodulation, Photomedicine, and Laser Surgery},
year={2020},
volume={38},
number={2},
pages={115-131},
doi={10.1089/photob.2019.4630},
note={cited By 7},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079471050&doi=10.1089%2fphotob.2019.4630&partnerID=40&md5=3d0487cd5700b533f47673f924944203},
abstract={Objective: To examine effects of four different transcranial, red/near-infrared (NIR), light-emitting diode (tLED) protocols on naming ability in persons with aphasia (PWA) due to left hemisphere (LH) stroke. This is the first study to report beneficial effects from tLED therapy in chronic stroke, and parallel changes on functional magnetic resonance imaging (fMRI). Materials and methods: Six PWA, 2-18 years poststroke, in whom 18 tLED treatments were applied (3 × /week, 6 weeks) using LED cluster heads: 500 mW, red (633 nm) and NIR (870 nm), 22.48 cm2, 22.2 mW/cm2. Results: After Protocol A with bilateral LED placements, including midline, at scalp vertex over left and right supplementary motor areas (L and R SMAs), picture naming was not improved. P1 underwent pre-/postovert, picture-naming task-fMRI scans; P2 could not. After Protocol A, P1 showed increased activation in LH and right hemisphere, including L and R SMAs. After Protocol B with LEDs only on ipsilesional, LH side, naming ability significantly improved for P1 and P2; the fMRI scans for P1 then showed activation only on the ipsilesional LH side. After Protocol C with LED placements on ipsilesional LH side, plus one midline placement over mesial prefrontal cortex (mPFC) at front hairline, a cortical node of the default mode network (DMN), P3 and P4 had only moderate/poor response, and no increase in functional connectivity on resting-state functional-connectivity MRI. After Protocol D, however, with LED placements on ipsilesional LH side, plus over two midline nodes of DMN, mPFC, and precuneus (high parietal) simultaneously, P5 and P6 each had good response with significant increase in functional connectivity within DMN, p &lt; 0.0005; salience network, p &lt; 0.0005; and central executive network, p &lt; 0.05. Conclusions: NIR photons can affect surface brain cortex areas subjacent to where LEDs are applied on the scalp. Improved naming ability was present with optimal Protocol D. Transcranial photobiomodulation may be an additional noninvasive therapy for stroke. © Copyright 2020, Mary Ann Liebert, Inc., publishers 2020.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Xiao2020478,
author={Xiao, L. and Wei, F. and Zhou, Y. and Anderson, G.J. and Frazer, D.M. and Lim, Y.C. and Liu, T. and Xiao, Y.},
title={Dihydrolipoic acid-gold nanoclusters regulate microglial polarization and have the potential to alter neurogenesis},
journal={Nano Letters},
year={2020},
volume={20},
number={1},
pages={478-495},
doi={10.1021/acs.nanolett.9b04216},
note={cited By 9},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077761276&doi=10.1021%2facs.nanolett.9b04216&partnerID=40&md5=53d3e9552568dba8688c69525ac92c38},
abstract={Microglia-mediated neuroinflammation is one of the most significant features in a variety of central nervous system (CNS) disorders such as traumatic brain injury, stroke, and many neurodegenerative diseases. Microglia become polarized upon stimulation. The two extremes of the polarization are the neuron-destructive proinflammatory M1-like and the neuron-regenerative M2-like phenotypes. Thus, manipulating microglial polarization toward the M2 phenotype is a promising therapeutic approach for CNS repair and regeneration. It has been reported that nanoparticles are potential tools for regulating microglial polarization. Gold nanoclusters (AuNCs) could penetrate the blood-brain barrier and have neuroprotective effects, suggesting the possibility of utilizing AuNCs to regulate microglial polarization and improve neuronal regeneration in CNS. In the current study, AuNCs functionalized with dihydrolipoic acid (DHLA-AuNCs), an antioxidant with demonstrated neuroprotective roles, were prepared, and their effects on polarization of a microglial cell line (BV2) were examined. DHLA-AuNCs effectively suppressed proinflammatory processes in BV2 cells by inducing polarization toward the M2-like phenotype. This was associated with a decrease in reactive oxygen species and reduced NF-kB signaling and an improvement in cell survival coupled with enhanced autophagy and inhibited apoptosis. Conditioned medium from DHLA-AuNC-treated BV2 cells was able to enhance neurogenesis in both the neuronal cell line N2a and in an ex vivo brain slice stroke model. The direct treatment of brain slices with DHLA-AuNCs also ameliorated stroke-related tissue injury and reduced astrocyte activation (astrogliosis). This study suggests that by regulating neuroinflammation to improve neuronal regeneration, DHLA-AuNCs could be a potential therapeutic agent in CNS disorders. © 2019 American Chemical Society.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Alizadeh2020,
author={Alizadeh, S.M. and Mahloojifar, A.},
title={Automatic skin cancer detection in dermoscopy images by combining convolutional neural networks and texture features},
journal={International Journal of Imaging Systems and Technology},
year={2020},
doi={10.1002/ima.22490},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090928795&doi=10.1002%2fima.22490&partnerID=40&md5=0c07c902fde798a6b3ce64a5dcfb2125},
abstract={Melanoma is one of the most dangerous types of skin cancer that its early detection can save patients' lives. Computer-aided methods can be used for this early detection with acceptable performance. In this study, a system is proposed to detect melanoma automatically using an ensemble approach, including convolutional neural networks (CNNs) and image texture feature extraction. Two CNN models, a proposed network and the VGG-19, were employed to classify images in the CNN phase. Furthermore, texture features were extracted, and their dimension was reduced using kernel principal component analysis (kPCA) to improve the classification performance in the feature extraction-based phase. The results of each step were then combined to obtain the final diagnosis. The proposed method was evaluated on three databases, that is, ISIC 2016, ISIC 2019, and PH2. The accuracy, average precision, sensitivity, and specificity of the proposed method on the ISIC 2016 dataset were 85.2%, 66%, 52%, and 93.4%, respectively. These evaluation metrics for the ISIC 2019 database were obtained equal to 96.7%, 95.1%, 96.3%, and 97.1%, respectively. Furthermore, the accuracy, sensitivity, and specificity of the proposed method on the PH2 dataset were 97.5%, 100%, and 96.88%, respectively. According to the experimental results, the ensemble method improves the evaluation metrics compared to each phase separately. Besides, the proposed approach can increase the performance of melanoma detection, compared to previous studies. © 2020 Wiley Periodicals LLC},
document_type={Article},
source={Scopus},
}

@ARTICLE{Yu2020,
author={Yu, X. and Lu, S. and Guo, L. and Wang, S.-H. and Zhang, Y.-D.},
title={ResGNet-C: A graph convolutional neural network for detection of COVID-19},
journal={Neurocomputing},
year={2020},
doi={10.1016/j.neucom.2020.07.144},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099550067&doi=10.1016%2fj.neucom.2020.07.144&partnerID=40&md5=34df804e1ea41507e60cc86e78a49f44},
abstract={The widely spreading COVID-19 has caused thousands of hundreds of mortalities over the world in the past few months. Early diagnosis of the virus is of great significance for both of infected patients and doctors providing treatments. Chest Computerized tomography (CT) screening is one of the most straightforward techniques to detect pneumonia which was caused by the virus and thus to make the diagnosis. To facilitate the process of diagnosing COVID-19, we therefore developed a graph convolutional neural network ResGNet-C under ResGNet framework to automatically classify lung CT images into normal and confirmed pneumonia caused by COVID-19. In ResGNet-C, two by-products named NNet-C, ResNet101-C that showed high performance on detection of COVID-19 are simultaneously generated as well. Our best model ResGNet-C achieved an averaged accuracy at 0.9662 with an averaged sensitivity at 0.9733 and an averaged specificity at 0.9591 using five cross-validations on the dataset, which is comprised of 296 CT images. To our best knowledge, this is the first attempt at integrating graph knowledge into the COVID-19 classification task. Graphs are constructed according to the Euclidean distance between features extracted by our proposed ResNet101-C and then are encoded with the features to give the prediction results of CT images. Besides the high-performance system, which surpassed all state-of-the-art methods, our proposed graph construction method is simple, transferrable yet quite helpful for improving the performance of classifiers, as can be justified by the experimental results. © 2020 Elsevier B.V.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Zheng202080,
author={Zheng, Q. and Yang, M. and Tian, X. and Wang, X. and Wang, D.},
title={Rethinking the role of activation functions in deep convolutional neural networks for image classification},
journal={Engineering Letters},
year={2020},
volume={28},
number={1},
pages={80-92},
note={cited By 5},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079841030&partnerID=40&md5=ae5c8b73efba2776284e59ce34da96da},
abstract={Deep convolutional neural network used for image classification is an important part of deep learning and has great significance in the field of computer vision. Moreover, it helps humans to simulate the human brain more realistically, pointing out the direction for the development of artificial intelligence. In fact, the rapid development and its application of deep neural networks are due to the improvements of various activation functions. The activation function is one of the most critical parts of the neural networks, which provides the possibility of strong nonlinear fitting ability of the deep neural network. In this paper, we analyze how the activation function affects the deep neural network, and then analyzes and summarizes the development status and the performance of different activation functions. Based on these, we designed a new activation function to improve the classification performance of neural networks. Finally, we perform extensive classification experiments on the MNIST, CIFAR10/100, and ImageNet datasets, and compare various popular activation functions to provide a reference for the selection of activation functions when designing deep neural network models. Deep convolutional neural networks, including the four models AlexNet, VGGNet, GoogLeNet, and Network in Network (NIN), are used to observe the role of the activation function in training and testing phase. The experimental results show that the constructed deep convolutional neural networks based on the improved activation function not only have a faster convergence rate, but also can improve the image classification accuracy more effectively. © 2020, International Association of Engineers. All rights reserved.},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Bansal2020131,
author={Bansal, D. and Khanna, K. and Chhikara, R. and Dua, R.K. and Malhotra, R.},
title={Classification of Magnetic Resonance Images using Bag of Features for Detecting Dementia},
journal={Procedia Computer Science},
year={2020},
volume={167},
pages={131-137},
doi={10.1016/j.procs.2020.03.190},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084451088&doi=10.1016%2fj.procs.2020.03.190&partnerID=40&md5=3079630c6b480cca0a00508610b0f50e},
abstract={In this paper, a model is presented for classification of Dementia brain disease using magnetic resonance imaging. Bag of features (BOF) is used for extracting the features of MRI scans, which are classified using multi-class Support Vector Machine (SVM) for distinguishing the scans into three categories as demented, mildly cognitive impaired and normal controls. The Magnetic Resonance Images (MRI) used for the classification is obtained from ADNI database. The speeded up robust features are extracted using BOF approach. The experimental results showed the achievement of competitive performance in terms of classification accuracy using the proposed methodology. The BOF approach clubbed with SVM leads to an accuracy of 93%. © 2020 The Author(s).},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Malik20201196,
author={Malik, S. and Ullah, I. and Kim, D. and Lee, K.},
title={Heuristic and Statistical Prediction Algorithms Survey for Smart Environments},
journal={Journal of Information Processing Systems},
year={2020},
volume={16},
number={5},
pages={1196-1213},
doi={10.3745/JIPS.04.0191},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099236240&doi=10.3745%2fJIPS.04.0191&partnerID=40&md5=5e1a5ca6262b6de2b2b3f1418b42c929},
abstract={There is a growing interest in the development of smart environments through predicting the behaviors of inhabitants of smart spaces in the recent past. Various smart services are deployed in modern smart cities to facilitate residents and city administration. Prediction algorithms are broadly used in the smart fields in order to well equip the smart services for the future demands. Hence, an accurate prediction technology plays a vital role in the smart services. In this paper, we take out an extensive survey of smart spaces such as smart homes, smart farms and smart cars and smart applications such as smart health and smart energy. Our extensive survey is based on more than 400 articles and the final list of research studies included in this survey consist of 134 research papers selected using Google Scholar database for period of 2008 to 2018. In this survey, we highlight the role of prediction algorithms in each sub-domain of smart Internet of Things (IoT) environments. We also discuss the main algorithms which play pivotal role in a particular IoT subfield and effectiveness of these algorithms. The conducted survey provides an efficient way to analyze and have a quick understanding of state of the art work in the targeted domain. To the best of our knowledge, this is the very first survey paper on main categories of prediction algorithms covering statistical, heuristic and hybrid approaches for smart environments. © 2020. All rights reserved.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Jiang2020182,
author={Jiang, X.},
title={Isolated Chinese Sign Language Recognition Using Gray-Level Co-occurrence Matrix and Parameter-Optimized Medium Gaussian Support Vector Machine},
journal={Advances in Intelligent Systems and Computing},
year={2020},
volume={1014},
pages={182-193},
doi={10.1007/978-981-13-9920-6_19},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075622482&doi=10.1007%2f978-981-13-9920-6_19&partnerID=40&md5=136c51eb971cb018f4a1973a7cf361e2},
abstract={In order to recognize Chinese sign language more accurately, we proposed an efficient method using gray-level co-occurrence matrix (GLCM) and parameter-optimized medium Gaussian support vector machine (MGSVM). First, sign language images were acquired by digital camera or picked from video as keyframes, and then the hand shapes were segmented from background. Second, each image was resized to N × N size and converted into gray-level image. The number of intensity values in grayscale image was reduced from 256 to 8, and gray-level co-occurrence matrix was created. Third, the extracted and reduced features were sent to MGSVM; meanwhile, the classification was performed on a tenfold cross-validation. The experimental results of the 450 isolated Chinese sign language images from the 30 categories demonstrated that the GLCM–MGSVM achieved a classification accuracy of 85.3%, which was much higher than GLCM-DT (decision tree). Therefore, the GLCM-MGSVM was seen to be effective in classifying Chinese sign language. © Springer Nature Singapore Pte Ltd. 2020.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Skaria2020203580,
author={Skaria, S. and Al-Hourani, A. and Evans, R.J.},
title={Deep-learning methods for hand-gesture recognition using ultra-wideband radar},
journal={IEEE Access},
year={2020},
volume={8},
pages={203580-203590},
doi={10.1109/ACCESS.2020.3037062},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102904682&doi=10.1109%2fACCESS.2020.3037062&partnerID=40&md5=afb134bf4d6ed8b4147164361b54e6b8},
abstract={Using deep-learning techniques for analyzing radar signatures has opened new possibilities in the field of smart-sensing, especially in the applications of hand-gesture recognition. In this paper, we present a framework, using deep-learning techniques, to classify hand-gesture signatures generated from an ultra-wideband (UWB) impulse radar. We extract the signals of 14 different hand-gestures and represent each signature as a 3-dimensional tensor consisting of range-Doppler frame sequence. These signatures are passed to a convolutional neural network (CNN) to extract the unique features of each gesture, and are then fed to a classifier. We compare 4 different classification architectures to predict the gesture class, namely; (i) fully connected neural network (FCNN), (ii) k-Nearest Neighbours (k-NN), (iii) support vector machine (SVM), (iv) long short term memory (LSTM) network. The shape of the range-Doppler-frame tensor and the parameters of the classifiers are optimized in order to maximize the classification accuracy. The classification results of the proposed architectures show a high level of accuracy above 96 % and a very low confusion probability even between similar gestures. © 2020 Institute of Electrical and Electronics Engineers Inc.. All rights reserved.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Rajalingam2020,
author={Rajalingam, B. and Al-Turjman, F. and Santhoshkumar, R. and Rajesh, M.},
title={Intelligent multimodal medical image fusion with deep guided filtering},
journal={Multimedia Systems},
year={2020},
doi={10.1007/s00530-020-00706-0},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095852169&doi=10.1007%2fs00530-020-00706-0&partnerID=40&md5=7f9e7baa88090f8dfd22a2e2d1ca3176},
abstract={Medical image fusion is a synthesis of visual information present in any number of medical imaging inputs into a single fused image without any distortion or loss of detail. It enhances image quality by retaining specific features to improve the clinical applicability of medical imaging for treatment and evaluation of medical conditions. A big challenge in the processing of medical images is to incorporate the pathological features of the complement into one image. The fused image presents various challenges, such as existence of fusion artifacts, hardness of the base, comparison of medical image input, and computational cost. The techniques of hybrid multimodal medical image fusion (HMMIF) have been designed for pathologic studies, such as neurocysticercosis, degenerative and neoplastic diseases. Two domain algorithms based on HMMIF techniques have been developed in this research for various medical image fusion applications for MRI-SPECT, MRI-PET, and MRI-CT. NSCT is initially used in the proposed method to decompose the input images which give components of low and high frequency. The average fusion rule applies to NSCT components with low frequency. The NSCT high frequency components are fused by the law of full fusion. NSCTs high frequency is handled with directed image filtration scheme. The fused picture is obtained by taking inverse transformations from all frequency bands with the coefficients obtained from them. The methods suggested are contrasted with traditional approaches in the state of the art. Experimentation proves that the methods suggested are superior in terms of both qualitative and quantitative assessment. The fused images using proposed algorithms provide information useful for visualizing and understanding the diseases to the best of both sources’ modality. © 2020, Springer-Verlag GmbH Germany, part of Springer Nature.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Meng2020159897,
author={Meng, X. and Zhang, J.},
title={Anxiety Recognition of College Students Using a Takagi-Sugeno-Kang Fuzzy System Modeling Method and Deep Features},
journal={IEEE Access},
year={2020},
volume={8},
pages={159897-159905},
doi={10.1109/ACCESS.2020.3021092},
art_number={9184941},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091303824&doi=10.1109%2fACCESS.2020.3021092&partnerID=40&md5=83d27d7e0431be2b929519fa2095a277},
abstract={College students are the most active, most sensitive, and most prone group with respect to various psychological problems in contemporary society. In recent years, with the intensification of social competition, including various pressures such as studies, examinations, economic loss, emotional loss, and employment, the incidence of anxiety, depression and suicide rates has increased. To effectively pay attention to the psychological development of college students and to strengthen mental health education, this research proposes a method to automatically identify the anxiety of college students using a Takagi-Sugeno-Kang (TSK) fuzzy system and deep features. First, preprocess the collected EEG of college students. Secondly, use convolutional neural network (CNN) to extract deep features from the input data. Finally, TSK fuzzy system is used to classify features to obtain the final recognition result. Through experiments on standard data sets and self-made data sets, the experimental results verify the superiority of the anxiety identification method used in this study. The experimental results further demonstrate that the depth features have richer information than traditional features. The noise immunity of TSK fuzzy system makes it show good classification performance and generalization. The recognition results can quickly locate students with anxiety disorders and narrow the scope of investigation for students with psychological problems. The automatic recognition of college students' anxiety can improve the efficiency of schools and teachers in investigating students' psychological problems. This research has very good practical application value. © 2013 IEEE.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Zemmari20201,
author={Zemmari, A. and Benois-Pineau, J.},
title={Deep learning in mining of visual content},
journal={SpringerBriefs in Computer Science},
year={2020},
pages={1-110},
doi={10.1007/978-3-030-34376-7},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078850227&doi=10.1007%2f978-3-030-34376-7&partnerID=40&md5=cc6f8c3bad0324bb0b263e799d4fffd9},
document_type={Book Chapter},
source={Scopus},
}

@ARTICLE{Naheed2020315,
author={Naheed, N. and Shaheen, M. and Khan, S.A. and Alawairdhi, M. and Khan, M.A.},
title={Importance of features selection, attributes selection, challenges and future directions for medical imaging data: A review},
journal={CMES - Computer Modeling in Engineering and Sciences},
year={2020},
volume={125},
number={1},
pages={315-344},
doi={10.32604/cmes.2020.011380},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091395588&doi=10.32604%2fcmes.2020.011380&partnerID=40&md5=b8902a88ac8349bbce7bfb25aa22b142},
abstract={In the area of pattern recognition and machine learning, features play a key role in prediction. The famous applications of features are medical imaging, image classification, and name a few more. With the exponential growth of information investments in medical data repositories and health service provision, medical institutions are collecting large volumes of data. These data repositories contain details information essential to support medical diagnostic decisions and also improve patient care quality. On the other hand, this growth also made it difficult to comprehend and utilize data for various purposes. The results of imaging data can become biased because of extraneous features present in larger datasets. Feature selection gives a chance to decrease the number of components in such large datasets. Through selection techniques, ousting the unimportant features and selecting a subset of components that produces prevalent characterization precision. The correct decision to find a good attribute produces a precise grouping model, which enhances learning pace and forecast control. This paper presents a review of feature selection techniques and attributes selection measures for medical imaging. This review is meant to describe feature selection techniques in a medical domain with their pros and cons and to signify its application in imaging data and data mining algorithms. The review reveals the shortcomings of the existing feature and attributes selection techniques to multi-sourced data. Moreover, this review provides the importance of feature selection for correct classification of medical infections. In the end, critical analysis and future directions are provided. © 2020 Tech Science Press. All rights reserved.},
document_type={Review},
source={Scopus},
}

@ARTICLE{Adeel2020,
author={Adeel, A. and Khan, M.A. and Akram, T. and Sharif, A. and Yasmin, M. and Saba, T. and Javed, K.},
title={Entropy-controlled deep features selection framework for grape leaf diseases recognition},
journal={Expert Systems},
year={2020},
doi={10.1111/exsy.12569},
note={cited By 12},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084429042&doi=10.1111%2fexsy.12569&partnerID=40&md5=552f770e2b74b709a0ba43e16b8480d9},
abstract={Several countries are most reliant on agriculture either in terms of employment opportunities, national income, availability of a raw material, food production, to name but a few. However, it faces a big challenge such as climate changes, diseases, pets, weeds etc. Therefore, last decade has provided a machine learning-based solution to the agricultural community, which helped farmers to identify the diseases at the early stages. In this article, our focus is on grape diseases, and proposes a novel framework to identify and classify the selected diseases at the early stages. A deep learning-based solution is embedded into a conventional architecture for optimal performance. Three primary steps are involved; (a) feature extraction after applying transfer learning on pre-trained deep models, AlexNet and ResNet101, (b) selection of best features using proposed Yager Entropy along with Kurtosis (YEaK) technique, (c) fusion of strong features using proposed parallel approach and later subject to classification step using least squared support vector machine (LS-SVM). The simulations are performed on infected grape leaves obtained from the plant village dataset to achieving an accuracy of 99%. From the simulation results, we sincerely believe that our proposed approach performed exceptionally compared to several existing methods. © 2020 John Wiley & Sons, Ltd},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Jiang202038714,
author={Jiang, Z.},
title={Spatial Structured Prediction Models: Applications, Challenges, and Techniques},
journal={IEEE Access},
year={2020},
volume={8},
pages={38714-38727},
doi={10.1109/ACCESS.2020.2975584},
art_number={9006803},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081533465&doi=10.1109%2fACCESS.2020.2975584&partnerID=40&md5=0b211042ebbde4a1ea42d403bd63ff5d},
abstract={Spatial structure patterns are prevalent in many real-world data and applications. For example, in biochemistry, the geometric topology of a molecular surface indicates protein functions; in hydrology, irregular geographic terrains and topography on the Earth's surface control water flows and distributions; in civil engineering, wetland parcels in remote sensing imagery are often made up of contiguous patches. Spatial structured prediction aims to learn a prediction model whose input and output data contain a spatial structure. Modeling spatial structural information in prediction models is critical for interdisciplinary applications due to two reasons. First, explicit spatial structural information often indicates the underlying physical process, and thus enhances model interpretability. Second, spatial structural constraints also have positive side-effects of enhancing model robustness against noise and obstacles and regularizing model learning when training labels are limited. However, spatial structured prediction also poses several unique challenges, such as the existence of implicit spatial structure in continuous space, structural complexity in geometric topology, and high computational costs. Over the years, various techniques have been proposed for spatial structured prediction in different applications. This paper aims to provide an overview of the spatial structured prediction problem. We provide a taxonomy of techniques based on the underlying approaches. We also discuss several future research directions. The paper can potentially not only help interdisciplinary researchers find relevant techniques but also help machine learning researchers identify new research opportunities. © 2013 IEEE.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Sharif2020273,
author={Sharif, M. and Amin, J. and Nisar, M.W. and Anjum, M.A. and Muhammad, N. and Ali Shad, S.},
title={A unified patch based method for brain tumor detection using features fusion},
journal={Cognitive Systems Research},
year={2020},
volume={59},
pages={273-286},
doi={10.1016/j.cogsys.2019.10.001},
note={cited By 6},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073749736&doi=10.1016%2fj.cogsys.2019.10.001&partnerID=40&md5=4b0f89ae435bb5fe79c39e09c5afef11},
abstract={The manuscript authenticates the effectiveness of fusing texture and geometrical (GEO) features in magnetic resonance imaging (MRI) for tumor classification. The presented technique is evaluated on two MRI including T2 and FLAIR. The tumor region is enhanced using fast non-local mean (FNLM) method with 4 × 4 patch size. Otsu algorithm is used for tumor segmentation. Moreover, multiple features are extracted for example local binary pattern (LBP), histogram of oriented gradients (HOG) and GEO (area, circularity, filled area, and perimeter) across each segmented image. These acquired features are merged into a single dimensional vector for prediction. In the end, the fused vector is used with multiple classifiers which proved that features fusion provides good results as compared with individual features. © 2019 Elsevier B.V.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Sun2020184360,
author={Sun, M.-L. and Liu, Y. and Liu, G. and Cui, D. and Heidari, A.A. and Jia, W.-Y. and Ji, X. and Chen, H. and Luo, Y.},
title={Application of machine learning to stomatology: A comprehensive review},
journal={IEEE Access},
year={2020},
volume={8},
pages={184360-184374},
doi={10.1109/ACCESS.2020.3028600},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102845761&doi=10.1109%2fACCESS.2020.3028600&partnerID=40&md5=9306e77df001afcc9330c20cdaff0c4b},
abstract={In recent years, machine learning methods has been widely used in various fields, such as finance, spatial sciences, smart grid, intelligent transportation, renewable energy, agriculture, especially medicine. In the era of big medical data, the advantage of machine learning is that it can predict and diagnose through the analysis of a large number of clinical data, and its performance is very close and competitive to or even better than the performance of clinicians. This article focuses on the application of machine learning techniques in the field of stomatology and detailedly describes application cases involving oral cancer, dental caries, periodontitis, dental pulp diseases, periapical lesions, oral implants, and orthodontics. Finally, the research obstacles and future work are discussed. © 2020 Institute of Electrical and Electronics Engineers Inc.. All rights reserved.},
document_type={Review},
source={Scopus},
}

@ARTICLE{Shaikh2020,
author={Shaikh, T.A. and Ali, R. and Beg, M.M.S.},
title={Transfer learning privileged information fuels CAD diagnosis of breast cancer},
journal={Machine Vision and Applications},
year={2020},
volume={31},
number={1},
doi={10.1007/s00138-020-01058-5},
art_number={9},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078941958&doi=10.1007%2fs00138-020-01058-5&partnerID=40&md5=4acaecafeb58fc9f26cb63933844a649},
abstract={The efficiency in breast cancer from imaging-based computer-aided diagnosis (CAD) has been revealed in recent years. As a fact, the methods grounded on a single modality constantly lack behind multimodal CAD imaging. However, owing to the restrictions of imaging devices, expressly in rural hospitals, single-modal imaging becomes a favorite in clinical practice for diagnosis. A fresh learning model trending nowadays known as learning using privileged information (LUPI) adopts additional privileged information (PI) modality to help during the training stage, but PI does not contribute in the testing stage. Meanwhile, the link exists between PI and training samples; the same is then reassigned to the learned model. We propose a LUPI-based CAD framework for breast cancer using privileged information in this work. The work offers both a classifier- or feature-level LUPI, in which the information is shifted from the additional PI modality to the diagnosis modality. A thorough comparison has been made among six classifier-level algorithms and six feature-level LUPI algorithms. The experimental results on both the acquired primary datasets show that all classifier-level and deep learning-based feature-level LUPI algorithms can enhance the performance of a single-modal imaging-based CAD for breast cancer by relocating PI. © 2020, Springer-Verlag GmbH Germany, part of Springer Nature.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Gonzalez-Lopez2020177995,
author={Gonzalez-Lopez, J.A. and Gomez-Alanis, A. and Martín Doñas, J.M. and Pérez-Córdoba, J.L. and Gomez, A.M.},
title={Silent speech interfaces for speech restoration: A review},
journal={IEEE Access},
year={2020},
volume={8},
pages={177995-178021},
doi={10.1109/ACCESS.2020.3026579},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101181371&doi=10.1109%2fACCESS.2020.3026579&partnerID=40&md5=7cc864b4fab51d72d7c9e0e9353fd30f},
abstract={This review summarises the status of silent speech interface (SSI) research. SSIs rely on non-acoustic biosignals generated by the human body during speech production to enable communication whenever normal verbal communication is not possible or not desirable. In this review, we focus on the first case and present latest SSI research aimed at providing new alternative and augmentative communication methods for persons with severe speech disorders. SSIs can employ a variety of biosignals to enable silent communication, such as electrophysiological recordings of neural activity, electromyographic (EMG) recordings of vocal tract movements or the direct tracking of articulator movements using imaging techniques. Depending on the disorder, some sensing techniques may be better suited than others to capture speech-related information. For instance, EMG and imaging techniques are well suited for laryngectomised patients, whose vocal tract remains almost intact but are unable to speak after the removal of the vocal folds, but fail for severely paralysed individuals. From the biosignals, SSIs decode the intended message, using automatic speech recognition or speech synthesis algorithms. Despite considerable advances in recent years, most present-day SSIs have only been validated in laboratory settings for healthy users. Thus, as discussed in this paper, a number of challenges remain to be addressed in future research before SSIs can be promoted to real-world applications. If these issues can be addressed successfully, future SSIs will improve the lives of persons with severe speech impairments by restoring their communication capabilities. © 2020 Institute of Electrical and Electronics Engineers Inc.. All rights reserved.},
document_type={Review},
source={Scopus},
}

@ARTICLE{Alam2020152377,
author={Alam, A. and Ullah, I. and Lee, Y.-K.},
title={Video Big Data Analytics in the Cloud: A Reference Architecture, Survey, Opportunities, and Open Research Issues},
journal={IEEE Access},
year={2020},
volume={8},
pages={152377-152422},
doi={10.1109/ACCESS.2020.3017135},
art_number={9169636},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090778099&doi=10.1109%2fACCESS.2020.3017135&partnerID=40&md5=65b52f718d8dcdc4293f99cf0cad0c0d},
abstract={The proliferation of multimedia devices over the Internet of Things (IoT) generates an unprecedented amount of data. Consequently, the world has stepped into the era of big data. Recently, on the rise of distributed computing technologies, video big data analytics in the cloud has attracted the attention of researchers and practitioners. The current technology and market trends demand an efficient framework for video big data analytics. However, the current work is too limited to provide a complete survey of recent research work on video big data analytics in the cloud, including the management and analysis of a large amount of video data, the challenges, opportunities, and promising research directions. To serve this purpose, we present this study, which conducts a broad overview of the state-of-the-art literature on video big data analytics in the cloud. It also aims to bridge the gap among large-scale video analytics challenges, big data solutions, and cloud computing. In this study, we clarify the basic nomenclatures that govern the video analytics domain and the characteristics of video big data while establishing its relationship with cloud computing. We propose a service-oriented layered reference architecture for intelligent video big data analytics in the cloud. Then, a comprehensive and keen review has been conducted to examine cutting-edge research trends in video big data analytics. Finally, we identify and articulate several open research issues and challenges, which have been raised by the deployment of big data technologies in the cloud for video big data analytics. To the best of our knowledge, this is the first study that presents the generalized view of the video big data analytics in the cloud. This paper provides the research studies and technologies advancing the video analyses in the era of big data and cloud computing. © 2013 IEEE.},
document_type={Review},
source={Scopus},
}

@ARTICLE{Kumari2020,
author={Kumari, N. and Anwar, S. and Bhattacharjee, V.},
title={Correlation and Relief Attribute Rank-based Feature Selection Methods for Detection of Alcoholic Disorder Using Electroencephalogram Signals},
journal={IETE Journal of Research},
year={2020},
doi={10.1080/03772063.2020.1780166},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087500146&doi=10.1080%2f03772063.2020.1780166&partnerID=40&md5=4f0bda365313abf2c8dfb2325ab1fb2b},
abstract={Electroencephalogram signals capture the brain electrical activity and provide factual cues to examine the current condition of a person which can be efficacious to understand and analyze the performance of the brain’s functioning. EEG signal is used in the diagnosis and monitoring of many brain-related diseases and mental disorders such as seizure detection, sleep disorders, alcoholism, etc. The incessant and uncontrolled alcohol consumption can critically affect the brain’s functionality and inevitably lead to an Alcoholic Disorder (AD). The prime objective of this paper is to classify alcoholic and controlled subjects based on the detailed interpretation of their recorded EEG signals. In this paper, an alcoholism detection model is proposed using the combination of linear and non-linear features. The most descriptive features are extracted from EEG signals and two techniques namely Correlation-based and Relief attribute rank-based feature selection methods are being used to select the most prominent features to fulfil the objective. The selected features are considered as input to the various classifiers including SVM, LS-SVM, k-NN and Weighted k-NN to discriminate the alcoholic and controlled group. The performance of the proposed methodology is assessed using accuracy, sensitivity, specificity, confusion matrix and ROC metrices. The obtained results indicate that correlation-based selected features outperformed using LS-SVM classifiers with the highest sensitivity, specificity and accuracy of 100%, 99% and 99.5%, respectively. The area under curve for the LS-SVM classifier by implementing the features selected through correlation rank was found to be 1 which specify the best classification result. © 2020, © 2020 IETE.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Chahar2020147,
author={Chahar, R. and Kaur, D.},
title={A systematic review of the machine learning algorithms for the computational analysis in different domains},
journal={International Journal of Advanced Technology and Engineering Exploration},
year={2020},
volume={7},
number={71},
pages={147-164},
doi={10.19101/IJATEE.2020.762057},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097402893&doi=10.19101%2fIJATEE.2020.762057&partnerID=40&md5=ae2d4e52eab56297a9dcae883fdb7a95},
abstract={In this paper machine learning algorithms have been discussed and analyzed. It has been discussed considering computational aspects in different domains. These algorithms have the capability of building mathematical and analytical model. These models may be helpful in the decision-making process. This paper elaborates the computational analysis in three different ways. The background and analytical aspect have been presented with the learning application in the first phase. In the second phase detail literature has been explored along with the pros and cons of the applied techniques in different domains. Based on the literatures, gap identification and the limitations have been discussed and highlighted in the third phase. Finally, computational analysis has been presented along with the machine learning results in terms of accuracy. The results mainly focus on the exploratory data analysis, domain applicability and the predictive problems. Our systematic analysis shows that the applicability of machine learning is wide and the results may be improved based on these algorithms. It is also inferred from the literature analysis that at the applicability of machine learning algorithm has the capability in the performance improvement. The main methods discussed here are classification and regression trees (CART), logistic regression, naïve Bayes (NB), k-nearest neighbors (KNN), support vector machine (SVM) and decision tree (DT). The domain covered mainly are disease detection, business intelligence, industry automation and sentiment analysis. © 2020 Ravita Chahar and Deepinder Kaur.},
document_type={Review},
source={Scopus},
}

@ARTICLE{Simon2020117,
author={Simon, P. and Uma, V.},
title={Analyzing the Applicability of Intelligent Data Mining Techniques for Texture Classification},
journal={Advances in Intelligent Systems and Computing},
year={2020},
volume={1148},
pages={117-139},
doi={10.1007/978-981-15-3914-5_10},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084704272&doi=10.1007%2f978-981-15-3914-5_10&partnerID=40&md5=1e309de0bf1f50a1ba221675858a01c6},
abstract={Textures represent the irregularities and spatial arrangements of pixels in a surface. Textures are significant in representing any real-world object, and hence, the classification of various textures has significant application in today’s world especially with respect to medical, satellite images and visual inspection. Real-world textures are complex and more difficult to represent. We introduce the data mining techniques used in the image processing domain especially for classifying textures. Enormous amount of data is generated everyday. Data is mined for identifying knowledge by uncovering the hidden patterns in the data which are helpful in classification, prediction and decision-making. This paper explores the potential of using data mining techniques in texture classification domain. In this work, we also analyze the literature to find various data mining techniques applied for texture classification in different applications. Our objective is to present some recent developments in applying data mining to texture classification system. © 2020, Springer Nature Singapore Pte Ltd.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Ahmed2020,
author={Ahmed, Z. and Mohamed, K. and Zeeshan, S. and Dong, X.},
title={Artificial intelligence with multi-functional machine learning platform development for better healthcare and precision medicine},
journal={Database},
year={2020},
volume={2020},
doi={10.1093/database/baaa010},
art_number={baaa010},
note={cited By 12},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082042802&doi=10.1093%2fdatabase%2fbaaa010&partnerID=40&md5=d944dfd024801bdaebc242df19ff4460},
abstract={Precision medicine is one of the recent and powerful developments in medical care, which has the potential to improve the traditional symptom-driven practice of medicine, allowing earlier interventions using advanced diagnostics and tailoring better and economically personalized treatments. Identifying the best pathway to personalized and population medicine involves the ability to analyze comprehensive patient information together with broader aspects to monitor and distinguish between sick and relatively healthy people, which will lead to a better understanding of biological indicators that can signal shifts in health. While the complexities of disease at the individual level have made it difficult to utilize healthcare information in clinical decision-making, some of the existing constraints have been greatly minimized by technological advancements. To implement effective precision medicine with enhanced ability to positively impact patient outcomes and provide real-time decision support, it is important to harness the power of electronic health records by integrating disparate data sources and discovering patient-specific patterns of disease progression. Useful analytic tools, technologies, databases, and approaches are required to augment networking and interoperability of clinical, laboratory and public health systems, as well as addressing ethical and social issues related to the privacy and protection of healthcare data with effective balance. Developing multifunctional machine learning platforms for clinical data extraction, aggregation, management and analysis can support clinicians by efficiently stratifying subjects to understand specific scenarios and optimize decision-making. Implementation of artificial intelligence in healthcare is a compelling vision that has the potential in leading to the significant improvements for achieving the goals of providing real-time, better personalized and population medicine at lower costs. In this study, we focused on analyzing and discussing various published artificial intelligence and machine learning solutions, approaches and perspectives, aiming to advance academic solutions in paving the way for a new data-centric era of discovery in healthcare. © 2020 The Author(s) 2020. Published by Oxford University Press.},
document_type={Review},
source={Scopus},
}

@ARTICLE{Kontogianni202081,
author={Kontogianni, G. and Maglogiannis, I.},
title={A review on state-of-the-art computer-based approaches for the early recognition of malignant melanoma},
journal={Studies in Computational Intelligence},
year={2020},
volume={891},
pages={81-101},
doi={10.1007/978-3-662-61114-2_6},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083989516&doi=10.1007%2f978-3-662-61114-2_6&partnerID=40&md5=c5d8e40ccd6de00eef8c16c419486aed},
abstract={Cancer is a complex and intricate disease, and the scientific community has been struggling for decades to identify any feebleness or rudimentary characteristics to discover effective treatments. Melanoma continues to be a rare form of skin cancer but causes the majority of skin cancer-related deaths. The most common technique for the detection of melanoma is dermoscopy (or dermatoscopy or epiluminescence microscopy ELM), which performs the examination through an optical system (magnifying glass) with a light source (polarized light), allowing an in-depth visualization of features used for the diagnosis. Over the past decades, efforts have been made to create computer-based systems able to analyze such dermoscopy images, assisting the early detection of skin cancer, while also allowing repeatability of results. One major issue of image dermoscopy is the inability to detect early melanoma or cases that lack optical features. To deal with that issue researchers have focused lately on molecular techniques. The aim of this chapter is to present the state-of-the-art concerning the detection methods of malignant melanoma and describe the contributions made in this area of research. © Springer-Verlag GmbH Germany, part of Springer Nature 2020.},
document_type={Book Chapter},
source={Scopus},
}

@ARTICLE{Ung202013,
author={Ung, W.C. and Tang, T.B. and Yap, K.H. and Ebenezer, E.G.M. and Chin, P.S. and Nordin, N. and Chan, S.C. and Yip, H.L. and Lu, C.-K. and Kiguchi, M.},
title={Assessing Neural Compensation with Visuospatial Working Memory Load Using Near-Infrared Imaging},
journal={IEEE Transactions on Neural Systems and Rehabilitation Engineering},
year={2020},
volume={28},
number={1},
pages={13-22},
doi={10.1109/TNSRE.2019.2956459},
art_number={8915857},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078354243&doi=10.1109%2fTNSRE.2019.2956459&partnerID=40&md5=64eee0a12f3f5e5633fe2ba46ed15e63},
abstract={Alzheimer's disease is characterized by the progressive deterioration of cognitive abilities particularly working memory while mild cognitive impairment (MCI) represents its prodrome. It is generally believed that neural compensation is intact in MCI but absent in Alzheimer's disease. This study investigated the effects of increasing task load as a means to induce neural compensation through a novel visual working memory (VSWM) task using functional near-infrared spectroscopy (fNIRS). The bilateral prefrontal cortex (PFC) was explored due to its relevance in VSWM and neural compensation. A total of 31 healthy controls (HC), 12 patients with MCI and 18 patients with mild Alzheimer's disease (mAD) were recruited. Although all groups showed sensitivity in terms of behavioral performance (i.e. score) towards increasing task load (level 1 to 3), only in MCI load effect on cortical response (as measured by fNIRS) was significant. At lower task load, bilateral PFC activation did not differ between MCI and HC. Neural compensation in the form of hyperactivation was only noticeable in MCI with a moderate task load. Lack of hyperactivation in mAD, coupled with significantly poorer task performance across task loads, suggested the inability to compensate due to a greater degree of neurodegeneration. Our findings provided an insight into the interaction of cognitive load theory and neural compensatory mechanisms. The experiment results demonstrated the feasibility of inducing neural compensation with the proposed VSWM task at the right amount of cognitive load. This may provide a promising avenue to develop an effective cognitive training and rehabilitation for dementia population. © 2001-2011 IEEE.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Suciu20201092,
author={Suciu, M. and Ionescu, C.M. and Ciorita, A. and Tripon, S.C. and Nica, D. and Al-Salami, H. and Barbu-Tudoran, L.},
title={Applications of superparamagnetic iron oxide nanoparticles in drug and therapeutic delivery, and biotechnological advancements},
journal={Beilstein Journal of Nanotechnology},
year={2020},
volume={11},
pages={1092-1109},
doi={10.3762/BJNANO.11.94},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089487853&doi=10.3762%2fBJNANO.11.94&partnerID=40&md5=2db5efc3c8facf204abe8801e881bc7b},
abstract={Superparamagnetic iron oxide nanoparticles (SPIONs) have unique properties with regard to biological and medical applications. SPIONs have been used in clinical settings although their safety of use remains unclear due to the great differences in their structure and in intra-and inter-patient absorption and response. This review addresses potential applications of SPIONs in vitro (formulations), ex vivo (in biological cells and tissues) and in vivo (preclinical animal models), as well as potential biomedical applications in the context of drug targeting, disease treatment and therapeutic efficacy, and safety studies. © 2020 Suciu et al.},
document_type={Review},
source={Scopus},
}

@ARTICLE{Baker2020161,
author={Baker, B. and Castelli, D.},
title={Physical Activity and Sedentary Behavior Influences on Executive Function in Daily Living},
journal={Cognitive Science and Technology},
year={2020},
pages={161-181},
doi={10.1007/978-3-030-34784-0_9},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080951428&doi=10.1007%2f978-3-030-34784-0_9&partnerID=40&md5=27ac1957b84012912d0b00be0cd0f117},
abstract={Today, work and learning environments are obesogenic, as individuals of all ages are seated for more than 6 h a day. This is despite the emerging evidence that increased cerebral blood flow may enhance executive function, immediately following a brief bout of physical activity. This chapter will provide an overview of the direct and indirect effects of physical activity from both acute and chronic perspectives. In addition, brain imaging evidence will be described. Specifically, one subsection would overview the effects of sedentary (i.e., sitting) and active behavior (i.e., standing and walking) on O2 uptake and neural activation on brain function and structure. © 2020, Springer Nature Switzerland AG.},
document_type={Book Chapter},
source={Scopus},
}

@ARTICLE{Nowak20201,
author={Nowak, A.K. and Vallacher, R.R. and Praszkier, R. and Rychwalska, A. and Zochowski, M.},
title={In sync: The emergence of function in minds, groups and societies},
journal={Understanding Complex Systems},
year={2020},
pages={1-226},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083436882&partnerID=40&md5=37ad7d8a3547bc78b20d97a9fd9f0464},
document_type={Book Chapter},
source={Scopus},
}

@ARTICLE{Almajidy2020292,
author={Almajidy, R.K. and Mankodiya, K. and Abtahi, M. and Hofmann, U.G.},
title={A newcomer's guide to functional near infrared spectroscopy experiments},
journal={IEEE Reviews in Biomedical Engineering},
year={2020},
volume={13},
pages={292-308},
doi={10.1109/RBME.2019.2944351},
art_number={8873645},
note={cited By 5},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073743458&doi=10.1109%2fRBME.2019.2944351&partnerID=40&md5=60590ea3cfb71b739e58e0fa1974688a},
abstract={This review presents a practical primer for functional near-infrared spectroscopy (fNIRS) with respect to technology, experimentation, and analysis software. Its purpose is to jump-start interested practitioners considering utilizing a non-invasive, versatile, nevertheless challenging window into the brain using optical methods. We briefly recapitulate relevant anatomical and optical foundations and give a short historical overview. We describe competing types of illumination (trans-illumination, reflectance, and differential reflectance) and data collection methods (continuous wave, time domain and frequency domain). Basic components (light sources, detection, and recording components) of fNIRS systems are presented. Advantages and limitations of fNIRS techniques are offered, followed by a list of very practical recommendations for its use. A variety of experimental and clinical studies with fNIRS are sampled, shedding light on many brain-related ailments. Finally, we describe and discuss a number of freely available analysis and presentation packages suited for data analysis. In conclusion, we recommend fNIRS due to its ever-growing body of clinical applications, state-of-the-art neuroimaging technique and manageable hardware requirements. It can be safely concluded that fNIRS adds a new arrow to the quiver of neuro-medical examinations due to both its great versatility and limited costs. © 2008-2011 IEEE.},
document_type={Review},
source={Scopus},
}

@ARTICLE{Li2020123,
author={Li, R. and Rui, G. and Zhao, C. and Wang, C. and Fang, F. and Zhang, Y.},
title={Functional Network Alterations in Patients with Amnestic Mild Cognitive Impairment Characterized Using Functional Near-Infrared Spectroscopy},
journal={IEEE Transactions on Neural Systems and Rehabilitation Engineering},
year={2020},
volume={28},
number={1},
pages={123-132},
doi={10.1109/TNSRE.2019.2956464},
art_number={8922610},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078342961&doi=10.1109%2fTNSRE.2019.2956464&partnerID=40&md5=48f34c07463001bba4de8e8cb6dd120c},
abstract={Amnestic mild cognitive impairment (aMCI) is conceptualized as a cognitive disorder characterized by memory deficits. Patients with aMCI are treated as prodromal stage of Alzheimer's disease (AD) and have an increased likelihood of developing into AD. The investigation of aMCI is therefore fundamental to the early detection and intervention of AD. Growing evidence has shown that functional network alterations induced by cognition impairment can be captured by advanced neuroimaging techniques. In this study, functional near-infrared spectroscopy (fNIRS), an affordable, robust and portable neuroimaging modality, was employed to characterize the functional network in aMCI patients. FNIRS data were collected from 16 healthy controls and 16 aMCI patients using a digits verbal span task. Functional networks were constructed from temporal hemodynamic response signals. Graph-based indices were then calculated from the constructed brain networks to assess global and regional differences between the groups. Results suggested that brain networks in aMCI patients were characterized with higher integration as well as higher segregation compared to healthy controls. In addition, major regions of interest (ROIs) within frontal, temporal, precentral and parietal areas were identified to be associated with cognition impairment. Our findings validate the feasibility of utilizing fNIRS as a portable and reliable tool for the investigation of abnormal network alterations in patients with cognition decline. © 2001-2011 IEEE.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Riva20201035,
author={Riva, G. and Mancuso, V. and Cavedoni, S. and Stramba-Badiale, C.},
title={Virtual reality in neurorehabilitation: a review of its effects on multiple cognitive domains},
journal={Expert Review of Medical Devices},
year={2020},
volume={17},
number={10},
pages={1035-1061},
doi={10.1080/17434440.2020.1825939},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092172505&doi=10.1080%2f17434440.2020.1825939&partnerID=40&md5=efb2dee7ebe035b05f010f9b7311e873},
abstract={Introduction: Neurological diseases frequently cause adult-onset disability and have increased the demand for rehabilitative interventions. Neurorehabilitation has been progressively relying on computer-assisted programs and, more recently, on virtual reality (VR). Current reviews explore VR-based neurorehabilitation for assessing and treating the most common neurological pathologies. However, none of them explored specifically the impact of VR on multiple cognitive domains. Areas covered: The present work is a review of 6 years of literature (2015-2020) on VR in neurorehabilitation with the purpose of analyzing its effects on memory, attention, executive functions, language, and visuospatial ability. Expert opinion: Our review suggests that VR-based neurorehabilitation showed encouraging results for executive functions and visuospatial abilities particularly for both acute and neurodegenerative conditions. Conversely, memory, and attention outcomes are conflicting, and language did not show significant improvements following VR-based rehabilitation. Within five years, it is plausible that VR-based intervention would be provided in standalone and mobile-based platforms that won’t need a PC to work, with reduced latency and improved user interaction. © 2020 Informa UK Limited, trading as Taylor & Francis Group.},
document_type={Review},
source={Scopus},
}

@ARTICLE{Yanase2019,
author={Yanase, J. and Triantaphyllou, E.},
title={A systematic survey of computer-aided diagnosis in medicine: Past and present developments},
journal={Expert Systems with Applications},
year={2019},
volume={138},
doi={10.1016/j.eswa.2019.112821},
art_number={112821},
note={cited By 25},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071723603&doi=10.1016%2fj.eswa.2019.112821&partnerID=40&md5=127089f055320d9861c31b01265af2f0},
abstract={Computer-aided diagnosis (CAD) in medicine is the result of a large amount of effort expended in the interface of medicine and computer science. As some CAD systems in medicine try to emulate the diagnostic decision-making process of medical experts, they can be considered as expert systems in medicine. Furthermore, CAD systems in medicine may process clinical data that can be complex and/or massive in size. They do so in order to infer new knowledge from data and use that knowledge to improve their diagnostic performance over time. Therefore, such systems can also be viewed as intelligent systems because they use a feedback mechanism to improve their performance over time. The main aim of the literature survey described in this paper is to provide a comprehensive overview of past and current CAD developments. This survey/review can be of significant value to researchers and professionals in medicine and computer science. There are already some reviews about specific aspects of CAD in medicine. However, this paper focuses on the entire spectrum of the capabilities of CAD systems in medicine. It also identifies the key developments that have led to today's state-of-the-art in this area. It presents an extensive and systematic literature review of CAD in medicine, based on 251 carefully selected publications. While medicine and computer science have advanced dramatically in recent years, each area has also become profoundly more complex. This paper advocates that in order to further develop and improve CAD, it is required to have well-coordinated work among researchers and professionals in these two constituent fields. Finally, this survey helps to highlight areas where there are opportunities to make significant new contributions. This may profoundly impact future research in medicine and in select areas of computer science. © 2019 Elsevier Ltd},
document_type={Review},
source={Scopus},
}

@ARTICLE{Wang2019167,
author={Wang, Y. and Cang, S. and Yu, H.},
title={A survey on wearable sensor modality centred human activity recognition in health care},
journal={Expert Systems with Applications},
year={2019},
volume={137},
pages={167-190},
doi={10.1016/j.eswa.2019.04.057},
note={cited By 28},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068560371&doi=10.1016%2fj.eswa.2019.04.057&partnerID=40&md5=c2f3c593c23ed24fb4b57b21cd02e908},
abstract={Increased life expectancy coupled with declining birth rates is leading to an aging population structure. Aging-caused changes, such as physical or cognitive decline, could affect people's quality of life, result in injuries, mental health or the lack of physical activity. Sensor-based human activity recognition (HAR) is one of the most promising assistive technologies to support older people's daily life, which has enabled enormous potential in human-centred applications. Recent surveys in HAR either only focus on the deep learning approaches or one specific sensor modality. This survey aims to provide a more comprehensive introduction for newcomers and researchers to HAR. We first introduce the state-of-art sensor modalities in HAR. We look more into the techniques involved in each step of wearable sensor modality centred HAR in terms of sensors, activities, data pre-processing, feature learning and classification, including both conventional approaches and deep learning methods. In the feature learning section, we focus on both hand-crafted features and automatically learned features using deep networks. We also present the ambient-sensor-based HAR, including camera-based systems, and the systems which combine the wearable and ambient sensors. Finally, we identify the corresponding challenges in HAR to pose research problems for further improvement in HAR. © 2019},
document_type={Review},
source={Scopus},
}

@ARTICLE{Yin2019786,
author={Yin, J. and Cao, J. and Siuly, S. and Wang, H.},
title={An Integrated MCI Detection Framework Based on Spectral-temporal Analysis},
journal={International Journal of Automation and Computing},
year={2019},
volume={16},
number={6},
pages={786-799},
doi={10.1007/s11633-019-1197-4},
note={cited By 5},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074561508&doi=10.1007%2fs11633-019-1197-4&partnerID=40&md5=4ce7e88ce153cb090e2462c8cf4cf10d},
abstract={Aiming to differentiate between mild cognitive impairment (MCI) patients and elderly control subjects, this study proposes an integrated framework based on spectral-temporal analysis for the automatic analysis of resting-state electroencephalogram (EEG) recordings. This framework firstly eliminates noise by employing stationary wavelet transformation (SWT). Then, a set of features is extracted through spectral-temporal analysis. Next, a new wrapper algorithm, named three-dimensional (3-D) evaluation algorithm, is proposed to derive an optimal feature subset. Finally, the support vector machine (SVM) algorithm is adopted to identify MCI patients on the optimal feature subset. Decision tree and K-nearest neighbors (KNN) algorithms are also used to test the effectiveness of the selected feature subset. Twenty-two subjects are involved in experiments, of which eleven persons were in an MCI condition and the rest were elderly control subjects. Extensive experiments show that our method is able to classify MCI patients and elderly control subjects automatically and effectively, with the accuracy of 96.94% achieved by the SVM classifier. Decision tree and KNN algorithms also achieved superior results based on the optimal feature subset extracted by the proposed framework. This study is conducive to timely diagnosis and intervention for MCI patients, and therefore to delaying cognitive decline and dementia onset. © 2019, Institute of Automation, Chinese Academy of Sciences and Springer-Verlag GmbH Germany, part of Springer Nature.},
document_type={Article},
source={Scopus},
}

@BOOK{Chen2019119,
author={Chen, D.},
title={Nanocontainers for the encapsulation and delivery of antioxidants/nutrients to food},
journal={Smart Nanocontainers: Micro and Nano Technologies},
year={2019},
pages={119-136},
doi={10.1016/B978-0-12-816770-0.00008-3},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094211815&doi=10.1016%2fB978-0-12-816770-0.00008-3&partnerID=40&md5=e0a02bbb0a84a4d8ac46dafe5bbc9074},
abstract={Nanocontainers, a nanotechnology based on delivery system, have emerged as one of the most major and promising technologies of science. Due to the novel biological, physical, and chemical properties, this kind of nanotechnology has been widely explored in various scientific fields, such as medicine, pharmacy, food, biology, agriculture, and environment. Oxidative stress is shown to be implicated in the development of cancer, atherosclerosis, and other chronic diseases in humans that promote the exploration of novel antioxidants for the treatment of oxidative stress-related diseases and medical care food. But poor water solubility, low oral bioavailability after ingestion, weak target specificity, and undesirable flavor properties are the urgent problems of antioxidants/nutrients in oxidative stress and food application. Hence, to solve these problems of antioxidants/nutrients used in nutritional supplements, yoghourt, juice, wine, food, and so on, nanoantioxidant and nanonutrient formulations, loaded in nanocontainers, were developed with novel nanotechnology. Antioxidant-/nutrient-loaded nanocontainers can be fabricated through nanomicelles, liposomes, nanoemulsion, and being in microneedles. This chapter summarizes the nanocontainer with an emphasis in antioxidant/nutrient application advancement by these classifications. © 2020 Elsevier Inc. All rights reserved.},
document_type={Book Chapter},
source={Scopus},
}

@ARTICLE{Moretti2019,
author={Moretti, R. and Peinkhofer, C.},
title={B vitamins and fatty acids: What do they share with small vessel disease-related dementia?},
journal={International Journal of Molecular Sciences},
year={2019},
volume={20},
number={22},
doi={10.3390/ijms20225797},
art_number={5797},
note={cited By 11},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075333033&doi=10.3390%2fijms20225797&partnerID=40&md5=3321db0214b48388604462d40bc6c2d8},
abstract={Many studies have been written on vitamin supplementation, fatty acid, and dementia, but results are still under debate, and no definite conclusion has yet been drawn. Nevertheless, a significant amount of lab evidence confirms that vitamins of the B group are tightly related to gene control for endothelium protection, act as antioxidants, play a co-enzymatic role in the most critical biochemical reactions inside the brain, and cooperate with many other elements, such as choline, for the synthesis of polyunsaturated phosphatidylcholine, through S-adenosyl-methionine (SAM) methyl donation. B-vitamins have anti-inflammatory properties and act in protective roles against neurodegenerative mechanisms, for example, through modulation of the glutamate currents and a reduction of the calcium currents. In addition, they also have extraordinary antioxidant properties. However, laboratory data are far from clinical practice. Many studies have tried to apply these results in everyday clinical activity, but results have been discouraging and far from a possible resolution of the associated mysteries, like those represented by Alzheimer’s disease (AD) or small vessel disease dementia. Above all, two significant problems emerge from the research: No consensus exists on general diagnostic criteria—MCI or AD? Which diagnostic criteria should be applied for small vessel disease-related dementia? In addition, no general schema exists for determining a possible correct time of implementation to have effective results. Here we present an up-to-date review of the literature on such topics, shedding some light on the possible interaction of vitamins and phosphatidylcholine, and their role in brain metabolism and catabolism. Further studies should take into account all of these questions, with well-designed and world-homogeneous trials. © 2019 by the authors. Licensee MDPI, Basel, Switzerland.},
document_type={Review},
source={Scopus},
}

@ARTICLE{Hong2019,
author={Hong, K.-S. and Yaqub, M.A.},
title={Application of functional near-infrared spectroscopy in the healthcare industry: A review},
journal={Journal of Innovative Optical Health Sciences},
year={2019},
volume={12},
number={6},
doi={10.1142/S179354581930012X},
art_number={1930012},
note={cited By 18},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074420738&doi=10.1142%2fS179354581930012X&partnerID=40&md5=e685a533c4d7039297efb3aa9fbd97df},
abstract={Functional near-infrared spectroscopy (fNIRS), a growing neuroimaging modality, has been utilized over the past few decades to understand the neuronal behavior in the brain. The technique has been used to assess the brain hemodynamics of impaired cohorts as well as able-bodied. Neuroimaging is a critical technique for patients with impaired cognitive or motor behaviors. The portable nature of the fNIRS system is suitable for frequent monitoring of the patients who exhibit impaired brain activity. This study comprehensively reviews brain-impaired patients: The studies involving patient populations and the diseases discussed in more than 10 works are included. Eleven diseases examined in this paper include autism spectrum disorder, attention-deficit hyperactivity disorder, epilepsy, depressive disorders, anxiety and panic disorder, schizophrenia, mild cognitive impairment, Alzheimer's disease, Parkinson's disease, stroke, and traumatic brain injury. For each disease, the tasks used for examination, fNIRS variables, and significant findings on the impairment are discussed. The channel configurations and the regions of interest are also outlined. Detecting the occurrence of symptoms at an earlier stage is vital for better rehabilitation and faster recovery. This paper illustrates the usability of fNIRS for early detection of impairment and the usefulness in monitoring the rehabilitation process. Finally, the limitations of the current fNIRS systems (i.e., nonexistence of a standard method and the lack of well-established features for classification) and future research directions are discussed. The authors hope that the findings in this paper would lead to advanced breakthrough discoveries in the fNIRS field in the future. © 2019 The Author(s).},
document_type={Review},
source={Scopus},
}

@ARTICLE{Bavaresco2019,
author={Bavaresco, M.V. and D'Oca, S. and Ghisi, E. and Lamberts, R.},
title={Technological innovations to assess and include the human dimension in the building-performance loop: A review},
journal={Energy and Buildings},
year={2019},
volume={202},
doi={10.1016/j.enbuild.2019.109365},
art_number={109365},
note={cited By 10},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070913677&doi=10.1016%2fj.enbuild.2019.109365&partnerID=40&md5=f18365f27447d1f83d64d420e8f2478e},
abstract={The human dimension plays an essential role in the energy performance of buildings and is considered as significant as technological advances. Several studies highlighted the negative influence of occupant behaviour in underperforming buildings, while some support that technological innovations may reduce human-related uncertainties. Thus, one may consider that fully automated smart buildings are essential to achieve energy efficiency. However, if technology excludes people from decision-making processes, low acceptance and comfort/welfare levels may be reported from users. Therefore, the right combination of humans and technologies are expected to solve these problems. Buildings are emerging as complex Cyber-Physical Systems, including the Social dimension, and this provides an excellent opportunity to achieve high-performance outcomes, considering both technical and social aspects. Thus, the right choice among available up-to-date behavioural sensing – comprising active and passive sensors, as well as Kinect technology – are important in the Internet-of-Things (IoT) era. IoT-driven buildings can use real-time monitoring data to inform users and drive behavioural-based consumption change, which is an important aspect to achieve high-performance buildings and deliver user-centred services. An essential feature in this regard is to allow for human-in-the-loop approaches enabled by human-centric computing and smart devices, which has grown fast in the last few years. This literature review summarises applications and main challenges related to the combination of the human dimension and technological innovations in the building sector. This combination is expected to increase user welfare and reduce the energy consumption in buildings, as human and machine components of intelligence may complement each other regarding building performance. © 2019 Elsevier B.V.},
document_type={Review},
source={Scopus},
}

@BOOK{Ribary2019543,
author={Ribary, U. and Doesburg, S.M. and Ward, L.M.},
title={Unified principles of thalamocortical network dynamics: A framework for typical/atypical functional connectivity},
journal={Magnetoencephalography: From Signals to Dynamic Cortical Networks: Second Edition},
year={2019},
pages={543-570},
doi={10.1007/978-3-030-00087-5_19},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085724105&doi=10.1007%2f978-3-030-00087-5_19&partnerID=40&md5=f7911365b4dcfb927255a40c2cc9bc22},
abstract={In more recent years, there has been increased interest in understanding the brain's functional connectivity within local and long-range networks. The structure and functional dynamics connectivity at the cortical level has received considerable attention, the structural and functional dynamics of thalamocortical interactions are as yet insufficiently integrated with our knowledge of large-scale connectivity and regional function. An important question, yet to be answered in detail, is how typical cognitive functions and their alterations in neuropsychiatric pathologies are temporally generated across the entire brain space (thalamocortical, corticocortical, corticothalamic) based on intact or altered brain structure, function, and neurochemistry. We are reviewing MEG and related EEG research in the context of multimodal imaging findings, focusing on thalamocortical dynamics and their role in functional connectivity across corticocortical, and corticothalamic circuits, including oscillatory synchronization within and across the various frequency bands underlying cognition. We then further explore the cognitive consequences of various disruptions of thalamocortical and corticocortical dynamics, including slowing and selective loss of functional network dynamics in particular brain networks related to disabilities or neuropsychiatric pathologies. We are presenting an overview of current findings and their conceptual implications for how brain imaging technologies can further contribute to a better understanding of the unified principles of the brain's structural, functional, and temporal connectivity dynamics and their relationship to typical and atypical sensory-motor processing and cognition including consciousness. © Springer Nature Switzerland AG 2019. All rights are reserved.},
document_type={Book Chapter},
source={Scopus},
}

@ARTICLE{Ataloglou2019563,
author={Ataloglou, D. and Dimou, A. and Zarpalas, D. and Daras, P.},
title={Fast and Precise Hippocampus Segmentation Through Deep Convolutional Neural Network Ensembles and Transfer Learning},
journal={Neuroinformatics},
year={2019},
volume={17},
number={4},
pages={563-582},
doi={10.1007/s12021-019-09417-y},
note={cited By 10},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063058355&doi=10.1007%2fs12021-019-09417-y&partnerID=40&md5=b3af50355d05871f5bb4f9776d57052a},
abstract={Automatic segmentation of the hippocampus from 3D magnetic resonance imaging mostly relied on multi-atlas registration methods. In this work, we exploit recent advances in deep learning to design and implement a fully automatic segmentation method, offering both superior accuracy and fast result. The proposed method is based on deep Convolutional Neural Networks (CNNs) and incorporates distinct segmentation and error correction steps. Segmentation masks are produced by an ensemble of three independent models, operating with orthogonal slices of the input volume, while erroneous labels are subsequently corrected by a combination of Replace and Refine networks. We explore different training approaches and demonstrate how, in CNN-based segmentation, multiple datasets can be effectively combined through transfer learning techniques, allowing for improved segmentation quality. The proposed method was evaluated using two different public datasets and compared favorably to existing methodologies. In the EADC-ADNI HarP dataset, the correspondence between the method’s output and the available ground truth manual tracings yielded a mean Dice value of 0.9015, while the required segmentation time for an entire MRI volume was 14.8 seconds. In the MICCAI dataset, the mean Dice value increased to 0.8835 through transfer learning from the larger EADC-ADNI HarP dataset. © 2019, Springer Science+Business Media, LLC, part of Springer Nature.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Pal20191,
author={Pal, H. and Kumar, A.},
title={MSBE analysis with power metric for automated identification of epileptic seizure},
journal={International Journal of Engineering and Advanced Technology},
year={2019},
volume={9},
number={1},
pages={1-5},
doi={10.35940/ijeat.A1000.109119},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074561040&doi=10.35940%2fijeat.A1000.109119&partnerID=40&md5=2543d90ce8674ce14a1d91fd75c14a6c},
abstract={Objective-This study explores a novel application of multi scale bubble entropy analysis with power metric analysis to achieve efficient epileptic seizure prediction performance. Method-This paper aims to develop a reliable seizure detection technique that incorporates AM FM model for decomposition of EEG into different sub bands. The initially first feature set is formed by acquiring the absolute and relative power components at each electrode. Second feature set is constructed by multi scale bubble entropy analysis from each sub band. These two major feature vectors are fuse into an integrated feature space to perform classification task using ANN. Result-Experimental results show that this method presents: 1) Consistent increase in complexity measures, 2) Increase in stability & discrimination of power. These finding suggest that extracted features can be used for treatment of epilepsy. Significance-This method provides greater stability, so this technique could be used to detect wider range of seizures. © BEIESP.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Li20192869,
author={Li, P. and Liu, H. and Si, Y. and Li, C. and Li, F. and Zhu, X. and Huang, X. and Zeng, Y. and Yao, D. and Zhang, Y. and Xu, P.},
title={EEG Based Emotion Recognition by Combining Functional Connectivity Network and Local Activations},
journal={IEEE Transactions on Biomedical Engineering},
year={2019},
volume={66},
number={10},
pages={2869-2881},
doi={10.1109/TBME.2019.2897651},
art_number={8634938},
note={cited By 33},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073610483&doi=10.1109%2fTBME.2019.2897651&partnerID=40&md5=d43d62c5be48516b92d78ccb225f4b9b},
abstract={Spectral power analysis plays a predominant role in electroencephalogram-based emotional recognition. It can reflect activity differences among multiple brain regions. In addition to activation difference, different emotions also involve different large-scale network during related information processing. In this paper, both information propagation patterns and activation difference in the brain were fused to improve the performance of emotional recognition. Methods: We constructed emotion-related brain networks with phase locking value and adopted a multiple feature fusion approach to combine the compensative activation and connection information for emotion recognition. Results: Recognition results on three public emotional databases demonstrated that the combined features are superior to either single feature based on power distribution or network character. Furthermore, the conducted feature fusion analysis revealed the common characters between activation and connection patterns involved in the positive, neutral, and negative emotions for information processing. Significance: The proposed feasible combination of both information propagation patterns and activation difference in the brain is meaningful for developing the effective human-computer interaction systems by adapting to human emotions in the real world applications. © 1964-2012 IEEE.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Salehpour2019635,
author={Salehpour, F. and Majdi, A. and Pazhuhi, M. and Ghasemi, F. and Khademi, M. and Pashazadeh, F. and Hamblin, M.R. and Cassano, P.},
title={Transcranial Photobiomodulation Improves Cognitive Performance in Young Healthy Adults: A Systematic Review and Meta-Analysis},
journal={Photobiomodulation, Photomedicine, and Laser Surgery},
year={2019},
volume={37},
number={10},
pages={635-643},
doi={10.1089/photob.2019.4673},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074118227&doi=10.1089%2fphotob.2019.4673&partnerID=40&md5=4359e79f600511f88f6efaa1828741a4},
abstract={Background: Transcranial photobiomodulation (t-PBM) is a noninvasive modality that may improve cognitive function in both healthy and diseased subjects. Objective: This systematic review and meta-analysis addresses the question of whether t-PBM improves cognitive function in healthy adults. Methods: We searched MEDLINE using PubMed, EMBASE, SCOPUS, Web of Science, and Cochrane Library up to March 2019. We also searched ProQuest and Google Scholar databases for unpublished material. The search was limited to articles on the procognitive effects of t-PBM in healthy adults. The initial search resulted in 871 studies, of which nine publications met our criteria for inclusion and exclusion. Seven studies were performed on young, healthy subjects (17-35 years), and two studies were conducted on older (≥49 years), normal subjects. A meta-analysis was performed on six full-text publications whose subjects were young adults. Results: t-PBM administration improved cognition-related outcomes by an 0.833 standardized mean difference (SMD; 95% confidence interval (CI): 0.458-1.209, 14 comparisons) in young, healthy participants. Funnel plotting revealed asymmetry, which was validated using Egger's (p = 0.030) and Begg's regression (p = 0.006) tests. However after reanalysis, this asymmetry disappeared in the attention subgroup, but not in the memory subgroup. The trim-and-fill analysis indicated two studies were lacking required data. Thus, the effect size was adjusted from an SMD of 0.761 (95% CI: 0.573-0.949) to 0.949 (0.779-1.120). The overall quality score of the studies was modest. Conclusions: We demonstrated a significant, beneficial effect of t-PBM on cognitive performance of young, healthy individuals; however, the heterogeneity of the data was high. This could be due to the modest quality or to the low number of included studies, or to the differences between the various subdomains assessed. These shortcomings should be meticulously addressed before concluding that t-PBM is a cognitive-enhancing intervention in healthy individuals. © 2019, Mary Ann Liebert, Inc., publishers.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Jahmunah2019,
author={Jahmunah, V. and Lih Oh, S. and Rajinikanth, V. and Ciaccio, E.J. and Hao Cheong, K. and Arunkumar, N. and Acharya, U.R.},
title={Automated detection of schizophrenia using nonlinear signal processing methods},
journal={Artificial Intelligence in Medicine},
year={2019},
volume={100},
doi={10.1016/j.artmed.2019.07.006},
art_number={101698},
note={cited By 46},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071552541&doi=10.1016%2fj.artmed.2019.07.006&partnerID=40&md5=5d2a44ea5bfbc9441aa2177bfec61770},
abstract={Examination of the brain's condition with the Electroencephalogram (EEG) can be helpful to predict abnormality and cerebral activities. The purpose of this study was to develop an Automated Diagnostic Tool (ADT) to investigate and classify the EEG signal patterns into normal and schizophrenia classes. The ADT implements a sequence of events, such as EEG series splitting, non-linear features mining, t-test assisted feature selection, classification and validation. The proposed ADT is employed to evaluate a 19-channel EEG signal collected from normal and schizophrenia class volunteers. A dataset was created by splitting the raw 19-channel EEG into a sequence of 6250 sample points, which was helpful to produce 1142 features of normal and schizophrenia class patterns. Non-linear feature extraction was then implemented to mine 157 features from each EEG pattern, from which 14 of the principal features were identified based on significance. Finally, a signal classification practice with Decision-Tree (DT), Linear-Discriminant analysis (LD), k-Nearest-Neighbour (KNN), Probabilistic-Neural-Network (PNN), and Support-Vector-Machine (SVM) with various kernels was implemented. The experimental outcome showed that the SVM with Radial-Basis-Function (SVM-RBF) offered a superior average performance value of 92.91% on the considered EEG dataset, as compared to other classifiers implemented in this work. © 2019},
document_type={Article},
source={Scopus},
}

@ARTICLE{Kaur2019844,
author={Kaur, M. and Singh, K.},
title={Review on titanium and titanium based alloys as biomaterials for orthopaedic applications},
journal={Materials Science and Engineering C},
year={2019},
volume={102},
pages={844-862},
doi={10.1016/j.msec.2019.04.064},
note={cited By 188},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065387409&doi=10.1016%2fj.msec.2019.04.064&partnerID=40&md5=966c73de6292c05ec8e160f5c9db97ca},
abstract={Variety of implant materials have been employed in various disciplines of medical science depending on the requirement of a particular application. Metals, alloys, ceramics, and polymers are the commonly used biomaterials. The main focus of this study is to review the various structural and microstructural properties of titanium and titanium based alloys used as orthopaedic implants. Orthopaedic implants need to possess certain important qualities to ensure their safe and effective use. These properties like the biocompatibility, relevant mechanical properties, high corrosion and wear resistance and osseointegration are summarized in this review. Various attempts to improve upon these properties like different processing routes, surface modifications have also been inculcated in the paper to provide an insight into the extent of research and effort that has been put into developing a highly superior titanium orthopaedic implant. © 2019 Elsevier B.V.},
document_type={Review},
source={Scopus},
}

@ARTICLE{Balakrishnan20191788,
author={Balakrishnan, G. and Zhao, A. and Sabuncu, M.R. and Guttag, J. and Dalca, A.V.},
title={VoxelMorph: A Learning Framework for Deformable Medical Image Registration},
journal={IEEE Transactions on Medical Imaging},
year={2019},
volume={38},
number={8},
pages={1788-1800},
doi={10.1109/TMI.2019.2897538},
art_number={8633930},
note={cited By 164},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063580508&doi=10.1109%2fTMI.2019.2897538&partnerID=40&md5=4b32a688f82650d87ffaa908c22b053c},
abstract={We present VoxelMorph, a fast learning-based framework for deformable, pairwise medical image registration. Traditional registration methods optimize an objective function for each pair of images, which can be time-consuming for large datasets or rich deformation models. In contrast to this approach and building on recent learning-based methods, we formulate registration as a function that maps an input image pair to a deformation field that aligns these images. We parameterize the function via a convolutional neural network and optimize the parameters of the neural network on a set of images. Given a new pair of scans, VoxelMorph rapidly computes a deformation field by directly evaluating the function. In this paper, we explore two different training strategies. In the first (unsupervised) setting, we train the model to maximize standard image matching objective functions that are based on the image intensities. In the second setting, we leverage auxiliary segmentations available in the training data. We demonstrate that the unsupervised model's accuracy is comparable to the state-of-the-art methods while operating orders of magnitude faster. We also show that VoxelMorph trained with auxiliary data improves registration accuracy at test time and evaluate the effect of training set size on registration. Our method promises to speed up medical image analysis and processing pipelines while facilitating novel directions in learning-based registration and its applications. Our code is freely available at https://github.com/voxelmorph/voxelmorph. © 1982-2012 IEEE.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Shahid2019638,
author={Shahid, A.H. and Singh, M.P.},
title={Computational intelligence techniques for medical diagnosis and prognosis: Problems and current developments},
journal={Biocybernetics and Biomedical Engineering},
year={2019},
volume={39},
number={3},
pages={638-672},
doi={10.1016/j.bbe.2019.05.010},
note={cited By 11},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068056224&doi=10.1016%2fj.bbe.2019.05.010&partnerID=40&md5=beed56b34a8a365e1f9bcdd42df5076e},
abstract={Diagnosis, being the first step in medical practice, is very crucial for clinical decision making. This paper investigates state-of-the-art computational intelligence (CI) techniques applied in the field of medical diagnosis and prognosis. The paper presents the performance of these techniques in diagnosing different diseases along with the detailed description of the data used. This paper includes basic as well as hybrid CI techniques that have been used in recent years so as to know the current trends in medical diagnosis domain. The paper presents the merits and demerits of different techniques in general as well as application specific context. This paper discusses some critical issues related to the medical diagnosis and prognosis such as uncertainties in the medical domain, problems in the medical data especially dealing with time-stamped (temporal) data, and knowledge acquisition. Moreover, this paper also discusses the features of good CI techniques in medical diagnosis. Overall, this review provides new insight for future research requirements in the medical diagnosis domain. © 2019 Nalecz Institute of Biocybernetics and Biomedical Engineering of the Polish Academy of Sciences},
document_type={Review},
source={Scopus},
}

@ARTICLE{Li2019765,
author={Li, M. and Shang, Z. and Yang, Z. and Zhang, Y. and Wan, H.},
title={Machine learning methods for MRI biomarkers analysis of pediatric posterior fossa tumors},
journal={Biocybernetics and Biomedical Engineering},
year={2019},
volume={39},
number={3},
pages={765-774},
doi={10.1016/j.bbe.2019.07.004},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070331334&doi=10.1016%2fj.bbe.2019.07.004&partnerID=40&md5=de5ace44bee95a65b7d423f680ae7625},
abstract={Medical imaging technologies provide an increasing number of opportunities for disease prediction and prognosis. Specifically, imaging biomarkers can quantify the entire tumor phenotypes to enhance the prediction. Machine learning technology can be explored to mine and analyze these biomarkers and to establish predictive models for the clinical applications. Several studies have applied various machine learning methods to imaging biomarkers based clinical predictions of different diseases. Here we seek to evaluate different machine learning methods in pediatric posterior fossa tumor prediction. We present a machine learning based magnetic resonance imaging biomarkers analysis framework for two kinds of pediatric posterior fossa tumors. In details, three feature extraction methods are used to obtain 300 imaging biomarkers. 10 feature selection methods and 11 classifiers are evaluated by the quantified predictive performance and stability, and importance consistency of features and the influence of the experimental factors are also analyzed. Our results demonstrate that the CFS feature selection method (accuracy: 83.85 ± 5.51%, stability: [0.84, 0.06]) and SVM classifier (accuracy: 85.38 ± 3.47%, RSD: 4.77%) show relatively better performance than others and should be preferred. Among all the biomarkers, 17 texture features seem to be more important. Multifactor analysis results indicate the choice of classifier accounts for the most contribution to the variability in performance (37.25%). The machine learning based framework is efficient for pediatric posterior fossa tumors biomarkers analysis and could provide valuable references and decision support for assisted clinical diagnosis. © 2019},
document_type={Article},
source={Scopus},
}

@ARTICLE{Walia2019231,
author={Walia, G.S. and Rishi, S. and Asthana, R. and Kumar, A. and Gupta, A.},
title={Secure multimodal biometric system based on diffused graphs and optimal score fusion},
journal={IET Biometrics},
year={2019},
volume={8},
number={4},
pages={231-242},
doi={10.1049/iet-bmt.2018.5018},
note={cited By 18},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067341986&doi=10.1049%2fiet-bmt.2018.5018&partnerID=40&md5=c0bf6a18d2274b2b654e62afd077cab2},
abstract={Biometric authentication systems offer potential advantages over traditional knowledge-based methods. However, most of the biometric systems which are extensively used lack template security and robustness. In order to address these issues, in this study, the authors have proposed a multimodal biometric system based on the combination of multiple modalities and optimal score level fusion. In addition, key features are introduced for each modality for generating cancellable biometric features. Features from individual traits are combined with corresponding key features to provide feature transformation. A robust template is generated by diffusion of individual transformed matrices using graph-based random walk cross-diffusion. In addition, individual classifier score is optimally fused using proposed multistage score level fusion model. Optimal belief masses for individual classifier are determined using cuckoo search optimisation. Wherein, optimal classifier beliefs are fused using DSmT based proportional conflict redistribution (PCR-6) rules. Experimental results demonstrate that optimal score fusion applied on cross-diffused features produce better results than existing state-of-the-art multimodal fusion schemes. On average of the outcome, equal error rate and accuracy achieved using the proposed method on four chimeric benchmarked datasets, are 2.32 and 98.316%. © The Institution of Engineering and Technology 2019},
document_type={Article},
source={Scopus},
}

@ARTICLE{Aliyari2019211,
author={Aliyari, H. and Hosseinian, S.H. and Menhaj, M.B. and Sahraei, H.},
title={Analysis of the Effects of High-Voltage Transmission Line on Human Stress and Attention Through Electroencephalography (EEG)},
journal={Iranian Journal of Science and Technology - Transactions of Electrical Engineering},
year={2019},
volume={43},
pages={211-218},
doi={10.1007/s40998-018-0151-8},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067583192&doi=10.1007%2fs40998-018-0151-8&partnerID=40&md5=224e5b21b8f9da94248326d4e4c14a2b},
abstract={Knowing the variable-frequency, high-intensity electromagnetic field plays an important role in the humans’ surroundings, numerous studies have been carried out on stress and attention based on EEG data. In this study, a comparison was drawn between the brain waves of individuals living near high-voltage transmission towers and those of people living outside of these zones. The levels of stress and attention were also assessed based on the brain activity of the participants. First, a general questionnaire is completed by the volunteers, and the predisposed samples are included in the research following the screening process. Two 10-member groups (average age of 27 years) of adult males were selected for the research. In one of the groups, the participants are not exposed to high-voltage electric fields. The homes of the members of the second group are located beneath or near high-voltage transmission towers (at a maximum distance of 20 m). Using a 14-channel EEG system, the brain waves of each participant were recorded 5 times over 2 days in the eyes-open resting state while the participants were looking at a white screen. (Ten records of data were obtained per person.) The saliva samples of each participant were also obtained to assess the basal cortisol hormone. The mean EEG stress and attention indices were obtained based on the data on each person, and the mean cortisol level of each group was compared to that of the other group. The investigation and comparison results proved that the mean EEG attention indices of people exposed to high-voltage electric fields were lower than those of the ordinary people. On the other hand, the mean levels of basal EEG stress and salivary cortisol hormone were higher in the people exposed to high-voltage electric fields than the ordinary people. Given the variations of the mean indices of stress and attention in the EEGs and salivary samples of the participants as a result, self-efficacy decreases over time. © 2018, Shiraz University.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Clark2019871,
author={Clark, J. and Provost, F.},
title={Unsupervised dimensionality reduction versus supervised regularization for classification from sparse data},
journal={Data Mining and Knowledge Discovery},
year={2019},
volume={33},
number={4},
pages={871-916},
doi={10.1007/s10618-019-00616-4},
note={cited By 5},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061893116&doi=10.1007%2fs10618-019-00616-4&partnerID=40&md5=e170a0d7b9088cbec919e4818d6f37d6},
abstract={Unsupervised matrix-factorization-based dimensionality reduction (DR) techniques are popularly used for feature engineering with the goal of improving the generalization performance of predictive models, especially with massive, sparse feature sets. Often DR is employed for the same purpose as supervised regularization and other forms of complexity control: exploiting a bias/variance tradeoff to mitigate overfitting. Contradicting this practice, there is consensus among existing expert guidelines that supervised regularization is a superior way to improve predictive performance. However, these guidelines are not always followed for this sort of data, and it is not unusual to find DR used with no comparison to modeling with the full feature set. Further, the existing literature does not take into account that DR and supervised regularization are often used in conjunction. We experimentally compare binary classification performance using DR features versus the original features under numerous conditions: using a total of 97 binary classification tasks, 6 classifiers, 3 DR techniques, and 4 evaluation metrics. Crucially, we also experiment using varied methodologies to tune and evaluate various key hyperparameters. We find a very clear, but nuanced result. Using state-of-the-art hyperparameter-selection methods, applying DR does not add value beyond supervised regularization, and can often diminish performance. However, if regularization is not done well (e.g., one just uses the default regularization parameter), DR does have relatively better performance—but these approaches result in lower performance overall. These latter results provide an explanation for why practitioners may be continuing to use DR without undertaking the necessary comparison to using the original features. However, this practice seems generally wrongheaded in light of the main results, if the goal is to maximize generalization performance. © 2019, The Author(s).},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Natarajan20192097,
author={Natarajan, M. and Sathiamoorthy, S.},
title={Content Based Medical Image Retrieval Using Multi-Trend Structure Descriptor and Fuzzy k-NN Classifier},
journal={Proceedings of the 4th International Conference on Communication and Electronics Systems, ICCES 2019},
year={2019},
pages={2097-2102},
doi={10.1109/ICCES45898.2019.9002310},
art_number={9002310},
note={cited By 5},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073544639&doi=10.1109%2fICCES45898.2019.9002310&partnerID=40&md5=617b28ea992c3ebc105277ce881bc05e},
abstract={In this work, Multi-trend structure descriptor is suggested for retrieving images from heterogeneous medical image dataset. The multi-trend structure descriptors acquires structures in the form of large, small and equal trends along four directions at both global and local level. For the retrieval of grayscale medical images, only the structure information computed by Multi-trend structure descriptor from the texture and edge information of an image is used while for color medical images the color information acquired by Multi-trend structure descriptor is also taken in to consideration for attaining effective retrieval rate. The fuzzy k-NN approach is incorporated to classify the feature vectors and it enhances the retrieval accuracy as well it increases the speed of retrieval. The results obviously shown that the fusion of Multi-trend structure descriptor and fuzzy k-NN outperforms the state-of-the-art approaches. © 2019 IEEE.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Wornyo2019,
author={Wornyo, D.K. and Shen, X.-J.},
title={Coupled least squares support vector ensemble machines},
journal={Information (Switzerland)},
year={2019},
volume={10},
number={6},
doi={10.3390/info10060195},
art_number={195},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067424224&doi=10.3390%2finfo10060195&partnerID=40&md5=e9749919dbd6a145cf800ccaacd0caee},
abstract={The least squares support vector method is a popular data-driven modeling method which shows better performance and has been successfully applied in awide range of applications. In this paper, we propose a novel coupled least squares support vector ensemble machine (C-LSSVEM). The proposed coupling ensemble helps improve robustness and produce good classification performance than the single model approach. The proposed C-LSSVEMcan choose appropriate kernel types and their parameters in a good coupling strategy with a set of classifiers being trained simultaneously. The proposed method can further minimize the total loss of ensembles in kernel space. Thus, we form an ensemble regressor by co-optimizing and weighing base regressors. Experiments conducted on several datasets such as artificial datasets, UCI classification datasets, UCI regression datasets, handwritten digits datasets and NWPU-RESISC45 datasets, indicate that C-LSSVEM performs better in achieving the minimal regression loss and the best classification accuracy relative to selected state-of-the-art regression and classification techniques. © 2019 by the authors.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Kienast2019,
author={Kienast, C. and Gunga, H.-C. and Steinach, M.},
title={Neuropeptide Y – Its role in human performance and extreme environments},
journal={REACH},
year={2019},
volume={14-15},
doi={10.1016/j.reach.2019.100032},
art_number={100032},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075559852&doi=10.1016%2fj.reach.2019.100032&partnerID=40&md5=985189f72a016bbb7c14d79ca67f1380},
abstract={Neuropeptide tyrosine (neuropeptide Y or NPY) is one of the most abundant neuropeptides in the mammalian central nervous system and also widely distributed in the peripheral nervous system. Among the many mediators involved in important physiological and psychological systems, NPY in particular appears to be a multisignaling key peptide. The biological actions of NPY are vast and mediated via the Y1, Y2, Y4, and Y5 receptors, which are involved in both essential physiological and pathophysiological processes. Here, we discuss various roles of NPY in seven systems: a) regulation of energy homeostasis, b) thermoregulation, c) circadian system, d) sleep, e) nociception, f) emotional behavior, and g) the autonomic nervous system. NPY regulates a) energy homeostasis with actions at different sites (central and peripheral), via different receptors in various neuronal tissues. Due to its prominent actions in the brain, including stimulating appetite, NPY function has gained importance. However, NPY is more than just an orexigenic peptide. Food intake and decrease in energy expenditure are exerted together by the Y1 and Y5 receptors. While the Y4 receptor exerts anorexigenic effects, the Y2 receptor has central anorexigenic and peripheral orexigenic properties. The involvement of NPY in b) thermoregulation remains unclear. Although it has been reported that cold exposure activates NPY. Increased or decreased thermogenesis has been observed as a result of NPY administration to different central sites. Central Y1 and Y5 receptors inhibit sympatho-adrenal transmitted thermogenesis in peripheral brown adipose tissue. NPY functions as a chemical messenger autonomous of the light-dark-cycle in the c) circadian rhythm and exerts similar phase-shifting effects to those of light. NPY leads to a shortened d) sleep onset and reduced REM latency, but its role in the circadian rhythm seems to be elusive and has not been established. NPY is implicated in e) pain perception and modulates nociception. It has been shown to cause both nociceptive and anti-nociceptive responses. Moreover, Y receptors are thought to form heterodimers with those of galanin and glutamate to enhance their nociceptive modulatory effects. Especially the role of the Y2 receptor within this system and all the other systems reveals opposite properties. The different effects of Y2 receptors are dependent on their central or peripheral location.These opposing effects can be observed in other receptors as well and are likely explained by tissue-specific differences in receptor expression (number and distribution of receptors). Differences in cell type-specific second messenger coupling also play a role. Therefore, centrally located receptors can have a completely different function than peripherally located receptors. The regulation of f) emotional behavior through NPY and its receptors is biphasic. The Y1 and Y5 receptor are anxiolytic, whereas the Y2 and Y4 receptors lead to anxiety- and depression-like behavior. Moreover, the Y2 receptor enhances dopamine mediated anxious behavior but can also reverse the dopamine effects. Comparison of several studies showed that NPY mainly exerts anxiolytic, anti-depressant effects, and is implicated in memory processing. Moreover, it seems to be the ‘peptide of success.’ Polymorphisms in NPY genes may predispose different kinds of human affective disorders. Lower levels of NPY are associated with major depression and bipolar disorder. These findings are consistent with NPY modulating emotional behavior and may help to explain interindividual variation in resiliency to stress. In the g) autonomic nervous system effects are mediated predominantly via Y1, Y2, and Y5 receptors. These receptors are expressed in neurons supplying the vascular smooth muscle cells, the cardiomyocytes and are involved in physiological processes including vasoconstriction and -dilatation, heart rate variability, cardiac remodeling, and angiogenesis. However, additional peripheral mediated Y receptor-ligand effects have received far less attention than central. Besides its several physiological roles, NPY has been implicated in several common diseases, such as chronic pain, depression, hypertension, and atherosclerosis. Therefore, the NPY-multi-signaling-system could be a therapeutic target but as well an interesting neurotransmitter which plays obviously an important role in human adaptation to extreme environments, including space. © 2019 Elsevier GmbH},
document_type={Review},
source={Scopus},
}

@ARTICLE{Zhang2019354,
author={Zhang, Z. and Sejdić, E.},
title={Radiological images and machine learning: Trends, perspectives, and prospects},
journal={Computers in Biology and Medicine},
year={2019},
volume={108},
pages={354-370},
doi={10.1016/j.compbiomed.2019.02.017},
note={cited By 33},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064937289&doi=10.1016%2fj.compbiomed.2019.02.017&partnerID=40&md5=3a3ece4e038d686acab1e3160624f6f1},
abstract={The application of machine learning to radiological images is an increasingly active research area that is expected to grow in the next five to ten years. Recent advances in machine learning have the potential to recognize and classify complex patterns from different radiological imaging modalities such as x-rays, computed tomography, magnetic resonance imaging and positron emission tomography imaging. In many applications, machine learning based systems have shown comparable performance to human decision-making. The applications of machine learning are the key ingredients of future clinical decision making and monitoring systems. This review covers the fundamental concepts behind various machine learning techniques and their applications in several radiological imaging areas, such as medical image segmentation, brain function studies and neurological disease diagnosis, as well as computer-aided systems, image registration, and content-based image retrieval systems. Synchronistically, we will briefly discuss current challenges and future directions regarding the application of machine learning in radiological imaging. By giving insight on how take advantage of machine learning powered applications, we expect that clinicians can prevent and diagnose diseases more accurately and efficiently. © 2019 Elsevier Ltd},
document_type={Review},
source={Scopus},
}

@ARTICLE{Zhao2019901,
author={Zhao, D. and Liu, H. and Zheng, Y. and He, Y. and Lu, D. and Lyu, C.},
title={A reliable method for colorectal cancer prediction based on feature selection and support vector machine},
journal={Medical and Biological Engineering and Computing},
year={2019},
volume={57},
number={4},
pages={901-912},
doi={10.1007/s11517-018-1930-0},
note={cited By 11},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057562239&doi=10.1007%2fs11517-018-1930-0&partnerID=40&md5=8864281a212c957a2d45defd68db466e},
abstract={Colorectal cancer (CRC) is a common cancer responsible for approximately 600,000 deaths per year worldwide. Thus, it is very important to find the related factors and detect the cancer accurately. However, timely and accurate prediction of the disease is challenging. In this study, we build an integrated model based on logistic regression (LR) and support vector machine (SVM) to classify the CRC into cancer and normal samples. From various factors, human location, age, gender, BMI, and cancer tumor type, tumor grade, and DNA, of the cancer, we select the most significant factors (p < 0.05) using logistic regression as main features, and with these features, a grid-search SVM model is designed using different kernel types (Linear, radial basis function (RBF), Sigmoid, and Polynomial). The result of the logistic regression indicates that the Firmicutes (AUC 0.918), Bacteroidetes (AUC 0.856), body mass index (BMI) (AUC 0.777), and age (AUC 0.710) and their combined factors (AUC 0.942) are effective for CRC detection. And the best kernel type is RBF, which achieves an accuracy of 90.1% when k = 5, and 91.2% when k = 10. This study provides a new method for colorectal cancer prediction based on independent risky factors. [Figure not available: see fulltext.]. © 2018, International Federation for Medical and Biological Engineering.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Mahmoodian201910,
author={Mahmoodian, N. and Schaufler, A. and Pashazadeh, A. and Boese, A. and Friebe, M. and Illanes, A.},
title={Proximal detection of guide wire perforation using feature extraction from bispectral audio signal analysis combined with machine learning},
journal={Computers in Biology and Medicine},
year={2019},
volume={107},
pages={10-17},
doi={10.1016/j.compbiomed.2019.02.001},
note={cited By 7},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061329789&doi=10.1016%2fj.compbiomed.2019.02.001&partnerID=40&md5=6b74685341fa796e99b3765e29e5de22},
abstract={Artery perforation during a vascular catheterization procedure is a potentially life threatening event. It is of particular importance for the surgeons to be aware of hidden or non-obvious events. To minimize the impact it is crucial for the surgeon to detect such a perforation very early. We propose a novel approach to identify perforations based on the acquisition and analysis of audio signals on the outside proximal end of a guide wire. The signals were acquired using a stethoscope equipped with a microphone and attached to the proximal end of the guide wire via a 3D printed adapter. Bispectral analysis was employed to extract acoustic signatures in the signal and several features were extracted from the bispectrum of the signal. Finally, three machine learning algorithms - K-nearest Neighbor, Support Vector Machine (SVM), and Artificial Neural Network (ANN)- were used to classify a signal as a perforation or as an artifact. The bispectrum-based features resulted in valuable features allowing a perforation to be clearly identifiable from other occurring events. A perforation leaves a clear audio signal trace in the time-frequency domain. The recordings were classified as perforation, friction or guide wire bump using SVM with 97% (polykernel) and 98.62% (RBF) accuracy, k-nearest Neighbor an accuracy of 98.28% and ANN with accuracy of 98.73% was obtained. The presented approach shows that interactions starting at the tip of a guide wire can be picked up at its proximal end providing a valuable additional information that could be used during a guide wire procedure. © 2019 Elsevier Ltd},
document_type={Article},
source={Scopus},
}

@ARTICLE{Zhu2019673,
author={Zhu, X. and Suk, H.-I. and Shen, D.},
title={Group sparse reduced rank regression for neuroimaging genetic study},
journal={World Wide Web},
year={2019},
volume={22},
number={2},
pages={673-688},
doi={10.1007/s11280-018-0637-3},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053605427&doi=10.1007%2fs11280-018-0637-3&partnerID=40&md5=6bba68192e53adf3a08b363b238ca18d},
abstract={The neuroimaging genetic study usually needs to deal with high dimensionality of both brain imaging data and genetic data, so that often resulting in the issue of curse of dimensionality. In this paper, we propose a group sparse reduced rank regression model to take the relations of both the phenotypes and the genotypes for the neuroimaging genetic study. Specifically, we propose designing a graph sparsity constraint as well as a reduced rank constraint to simultaneously conduct subspace learning and feature selection. The group sparsity constraint conducts feature selection to identify genotypes highly related to neuroimaging data, while the reduced rank constraint considers the relations among neuroimaging data to conduct subspace learning in the feature selection model. Furthermore, an alternative optimization algorithm is proposed to solve the resulting objective function and is proved to achieve fast convergence. Experimental results on the Alzheimer’s Disease Neuroimaging Initiative (ADNI) dataset showed that the proposed method has superiority on predicting the phenotype data by the genotype data, than the alternative methods under comparison. © 2018, Springer Science+Business Media, LLC, part of Springer Nature.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Itani2019300,
author={Itani, S. and Lecron, F. and Fortemps, P.},
title={Specifics of medical data mining for diagnosis aid: A survey},
journal={Expert Systems with Applications},
year={2019},
volume={118},
pages={300-314},
doi={10.1016/j.eswa.2018.09.056},
note={cited By 23},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054837692&doi=10.1016%2fj.eswa.2018.09.056&partnerID=40&md5=8dd00d4cde24d89c99d5c894a94ddfad},
abstract={Data mining continues to play an important role in medicine; specifically, for the development of diagnosis aid models used in expert and intelligent systems. Although we can find abundant research on this topic, clinicians remain reluctant to use decision support tools. Social pressure explains partly this lukewarm position, but concerns about reliability and credibility are also put forward. To address this reticence, we emphasize the importance of the collaboration between both data miners and clinicians. This survey lays the foundation for such an interaction, by focusing on the specifics of diagnosis aid, and the related data modeling goals. On this regard, we propose an overview on the requirements expected by the clinicians, who are both the experts and the final users. Indeed, we believe that the interaction with clinicians should take place from the very first steps of the process and throughout the development of the predictive models, thus not only at the final validation stage. Actually, against a current research approach quite blindly driven by data, we advocate the need for a new expert-aware approach. This survey paper provides guidelines to contribute to the design of daily helpful diagnosis aid systems. © 2018 Elsevier Ltd},
document_type={Review},
source={Scopus},
}

@ARTICLE{Lim2019,
author={Lim, M. and Puttick, S. and Houston, Z.H. and Thurecht, K.J. and Kalita-De Croft, P. and Mahler, S. and Rose, S.E. and Jeffree, R.L. and Mazzieri, R. and Dolcetti, R. and Lakhani, S.R. and Saunus, J.M.},
title={Innovative therapeutic strategies for effective treatment of brain metastases},
journal={International Journal of Molecular Sciences},
year={2019},
volume={20},
number={6},
doi={10.3390/ijms20061280},
art_number={1280},
note={cited By 7},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062989532&doi=10.3390%2fijms20061280&partnerID=40&md5=d5b08fb5dfd69dcb02684e24ecf87f0f},
abstract={Brain metastases are the most prevalent of intracranial malignancies. They are associated with a very poor prognosis and near 100% mortality. This has been the case for decades, largely because we lack effective therapeutics to augment surgery and radiotherapy. Notwithstanding improvements in the precision and efficacy of these life-prolonging treatments, with no reliable options for adjunct systemic therapy, brain recurrences are virtually inevitable. The factors limiting intracranial efficacy of existing agents are both physiological and molecular in nature. For example, heterogeneous permeability, abnormal perfusion and high interstitial pressure oppose the conventional convective delivery of circulating drugs, thus new delivery strategies are needed to achieve uniform drug uptake at therapeutic concentrations. Brain metastases are also highly adapted to their microenvironment, with complex cross-talk between the tumor, the stroma and the neural compartments driving speciation and drug resistance. New strategies must account for resistance mechanisms that are frequently engaged in this milieu, such as HER3 and other receptor tyrosine kinases that become induced and activated in the brain microenvironment. Here, we discuss molecular and physiological factors that contribute to the recalcitrance of these tumors, and review emerging therapeutic strategies, including agents targeting the PI3K axis, immunotherapies, nanomedicines and MRI-guided focused ultrasound for externally controlling drug delivery. © 2019 by the authors. Licensee MDPI, Basel, Switzerland.},
document_type={Review},
source={Scopus},
}

@ARTICLE{Chao2019133,
author={Chao, L.L.},
title={Effects of Home Photobiomodulation Treatments on Cognitive and Behavioral Function, Cerebral Perfusion, and Resting-State Functional Connectivity in Patients with Dementia: A Pilot Trial},
journal={Photobiomodulation, Photomedicine, and Laser Surgery},
year={2019},
volume={37},
number={3},
pages={133-141},
doi={10.1089/photob.2018.4555},
note={cited By 18},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062898067&doi=10.1089%2fphotob.2018.4555&partnerID=40&md5=e3c04ce4696300c5c2e399df1e6415eb},
abstract={Objective: To examine the effects of transcranial and intranasal photobiomodulation (PBM) therapy, administered at home, in patients with dementia. Background: This study sought to replicate and build upon a previously published case series report describing improved cognitive function in five patients with mild-To-moderate dementia after 12 weeks of transcranial and intranasal near-infrared (NIR) PBM therapy. Materials and methods: Eight participants (mean age: 79.8 ± 5.8 years old) diagnosed with dementia by their physicians were randomized to 12 weeks of usual care (UC, n = 4) or home PBM treatments (n = 4). The NIR PBM treatments were administered by a study partner at home three times per week with the Vielight Neuro Gamma device. The participants were assessed with the Alzheimer's Disease Assessment Scale-cognitive (ADAS-cog) subscale and the Neuropsychiatric Inventory (NPI) at baseline and 6 and 12 weeks, and with arterial spin-labeled perfusion magnetic resonance imaging (MRI) and resting-state functional MRI at baseline and 12 weeks. Results: At baseline, the UC and PBM groups did not differ demographically or clinically. However, after 12 weeks, there were improvements in ADAS-cog (group × time interaction: F 1,6 = 16.35, p = 0.007) and NPI (group × time interaction: F 1,6 = 7.52, p = 0.03), increased cerebral perfusion (group × time interaction: F 1,6 = 8.46, p &lt; 0.03), and increased connectivity between the posterior cingulate cortex and lateral parietal nodes within the default-mode network in the PBM group. Conclusions: Because PBM was well tolerated and associated with no adverse side effects, these results support the potential of PBM therapy as a viable home treatment for individuals with dementia. © Copyright 2019, Mary Ann Liebert, Inc., publishers 2019.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Kawauchi2019,
author={Kawauchi, S. and Okuda, W. and Nawashiro, H. and Sato, S. and Nishidate, I.},
title={Multispectral imaging of cortical vascular and hemodynamic responses to a shock wave: Observation of spreading depolarization and oxygen supply-demand mismatch},
journal={Journal of Biomedical Optics},
year={2019},
volume={24},
number={3},
doi={10.1117/1.JBO.24.3.035005},
art_number={035005},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062629035&doi=10.1117%2f1.JBO.24.3.035005&partnerID=40&md5=bbb015e6aa232dc914b619498710c7ce},
abstract={Blast-induced traumatic brain injury has been a recent major concern in neurotraumatology. However, its pathophysiology and mechanism are not understood partly due to insufficient information on the brain pathophysiology during/immediately after shock wave exposure. We transcranially applied a laserinduced shock wave (LISW, ∼19 Pa s) to the left frontal region in a rat and performed multispectral imaging of the ipsilateral cortex through a cranial window (n =4). For the spectral data obtained, we conducted multiple regression analysis aided by Monte Carlo simulation to evaluate vascular diameters, regional hemoglobin concentration (rCHb), tissue oxygen saturation (StO2), oxygen extraction fraction, and light-scattering signals as a signature of cortical spreading depolarization (CSD). Immediately after LISW exposure, rCHb and StO2 were significantly decreased with distinct venular constriction. CSD was then generated and was accompanied by distinct hyperemia/hyperoxemia. This was followed by oligemia with arteriolar constriction, but it soon recovered (within ∼20 min). However, severe hypoxemia was persistently observed during the post-CSD period (∼1 h). These observations indicate that inadequate oxygen supply and/or excessive oxygen consumption continued even after blood supply was restored in the cortex. Such a hypoxemic state and/or a hypermetabolic state might be associated with brain damage caused by a shock wave. © The Authors. Published by SPIE under a Creative Commons Attribution 4.0 Unported License.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Salehpour2019159,
author={Salehpour, F. and Hamblin, M.R. and Diduro, J.O.},
title={Rapid Reversal of Cognitive Decline, Olfactory Dysfunction, and Quality of Life Using Multi-Modality Photobiomodulation Therapy: Case Report},
journal={Photobiomodulation, Photomedicine, and Laser Surgery},
year={2019},
volume={37},
number={3},
pages={159-167},
doi={10.1089/photob.2018.4569},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062907754&doi=10.1089%2fphotob.2018.4569&partnerID=40&md5=3f948666a038423351ea756103fa0a8b},
abstract={Objective: We present a case report of reversal of cognitive impairment, olfactory dysfunction, and quality of life measures in a patient with cognitive decline after multi-modality photobiomodulation (PBM) therapy. Background: Transcranial and intranasal PBM has been introduced as a light-based therapeutic technique in which exposure to low levels of red to near-infrared (NIR) light stimulates neuronal function, leading to beneficial neurological effects. Materials and methods: Patient received twice-daily PBM therapy at home using three different wearable light-emitting diode (LED) devices. For the first week containing a mixture of continuous wave mode red (635 nm) and NIR (810 nm) LEDs, a prototype transcranial light helmet and a body pad were used. The body pad was placed on various areas on the lower back and the helmet was worn while seated. After the first week of treatment, an intranasal LED device, 10-Hz pulsed wave mode NIR (810 nm), was initiated in the left nostril twice daily. All three devices were applied simultaneously for an irradiation time of 25 min per session. Results: The patient showed a significant improvement in the Montreal Cognitive Assessment score from 18 to 24 and in the Working Memory Questionnaire score from 53 to 10. The cognitive enhancement was accompanied by reversal of olfactory dysfunction as measured by the Alberta Smell Test and peanut butter odor detection test. Quality-of-life measures improved and caregiver stress was reduced. No adverse effects were reported. Conclusions: PBM therapy may be a promising noninvasive approach for patients with neurodegenerative diseases. © Copyright 2019, Mary Ann Liebert, Inc., publishers 2019.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Xu20195,
author={Xu, X. and Liang, T. and Zhu, J. and Zheng, D. and Sun, T.},
title={Review of classical dimensionality reduction and sample selection methods for large-scale data processing},
journal={Neurocomputing},
year={2019},
volume={328},
pages={5-15},
doi={10.1016/j.neucom.2018.02.100},
note={cited By 20},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052748949&doi=10.1016%2fj.neucom.2018.02.100&partnerID=40&md5=3175b82663357eab7bb35719bd26cf6d},
abstract={In the era of big data, all types of data with increasing samples and high-dimensional attributes are demonstrating their important roles in various fields, such as data mining, pattern recognition and machine learning, etc. Meanwhile, machine learning algorithms are being effectively applied in large-scale data processing. This paper mainly reviews the classical dimensionality reduction and sample selection methods based on machine learning algorithms for large-scale data processing. Firstly, the paper provides a brief overview to the classical sample selection and dimensionality reduction methods. Then, it pays attention to the applications of those methods and their combinations with the classical machine learning methods, such as clustering, random forest, fuzzy set, and heuristic algorithms, particularly deep leaning methods. Furthermore, the paper primarily introduces the application frameworks that combine sample selection and dimensionality reduction in the context of two aspects: sequential and simultaneous, which almost all get the ideal results in the processing of the large-scale training data contrasting to the original models. Lastly, we further conclude that sample selection and dimensionality reduction methods are essential and effective for the modern large-scale data processing. In the future work, the machine learning algorithms, especially the deep learning methods, will play a more important role in the processing of large-scale data. © 2018},
document_type={Article},
source={Scopus},
}

@ARTICLE{Bergamasco201919,
author={Bergamasco, L.C.C. and Nunes, F.L.S.},
title={Intelligent retrieval and classification in three-dimensional biomedical images - A systematic mapping},
journal={Computer Science Review},
year={2019},
volume={31},
pages={19-38},
doi={10.1016/j.cosrev.2018.10.003},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061636974&doi=10.1016%2fj.cosrev.2018.10.003&partnerID=40&md5=ab6527e2c0673d47b3f4f90ff7f94e43},
abstract={The massive generation of data has raised new research topics, such as methods to store and to retrieve large volumes of information. Some medical image modalities, such as Magnetic Resonance Imaging, generate hundreds images series and many research groups have presented studies to develop intelligent techniques to classify and to retrieve this information. However, these studies are dispersed in several databases, and cataloged by using different terms. In this paper we present an analysis of these studies, through a Systematic Mapping that identifies methods and techniques currently being used in this scenario. In addition, we provide a perspective about the type of scientific literature the researchers have been disclosed their studies as well as impact on the scientific literature in dissemination of this knowledge domain. Some challenges and research opportunities are also highlighted in order to propitiate advances in the area. © 2018 Elsevier Inc.},
document_type={Review},
source={Scopus},
}

@ARTICLE{Önen201914,
author={Önen, Z. and Sayin, S. and Gürvit, I.H.},
title={Optimal population screening policies for Alzheimer’s disease*},
journal={IISE Transactions on Healthcare Systems Engineering},
year={2019},
volume={9},
number={1},
pages={14-25},
doi={10.1080/24725579.2018.1543738},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062361637&doi=10.1080%2f24725579.2018.1543738&partnerID=40&md5=7f36c888f90ddab8effc742728958ef6},
abstract={Alzheimer’s disease (AD) constitutes a serious societal healthcare issue as the proportion of the aging population increases. There are ongoing discussions about the necessity of screening the population for AD. We investigate optimal population screening policies for AD using Markov Decision Processes (MDPs). The objective function combines quality-adjusted life years and costs. The disease states are identified according to Clinical Dementia Rating (CDR) scores. The screening test in the model is the Mini Mental State Examination (MMSE), a cognitive test that is widely used in clinical practice. A numerical implementation of the MDP model is presented based on data from the Alzheimer’s Disease Neuroimaging Initiative (ADNI) and existing literature. In the baseline case, the optimal outcome is not to employ a population-wide screening program. We conduct extensive sensitivity analyses on several model parameters. Our study reveals that the optimal policy may be sensitive to changes in transition probability estimates. When we focus on transitions that are related to treatment effectiveness, we find that implementing a population screening policy becomes socially optimal when plans that lead to cognitive ability stabilization or improvement become available. © 2019, © 2019 “IISE”.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Yıldız20192241,
author={Yıldız, O.},
title={Melanoma detection from dermoscopy images with deep learning methods: A comprehensive study [Derin öğrenme yöntemleriyle dermoskopi görüntülerinden melanom tespiti: Kapsamlı bir çalışma]},
journal={Journal of the Faculty of Engineering and Architecture of Gazi University},
year={2019},
volume={34},
number={4},
pages={2241-2260},
doi={10.17341/gazimmfd.435217},
note={cited By 6},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069821799&doi=10.17341%2fgazimmfd.435217&partnerID=40&md5=1c3af2424da6acab2071f61b5a895390},
abstract={Skin cancer is common and a serious disease, which can lead to death if not treated in time. Melanoma is the rarest and most dangerous type of skin cancer. It causes the most deaths. As in all diseases, early and correct detection of skin cancer are very important. Computer Aided Diagnosis systems can help physicians and patients make better decisions. Especially, machine learning and deep learning use effectively in Computer Aided Diagnosis systems. In this study, an automatic detection system for melanoma is suggested. To illustrate the advantage of the proposed CNN model C4Net, a comprehensive experimental study has been carried out. In addition, the proposed C4Net has been compared with not only the existing deep learning algorithms such as AlexNet, GoogLeNet, ResNet and VGGNet but also conventional machine learning algorithms such as Artificial neural networks, k-Nearest neighbor algorithm and Support vector machine. In experimental studies, C4Net, which is designed as deep neural network model for melanoma detection, has obtained more classification accuracy than other methods with 96.94%. © 2019 Gazi Universitesi Muhendislik-Mimarlik. All rights reserved.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Sandeep2019509,
author={Sandeep, C.S. and Sukesh Kumar, A. and Mahadevan, K. and Manoj, P.},
title={Analysis of retinal OCT images for the early diagnosis of Alzheimer’s disease},
journal={Advances in Intelligent Systems and Computing},
year={2019},
volume={749},
pages={509-520},
doi={10.1007/978-3-319-74808-5_43},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056464359&doi=10.1007%2f978-3-319-74808-5_43&partnerID=40&md5=76553b451b76595b00316e2125463e7a},
abstract={Alzheimer disease (AD) is a cumulative brain disorder as well as irreversible neuronal disease that affects mostly the old age population. The investigation made on AD reveals that early symptoms of AD not only affect the brain but also the retina, especially on the Optical Coherence Tomography (OCT) images. For making an analysis using OCT images for diagnosing AD, an efficient and reliable technique should be developed with the help of advanced Biomedical methods on Engineering. The available brain imaging methods used for predicting AD is Positron Emission Tomography, Single Photon Emission Computed Tomography, and Magnetic Resonance Imaging. OCT is the most reliable retina imaging technique that can be used for diagnosing AD. In this regard, a scheme based on Wavelet Networks (WN) on OCT images for predicting AD at its earlier stage has been introduced. The WN uses mother wavelets and child wavelets for creating networks. This can be applied on OCT type images. © Springer Nature Switzerland AG 2019.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Bidani2019925,
author={Bidani, A. and Gouider, M.S. and Travieso-González, C.M.},
title={Dementia Detection and Classification from MRI Images Using Deep Neural Networks and Transfer Learning},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2019},
volume={11506 LNCS},
pages={925-933},
doi={10.1007/978-3-030-20521-8_75},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067466427&doi=10.1007%2f978-3-030-20521-8_75&partnerID=40&md5=070f2561002a7620551c2b5c86899ab4},
abstract={In this paper, we present a new approach in the field of Deep Machine Learning, that comprises both DCNN (Deep Convolutional Neural Network) model and Transfer Learning model to detect and classify the dementia disease. This neurodegenerative disease which is described as a decline in memory, language, and other problems of cognitive skills to make daily activities, is identified in this study by using MRI (Magnetic Resonance Imaging) brain scans from OASIS dataset. These MRI brain scans are normalized before the image extraction with Bag of the features and the Learning classification methods into no-demented, very mild demented, and mild demented. Results showed that the DCNN model achieved significant accuracy for better Dementia diagnosis. © 2019, Springer Nature Switzerland AG.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Gao201943110,
author={Gao, M. and Jiang, J. and Zou, G. and John, V. and Liu, Z.},
title={RGB-D-Based Object Recognition Using Multimodal Convolutional Neural Networks: A Survey},
journal={IEEE Access},
year={2019},
volume={7},
pages={43110-43136},
doi={10.1109/ACCESS.2019.2907071},
art_number={8683987},
note={cited By 14},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064867702&doi=10.1109%2fACCESS.2019.2907071&partnerID=40&md5=6b5abed76d9d371673b48ed5c3085f8e},
abstract={Object recognition in real-world environments is one of the fundamental and key tasks in computer vision and robotics communities. With the advanced sensing technologies and low-cost depth sensors, the high-quality RGB and depth images can be recorded synchronously, and the object recognition performance can be improved by jointly exploiting them. RGB-D-based object recognition has evolved from early methods that using hand-crafted representations to the current state-of-the-art deep learning-based methods. With the undeniable success of deep learning, especially convolutional neural networks (CNNs) in the visual domain, the natural progression of deep learning research points to problems involving larger and more complex multimodal data. In this paper, we provide a comprehensive survey of recent multimodal CNNs (MMCNNs)-based approaches that have demonstrated significant improvements over previous methods. We highlight two key issues, namely, training data deficiency and multimodal fusion. In addition, we summarize and discuss the publicly available RGB-D object recognition datasets and present a comparative performance evaluation of the proposed methods on these benchmark datasets. Finally, we identify promising avenues of research in this rapidly evolving field. This survey will not only enable researchers to get a good overview of the state-of-the-art methods for RGB-D-based object recognition but also provide a reference for other multimodal machine learning applications, e.g., multimodal medical image fusion, audio-visual speech recognition, and multimedia retrieval and generation. © 2013 IEEE.},
document_type={Review},
source={Scopus},
}

@ARTICLE{RiniNovitasari2019115,
author={Rini Novitasari, D.C. and Lubab, A. and Sawiji, A. and Asyhar, A.H.},
title={Application of feature extraction for breast cancer using one order statistic, glcm, glrlm, and gldm},
journal={Advances in Science, Technology and Engineering Systems},
year={2019},
volume={4},
number={4},
pages={115-120},
doi={10.25046/aj040413},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071382081&doi=10.25046%2faj040413&partnerID=40&md5=69079e3a3ec222cd937ffc2a80eb78ca},
abstract={The increasing number of breast cancer in recent years has attracted numerous researchers' attention. Several techniques of Computer Aided Diagnosis System have been proposed as alternative solutions to diagnose breast cancer. The flaw of simply using the naked eye to see the differences between normal and with cancer mammogram images makes the texture analysis play an important role in classifying breast cancer. In this study, the results of the classification were compared using various methods of texture analysis in extracting a feature of the mammogram image. Some texture analysis methods, including first order, which consist of GLCM, GLRLM, and GLDM, have successfully extracted features based on their characteristics. The statistical features of these methods are used as input for the ECOC SVM classification, which three kernel comparisons; linear, RBF, and polynomial, build the classification. The results show that the best kernel is polynomial kernels with statistical features built by GLRLM with 93.9757% accuracy value. © 2019 ASTES Publishers. All rights reserved.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Xie201976061,
author={Xie, W.-Y. and Liu, B.-D. and Shao, S. and Li, Y. and Wang, Y.-J.},
title={Sparse Representation and Collaborative Representation? Both Help Image Classification},
journal={IEEE Access},
year={2019},
volume={7},
pages={76061-76070},
doi={10.1109/ACCESS.2019.2921538},
art_number={8733018},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068263153&doi=10.1109%2fACCESS.2019.2921538&partnerID=40&md5=24c132f2fbb5dd8655ee94f0be663da5},
abstract={Image classification has attracted more and more attention. During the past decades, image classification has shown growing interest in representation-based classification methods, such as sparse representation-based classification and collaborative representation-based classification. However, the available representation-based methods still suffer from some problems. Especially, most methods only consider the shared representation of a test image. In this paper, we propose an elastic-net regularized regression algorithm (ENRR) for image classification. Specifically, our proposed method combines shared sparse representation with class specific collaborative representation when representing the test sample. Moreover, we extend the proposed ENRR to arbitrary kernel space to achieve better classification performance due to specificities and complexities of original images. The extensive experiments on face recognition datasets, handwritten recognition datasets, and remote sensing image datasets clearly demonstrate that the proposed ENRR outperforms several conventional methods in classification accuracy. © 2013 IEEE.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Zamini2019229,
author={Zamini, M. and Hasheminejad, S.M.H.},
title={A comprehensive survey of anomaly detection in banking, wireless sensor networks, social networks, and healthcare},
journal={Intelligent Decision Technologies},
year={2019},
volume={13},
number={2},
pages={229-270},
doi={10.3233/IDT-170155},
note={cited By 6},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066907480&doi=10.3233%2fIDT-170155&partnerID=40&md5=4313870bd6c3bc524d9f4215ae560326},
abstract={Anomaly detection is an important issue, which has been investigated in various research fields and application domains. Many anomaly detection techniques have been developed exclusively for certain application domains, in contrast, others are more general. This survey aims to create a structured and comprehensive overview of the research on anomaly detection. First, we tried to introduce the concept of anomalies and types of anomaly detection. We have tried to classify anomaly detection according to their application and then categorized their techniques. For each application and technique, we have described key assumptions, which are used by the techniques to distinguish between normal and abnormal behavior. For each application, a basic anomaly detection technique has been provided, in the end; the differences among existing techniques in each specific category are discussed. Furthermore, we tried to describe the advantages and disadvantages of each technique in that field. In addition, we tried to bring some data sets that were used in some papers in order to test your methods with them. We hope that this survey provides a better concept of the various directions, which has been researched on that specific topic. © 2019 - IOS Press and the authors. All rights reserved.},
document_type={Review},
source={Scopus},
}

@ARTICLE{Lei2019,
author={Lei, M. and Rao, Z. and Li, M. and Yu, X. and Zou, L.},
title={Identification of coal geographical origin using Near Infrared sensor based on broad learning},
journal={Applied Sciences (Switzerland)},
year={2019},
volume={9},
number={6},
doi={10.3390/app9061111},
art_number={1111},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063737665&doi=10.3390%2fapp9061111&partnerID=40&md5=48bbdde76f38776b392a48cb4ea08f1c},
abstract={Geographical origin, an important indicator of the chemical composition and quality grading, is one essential factor that should be taken into account in evaluating coal quality. However, traditional coal origin identification methods based on chemistry experiments are not only time consuming and labour intensive, but also costly. Near-Infrared (NIR) spectroscopy is an effective and efficient way to measure the chemical compositions of samples and has demonstrated excellent performance in various fields of quantitative and qualitative research. In this study, we employ NIR spectroscopy to identify coal origin. Considering the fact that the NIR spectra of coal samples always contain a large amount of redundant information and the number of samples is small, the broad learning algorithm is utilized here as the modelling system to classify the coal geographical origin. In addition, the particle swarm optimization algorithm is introduced to improve the structure of the Broad Learning (BL) model. We compare the improved model with the other five multivariate classification methods on a dataset with 243 coal samples collected from five countries. The experimental results indicate that the improved BL model can achieve the highest overall accuracy of 97.05%. The results obtained in this study suggest that the NIR technique combined with machine learning methods has significant potential for further development of coal geographical origin identification systems. © 2019 by the authors.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Brihadiswaran20191161,
author={Brihadiswaran, G. and Haputhanthri, D. and Gunathilaka, S. and Meedeniya, D. and Jayarathna, S.},
title={EEG-based processing and classification methodologies for autism spectrum disorder: A review},
journal={Journal of Computer Science},
year={2019},
volume={15},
number={8},
pages={1161-1183},
doi={10.3844/jcssp.2019.1161.1183},
note={cited By 11},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072804041&doi=10.3844%2fjcssp.2019.1161.1183&partnerID=40&md5=2905c2d77e9977d26eacf3fff2296e91},
abstract={Autism Spectrum Disorder is a lifelong neurodevelopmental condition which affects social interaction, communication and behaviour of an individual. The symptoms are diverse with different levels of severity. Recent studies have revealed that early intervention is highly effective for improving the condition. However, current ASD diagnostic criteria are subjective which makes early diagnosis challenging, due to the unavailability of well-defined medical tests to diagnose ASD. Over the years, several objective measures utilizing abnormalities found in EEG signals and statistical analysis have been proposed. Machine learning based approaches provide more flexibility and have produced better results in ASD classification. This paper presents a survey of major EEG-based ASD classification approaches from 2010 to 2018, which adopt machine learning. The methodology is divided into four phases: EEG data collection, pre-processing, feature extraction and classification. This study explores different techniques and tools used for pre-processing, feature extraction and feature selection techniques, classification models and measures for evaluating the model. We analyze the strengths and weaknesses of the techniques and tools. Further, this study summarizes the ASD classification approaches and discusses the existing challenges, limitations and future directions. © 2019 Gunavaran Brihadiswaran, Dilantha Haputhanthri, Sahan Gunathilaka, Dulani Meedeniya, Sampath Jayarathna.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Amelio201931,
author={Amelio, L. and Amelio, A.},
title={Classification methods in image analysis with a special focus on medical analytics},
journal={Intelligent Systems Reference Library},
year={2019},
volume={149},
pages={31-69},
doi={10.1007/978-3-319-94030-4_3},
note={cited By 6},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049526688&doi=10.1007%2f978-3-319-94030-4_3&partnerID=40&md5=43a7f4ca3f662d0f9a4ea92adbe950dc},
abstract={This paper describes the design and application of classification methods for image analysis and processing. Accordingly, the main trends and challenges of the machine learning are presented in multiple contexts where the image analysis plays a very important role, including security and biometrics, aerospace and satellite monitoring, document analysis, natural language understanding, and information retrieval. This is accomplished by introducing a categorisation of the most challenging classification methods according to the thematic context and classification typology. Hence, supervised and unsupervised classification methods are presented and discussed. It is followed by a special focus on the medical context, where the classification methods for image analysis are of prior importance in supporting the medical diagnosis process. Accordingly, the second part of the paper surveys the recent and current research in medical analytics where the image classification is a key aspect, and tracks the horizon of the research for future challenges in the field. © 2019, Springer International Publishing AG, part of Springer Nature.},
document_type={Book Chapter},
source={Scopus},
}

@ARTICLE{Yu2019100763,
author={Yu, B. and Li, F. and Zhou, F. and Wang, Z. and Zhu, R. and Feng, X. and Qi, M. and Li, J. and Zhao, R. and Huang, L. and Xin, R.},
title={The Transverse Ultrasonogram of Thyroid Papillary Carcinoma Has a Better Prediction Accuracy Than the Longitudinal One},
journal={IEEE Access},
year={2019},
volume={7},
pages={100763-100770},
doi={10.1109/ACCESS.2019.2926377},
art_number={8753680},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097336212&doi=10.1109%2fACCESS.2019.2926377&partnerID=40&md5=67396f95fe82644d7fbe6f22b4665c31},
abstract={Thyroid produces multiple essential hormones for vital life processes. Thyroid cancer has no symptoms and may be detected by ultrasound imaging incidentally for other medical conditions. An accurate computational detection model may help the precise diagnose of thyroid papillary cancer (TPC). A standard protocol captures at least the transverse and longitudinal ultrasonograms of the thyroid. This study investigated the detection problem of thyroid cancer using the ultrasound images. Our data suggested that the original local binary pattern (LBP) features extracted from the ultrasonograms were very sparse and the compressed LBP features outperformed the original version. And the best model (Acc = 0.9829) was achieved by the fivefold cross validation of the classifier support vector machine (SVM). Other sources of biomedical data may be integrated to further improve the TPC detection model in future studies. © 2013 IEEE.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Sharma2019,
author={Sharma, D. and Singh Aujla, G. and Bajaj, R.},
title={Evolution from ancient medication to human-centered Healthcare 4.0: A review on health care recommender systems},
journal={International Journal of Communication Systems},
year={2019},
doi={10.1002/dac.4058},
art_number={e4058},
note={cited By 7},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071931036&doi=10.1002%2fdac.4058&partnerID=40&md5=8d725f937a52bd19cfa9542229d32172},
abstract={The evolution of intelligent and data-driven systems has pushed for the tectonic transition from ancient medication to human-centric Healthcare 4.0. The rise of Internet of Things, Internet of Systems, and wireless body area networks has endowed the health care ecosystem with a new digital transformation supported by sophisticated machine learning and artificial intelligence algorithms. Under this umbrella, health care recommendation systems have emerged as a driver for providing patient-centric personalized health care services. Recommendation systems are automatic systems that derive the decisions on the basis of some valid input parameters and vital health information collected through wearable devices, implantable equipments, and various sensor. Therefore, to understand the state-of-the-art developments in the health care ecosystem, this paper provides a comprehensive survey on health care recommendation systems and the associated paradigms. This survey starts from the ancient health care era and move toward the Healthcare 4.0 in a phased manner. The road map from Healthcare 1.0 to Healthcare 4.0 is analyzed to highlight different technology verticals supporting the digital transformation. This study also provides the systematic review of the health care systems, the types of health care systems, and the recommender systems. Moreover, a deep analysis of health care recommender systems and its types is also presented. Finally, the open issues and challenges associated with the adaption and implementation of human-centric Healthcare 4.0 ecosystem are discussed. This is provided to find out the possible research questions and gaps so that the corresponding solutions could be developed in the near future. © 2019 John Wiley & Sons, Ltd.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Diniz201849,
author={Diniz, P.H.B. and Valente, T.L.A. and Diniz, J.O.B. and Silva, A.C. and Gattass, M. and Ventura, N. and Muniz, B.C. and Gasparetto, E.L.},
title={Detection of white matter lesion regions in MRI using SLIC0 and convolutional neural network},
journal={Computer Methods and Programs in Biomedicine},
year={2018},
volume={167},
pages={49-63},
doi={10.1016/j.cmpb.2018.04.011},
note={cited By 8},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046153286&doi=10.1016%2fj.cmpb.2018.04.011&partnerID=40&md5=43bf3f94ddddf38aa4098335ccbe45d2},
abstract={Background and Objective: White matter lesions are non-static brain lesions that have a prevalence rate up to 98% in the elderly population. Because they may be associated with several brain diseases, it is important that they are detected as soon as possible. Magnetic Resonance Imaging (MRI) provides three-dimensional data with the possibility to detect and emphasize contrast differences in soft tissues, providing rich information about the human soft tissue anatomy. However, the amount of data provided for these images is far too much for manual analysis/interpretation, representing a difficult and time-consuming task for specialists. This work presents a computational methodology capable of detecting regions of white matter lesions of the brain in MRI of FLAIR modality. The techniques highlighted in this methodology are SLIC0 clustering for candidate segmentation and convolutional neural networks for candidate classification. Methods: The methodology proposed here consists of four steps: (1) images acquisition, (2) images preprocessing, (3) candidates segmentation and (4) candidates classification. Results: The methodology was applied on 91 magnetic resonance images provided by DASA, and achieved an accuracy of 98.73%, specificity of 98.77% and sensitivity of 78.79% with 0.005 of false positives, without any false positives reduction technique, in detection of white matter lesion regions. Conclusions: It is demonstrated the feasibility of the analysis of brain MRI using SLIC0 and convolutional neural network techniques to achieve success in detection of white matter lesions regions. © 2018},
document_type={Article},
source={Scopus},
}

@ARTICLE{Knight2018119,
author={Knight, J. and Taylor, G.W. and Khademi, A.},
title={Voxel-Wise Logistic Regression and Leave-One-Source-Out Cross Validation for white matter hyperintensity segmentation},
journal={Magnetic Resonance Imaging},
year={2018},
volume={54},
pages={119-136},
doi={10.1016/j.mri.2018.06.009},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052860783&doi=10.1016%2fj.mri.2018.06.009&partnerID=40&md5=073e9037cdb81b8683476188c5940ae1},
abstract={Many algorithms have been proposed for automated segmentation of white matter hyperintensities (WMH) in brain MRI. Yet, broad uptake of any particular algorithm has not been observed. In this work, we argue that this may be due to variable and suboptimal validation data and frameworks, precluding direct comparison of methods on heterogeneous data. As a solution, we present Leave-One-Source-Out Cross Validation (LOSO-CV), which leverages all available data for performance estimation, and show that this gives more realistic (lower) estimates of segmentation algorithm performance on data from different scanners. We also develop a FLAIR-only WMH segmentation algorithm: Voxel-Wise Logistic Regression (VLR), inspired by the open-source Lesion Prediction Algorithm (LPA). Our variant facilitates more accurate parameter estimation, and permits intuitive interpretation of model parameters. We illustrate the performance of the VLR algorithm using the LOSO-CV framework with a dataset comprising freely available data from several recent competitions (96 images from 7 scanners). The performance of the VLR algorithm (median Similarity Index of 0.69) is compared to its LPA predecessor (0.58), and the results of the VLR algorithm in the 2017 WMH Segmentation Competition are also presented. © 2018 Elsevier Inc.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Kliangsuwan201840,
author={Kliangsuwan, T. and Heednacram, A.},
title={FFT features and hierarchical classification algorithms for cloud images},
journal={Engineering Applications of Artificial Intelligence},
year={2018},
volume={76},
pages={40-54},
doi={10.1016/j.engappai.2018.08.008},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052914258&doi=10.1016%2fj.engappai.2018.08.008&partnerID=40&md5=2e863408b96ebbbc2c77b9c11be74712},
abstract={Cloud-type recognition is useful in preventing losses caused by adverse weather conditions. This paper presents a methodology and algorithms for automatic recognition of cloud types from color cloud images taken from the ground. We propose a number of eight algorithms for automatic cloud classification of seven cloud types defined by meteorological organization. Recognition is based on a number of features extracted from images which are related to color, texture, and shape. We introduce three new features based on the Fourier transform, namely, the modified k-FFTPX, the half k-FFTPX, and the h×k-FFT. The classification technique is based on artificial neural network (ANN) with tree algorithm to extract features. The proposed classification tree algorithm uses the technique called hierarchical classification which is composed of three levels of tree. Each level of the tree is capable of classifying up to four classes. We show that this method provides the highest accuracy at 98.08% through a series of four experiments. For accuracy assessment, each experiment splits dataset into train and test images using Leave-One-Out Cross-Validation (LOOCV). The result confirms that the hierarchical classification performs better than a single classification. In addition, the tree can be adapted to classify lesser number of cloud types. Our experiment reveals that the accuracy for classifying two classes, cloud and no-cloud, is high as 100%. © 2018 Elsevier Ltd},
document_type={Article},
source={Scopus},
}

@ARTICLE{Santos201859,
author={Santos, M.S. and Soares, J.P. and Abreu, P.H. and Araujo, H. and Santos, J.},
title={Cross-validation for imbalanced datasets: Avoiding overoptimistic and overfitting approaches [Research Frontier]},
journal={IEEE Computational Intelligence Magazine},
year={2018},
volume={13},
number={4},
pages={59-76},
doi={10.1109/MCI.2018.2866730},
art_number={8492368},
note={cited By 55},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055271044&doi=10.1109%2fMCI.2018.2866730&partnerID=40&md5=670f7822dcfc82a8160b8451f71cb8e3},
abstract={Although cross-validation is a standard procedure for performance evaluation, its joint application with oversampling remains an open question for researchers farther from the imbalanced data topic. A frequent experimental flaw is the application of oversampling algorithms to the entire dataset, resulting in biased models and overly-optimistic estimates. We emphasize and distinguish overoptimism from overfitting, showing that the former is associated with the cross-validation procedure, while the latter is influenced by the chosen oversampling algorithm. Furthermore, we perform a thorough empirical comparison of well-established oversampling algorithms, supported by a data complexi ty analysis. The best oversampling techniques seem to possess three key characteristics: Use of cleaning procedures, cluster-based example synthetization and adaptive weighting of minority examples, where Synthetic Minority Oversampling Technique coupled with Tomek Links and Majority Weighted Minority Oversampling Technique stand out, being capable of increasing the discriminative power of data. © 2018 IEEE.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Alexandridis2018202,
author={Alexandridis, K. and Takemura, S. and Webb, A. and Lausche, B. and Culter, J. and Sato, T.},
title={Semantic knowledge network inference across a range of stakeholders and communities of practice},
journal={Environmental Modelling and Software},
year={2018},
volume={109},
pages={202-222},
doi={10.1016/j.envsoft.2018.08.026},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052628337&doi=10.1016%2fj.envsoft.2018.08.026&partnerID=40&md5=b29d12a3c63aa3275a0b509ad856932b},
abstract={This paper provides empirical and experimental assessments of thematic knowledge discourses based on two case studies in the US Virgin Islands and Florida. We utilize a latent semantic indexing analysis over natural language corpus to classify and categorize knowledge categories. We computed TF*IDF scores and associated co-occurrence Jaccard similarity scores to construct semantic knowledge networks. Using network analysis, we computed structural metrics over four composite groups: neighbor-based, centrality, equivalence and position. The analysis show that structural network characteristics of environmental knowledge can exponentially predict associations between knowledge categories. We show that connectivity play a critical role on acquisition, representation, and diffusion patterns of knowledge within local communities. We provide evidence of a global prevalence of a shared knowledge core. We show that core social-ecological attributes of knowledge follow scale-free, power law distributions and stable, equilibrium network structures. We identify two distinct models of bidirectional translation: a bottom-up and a top-down. © 2018 Elsevier Ltd},
document_type={Article},
source={Scopus},
}

@ARTICLE{Zhou2018,
author={Zhou, L. and Qiu, T. and Lv, F. and Liu, L. and Ying, J. and Wang, S.},
title={Self-Assembled Nanomedicines for Anticancer and Antibacterial Applications},
journal={Advanced Healthcare Materials},
year={2018},
volume={7},
number={20},
doi={10.1002/adhm.201800670},
art_number={1800670},
note={cited By 31},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052621800&doi=10.1002%2fadhm.201800670&partnerID=40&md5=875f8f8208c91dd64aaef43792c5f976},
abstract={Self-assembly strategies have been widely applied in the nanomedicine field, which provide a convenient approach for building various structures for delivery carriers. When cooperating with biomolecules, self-assembly systems have significant influence on the cell activity and life process and could be used for regulating nanodrug activity. In this review, self-assembled nanomedicines are introduced, including materials, encapsulation, and releasing strategies, where self-assembly strategies are involved. Furthermore, as a promising and emerging area for nanomedicine, in situ self-assembly of anticancer drugs and supramolecular antibiotic switches is also discussed about how to regulate drug activity. Selective pericellular assembly can block mass transformation of cancer cells inducing cell apoptosis, and the intracellular assembly can either cause cell death or effectively avoid drug elimination from cytosol of cancer cells because of the assembly-induced retention (AIR) effect. Host–guest interactions of drug and competitive molecules offer reversible regulations of antibiotic activity, which can reduce drug-resistance and inhibit the generation of drug-resistant bacteria. Finally, the challenges and development trend in the field are discussed. © 2018 WILEY-VCH Verlag GmbH & Co. KGaA, Weinheim},
document_type={Review},
source={Scopus},
}

@ARTICLE{Kwon2018,
author={Kwon, H.J. and Shin, K. and Soh, M. and Chang, H. and Kim, J. and Lee, J. and Ko, G. and Kim, B.H. and Kim, D. and Hyeon, T.},
title={Large-Scale Synthesis and Medical Applications of Uniform-Sized Metal Oxide Nanoparticles},
journal={Advanced Materials},
year={2018},
volume={30},
number={42},
doi={10.1002/adma.201704290},
art_number={1704290},
note={cited By 31},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044313686&doi=10.1002%2fadma.201704290&partnerID=40&md5=40cc7afbb0b547444e6e60cea4bc9857},
abstract={Thanks to recent advances in the synthesis of high-quality inorganic nanoparticles, more and more types of nanoparticles are becoming available for medical applications. Especially, metal oxide nanoparticles have drawn much attention due to their unique physicochemical properties and relatively inexpensive production costs. To further promote the development and clinical translation of these nanoparticle-based agents, however, it is highly desirable to reduce unwanted interbatch variations of the nanoparticles because characterizing and refining each batch are costly, take a lot of effort, and, thus, are not productive. Large-scale synthesis is a straightforward and economic pathway to minimize this issue. Here, the recent achievements in the large-scale synthesis of uniform-sized metal oxide nanoparticles and their biomedical applications are summarized, with a focus on nanoparticles of transition metal oxides and lanthanide oxides, and clarifying the underlying mechanism for the synthesis of uniform-sized nanoparticles. Surface modification steps to endow hydrophobic nanoparticles with water dispersibility and biocompatibility are also briefly described. Finally, various medical applications of metal oxide nanoparticles, such as bioimaging, drug delivery, and therapy, are presented. © 2018 WILEY-VCH Verlag GmbH & Co. KGaA, Weinheim},
document_type={Review},
source={Scopus},
}

@ARTICLE{Lerman2018359,
author={Lerman, M.J. and Lembong, J. and Muramoto, S. and Gillen, G. and Fisher, J.P.},
title={The Evolution of Polystyrene as a Cell Culture Material},
journal={Tissue Engineering - Part B: Reviews},
year={2018},
volume={24},
number={5},
pages={359-372},
doi={10.1089/ten.teb.2018.0056},
note={cited By 53},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054780543&doi=10.1089%2ften.teb.2018.0056&partnerID=40&md5=d5747f29aef958e840b24f2b6e3bd943},
abstract={Polystyrene (PS) has brought in vitro cell culture from its humble beginnings to the modern era, propelling dozens of research fields along the way. This review discusses the development of the material, fabrication, and treatment approaches to create the culture material. However, native PS surfaces poorly facilitate cell adhesion and growth in vitro. To overcome this, liquid surface deposition, energetic plasma activation, and emerging functionalization methods transform the surface chemistry. This review seeks to highlight the many potential applications of the first widely accepted polymer growth surface. Although the majority of in vitro research occurs on two-dimensional surfaces, the importance of three-dimensional (3D) culture models cannot be overlooked. The methods to transition PS to specialized 3D culture surfaces are also reviewed. Specifically, casting, electrospinning, 3D printing, and microcarrier approaches to shift PS to a 3D culture surface are highlighted. The breadth of applications of the material makes it impossible to highlight every use, but the aim remains to demonstrate the versatility and potential as both a general and custom cell culture surface. The review concludes with emerging scaffolding approaches and, based on the findings, presents our insights on the future steps for PS as a tissue culture platform. © Max J. Lerman et al., 2018; Published by Mary Ann Liebert, Inc. 2018.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Zhang201822821,
author={Zhang, Y.-D. and Muhammad, K. and Tang, C.},
title={Twelve-layer deep convolutional neural network with stochastic pooling for tea category classification on GPU platform},
journal={Multimedia Tools and Applications},
year={2018},
volume={77},
number={17},
pages={22821-22839},
doi={10.1007/s11042-018-5765-3},
note={cited By 62},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042533640&doi=10.1007%2fs11042-018-5765-3&partnerID=40&md5=f719a5d8a75596998ee04a6a9a46e072},
abstract={Automatic tea-category identification is an important topic in factories and supermarkets. Traditional methods need to extract features from tea images manually, which may not be optimal for tea images classification. To avoid the time consuming efforts of handcrafted features extraction, this study proposed a new method combining convolutional neural network (CNN) with stochastic pooling. We collected 900 tea images of Oolong, green, and black teas, with 300 images for each category. The data augmentation method was used over the training set. We employed stochastic gradient descent with momentum (SGDM) to train the CNN. The experiments showed that a 12-layer CNN gives a good result. The sensitivities of Oolong, green, and black tea are 99.5%, 97.5%, and 98.0%, respectively. The overall accuracy of all three-tea categories is 98.33%. The stochastic pooling gives better results than maximum pooling and average pooling. The optimal number of convolutional layer for this task is 5. In addition, GPU has a 175× acceleration in training set and a 122× acceleration in test set, compared to CPU platform. © 2018, Springer Science+Business Media, LLC, part of Springer Nature.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Kaushal2018423,
author={Kaushal, M. and Khehra, B.S. and Sharma, A.},
title={Soft Computing based object detection and tracking approaches: State-of-the-Art survey},
journal={Applied Soft Computing Journal},
year={2018},
volume={70},
pages={423-464},
doi={10.1016/j.asoc.2018.05.023},
note={cited By 21},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048538662&doi=10.1016%2fj.asoc.2018.05.023&partnerID=40&md5=b2d27a78d3c5708ed34f5fa810f8905f},
abstract={In recent years, analysis and interpretation of video sequences to detect and track objects of interest had become an active research field in computer vision and image processing. Detection and tracking includes extraction of moving object from frames and continuous tracking it thereafter forming persistent object trajectories over time. There are some really smart techniques proposed by researchers for efficient and robust detection or tracking of objects in videos. A comprehensive coverage of such innovative techniques for which solutions have been motivated by theories of soft computing approaches is proposed. The main objective of this research investigation is to study and highlight efforts of researchers who had conducted some brilliant work on soft computing based detection and tracking approaches in video sequence. The study is novel as it traces rise of soft computing methods in field of object detection and tracking in videos which has been neglected over the years. The survey is compilation of studies on neural network, deep learning, fuzzy logic, evolutionary algorithms, hybrid and recent innovative approaches that have been applied to field of detection and tracking. The paper also highlights benchmark datasets available to researchers for experimentation and validation of their own algorithms. Major research challenges in the field of detection and tracking along with some recommendations are also provided. The paper provides number of analyses to guide future directions of research and advocates for more applications of soft computing approaches for object detection and tracking approaches in videos. The paper is targeted at young researchers who will like to see it as platform for introduction to a mature and relatively complex field. The study will be helpful in appropriate use of an existing method for systematically designing a new approach or improving performance of existing approaches. © 2018 Elsevier B.V.},
document_type={Review},
source={Scopus},
}

@ARTICLE{Serra2018,
author={Serra, A. and Galdi, P. and Tagliaferri, R.},
title={Machine learning for bioinformatics and neuroimaging},
journal={Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery},
year={2018},
volume={8},
number={5},
doi={10.1002/widm.1248},
art_number={e1248},
note={cited By 17},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042368561&doi=10.1002%2fwidm.1248&partnerID=40&md5=0106dec06cfbadffc5a80a3a3efafab6},
abstract={Machine Learning (ML) is a well-known paradigm that refers to the ability of systems to learn a specific task from the data and aims to develop computer algorithms that improve with experience. It involves computational methodologies to address complex real-world problems and promises to enable computers to assist humans in the analysis of large, complex data sets. ML approaches have been widely applied to biomedical fields and a great body of research is devoted to this topic. The purpose of this article is to present the state-of-the art in ML applications to bioinformatics and neuroimaging and motivate research in new trend-setting directions. We show how ML techniques such as clustering, classification, embedding techniques and network-based approaches can be successfully employed to tackle various problems such as gene expression clustering, patient classification, brain networks analysis, and identification of biomarkers. We also present a short description of deep learning and multiview learning methodologies applied in these contexts. We discuss some representative methods to provide inspiring examples to illustrate how ML can be used to address these problems and how biomedical data can be characterized through ML. Challenges to be addressed and directions for future research are presented and an extensive bibliography is included. This article is categorized under: Application Areas > Health Care Technologies > Computational Intelligence Fundamental Concepts of Data and Knowledge > Motivation and Emergence of Data Mining Fundamental Concepts of Data and Knowledge > Key Design Issues in Data Mining. © 2018 Wiley Periodicals, Inc.},
document_type={Review},
source={Scopus},
}

@ARTICLE{Shishvan201846419,
author={Shishvan, O.R. and Zois, D.-S. and Soyata, T.},
title={Machine Intelligence in Healthcare and Medical Cyber Physical Systems: A Survey},
journal={IEEE Access},
year={2018},
volume={6},
pages={46419-46494},
doi={10.1109/ACCESS.2018.2866049},
art_number={8440026},
note={cited By 18},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051811308&doi=10.1109%2fACCESS.2018.2866049&partnerID=40&md5=fdafbf1877d0d2e156ac13992dbde09c},
abstract={Today, the US healthcare industry alone can save $300 B per year by using machine intelligence to analyze a rich set of existing medical data; results from these analyses can lead to breakthroughs such as more accurate medical diagnoses, discovery of new cures for diseases, and cost savings in the patient admission process at healthcare organizations. Because healthcare applications intrinsically imply a vast amount of data, the execution of any algorithm on medical data is computationally intensive. Significant advancements made in computational power in the past decade have provided the opportunity for many researchers to successfully implement various machine intelligence-based healthcare applications, which didn't run efficiently on earlier computational platforms. In this paper, we provide a survey of machine intelligence algorithms within the context of healthcare applications; our survey includes a comprehensive list of the most commonly used computational models and algorithms. We view the application of these algorithms in multiple steps, namely, data acquisition, feature extraction, and aggregation, modeling, algorithm training, and algorithm execution and provide details-as well as representative case studies-for each step. We provide a set of metrics that are used to evaluate modeling and algorithmic performance, which facilitate the comparison of the presented models and algorithms. Medical cyber-physical systems are presented as an emerging application case study of machine intelligence in healthcare. We conclude our paper by providing a list of opportunities and challenges for incorporating machine intelligence in healthcare applications and provide an extensive list of tools and databases to help other researchers. © 2013 IEEE.},
document_type={Review},
source={Scopus},
}

@ARTICLE{Ghosal20182653,
author={Ghosal, K. and Sarkar, K.},
title={Biomedical Applications of Graphene Nanomaterials and beyond},
journal={ACS Biomaterials Science and Engineering},
year={2018},
volume={4},
number={8},
pages={2653-2703},
doi={10.1021/acsbiomaterials.8b00376},
note={cited By 66},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049326377&doi=10.1021%2facsbiomaterials.8b00376&partnerID=40&md5=978a4c08dc5d4348271bed4cada17fe4},
abstract={Graphene nanomaterials have been considered as a novel class of nanomaterials that show exceptional structural, optical, thermal, electrical, and mechanical properties. As a consequence, it has been extensively studied in various fields including electronics, energy, catalysis, sensing, and biomedical fields. In the previous couple of years, a significant number of studies have been done on graphene-based nanomaterials, where it is utilized in a wide range of bioapplications that includes delivery of small molecule drugs/genes, biosensing, tissue engineering, bioimaging, and photothermal and photodynamic therapies because of its excellent aqueous processability, surface functionalizability, outstanding electrical and mechanical properties, tunable fluorescence properties, and surface-enhanced Raman scattering (SERS).Therefore, it is necessary to get detailed knowledge about it. In this review, we will highlight the various synthesis procedures of graphene family nanomaterials including graphene oxide (GO), reduced graphene oxide (rGO), and graphene quantum dots (GQDs) as well as their biomedical applications. We will also highlight the biocompatibity of graphene nanomaterials as well as its possible risk factors for bioapplications. In conclusion, we will outline the future perspective and current challenges of graphene nanomaterials for clinical applications. © Copyright 2018 American Chemical Society.},
document_type={Review},
source={Scopus},
}

@ARTICLE{Lee2018393,
author={Lee, H. and Mansouri, M. and Tajmir, S. and Lev, M.H. and Do, S.},
title={A Deep-Learning System for Fully-Automated Peripherally Inserted Central Catheter (PICC) Tip Detection},
journal={Journal of Digital Imaging},
year={2018},
volume={31},
number={4},
pages={393-402},
doi={10.1007/s10278-017-0025-z},
note={cited By 14},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030710900&doi=10.1007%2fs10278-017-0025-z&partnerID=40&md5=7a2dc1dc54402cb466da72c101479330},
abstract={A peripherally inserted central catheter (PICC) is a thin catheter that is inserted via arm veins and threaded near the heart, providing intravenous access. The final catheter tip position is always confirmed on a chest radiograph (CXR) immediately after insertion since malpositioned PICCs can cause potentially life-threatening complications. Although radiologists interpret PICC tip location with high accuracy, delays in interpretation can be significant. In this study, we proposed a fully-automated, deep-learning system with a cascading segmentation AI system containing two fully convolutional neural networks for detecting a PICC line and its tip location. A preprocessing module performed image quality and dimension normalization, and a post-processing module found the PICC tip accurately by pruning false positives. Our best model, trained on 400 training cases and selectively tuned on 50 validation cases, obtained absolute distances from ground truth with a mean of 3.10 mm, a standard deviation of 2.03 mm, and a root mean squares error (RMSE) of 3.71 mm on 150 held-out test cases. This system could help speed confirmation of PICC position and further be generalized to include other types of vascular access and therapeutic support devices. © 2017, Society for Imaging Informatics in Medicine.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Yuvaraj20181225,
author={Yuvaraj, R. and Rajendra Acharya, U. and Hagiwara, Y.},
title={A novel Parkinson’s Disease Diagnosis Index using higher-order spectra features in EEG signals},
journal={Neural Computing and Applications},
year={2018},
volume={30},
number={4},
pages={1225-1235},
doi={10.1007/s00521-016-2756-z},
note={cited By 35},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85004009876&doi=10.1007%2fs00521-016-2756-z&partnerID=40&md5=5c25f966d1a4aa1b842de888e4578a1c},
abstract={Higher-order spectra (HOS) is an efficient feature extraction method used in various biomedical applications such as stages of sleep, epilepsy detection, cardiac abnormalities, and affective computing. The motive of this work was to explore the application of HOS for an automated diagnosis of Parkinson’s disease (PD) using electroencephalography (EEG) signals. Resting-state EEG signals collected from 20 PD patients with medication and 20 age-matched normal subjects were used in this study. HOS bispectrum features were extracted from the EEG signals. The obtained features were ranked using t value, and highly ranked features were used in order to develop the PD Diagnosis Index (PDDI). The PDDI is a single value, which can discriminate the two classes. Also, the ranked features were fed one by one to the various classifiers, namely decision tree (DT), fuzzy K-nearest neighbor (FKNN), K-nearest neighbor (KNN), naive bayes (NB), probabilistic neural network (PNN), and support vector machine (SVM), to choose the best classifier using minimum number of features. We have obtained an optimum mean classification accuracy of 99.62%, mean sensitivity and specificity of 100.00 and 99.25%, respectively, using the SVM classifier. The proposed PDDI can aid the clinicians in their diagnosis and help to test the efficacy of drugs. © 2016, The Natural Computing Applications Forum.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Idri201869,
author={Idri, A. and Benhar, H. and Fernández-Alemán, J.L. and Kadi, I.},
title={A systematic map of medical data preprocessing in knowledge discovery},
journal={Computer Methods and Programs in Biomedicine},
year={2018},
volume={162},
pages={69-85},
doi={10.1016/j.cmpb.2018.05.007},
note={cited By 16},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046706780&doi=10.1016%2fj.cmpb.2018.05.007&partnerID=40&md5=30324a8f7b2702347d51c7c56b55b294},
abstract={Background and objective: Datamining (DM) has, over the last decade, received increased attention in the medical domain and has been widely used to analyze medical datasets in order to extract useful knowledge and previously unknown patterns. However, historical medical data can often comprise inconsistent, noisy, imbalanced, missing and high dimensional data. These challenges lead to a serious bias in predictive modeling and reduce the performance of DM techniques. Data preprocessing is, therefore, an essential step in knowledge discovery as regards improving the quality of data and making it appropriate and suitable for DM techniques. The objective of this paper is to review the use of preprocessing techniques in clinical datasets. Methods: We performed a systematic map of studies regarding the application of data preprocessing to healthcare and published between January 2000 and December 2017. A search string was determined on the basis of the mapping questions and the PICO categories. The search string was then applied in digital databases covering the fields of computer science and medical informatics in order to identify relevant studies. The studies were initially selected by reading their titles, abstracts and keywords. Those that were selected at that stage were then reviewed using a set of inclusion and exclusion criteria in order to eliminate any that were not relevant. This process resulted in 126 primary studies. Results: Selected studies were analyzed and classified according to their publication years and channels, research type, empirical type and contribution type. The findings of this mapping study revealed that researchers have paid a considerable amount of attention to preprocessing in medical DM in last decade. A significant number of the selected studies used data reduction and cleaning preprocessing tasks. Moreover, the disciplines in which preprocessing have received most attention are: cardiology, endocrinology and oncology. Conclusions: Researchers should develop and implement standards for an effective integration of multiple medical data types. Moreover, we identified the need to perform literature reviews. © 2018 Elsevier B.V.},
document_type={Review},
source={Scopus},
}

@ARTICLE{Cai201870,
author={Cai, J. and Luo, J. and Wang, S. and Yang, S.},
title={Feature selection in machine learning: A new perspective},
journal={Neurocomputing},
year={2018},
volume={300},
pages={70-79},
doi={10.1016/j.neucom.2017.11.077},
note={cited By 307},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043994324&doi=10.1016%2fj.neucom.2017.11.077&partnerID=40&md5=edd109b0c2dcefd65daab6ed82f86eef},
abstract={High-dimensional data analysis is a challenge for researchers and engineers in the fields of machine learning and data mining. Feature selection provides an effective way to solve this problem by removing irrelevant and redundant data, which can reduce computation time, improve learning accuracy, and facilitate a better understanding for the learning model or data. In this study, we discuss several frequently-used evaluation measures for feature selection, and then survey supervised, unsupervised, and semi-supervised feature selection methods, which are widely applied in machine learning problems, such as classification and clustering. Lastly, future challenges about feature selection are discussed. © 2018 Elsevier B.V.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Liu20181197,
author={Liu, M. and Gao, Y. and Yap, P.-T. and Shen, D.},
title={Multi-Hypergraph Learning for Incomplete Multimodality Data},
journal={IEEE Journal of Biomedical and Health Informatics},
year={2018},
volume={22},
number={4},
pages={1197-1208},
doi={10.1109/JBHI.2017.2732287},
note={cited By 16},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028942363&doi=10.1109%2fJBHI.2017.2732287&partnerID=40&md5=ae028ed3a935e0086fb448445503cbf8},
abstract={Multi-modality data convey complementary information that can be used to improve the accuracy of prediction models in disease diagnosis. However, effectively integrating multi-modality data remains a challenging problem, especially when the data are incomplete. For instance, more than half of the subjects in the Alzheimer's disease neuroimaging initiative (ADNI) database have no fluorodeoxyglucose positron emission tomography and cerebrospinal fluid data. Currently, there are two commonly used strategies to handle the problem of incomplete data: 1) discard samples having missing features; and 2) impute those missing values via specific techniques. In the first case, a significant amount of useful information is lost and, in the second case, additional noise and artifacts might be introduced into the data. Also, previous studies generally focus on the pairwise relationships among subjects, without considering their underlying complex (e.g., high-order) relationships. To address these issues, in this paper, we propose a multi-hypergraph learning method for dealing with incomplete multimodality data. Specifically, we first construct multiple hypergraphs to represent the high-order relationships among subjects by dividing them into several groups according to the availability of their data modalities. A hypergraph regularized transductive learning method is then applied to these groups for automatic diagnosis of brain diseases. Extensive evaluation of the proposed method using all subjects in the baseline ADNI database indicates that our method achieves promising results in AD/MCI classification, compared with the state-of-the-art methods. © 2017 IEEE.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Kellmeyer2018,
author={Kellmeyer, P. and Grosse-Wentrup, M. and Schulze-Bonhage, A. and Ziemann, U. and Ball, T.},
title={Electrophysiological correlates of neurodegeneration in motor and non-motor brain regions in amyotrophic lateral sclerosis - Implications for brain-computer interfacing},
journal={Journal of Neural Engineering},
year={2018},
volume={15},
number={4},
doi={10.1088/1741-2552/aabfa5},
art_number={041003},
note={cited By 6},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049800682&doi=10.1088%2f1741-2552%2faabfa5&partnerID=40&md5=e28f840db55ccb652024a53078655dc7},
abstract={Objective. For patients with amyotrophic lateral sclerosis (ALS) who are suffering from severe communication or motor problems, brain-computer interfaces (BCIs) can improve the quality of life and patient autonomy. However, current BCI systems are not as widely used as their potential and patient demand would let assume. This underutilization is a result of technological as well as user-based limitations but also of the comparatively poor performance of currently existing BCIs in patients with late-stage ALS, particularly in the locked-in state. Approach. Here we review a broad range of electrophysiological studies in ALS patients with the aim to identify electrophysiological correlates of ALS-related neurodegeneration in motor and non-motor brain regions in to better understand potential neurophysiological limitations of current BCI systems for ALS patients. To this end we analyze studies in ALS patients that investigated basic sensory evoked potentials, resting-state and task-based paradigms using electroencephalography or electrocorticography for basic research purposes as well as for brain-computer interfacing. Main results and significance. Our review underscores that, similarly to mounting evidence from neuroimaging and neuropathology, electrophysiological measures too indicate neurodegeneration in non-motor areas in ALS. Furthermore, we identify an unexpected gap of basic and advanced electrophysiological studies in late-stage ALS patients, particularly in the locked-in state. We propose a research strategy on how to fill this gap in order to improve the design and performance of future BCI systems for this patient group. © 2018 IOP Publishing Ltd.},
document_type={Review},
source={Scopus},
}

@ARTICLE{Mahmud20182063,
author={Mahmud, M. and Kaiser, M.S. and Hussain, A. and Vassanelli, S.},
title={Applications of Deep Learning and Reinforcement Learning to Biological Data},
journal={IEEE Transactions on Neural Networks and Learning Systems},
year={2018},
volume={29},
number={6},
pages={2063-2079},
doi={10.1109/TNNLS.2018.2790388},
note={cited By 213},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041424010&doi=10.1109%2fTNNLS.2018.2790388&partnerID=40&md5=7eaf8e273afd77b7f7d3f54e3c30471f},
abstract={Rapid advances in hardware-based technologies during the past decades have opened up new possibilities for life scientists to gather multimodal data in various application domains, such as omics, bioimaging, medical imaging, and (brain/body)-machine interfaces. These have generated novel opportunities for development of dedicated data-intensive machine learning techniques. In particular, recent research in deep learning (DL), reinforcement learning (RL), and their combination (deep RL) promise to revolutionize the future of artificial intelligence. The growth in computational power accompanied by faster and increased data storage, and declining computing costs have already allowed scientists in various fields to apply these techniques on data sets that were previously intractable owing to their size and complexity. This paper provides a comprehensive survey on the application of DL, RL, and deep RL techniques in mining biological data. In addition, we compare the performances of DL techniques when applied to different data sets across various application domains. Finally, we outline open issues in this challenging research area and discuss future development perspectives. © 2012 IEEE.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Zhang2018,
author={Zhang, Y. and Yang, S. and Liu, Y. and Zhang, Y. and Han, B. and Zhou, F.},
title={Integration of 24 feature types to accurately detect and predict seizures using scalp EEG signals},
journal={Sensors (Switzerland)},
year={2018},
volume={18},
number={5},
doi={10.3390/s18051372},
art_number={1372},
note={cited By 21},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046115702&doi=10.3390%2fs18051372&partnerID=40&md5=8103625208ba9b3f53ca916a282bf5fe},
abstract={The neurological disorder epilepsy causes substantial problems to the patients with uncontrolled seizures or even sudden deaths. Accurate detection and prediction of epileptic seizures will significantly improve the life quality of epileptic patients. Various feature extraction algorithms were proposed to describe the EEG signals in frequency or time domains. Both invasive intracranial and non-invasive scalp EEG signals have been screened for the epileptic seizure patterns. This study extracted a comprehensive list of 24 feature types from the scalp EEG signals and found 170 out of the 2794 features for an accurate classification of epileptic seizures. An accuracy (Acc) of 99.40% was optimized for detecting epileptic seizures from the scalp EEG signals. A balanced accuracy (bAcc) was calculated as the average of sensitivity and specificity and our seizure detection model achieved 99.61% in bAcc. The same experimental procedure was applied to predict epileptic seizures in advance, and the model achieved Acc = 99.17% for predicting epileptic seizures 10 s before happening. © 2018 by the authors. Licensee MDPI, Basel, Switzerland.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Bernard2018,
author={Bernard, L. and Bonnet, M. and Delavaud, C. and Delosière, M. and Ferlay, A. and Fougère, H. and Graulet, B.},
title={Milk Fat Globule in Ruminant: Major and Minor Compounds, Nutritional Regulation and Differences Among Species},
journal={European Journal of Lipid Science and Technology},
year={2018},
volume={120},
number={5},
doi={10.1002/ejlt.201700039},
art_number={1700039},
note={cited By 24},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044720053&doi=10.1002%2fejlt.201700039&partnerID=40&md5=623130aa368fa11103ebf2b50adaa6a8},
abstract={Recent knowledge is presented on the composition of ruminant milk fat fractions and the nutritional strategies known to alter their amount. The development of lipidomic and proteomic analyses has allowed for the characterization of minor components, such as proteins, liposoluble vitamins, and phospholipids of the milk fat globule (MFG), in addition to the triacylglycerols (TAG), which are the major constituents of the MFG core. Few differences in these components among ruminant species exist, and they have been outlined mainly on the fatty acids (FA) profile of the TAG, whereas comparative data are still lacking on vitamins and proteins. The effects of dietary treatments enriched in n-3 polyunsaturated FA (PUFA) on the composition of the milk fat fraction are explored. In particular, pasture and plant oilseeds increase milk n-3 PUFA and cis-9,trans-11 CLA and decrease saturated FA, whereas data with new feed resources, such as algae, are still rare. The peculiarities of the response of the milk fat to diets that induce a milk fat depression in cows but in lesser extent in small ruminants are described. The potential effects of polar lipids, proteins, and liposoluble vitamins of the MFG on human health are reviewed, highlighting the nutraceutical properties of milk. Practical Applications: This review provides an overview of the different components of the milk fat fraction in ruminant species and on nutritional strategies to alter their amounts to improve the nutritional quality of milk. Furthermore, this review presents recent data on species peculiarities of the milk fat fraction composition and of its response to nutritional factors, which offers a promising model to identify news levers of regulation of this fraction and foster the identification of new feeding strategies to better control milk fat composition and feed efficiency. This review synthesizes data on the composition of the milk fat fraction in ruminant species, reports advances in nutritional strategies to alter their amounts and species-specific responses to nutrition, as well as the potential effects on human health of the major and minor components of this fraction. © 2018 WILEY-VCH Verlag GmbH & Co. KGaA, Weinheim},
document_type={Review},
source={Scopus},
}

@ARTICLE{Jha2018140,
author={Jha, D. and Kwon, G.-R.},
title={Development of an efficient cascade pathological-brain detection system using a median filter and quadratic discriminant analysis},
journal={IEIE Transactions on Smart Processing and Computing},
year={2018},
volume={7},
number={2},
pages={140-147},
doi={10.5573/IEIESPC.2018.7.2.140},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049158983&doi=10.5573%2fIEIESPC.2018.7.2.140&partnerID=40&md5=9d1313d50b10ad8d0448b1d3c03076c0},
abstract={This research article proposes smart utilization of a machine learning technique to discriminate between normal and pathological brain images. The method is based on the following computational technique: a median filter is utilized for pre-processing input images; discrete wavelet transform (DWT) is utilized for feature extraction; principal component analysis (PCA) minimizes the dimensionality of the wavelet coefficients; and quadratic discriminate analysis (QDA) classifies the reduced features as normal or pathological. Experiments were carried out on 90 images (five normal and 85 pathological) from a Harvard Medical School dataset. The proposed system yielded excellent classification accuracy of 98.90% with 10× 5-fold stratified cross-validation (SCV). Moreover, the proposed technique outperforms seven state-of-the-art algorithms in terms of accuracy. Furthermore, our method signifies its effectiveness when compared with other machine learning approaches. © 2018 Institute of Electronics and Information Engineers. All rights reserved.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Wen2018,
author={Wen, D. and Wei, Z. and Zhou, Y. and Li, G. and Zhang, X. and Han, W.},
title={Deep learning methods to process fmri data and their application in the diagnosis of cognitive impairment: A brief overview and our opinion},
journal={Frontiers in Neuroinformatics},
year={2018},
volume={12},
doi={10.3389/fninf.2018.00023},
art_number={23},
note={cited By 27},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049066468&doi=10.3389%2ffninf.2018.00023&partnerID=40&md5=7025a0d76da7576306639af03e4dfc60},
document_type={Note},
source={Scopus},
}

@ARTICLE{Kanmani2018,
author={Kanmani, P. and Marikkannu, P.},
title={MRI Brain Images Classification: A Multi-Level Threshold Based Region Optimization Technique},
journal={Journal of Medical Systems},
year={2018},
volume={42},
number={4},
doi={10.1007/s10916-018-0915-8},
art_number={62},
note={cited By 16},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042562222&doi=10.1007%2fs10916-018-0915-8&partnerID=40&md5=0ba8d62e2d47da7ae3f7c9992d7e44cf},
abstract={Medical image processing is the most challenging and emerging field nowadays. Magnetic Resonance Images (MRI) act as the source for the development of classification system. The extraction, identification and segmentation of infected region from Magnetic Resonance (MR) brain image is significant concern but a dreary and time-consuming task performed by radiologists or clinical experts, and the final classification accuracy depends on their experience only. To overcome these limitations, it is necessary to use computer-aided techniques. To improve the efficiency of classification accuracy and reduce the recognition complexity involves in the medical image segmentation process, we have proposed Threshold Based Region Optimization (TBRO) based brain tumor segmentation. The experimental results of proposed technique have been evaluated and validated for classification performance on magnetic resonance brain images, based on accuracy, sensitivity, and specificity. The experimental results achieved 96.57% accuracy, 94.6% specificity, and 97.76% sensitivity, shows the improvement in classifying normal and abnormal tissues among given images. Detection, extraction and classification of tumor from MRI scan images of the brain is done by using MATLAB software. © 2018, Springer Science+Business Media, LLC, part of Springer Nature.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Sathyanarayana2018225,
author={Sathyanarayana, S. and Satzoda, R.K. and Sathyanarayana, S. and Thambipillai, S.},
title={Vision-based patient monitoring: a comprehensive review of algorithms and technologies},
journal={Journal of Ambient Intelligence and Humanized Computing},
year={2018},
volume={9},
number={2},
pages={225-251},
doi={10.1007/s12652-015-0328-1},
note={cited By 37},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044944852&doi=10.1007%2fs12652-015-0328-1&partnerID=40&md5=0c48fbd0acea4d9db0f206172fb4d536},
abstract={Vision-based monitoring for assisted living is gaining increasing attention, especially in multi-modal monitoring systems owing to the several advantages of vision-based sensors. In this paper, a detailed survey of some of the important vision-based patient monitoring applications is presented, namely (a) fall detection (b) action and activity monitoring (c) sleep monitoring (d) respiration and apnea monitoring (e) epilepsy monitoring (f) vital signs monitoring and (g) facial expression monitoring. The challenges and state-of-art technologies in each of these applications is presented. This is the first work to present such a comprehensive survey with the focus on a set of seven most common applications pertaining to patient monitoring. Potential future directions are presented while also considering practical large scale deployment of vision-based systems in patient monitoring. One of the important conclusions drawn is that rather than applying generic algorithms, use of the application context of patient monitoring can be a useful way to develop novel techniques that are robust and yet cost-effective. © 2015, Springer-Verlag Berlin Heidelberg.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Wang2018,
author={Wang, R.W.Y. and Huarng, S.-P. and Chuang, S.-W.},
title={Right Fronto-Temporal EEG can Differentiate the Affective Responses to Award-Winning Advertisements},
journal={International Journal of Neural Systems},
year={2018},
volume={28},
number={3},
doi={10.1142/S0129065717500307},
art_number={1750030},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021053598&doi=10.1142%2fS0129065717500307&partnerID=40&md5=161f05f3986d20e9531f676738537e30},
abstract={Affective engineering aims to improve service/product design by translating the customer's psychological feelings. Award-winning advertisements (AAs) were selected on the basis of the professional standards that consider creativity as a prerequisite. However, it is unknown if AA is related to satisfactory advertising performance among customers or only to the experts' viewpoints towards the advertisements. This issue in the field of affective engineering and design merits in-depth evaluation. We recruited 30 subjects and performed an electroencephalography (EEG) experiment while watching AAs and non-AAs (NAAs). The event-related potential (ERP) data showed that AAs evoked larger positive potentials 250-1400 ms after stimulus onset, particularly in the right frontooral regions. The behavioral results were consistent with the professional recognition given to AAs by experts. The perceived levels of creativity and "product-like" quality were higher for the AAs than for the NAAs. Event-related spectral perturbation (ERSP) analysis further revealed statistically significant differences in the theta, alpha, beta, and gamma band activity in the right frontooral regions between the AAs and NAAs. Our results confirm that EEG features from the time/frequency domains can differentiate affective responses to AAs at a neural circuit level, and provide scientific evidence to support the identification of AAs. © 2018 World Scientific Publishing Company.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Ahadian2018,
author={Ahadian, S. and Civitarese, R. and Bannerman, D. and Mohammadi, M.H. and Lu, R. and Wang, E. and Davenport-Huyer, L. and Lai, B. and Zhang, B. and Zhao, Y. and Mandla, S. and Korolj, A. and Radisic, M.},
title={Organ-On-A-Chip Platforms: A Convergence of Advanced Materials, Cells, and Microscale Technologies},
journal={Advanced Healthcare Materials},
year={2018},
volume={7},
number={2},
doi={10.1002/adhm.201700506},
art_number={1700506},
note={cited By 95},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031413199&doi=10.1002%2fadhm.201700506&partnerID=40&md5=bf640139fc6614a51dec4cef19446418},
abstract={Significant advances in biomaterials, stem cell biology, and microscale technologies have enabled the fabrication of biologically relevant tissues and organs. Such tissues and organs, referred to as organ-on-a-chip (OOC) platforms, have emerged as a powerful tool in tissue analysis and disease modeling for biological and pharmacological applications. A variety of biomaterials are used in tissue fabrication providing multiple biological, structural, and mechanical cues in the regulation of cell behavior and tissue morphogenesis. Cells derived from humans enable the fabrication of personalized OOC platforms. Microscale technologies are specifically helpful in providing physiological microenvironments for tissues and organs. In this review, biomaterials, cells, and microscale technologies are described as essential components to construct OOC platforms. The latest developments in OOC platforms (e.g., liver, skeletal muscle, cardiac, cancer, lung, skin, bone, and brain) are then discussed as functional tools in simulating human physiology and metabolism. Future perspectives and major challenges in the development of OOC platforms toward accelerating clinical studies of drug discovery are finally highlighted. © 2017 WILEY-VCH Verlag GmbH & Co. KGaA, Weinheim},
document_type={Review},
source={Scopus},
}

@ARTICLE{Qureshi2018347,
author={Qureshi, S. and Hagelbäck, J. and Iqbal, S.M.Z. and Javaid, H. and Lindley, C.A.},
title={Evaluation of classifiers for emotion detection while performing physical and visual tasks: Tower of Hanoi and IAPS},
journal={Advances in Intelligent Systems and Computing},
year={2018},
volume={868},
pages={347-363},
doi={10.1007/978-3-030-01054-6_25},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057084220&doi=10.1007%2f978-3-030-01054-6_25&partnerID=40&md5=37b9427d50e58dd29e6112a3dc0fe206},
abstract={With the advancement in robot technology, smart human-robot interaction is of increasing importance for allowing the more excellent use of robots integrated into human environments and activities. If a robot can identify emotions and intentions of a human interacting with it, interactions with humans can potentially become more natural and effective. However, mechanisms of perception and empathy used by humans to achieve this understanding may not be suitable or adequate for use within robots. Electroencephalography (EEG) can be used for recording signals revealing emotions and motivations from a human brain. This study aimed to evaluate different machine learning techniques to classify EEG data associated with specific affective/emotional states. For experimental purposes, we used visual (IAPS) and physical (Tower of Hanoi) tasks to record human emotional states in the form of EEG data. The obtained EEG data processed, formatted and evaluated using various machine learning techniques to find out which method can most accurately classify EEG data according to associated affective/emotional states. The experiment confirms the choice of a method for improving the accuracy of results. According to the results, Support Vector Machine was the first, and Regression Tree was the second best method for classifying EEG data associated with specific affective/emotional states with accuracies up to 70.00% and 60.00%, respectively. In both tasks, SVM was better in performance than RT. © Springer Nature Switzerland AG 2019.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Berahim20183152,
author={Berahim, M. and Samsudin, N.A. and Nathan, S.S.},
title={A Review: Supervised technique for automated disease diagnostic using medical image},
journal={Journal of Engineering and Applied Sciences},
year={2018},
volume={13},
number={Specialissue3},
pages={3152-3158},
doi={10.3923/jeasci.2018.3152.3158},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049919225&doi=10.3923%2fjeasci.2018.3152.3158&partnerID=40&md5=ebbc1e94227d467a5b0941bb70a6ba67},
abstract={The result of medical images diagnostic will affect clinical decision-making for diagnostics as well as the treatment planning. Thus, an accurate classifier is needed to improve automated diagnostic result. Each design of classifier and all phases involved will lead to better classification result for the accurate diagnostic. Many techniques have been used either conventional, modification or extension. However, limited review has been done in listing the recent supervised techniques in parametric and non-parametric categories for medical diagnostic procedure. Thus, the aim of this study is to provide an overview of medical image diagnostic using supervised technique and the factors to be considered for developing an accurate classifier. This will inspire newbie researcher or radiologist for and to be used when analyzing different types of medical image. The current studies of image classification task were summarized, the prominent parametric and non-parametric supervised technique identified and discussed in this study. © Medwell Journals, 2018.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Berahim2018298,
author={Berahim, M. and Samsudin, N.A. and Nathan, S.S.},
title={A review: Image analysis techniques to improve labeling accuracy of medical image classification},
journal={Advances in Intelligent Systems and Computing},
year={2018},
volume={700},
pages={298-307},
doi={10.1007/978-3-319-72550-5_29},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041518445&doi=10.1007%2f978-3-319-72550-5_29&partnerID=40&md5=c444e47a661974d032a6ede59eb9eb69},
abstract={Medical images contain the Region of Interest (ROI) from the affected area in human body and provide useful information to support clinical decision-making for diagnostics as well as the treatment planning. Unfortunately, medical image data may contain noise, missing values, inhomogeneous ROI that may give inaccurate diagnostic. Therefore, image analysis techniques are needed to improve the quality of an image. Then, features extraction task will be performed to produce best feature of images which leads to better classification result for accurate diagnostic. Many techniques have been used for image analysis. However, limited review have been done in categorize the list of related techniques for each image analysis task in medical imaging application. Thus, the aims of this paper is to gather and present general overview of image analysis task and their techniques in order to inspire researcher, pathologist or radiologist to adapt it when analyzing different types of medical image. The current study of image analysis task was summarized and discussed in this paper. © 2018, Springer International Publishing AG.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Cai2018,
author={Cai, H. and Han, J. and Chen, Y. and Sha, X. and Wang, Z. and Hu, B. and Yang, J. and Feng, L. and Ding, Z. and Chen, Y. and Gutknecht, J.},
title={A Pervasive Approach to EEG-Based Depression Detection},
journal={Complexity},
year={2018},
volume={2018},
doi={10.1155/2018/5238028},
art_number={5238028},
note={cited By 45},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042526659&doi=10.1155%2f2018%2f5238028&partnerID=40&md5=f44ecdcbe0893328c3c8980db5697832},
abstract={Nowadays, depression is the world's major health concern and economic burden worldwide. However, due to the limitations of current methods for depression diagnosis, a pervasive and objective approach is essential. In the present study, a psychophysiological database, containing 213 (92 depressed patients and 121 normal controls) subjects, was constructed. The electroencephalogram (EEG) signals of all participants under resting state and sound stimulation were collected using a pervasive prefrontal-lobe three-electrode EEG system at Fp1, Fp2, and Fpz electrode sites. After denoising using the Finite Impulse Response filter combining the Kalman derivation formula, Discrete Wavelet Transformation, and an Adaptive Predictor Filter, a total of 270 linear and nonlinear features were extracted. Then, the minimal-redundancy-maximal-relevance feature selection technique reduced the dimensionality of the feature space. Four classification methods (Support Vector Machine, K-Nearest Neighbor, Classification Trees, and Artificial Neural Network) distinguished the depressed participants from normal controls. The classifiers' performances were evaluated using 10-fold cross-validation. The results showed that K-Nearest Neighbor (KNN) had the highest accuracy of 79.27%. The result also suggested that the absolute power of the theta wave might be a valid characteristic for discriminating depression. This study proves the feasibility of a pervasive three-electrode EEG acquisition system for depression diagnosis. © 2018 Hanshu Cai et al.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Mohd20181,
author={Mohd, F. and Jalil, M.A. and Mohamad Noor, N.M. and Bakar, Z.A. and Abdullah, Z.},
title={Enhancement of bayesian model with relevance feedback for improving diagnostic model},
journal={Malaysian Journal of Computer Science},
year={2018},
volume={31},
number={5},
pages={1-14},
doi={10.22452/mjcs.sp2018no1.1},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065493419&doi=10.22452%2fmjcs.sp2018no1.1&partnerID=40&md5=0e9fd819b5516330ece68c3f0a9ead02},
abstract={An enhanced method to classify multi-class clinical disease is proposed in this study. The enhanced method is based on the Bayesian Model, which incorporates Bayes' rule and probability theory. It covers three main components: prior, conditional, and posterior probability. The recommended enhancement method is the Bayesian Relevance Feedback (BRF) Model. BRF can solve the non-existent value of posterior probabilities (zero values of probability), focusing on increasing the classification accuracy in the diagnosis of disease. The BRF has the capability to produce significant classes or target (cancer stage) by exploiting relevance feedback. Consequently, models based on eight different classifiers-K-Nearest Neighbors, Bayesian Model, Rule OneR, Meta MultiClass Classifier, Multilayer Perceptron, Random Tree, SMO-Poly Kernel, and Naive Bayes-were applied in the evaluation process. The results of the experimental works using an oral cancer dataset show that BRF outperformed the eight other classifier models, achieving 95.83% classification accuracy. © 2018, Malaysian Journal of Computer Science.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Li201866,
author={Li, Z. and Zhang, X. and Müller, H. and Zhang, S.},
title={Large-scale retrieval for medical image analytics: A comprehensive review},
journal={Medical Image Analysis},
year={2018},
volume={43},
pages={66-84},
doi={10.1016/j.media.2017.09.007},
note={cited By 75},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031765308&doi=10.1016%2fj.media.2017.09.007&partnerID=40&md5=335200bd8a11a7e0497b257b7a098d85},
abstract={Over the past decades, medical image analytics was greatly facilitated by the explosion of digital imaging techniques, where huge amounts of medical images were produced with ever-increasing quality and diversity. However, conventional methods for analyzing medical images have achieved limited success, as they are not capable to tackle the huge amount of image data. In this paper, we review state-of-the-art approaches for large-scale medical image analysis, which are mainly based on recent advances in computer vision, machine learning and information retrieval. Specifically, we first present the general pipeline of large-scale retrieval, summarize the challenges/opportunities of medical image analytics on a large-scale. Then, we provide a comprehensive review of algorithms and techniques relevant to major processes in the pipeline, including feature representation, feature indexing, searching, etc. On the basis of existing work, we introduce the evaluation protocols and multiple applications of large-scale medical image retrieval, with a variety of exploratory and diagnostic scenarios. Finally, we discuss future directions of large-scale retrieval, which can further improve the performance of medical image analysis. © 2017 Elsevier B.V.},
document_type={Review},
source={Scopus},
}

@ARTICLE{Li201866723,
author={Li, Y. and Wang, X. and Liu, Z. and Liang, X. and Si, S.},
title={The entropy algorithm and its variants in the fault diagnosis of rotating machinery: A review},
journal={IEEE Access},
year={2018},
volume={6},
pages={66723-66741},
doi={10.1109/ACCESS.2018.2873782},
art_number={8528456},
note={cited By 84},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056562278&doi=10.1109%2fACCESS.2018.2873782&partnerID=40&md5=f97edecb788b5ebb2a6531ae988da6af},
abstract={Rotating machines have been widely used in industrial engineering. The fault diagnosis of rotating machines plays a vital important role to reduce the catastrophic failures and heavy economic loss. However, the measured vibration signal of rotating machinery often represents non-linear and non-stationary characteristics, resulting in difficulty in the fault feature extraction. As a statistical measure, entropy can quantify the complexity and detect dynamic change through taking into account the non-linear behavior of time series. Therefore, entropy can be served as a promising tool to extract the dynamic characteristics of rotating machines. Recently, many studies have applied entropy in fault diagnosis of rotating machinery. This paper aims to investigate the applications of entropy for the fault characteristics extraction of rotating machines. First, various entropy methods are briefly introduced. Its foundation, application, and some improvements are described and discussed. The review is divided into eight parts: Shannon entropy, Rényi entropy, approximate entropy, sample entropy, fuzzy entropy, permutation entropy, and other entropy methods. In each part, we will review the applications using the original entropy method and the improved entropy methods, respectively. In the end, a summary and some research prospects are given. © 2013 IEEE.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Almeida201826,
author={Almeida, J.R.C. and Greenberg, T. and Lu, H. and Chase, H.W. and Fournier, J. and Cooper, C.M. and Deckersbach, T. and Adams, P. and Carmody, T. and Fava, M. and Kurian, B. and McGrath, P.J. and McInnis, M.G. and Oquendo, M.A. and Parsey, R. and Weissman, M. and Trivedi, M. and Phillips, M.L.},
title={Test-retest reliability of cerebral blood flow in healthy individuals using arterial spin labeling: Findings from the EMBARC study},
journal={Magnetic Resonance Imaging},
year={2018},
volume={45},
pages={26-33},
doi={10.1016/j.mri.2017.09.004},
note={cited By 7},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029804464&doi=10.1016%2fj.mri.2017.09.004&partnerID=40&md5=5d2fee13a665fa8c619acb4152ce6a3e},
abstract={Introduction Previous investigations of test-retest reliability of cerebral blood flow (CBF) at rest measured with pseudo-continuous Arterial Spin Labeling (pCASL) demonstrated good reliability, but are limited by the use of similar scanner platforms. In the present study we examined test-retest reliability of CBF in regions implicated in emotion and the default mode network. Material and methods We measured absolute and relative CBF at rest in thirty-one healthy subjects in two scan sessions, one week apart, at four different sites and three different scan platforms. We derived CBF from pCASL images with an automated algorithm and calculated intra-class correlation coefficients (ICCs) across sessions for regions of interest. In addition, we investigated site effects. Results For both absolute and relative CBF measures, ICCs were good to excellent (i.e. > 0.6) in most brain regions, with highest values observed for the subgenual anterior cingulate cortex and ventral striatum. A leave-one-site-out cross validation analysis did not show a significant effect for site on whole brain CBF and there was no proportional bias across sites. However, a significant site effect was present in the repeated measures ANOVA. Conclusions The high test-retest reliability of CBF measured with pCASL in a range of brain regions implicated in emotion and salience processing, emotion regulation, and the default mode network, which have been previously linked to depression symptomatology supports its use in studies that aim to identify neuroimaging biomarkers of treatment response. © 2017 Elsevier Inc.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Cox2018481,
author={Cox, R. and Schapiro, A.C. and Stickgold, R.},
title={Variability and stability of large-scale cortical oscillation patterns},
journal={Network Neuroscience},
year={2018},
volume={2},
number={4},
pages={481-512},
doi={10.1162/netn_a_00046},
note={cited By 7},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077174625&doi=10.1162%2fnetn_a_00046&partnerID=40&md5=76b6454f8ad2ffeea7634a3067dc011b},
abstract={Individual differences in brain organization exist at many spatiotemporal scales and underlie the diversity of human thought and behavior. Oscillatory neural activity is crucial for these processes, but how such rhythms are expressed across the cortex within and across individuals is poorly understood. We conducted a systematic characterization of brain-wide activity across frequency bands and oscillatory features during rest and task execution. We found that oscillatory profiles exhibit sizable group-level similarities, indicating the presence of common templates of oscillatory organization. Nonetheless, well-defined subject-specific network profiles were discernible beyond the structure shared across individuals. These individualized patterns were sufficiently stable to recognize individuals several months later. Moreover, network structure of rhythmic activity varied considerably across distinct oscillatory frequencies and features, indicating the existence of several parallel information processing streams embedded in distributed electrophysiological activity. These findings suggest that network similarity analyses may be useful for understanding the role of large-scale brain oscillations in physiology and behavior. © 2018 Massachusetts Institute of Technology Published under a Creative Commons Attribution 4.0 International (CC BY 4.0) license.},
document_type={Article},
source={Scopus},
}
